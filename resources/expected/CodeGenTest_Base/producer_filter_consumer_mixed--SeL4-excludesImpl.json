{
  "type" : "TestResult",
  "map" : {
    "type" : "Map",
    "entries" : [
      [
        "slang\/src\/main\/data\/pfc_project\/Base_Types.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage pfc_project\n\nimport org.sireum._\nimport org.sireum.S8._\nimport org.sireum.S16._\nimport org.sireum.S32._\nimport org.sireum.S64._\nimport org.sireum.U8._\nimport org.sireum.U16._\nimport org.sireum.U32._\nimport org.sireum.U64._\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\nobject Base_Types {\n\n  type Boolean = B\n\n  type Integer = Z\n\n  type Integer_8 = S8\n  type Integer_16 = S16\n  type Integer_32 = S32\n  type Integer_64 = S64\n\n  type Unsigned_8 = U8\n  type Unsigned_16 = U16\n  type Unsigned_32 = U32\n  type Unsigned_64 = U64\n\n  \/\/ TODO: Base_Types::Natural\n\n  type Float = R\n  type Float_32 = F32\n  type Float_64 = F64\n\n  type Character = C\n  type String = org.sireum.String\n\n  type Bits = org.sireum.ISZ[B]\n\n  @datatype class Boolean_Payload(value: B) extends art.DataContent\n\n  @datatype class Integer_Payload(value: Z) extends art.DataContent\n\n  @datatype class Integer_8_Payload(value: S8) extends art.DataContent\n  @datatype class Integer_16_Payload(value: S16) extends art.DataContent\n  @datatype class Integer_32_Payload(value: S32) extends art.DataContent\n  @datatype class Integer_64_Payload(value: S64) extends art.DataContent\n\n  @datatype class Unsigned_8_Payload(value: U8) extends art.DataContent\n  @datatype class Unsigned_16_Payload(value: U16) extends art.DataContent\n  @datatype class Unsigned_32_Payload(value: U32) extends art.DataContent\n  @datatype class Unsigned_64_Payload(value: U64) extends art.DataContent\n\n  @datatype class Float_Payload(value: R) extends art.DataContent\n  @datatype class Float_32_Payload(value: F32) extends art.DataContent\n  @datatype class Float_64_Payload(value: F64) extends art.DataContent\n\n  @datatype class Character_Payload(value: C) extends art.DataContent\n  @datatype class String_Payload(value: String) extends art.DataContent\n\n  @datatype class Bits_Payload(value: ISZ[B]) extends art.DataContent\n\n  def Boolean_example(): Boolean = {\n    Contract(Ensures(Res == F))\n    return F\n  }\n\n\n  def Integer_example(): Integer = {\n    Contract(Ensures(Res == z\"0\"))\n    return z\"0\"\n  }\n\n  def Integer_8_example(): Integer_8 = {\n    Contract(Ensures(Res == s8\"0\"))\n    return s8\"0\"\n  }\n\n  def Integer_16_example(): Integer_16 = {\n    Contract(Ensures(Res == s16\"0\"))\n    return s16\"0\"\n  }\n\n  def Integer_32_example(): Integer_32 = {\n    Contract(Ensures(Res == s32\"0\"))\n    return s32\"0\"\n  }\n\n  def Integer_64_example(): Integer_64 = {\n    Contract(Ensures(Res == s64\"0\"))\n    return s64\"0\"\n  }\n\n\n  def Unsigned_8_example(): Unsigned_8 = {\n    Contract(Ensures(Res == u8\"0\"))\n    return u8\"0\"\n  }\n\n  def Unsigned_16_example(): Unsigned_16 = {\n    Contract(Ensures(Res == u16\"0\"))\n    return u16\"0\"\n  }\n\n  def Unsigned_32_example(): Unsigned_32 = {\n    Contract(Ensures(Res == u32\"0\"))\n    return u32\"0\"\n  }\n\n  def Unsigned_64_example(): Unsigned_64 = {\n    Contract(Ensures(Res == u64\"0\"))\n    return u64\"0\"\n  }\n\n\n  def Float_example(): Float = {\n    Contract(Ensures(Res == r\"0\"))\n    return r\"0\"\n  }\n\n  def Float_32_example(): Float_32 = {\n    Contract(Ensures(Res == f32\"0\"))\n    return f32\"0\"\n  }\n\n  def Float_64_example(): Float_64 = {\n    Contract(Ensures(Res == f64\"0\"))\n    return f64\"0\"\n  }\n\n\n  def Character_example(): Character = {\n    Contract(Ensures(Res == ' '))\n    return ' '\n  }\n\n  def String_example(): String = {\n    Contract(Ensures(Res == \"\"))\n    return \"\"\n  }\n\n\n  def Bits_example(): Bits = {\n    Contract(Ensures(Res == ISZ[B]()))\n    return ISZ[B]()\n  }\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : true
        }
      ],
      [
        "slang\/src\/main\/architecture\/pfc_project\/Arch.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage pfc_project\n\nimport org.sireum._\nimport art._\nimport art.PortMode._\nimport art.DispatchPropertyProtocol._\nimport art.Art.BridgeId._\nimport art.Art.PortId._\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\nobject Arch {\n  val PFC_Sys_Impl_Instance_proc_producer : pfc_project.PFC.Producer_proc_producer_Bridge = {\n    val to_filter_data = Port[Base_Types.Bits] (id = portId\"0\", name = \"PFC_Sys_Impl_Instance_proc_producer_to_filter_data\", mode = DataOut)\n    val to_filter_event = Port[art.Empty] (id = portId\"1\", name = \"PFC_Sys_Impl_Instance_proc_producer_to_filter_event\", mode = EventOut)\n\n    pfc_project.PFC.Producer_proc_producer_Bridge(\n      id = bridgeId\"0\",\n      name = \"PFC_Sys_Impl_Instance_proc_producer\",\n      dispatchProtocol = Periodic(period = 1000),\n      dispatchTriggers = None(),\n\n      to_filter_data = to_filter_data,\n      to_filter_event = to_filter_event\n    )\n  }\n  val PFC_Sys_Impl_Instance_proc_filter : pfc_project.PFC.Filter_proc_filter_Bridge = {\n    val from_producer_data = Port[Base_Types.Bits] (id = portId\"2\", name = \"PFC_Sys_Impl_Instance_proc_filter_from_producer_data\", mode = DataIn)\n    val to_consumer = Port[Base_Types.Bits] (id = portId\"3\", name = \"PFC_Sys_Impl_Instance_proc_filter_to_consumer\", mode = EventOut)\n    val from_producer_event = Port[art.Empty] (id = portId\"4\", name = \"PFC_Sys_Impl_Instance_proc_filter_from_producer_event\", mode = EventIn)\n\n    pfc_project.PFC.Filter_proc_filter_Bridge(\n      id = bridgeId\"1\",\n      name = \"PFC_Sys_Impl_Instance_proc_filter\",\n      dispatchProtocol = Periodic(period = 1000),\n      dispatchTriggers = None(),\n\n      from_producer_data = from_producer_data,\n      to_consumer = to_consumer,\n      from_producer_event = from_producer_event\n    )\n  }\n  val PFC_Sys_Impl_Instance_proc_consumer : pfc_project.PFC.Consumer_proc_consumer_Bridge = {\n    val from_filter = Port[Base_Types.Bits] (id = portId\"5\", name = \"PFC_Sys_Impl_Instance_proc_consumer_from_filter\", mode = EventIn)\n\n    pfc_project.PFC.Consumer_proc_consumer_Bridge(\n      id = bridgeId\"2\",\n      name = \"PFC_Sys_Impl_Instance_proc_consumer\",\n      dispatchProtocol = Sporadic(min = 1),\n      dispatchTriggers = None(),\n\n      from_filter = from_filter\n    )\n  }\n\n  val ad : ArchitectureDescription = {\n    TranspilerUtil.touch()\n\n    ArchitectureDescription(\n      components = IS[Art.BridgeId, Bridge] (PFC_Sys_Impl_Instance_proc_producer, PFC_Sys_Impl_Instance_proc_filter, PFC_Sys_Impl_Instance_proc_consumer),\n\n      connections = IS[Art.ConnectionId, UConnection] (Connection(from = PFC_Sys_Impl_Instance_proc_producer.to_filter_data, to = PFC_Sys_Impl_Instance_proc_filter.from_producer_data),\n                                                       Connection(from = PFC_Sys_Impl_Instance_proc_producer.to_filter_event, to = PFC_Sys_Impl_Instance_proc_filter.from_producer_event),\n                                                       Connection(from = PFC_Sys_Impl_Instance_proc_filter.to_consumer, to = PFC_Sys_Impl_Instance_proc_consumer.from_filter))\n    )\n  }\n}\n\nobject TranspilerUtil {\n  def touch(): Unit = {\n    if(F) {\n      TranspilerToucher.touch()\n\n      \/\/ add types used in Platform.receive and Platform.receiveAsync\n      val mbox2Boolean_Payload: MBox2[Art.PortId, DataContent] = MBox2(portId\"0\", Base_Types.Boolean_Payload(T))\n      val mbox2OptionDataContent: MBox2[Art.PortId, Option[DataContent]] = MBox2(portId\"0\", None())\n\n      \/\/ touch process\/thread timing properties\n      println(Schedulers.PFC_Sys_Impl_Instance_proc_producer_timingProperties)\n      println(Schedulers.PFC_Sys_Impl_Instance_proc_filter_timingProperties)\n      println(Schedulers.PFC_Sys_Impl_Instance_proc_consumer_timingProperties)\n\n      \/\/ touch each payload\/type in case some are only used as a field in a record\n      def printDataContent(a: art.DataContent): Unit = { println(s\"${a}\") }\n\n      printDataContent(Base_Types.Bits_Payload(Base_Types.Bits_example()))\n      printDataContent(art.Empty())\n\n      {\n        pfc_project.PFC.Producer_proc_producer_Bridge.c_initialization_api.get.logInfo(\"\")\n        pfc_project.PFC.Producer_proc_producer_Bridge.c_initialization_api.get.logDebug(\"\")\n        pfc_project.PFC.Producer_proc_producer_Bridge.c_initialization_api.get.logError(\"\")\n        pfc_project.PFC.Producer_proc_producer_Bridge.c_operational_api.get.logInfo(\"\")\n        pfc_project.PFC.Producer_proc_producer_Bridge.c_operational_api.get.logDebug(\"\")\n        pfc_project.PFC.Producer_proc_producer_Bridge.c_operational_api.get.logError(\"\")\n        pfc_project.PFC.Producer_proc_producer_Bridge.c_initialization_api.get.put_to_filter_data(Base_Types.Bits_example())\n        pfc_project.PFC.Producer_proc_producer_Bridge.c_operational_api.get.put_to_filter_data(Base_Types.Bits_example())\n        pfc_project.PFC.Producer_proc_producer_Bridge.c_initialization_api.get.put_to_filter_event()\n        pfc_project.PFC.Producer_proc_producer_Bridge.c_operational_api.get.put_to_filter_event()\n      }\n      {\n        pfc_project.PFC.Filter_proc_filter_Bridge.c_initialization_api.get.logInfo(\"\")\n        pfc_project.PFC.Filter_proc_filter_Bridge.c_initialization_api.get.logDebug(\"\")\n        pfc_project.PFC.Filter_proc_filter_Bridge.c_initialization_api.get.logError(\"\")\n        pfc_project.PFC.Filter_proc_filter_Bridge.c_operational_api.get.logInfo(\"\")\n        pfc_project.PFC.Filter_proc_filter_Bridge.c_operational_api.get.logDebug(\"\")\n        pfc_project.PFC.Filter_proc_filter_Bridge.c_operational_api.get.logError(\"\")\n        val apiUsage_from_producer_data: Option[Base_Types.Bits] = pfc_project.PFC.Filter_proc_filter_Bridge.c_operational_api.get.get_from_producer_data()\n        pfc_project.PFC.Filter_proc_filter_Bridge.c_initialization_api.get.put_to_consumer(Base_Types.Bits_example())\n        pfc_project.PFC.Filter_proc_filter_Bridge.c_operational_api.get.put_to_consumer(Base_Types.Bits_example())\n        val apiUsage_from_producer_event: Option[art.Empty] = pfc_project.PFC.Filter_proc_filter_Bridge.c_operational_api.get.get_from_producer_event()\n      }\n      {\n        pfc_project.PFC.Consumer_proc_consumer_Bridge.c_initialization_api.get.logInfo(\"\")\n        pfc_project.PFC.Consumer_proc_consumer_Bridge.c_initialization_api.get.logDebug(\"\")\n        pfc_project.PFC.Consumer_proc_consumer_Bridge.c_initialization_api.get.logError(\"\")\n        pfc_project.PFC.Consumer_proc_consumer_Bridge.c_operational_api.get.logInfo(\"\")\n        pfc_project.PFC.Consumer_proc_consumer_Bridge.c_operational_api.get.logDebug(\"\")\n        pfc_project.PFC.Consumer_proc_consumer_Bridge.c_operational_api.get.logError(\"\")\n        val apiUsage_from_filter: Option[Base_Types.Bits] = pfc_project.PFC.Consumer_proc_consumer_Bridge.c_operational_api.get.get_from_filter()\n      }\n    }\n  }\n}\n\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/architecture\/pfc_project\/Demo.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage pfc_project\n\nimport org.sireum._\nimport art.scheduling.Scheduler\n\n\/\/ This file will not be overwritten so is safe to edit\n\nobject Demo extends App {\n\n  \/** @return the scheduler to use for JVM based simulation as well as the 'default' scheduler\n    *         that will be used when taking this program down to C\/Linux.  Refer to\n    *         'bin\/run.sh -h' if you want to use a specific scheduler for C.  If the scheduler\n    *         accepts a schedule and you want to provide that in C then just pass None()\n    *\n    *         If you want to use the legacy scheduler for C then you must use\n    *           bin\/transpile.cmd --legacy\n    *           bin\/compile.cmd\n    *           bin\/run.sh --legacy\n    *\/\n  def defaultScheduler(): Scheduler = {\n    return Schedulers.getRoundRobinScheduler(None())\n  }\n\n  def main(args: ISZ[String]): Z = {\n    Cli(' ').parseRun(args, 0) match {\n      case Some(o: Cli.RunOption) =>\n        val scheduler: Scheduler = o.scheduler match {\n          case Cli.RunChoice.Default => defaultScheduler()\n          case Cli.RunChoice.RoundRobin => Schedulers.getRoundRobinScheduler(None())\n          case Cli.RunChoice.Static => Schedulers.getStaticSchedulerH(MNone())\n          case Cli.RunChoice.Legacy => Schedulers.getLegacyScheduler()\n        }\n\n        Platform.setup()\n\n        art.Art.run(Arch.ad, scheduler)\n\n        Platform.tearDown()\n      case Some(o: Cli.HelpOption) =>\n      case _ => return 1\n    }\n    return 0\n  }\n}\n\nobject Cli {\n\n  @datatype trait RunTopOption\n\n  @datatype class HelpOption extends RunTopOption\n\n  @enum object RunChoice {\n    'Default\n    'RoundRobin\n    'Static\n    'Legacy\n  }\n\n  @datatype class RunOption(\n                             val help: String,\n                             val args: ISZ[String],\n                             val scheduler: RunChoice.Type\n                           ) extends RunTopOption\n}\n\nimport Cli._\n\n@record class Cli(val pathSep: C) {\n\n  def parseRunChoiceH(arg: String): Option[RunChoice.Type] = {\n    arg match {\n      case \"default\" => return Some(RunChoice.Default)\n      case \"roundRobin\" => return Some(RunChoice.RoundRobin)\n      case \"static\" => return Some(RunChoice.Static)\n      case \"legacy\" => return Some(RunChoice.Legacy)\n      case s =>\n        eprintln(s\"Expecting one of the following: { default, roundRobin, static, legacy }, but found '$s'.\")\n        return None()\n    }\n  }\n\n  def parseRunChoice(args: ISZ[String], i: Z): Option[RunChoice.Type] = {\n    if (i >= args.size) {\n      eprintln(\"Expecting one of the following: { default, roundRobin, static, legacy }, but none found.\")\n      return None()\n    }\n    val r = parseRunChoiceH(args(i))\n    return r\n  }\n\n  def parseRun(args: ISZ[String], i: Z): Option[RunTopOption] = {\n\n    def help(): Unit = {\n      println(\"Run Slang Embedded Program\")\n      println()\n      println(\"Usage: <option>*\")\n      println()\n      println(\"Available Options:\")\n      println(\"-s, --scheduler          The scheduler to use.  See Demo.scala for information\")\n      println(\"                           on 'default' (expects one of { default, roundRobin,\")\n      println(\"                           static, legacy }; default: default)\")\n      println(\"-h, --help               Display this information\")\n    }\n\n    var scheduler: RunChoice.Type = RunChoice.Default\n    var j = i\n    var isOption = T\n    while (j < args.size && isOption) {\n      var arg = args(j)\n      if (arg == \"-h\" || arg == \"--help\") {\n        help()\n        return Some(HelpOption())\n      } else if (arg == \"-s\" || arg == \"--scheduler\") {\n        val o: Option[RunChoice.Type] = parseRunChoice(args, j + 1)\n        o match {\n          case Some(v) => scheduler = v\n          case _ => return None()\n        }\n      } else {\n        eprintln(s\"Unrecognized option '$arg'.\")\n        return None()\n      }\n      j = j + 2\n    }\n\n    return Some(RunOption(\"\", args, scheduler))\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/architecture\/pfc_project\/Schedulers.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\npackage pfc_project\n\nimport org.sireum._\nimport art.Art\nimport art.scheduling.legacy.Legacy\nimport art.scheduling.roundrobin.RoundRobin\nimport art.scheduling.static.Schedule.{DSchedule, DScheduleSpec}\nimport art.scheduling.static._\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\n@datatype class ProcessorTimingProperties(val clockPeriod: Option[Z],\n                                          val framePeriod: Option[Z],\n                                          val maxDomain: Option[Z],\n                                          val slotTime: Option[Z])\n\n@datatype class ThreadTimingProperties(val domain: Option[Z],\n                                       val computeExecutionTime: Option[(Z, Z)])\n\nobject Schedulers {\n\n  val threadNickNames: Map[String, Art.BridgeId] = Map(\n    ISZ(\n      Arch.PFC_Sys_Impl_Instance_proc_producer.name ~> Arch.PFC_Sys_Impl_Instance_proc_producer.id,\n      Arch.PFC_Sys_Impl_Instance_proc_filter.name ~> Arch.PFC_Sys_Impl_Instance_proc_filter.id,\n      Arch.PFC_Sys_Impl_Instance_proc_consumer.name ~> Arch.PFC_Sys_Impl_Instance_proc_consumer.id)\n  )\n\n  val revThreadNickNames: Map[Art.BridgeId, String] = Map.empty[Art.BridgeId, String] ++ (for (e <- threadNickNames.entries) yield e._2 ~> e._1)\n\n\n  val PFC_Sys_Impl_Instance_proc_producer_timingProperties: ThreadTimingProperties = ThreadTimingProperties(\n    computeExecutionTime = None(),\n    domain = None())\n\n  val PFC_Sys_Impl_Instance_proc_filter_timingProperties: ThreadTimingProperties = ThreadTimingProperties(\n    computeExecutionTime = None(),\n    domain = None())\n\n  val PFC_Sys_Impl_Instance_proc_consumer_timingProperties: ThreadTimingProperties = ThreadTimingProperties(\n    computeExecutionTime = None(),\n    domain = None())\n\n\n  \/**********************************************************************\n   * Round Robin Scheduler\n   *********************************************************************\/\n\n  \/\/ roundRobinSchedule represents the component dispatch order\n  val roundRobinSchedule: ISZ[Art.BridgeId] = {\n    \/\/ convert IS[Art.BridgeId, art.Bridge] to an IS[Z, Art.BridgeId] to allow bridges to be dispatched\n    \/\/ multiple times during a hyper-period\n    var ret: ISZ[Art.BridgeId] = ISZ()\n    for (e <- Arch.ad.components) {\n      ret = ret :+ e.id\n    }\n    ret\n  }\n\n  def getRoundRobinScheduler(schedule: Option[ISZ[Art.BridgeId]]): RoundRobin = {\n    if (roundRobinSchedule.isEmpty) {} \/\/ line needed for transpiler; do not remove\n    schedule match {\n      case Some(s) => return RoundRobin(s)\n      case _ => return RoundRobin(ScheduleProviderI.getRoundRobinOrder())\n    }\n  }\n\n  \/**********************************************************************\n   * Static Scheduler\n   *********************************************************************\/\n\n  val framePeriod: Z = 1000\n  val numComponents: Z = Arch.ad.components.size\n  val maxExecutionTime: Z = numComponents \/ framePeriod\n\n  \/\/ defaultStaticSchedule represents the component dispatch order\n  val defaultStaticSchedule: DScheduleSpec = DScheduleSpec(0, 0, DSchedule(ISZ(\n    Schedule.Slot(0, maxExecutionTime),\n    Schedule.Slot(1, maxExecutionTime),\n    Schedule.Slot(2, maxExecutionTime)\n  )))\n\n  val defaultDomainToBridgeIdMap: ISZ[Art.BridgeId] = ISZ(\n    \/* domain 0 *\/ Arch.PFC_Sys_Impl_Instance_proc_producer.id,\n    \/* domain 1 *\/ Arch.PFC_Sys_Impl_Instance_proc_filter.id,\n    \/* domain 2 *\/ Arch.PFC_Sys_Impl_Instance_proc_consumer.id\n  )\n\n  def getStaticSchedulerH(userProvided: MOption[(DScheduleSpec, ISZ[Art.BridgeId], Map[String, Art.BridgeId], CommandProvider)]): StaticScheduler = {\n    if (defaultStaticSchedule.schedule.slots.isEmpty && defaultDomainToBridgeIdMap.isEmpty && threadNickNames.isEmpty) {} \/\/ line needed for transpiler; do not remove\n    userProvided match {\n      case MSome((schedule_, domainToBridgeIdMap_, threadNickNames_, commandProvider)) =>\n        return getStaticScheduler(schedule_, domainToBridgeIdMap_, threadNickNames_, commandProvider)\n      case _ =>\n        return getStaticScheduler(\n          ScheduleProviderI.getStaticSchedule(),\n          \/\/ TODO: get the following from extension so they can be customized via C\n          defaultDomainToBridgeIdMap,\n          threadNickNames,\n          DefaultCommandProvider())\n    }\n  }\n\n  def getStaticScheduler(schedule: DScheduleSpec,\n                         domainToBridgeIdMap: ISZ[Art.BridgeId],\n                         threadNickNames: Map[String, Art.BridgeId],\n                         commandProvider: CommandProvider): StaticScheduler = {\n    return StaticScheduler(schedule, Arch.ad.components, domainToBridgeIdMap, threadNickNames,\n      if (commandProvider.isInstanceOf[InfoCommandProvider])\n        commandProvider.asInstanceOf[InfoCommandProvider].init(\n          threadNickNames,\n          schedule.schedule.slots.size,\n          domainToBridgeIdMap\n        )\n      else commandProvider)\n  }\n\n\n  \/**********************************************************************\n   * Legacy Scheduler\n   *********************************************************************\/\n\n  def getLegacyScheduler(): Legacy = {\n    return Legacy(Arch.ad.components)\n  }\n}\n\n\/\/ the purpose of this extension is to allow users to provide custom schedules\n\/\/ at the C level after transpiling\n@ext(name = \"ScheduleProvider\") object ScheduleProviderI {\n  def getRoundRobinOrder(): ISZ[Art.BridgeId] = $\n\n  def getStaticSchedule(): DScheduleSpec = $\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/architecture\/pfc_project\/ScheduleProvider.scala",
        {
          "type" : "ITestResource",
          "content" : "package pfc_project\n\nimport org.sireum._\nimport art.Art\nimport art.scheduling.static.Schedule.DScheduleSpec\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\nobject ScheduleProvider {\n\n  def getRoundRobinOrder(): ISZ[Art.BridgeId] = {\n    return Schedulers.roundRobinSchedule\n  }\n\n  def getStaticSchedule(): DScheduleSpec = {\n    return Schedulers.defaultStaticSchedule\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/inspector\/pfc_project\/InspectorDemo.scala",
        {
          "type" : "ITestResource",
          "content" : "package pfc_project\n\nimport art.{ArchitectureDescription, Bridge, DataContent, UPort}\nimport org.reactivestreams.Publisher\nimport org.sireum.hamr.inspector.common.{Filter, Injection, InspectionBlueprint, Msg, Rule}\nimport org.sireum.hamr.inspector.capabilities.InspectorCapabilitiesLauncher\nimport org.sireum.hamr.inspector.gui.InspectorGUILauncher\nimport org.sireum.hamr.inspector.stream.Flux\n\nobject InspectorDemo extends App {\n\n  {\n    InspectorCapabilitiesLauncher.run(Blueprint)\n\n    val filters: Set[Filter] = Set(NoFilter, EvensOnly)\n    val rules: Set[Rule] = Set(Require100OrMore)\n    val injections: Set[Injection] = Set()\n\n    InspectorGUILauncher.run(Blueprint, filters, rules, injections, args)\n  }\n\n  object Blueprint extends InspectionBlueprint {\n    override def ad(): ArchitectureDescription = Arch.ad\n    override def serializer(): DataContent => String = JSON.from_artDataContent(_, true).value\n    override def deserializer(): String => DataContent = JSON.to_artDataContent(_).left\n  }\n\n  object NoFilter extends Filter {\n    override def filter(in: Flux[Msg]): Publisher[Msg] = in\n  }\n\n  object EvensOnly extends Filter {\n    override def filter(in: Flux[Msg]): Publisher[Msg] = in.filter(_.sequence % 2 == 0)\n  }\n\n  object Require100OrMore extends Rule {\n    override def rule(in: Flux[Msg]): Publisher[_] = in.skip(99).next().single()\n  }\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/test\/util\/pfc_project\/PFC\/Producer_proc_producer_TestApi.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage pfc_project.PFC\n\nimport org.sireum._\nimport art.Art\nimport pfc_project._\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n@msig trait Producer_proc_producer_TestApi {\n\n  def BeforeEntrypoint(): Unit = {\n    Art.initTest(Arch.PFC_Sys_Impl_Instance_proc_producer)\n  }\n\n  def AfterEntrypoint(): Unit = {\n    Art.finalizeTest(Arch.PFC_Sys_Impl_Instance_proc_producer)\n  }\n\n  def testCompute(): Unit = {\n    Art.manuallyClearOutput()\n    Art.testCompute(Arch.PFC_Sys_Impl_Instance_proc_producer)\n  }\n\n  def testInitialise(): Unit = {\n    Art.manuallyClearOutput()\n    Art.testInitialise(Arch.PFC_Sys_Impl_Instance_proc_producer)\n  }\n\n  \/** helper function to check Producer_proc_producer's\n   * output ports.  Use named arguments to check subsets of the output ports.\n   * @param to_filter_data method that will be called with the value of the outgoing data\n   *        port 'to_filter_data'.\n   * @param to_filter_event method that will be called with the number of events to be sent\n   *        on the outgoing event port 'to_filter_event'.\n   *\/\n  def check_concrete_output(to_filter_data: Base_Types.Bits => B,\n                            to_filter_event: Z => B): Unit = {\n    var testFailures: ISZ[ST] = ISZ()\n\n    val to_filter_dataValue: Base_Types.Bits = get_to_filter_data().get\n    if(!to_filter_data(to_filter_dataValue)) {\n      testFailures = testFailures :+ st\"'to_filter_data' did not match expected: value of the outgoing data port is ${to_filter_dataValue}\"\n    }\n    \/\/ TODO: event port getter should return the number of events in\n    \/\/       the output queue when queue sizes > 1 support is added to ART\n    val to_filter_eventValue: Z = if(get_to_filter_event().nonEmpty) z\"1\" else z\"0\"\n    if(!to_filter_event(to_filter_eventValue)) {\n      testFailures = testFailures :+ st\"'to_filter_event' did not match expected: ${to_filter_eventValue} events were in the outgoing event queue\"\n    }\n\n    assert(testFailures.isEmpty, st\"${(testFailures, \"\\n\")}\".render)\n  }\n\n\n  \/\/ getter for out DataPort\n  def get_to_filter_data(): Option[Base_Types.Bits] = {\n    val value: Option[Base_Types.Bits] = get_to_filter_data_payload() match {\n      case Some(Base_Types.Bits_Payload(v)) => Some(v)\n      case Some(v) => halt(s\"Unexpected payload on port to_filter_data.  Expecting 'Base_Types.Bits_Payload' but received ${v}\")\n      case _ => None[Base_Types.Bits]()\n    }\n    return value\n  }\n\n  \/\/ payload getter for out DataPort\n  def get_to_filter_data_payload(): Option[Base_Types.Bits_Payload] = {\n    return Art.observeOutInfrastructurePort(Arch.PFC_Sys_Impl_Instance_proc_producer.initialization_api.to_filter_data_Id).asInstanceOf[Option[Base_Types.Bits_Payload]]\n  }\n\n  \/\/ getter for out EventPort\n  def get_to_filter_event(): Option[art.Empty] = {\n    val value: Option[art.Empty] = get_to_filter_event_payload() match {\n      case Some(art.Empty()) => Some(art.Empty())\n      case Some(v) => halt(s\"Unexpected payload on port to_filter_event.  Expecting 'art.Empty' but received ${v}\")\n      case _ => None[art.Empty]()\n    }\n    return value\n  }\n\n  \/\/ payload getter for out EventPort\n  def get_to_filter_event_payload(): Option[art.Empty] = {\n    return Art.observeOutInfrastructurePort(Arch.PFC_Sys_Impl_Instance_proc_producer.initialization_api.to_filter_event_Id).asInstanceOf[Option[art.Empty]]\n  }\n\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/test\/util\/pfc_project\/PFC\/Producer_proc_producer_ScalaTest.scala",
        {
          "type" : "ITestResource",
          "content" : "package pfc_project.PFC\n\nimport org.scalatest.{BeforeAndAfterEach, OneInstancePerTest}\nimport org.scalatest.funsuite.AnyFunSuite\nimport org.sireum.$internal.MutableMarker\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\nabstract class Producer_proc_producer_ScalaTest extends\n  AnyFunSuite with OneInstancePerTest with BeforeAndAfterEach with\n  Producer_proc_producer_TestApi {\n\n  var clonable: Boolean = true\n  var owned: Boolean = false\n\n  override def string: org.sireum.String = {\n    this.toString()\n  }\n\n  override def $clonable: Boolean = {\n    return clonable\n  }\n\n  override def $clonable_=(b: Boolean): MutableMarker = {\n    clonable = b\n    return this\n  }\n\n  override def $owned: Boolean = {\n    return owned\n  }\n\n  override def $owned_=(b: Boolean): MutableMarker = {\n    owned = b\n    return this\n  }\n\n  override def $clone: MutableMarker = {\n    \/\/ not expecting users to want to clone realizations of this abstract class\n    return this\n  }\n\n  override def beforeEach(): Unit = {\n    BeforeEntrypoint()\n  }\n\n  override def afterEach(): Unit = {\n    AfterEntrypoint()\n  }\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/test\/bridge\/pfc_project\/PFC\/Producer_proc_producer_Test.scala",
        {
          "type" : "ITestResource",
          "content" : "package pfc_project.PFC\n\nimport org.sireum._\nimport pfc_project.PFC._\n\n\/\/ This file will not be overwritten so is safe to edit\nclass Producer_proc_producer_Test extends Producer_proc_producer_ScalaTest {\n\n  test(\"Example Unit Test for Initialise Entry Point\"){\n    \/\/ Initialise Entry Point doesn't read input port values, so just proceed with\n    \/\/ launching the entry point code\n    testInitialise()\n    \/\/ use get_XXX methods and check_concrete_output() from test\/util\/..\/YYY_TestApi\n    \/\/ retrieve values from output ports and check against expected results\n  }\n\n  test(\"Example Unit Test for Compute Entry Point\"){\n    \/\/ use put_XXX methods from test\/util\/..\/YYY_TestApi to seed input ports with values\n    testCompute()\n    \/\/ use get_XXX methods and check_concrete_output() from test\/util\/..\/YYY_TestApi\n    \/\/ retrieve values from output ports and check against expected results\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/bridge\/pfc_project\/PFC\/Producer_proc_producer_Bridge.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage pfc_project.PFC\n\nimport org.sireum._\nimport art._\nimport pfc_project._\nimport pfc_project.PFC.{Producer_proc_producer => component}\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\n@datatype class Producer_proc_producer_Bridge(\n  val id: Art.BridgeId,\n  val name: String,\n  val dispatchProtocol: DispatchPropertyProtocol,\n  val dispatchTriggers: Option[ISZ[Art.PortId]],\n\n  to_filter_data: Port[Base_Types.Bits],\n  to_filter_event: Port[art.Empty]\n  ) extends Bridge {\n\n  val ports : Bridge.Ports = Bridge.Ports(\n    dataIns = ISZ[art.UPort](),\n\n    dataOuts = ISZ[art.UPort](to_filter_data),\n\n    eventIns = ISZ[art.UPort](),\n\n    eventOuts = ISZ[art.UPort](to_filter_event)\n  )\n\n  val initialization_api : Producer_Initialization_Api = {\n    val api = Producer_Initialization_Api(\n      id,\n      to_filter_data.id,\n      to_filter_event.id\n    )\n    Producer_proc_producer_Bridge.c_initialization_api = Some(api)\n    api\n  }\n\n  val operational_api : Producer_Operational_Api = {\n    val api = Producer_Operational_Api(\n      id,\n      to_filter_data.id,\n      to_filter_event.id\n    )\n    Producer_proc_producer_Bridge.c_operational_api = Some(api)\n    api\n  }\n\n  val entryPoints : Bridge.EntryPoints =\n    Producer_proc_producer_Bridge.EntryPoints(\n      id,\n\n      to_filter_data.id,\n      to_filter_event.id,\n\n      dispatchTriggers,\n\n      initialization_api,\n      operational_api)\n}\n\nobject Producer_proc_producer_Bridge {\n\n  var c_initialization_api: Option[Producer_Initialization_Api] = None()\n  var c_operational_api: Option[Producer_Operational_Api] = None()\n\n  @datatype class EntryPoints(\n    Producer_proc_producer_BridgeId : Art.BridgeId,\n    to_filter_data_Id : Art.PortId,\n    to_filter_event_Id : Art.PortId,\n    dispatchTriggers : Option[ISZ[Art.PortId]],\n    initialization_api: Producer_Initialization_Api,\n    operational_api: Producer_Operational_Api) extends Bridge.EntryPoints {\n\n    val dataInPortIds: ISZ[Art.PortId] = IS()\n\n    val eventInPortIds: ISZ[Art.PortId] = IS()\n\n    val dataOutPortIds: ISZ[Art.PortId] = IS(to_filter_data_Id)\n\n    val eventOutPortIds: ISZ[Art.PortId] = IS(to_filter_event_Id)\n\n    def initialise(): Unit = {\n      \/\/ implement the following method in 'component':  def initialise(api: Producer_Initialization_Api): Unit = {}\n      component.initialise(initialization_api)\n      Art.sendOutput(eventOutPortIds, dataOutPortIds)\n    }\n\n    def compute(): Unit = {\n      Art.receiveInput(eventInPortIds, dataInPortIds)\n\n      \/\/ implement the following in 'component':  def timeTriggered(api: Producer_Operational_Api): Unit = {}\n      component.timeTriggered(operational_api)\n\n      Art.sendOutput(eventOutPortIds, dataOutPortIds)\n    }\n\n    def activate(): Unit = {\n      \/\/ implement the following method in 'component':  def activate(api: Producer_Operational_Api): Unit = {}\n      component.activate(operational_api)\n    }\n\n    def deactivate(): Unit = {\n      \/\/ implement the following method in 'component':  def deactivate(api: Producer_Operational_Api): Unit = {}\n      component.deactivate(operational_api)\n    }\n\n    def finalise(): Unit = {\n      \/\/ implement the following method in 'component':  def finalise(api: Producer_Operational_Api): Unit = {}\n      component.finalise(operational_api)\n    }\n\n    def recover(): Unit = {\n      \/\/ implement the following method in 'component':  def recover(api: Producer_Operational_Api): Unit = {}\n      component.recover(operational_api)\n    }\n\n    override\n    def testInitialise(): Unit = {\n      \/\/ implement the following method in 'component':  def initialise(api: Producer_Initialization_Api): Unit = {}\n      component.initialise(initialization_api)\n      Art.releaseOutput(eventOutPortIds, dataOutPortIds)\n    }\n\n    override\n    def testCompute(): Unit = {\n      Art.receiveInput(eventInPortIds, dataInPortIds)\n\n      \/\/ implement the following in 'component':  def timeTriggered(api: Producer_Operational_Api): Unit = {}\n      component.timeTriggered(operational_api)\n\n      Art.releaseOutput(eventOutPortIds, dataOutPortIds)\n    }\n  }\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/bridge\/pfc_project\/PFC\/Producer_Api.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage pfc_project.PFC\n\nimport org.sireum._\nimport art._\nimport pfc_project._\n\n@sig trait Producer_Api {\n  def id: Art.BridgeId\n  def to_filter_data_Id : Art.PortId\n  def to_filter_event_Id : Art.PortId\n\n  \/\/ Logika spec var representing port state for outgoing data port\n  @spec var to_filter_data: Base_Types.Bits = $\n\n  def put_to_filter_data(value : Base_Types.Bits) : Unit = {\n    Contract(\n      Modifies(to_filter_data),\n      Ensures(\n        to_filter_data == value\n      )\n    )\n    Spec {\n      to_filter_data = value\n    }\n\n    Art.putValue(to_filter_data_Id, Base_Types.Bits_Payload(value))\n  }\n\n  \/\/ Logika spec var representing port state for outgoing event port\n  @spec var to_filter_event: Option[art.Empty] = $\n\n  def put_to_filter_event() : Unit = {\n    Contract(\n      Modifies(to_filter_event),\n      Ensures(\n        to_filter_event == Some(Empty())\n      )\n    )\n    Spec {\n      to_filter_event = Some(Empty())\n    }\n\n    Art.putValue(to_filter_event_Id, art.Empty())\n  }\n\n  def logInfo(msg: String): Unit = {\n    Art.logInfo(id, msg)\n  }\n\n  def logDebug(msg: String): Unit = {\n    Art.logDebug(id, msg)\n  }\n\n  def logError(msg: String): Unit = {\n    Art.logError(id, msg)\n  }\n}\n\n@datatype class Producer_Initialization_Api (\n  val id: Art.BridgeId,\n  val to_filter_data_Id : Art.PortId,\n  val to_filter_event_Id : Art.PortId) extends Producer_Api\n\n@datatype class Producer_Operational_Api (\n  val id: Art.BridgeId,\n  val to_filter_data_Id : Art.PortId,\n  val to_filter_event_Id : Art.PortId) extends Producer_Api {\n\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/component\/pfc_project\/PFC\/Producer_proc_producer.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage pfc_project.PFC\n\nimport org.sireum._\nimport pfc_project._\n\n\/\/ This file will not be overwritten so is safe to edit\nobject Producer_proc_producer {\n\n  def initialise(api: Producer_Initialization_Api): Unit = { }\n\n  def timeTriggered(api: Producer_Operational_Api): Unit = { }\n\n  def activate(api: Producer_Operational_Api): Unit = { }\n\n  def deactivate(api: Producer_Operational_Api): Unit = { }\n\n  def finalise(api: Producer_Operational_Api): Unit = { }\n\n  def recover(api: Producer_Operational_Api): Unit = { }\n}\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/test\/util\/pfc_project\/PFC\/Filter_proc_filter_TestApi.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage pfc_project.PFC\n\nimport org.sireum._\nimport art.Art\nimport pfc_project._\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n@msig trait Filter_proc_filter_TestApi {\n\n  def BeforeEntrypoint(): Unit = {\n    Art.initTest(Arch.PFC_Sys_Impl_Instance_proc_filter)\n  }\n\n  def AfterEntrypoint(): Unit = {\n    Art.finalizeTest(Arch.PFC_Sys_Impl_Instance_proc_filter)\n  }\n\n  def testCompute(): Unit = {\n    Art.manuallyClearOutput()\n    Art.testCompute(Arch.PFC_Sys_Impl_Instance_proc_filter)\n  }\n\n  def testInitialise(): Unit = {\n    Art.manuallyClearOutput()\n    Art.testInitialise(Arch.PFC_Sys_Impl_Instance_proc_filter)\n  }\n\n  \/** helper function to set the values of all input ports.\n   * @param from_producer_data payload for data port from_producer_data\n   * @param from_producer_event the number of events to place in the from_producer_event event port queue.\n   *   ART currently supports single element event queues so at most\n   *   one event will be placed in the queue.\n   *\/\n  def put_concrete_inputs(from_producer_data : Base_Types.Bits,\n                          from_producer_event : Z): Unit = {\n    put_from_producer_data(from_producer_data)\n    for(i <- 0 until from_producer_event) {\n      put_from_producer_event()\n    }\n  }\n\n\n  \/** helper function to check Filter_proc_filter's\n   * output ports.  Use named arguments to check subsets of the output ports.\n   * @param to_consumer method that will be called with the payloads to be sent\n   *        on the outgoing event data port 'to_consumer'.\n   *\/\n  def check_concrete_output(to_consumer: ISZ[Base_Types.Bits] => B): Unit = {\n    var testFailures: ISZ[ST] = ISZ()\n\n    var to_consumerValue: ISZ[Base_Types.Bits] = ISZ()\n    \/\/ TODO: event data port getter should return all of the events\/payloads\n    \/\/       received on event data ports when queue sizes > 1 support is added\n    \/\/       to ART\n    if(get_to_consumer().nonEmpty) { to_consumerValue = to_consumerValue :+ get_to_consumer().get }\n    if(!to_consumer(to_consumerValue)) {\n      testFailures = testFailures :+ st\"'to_consumer' did not match expected: received ${to_consumerValue.size} events with the following payloads ${to_consumerValue}\"\n    }\n\n    assert(testFailures.isEmpty, st\"${(testFailures, \"\\n\")}\".render)\n  }\n\n\n  \/\/ setter for in DataPort\n  def put_from_producer_data(value : Base_Types.Bits): Unit = {\n    Art.insertInInfrastructurePort(Arch.PFC_Sys_Impl_Instance_proc_filter.operational_api.from_producer_data_Id, Base_Types.Bits_Payload(value))\n  }\n\n  \/\/ setter for in EventPort\n  def put_from_producer_event(): Unit = {\n    Art.insertInInfrastructurePort(Arch.PFC_Sys_Impl_Instance_proc_filter.operational_api.from_producer_event_Id, art.Empty())\n  }\n\n  \/\/ getter for out EventDataPort\n  def get_to_consumer(): Option[Base_Types.Bits] = {\n    val value: Option[Base_Types.Bits] = get_to_consumer_payload() match {\n      case Some(Base_Types.Bits_Payload(v)) => Some(v)\n      case Some(v) => halt(s\"Unexpected payload on port to_consumer.  Expecting 'Base_Types.Bits_Payload' but received ${v}\")\n      case _ => None[Base_Types.Bits]()\n    }\n    return value\n  }\n\n  \/\/ payload getter for out EventDataPort\n  def get_to_consumer_payload(): Option[Base_Types.Bits_Payload] = {\n    return Art.observeOutInfrastructurePort(Arch.PFC_Sys_Impl_Instance_proc_filter.initialization_api.to_consumer_Id).asInstanceOf[Option[Base_Types.Bits_Payload]]\n  }\n\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/test\/util\/pfc_project\/PFC\/Filter_proc_filter_ScalaTest.scala",
        {
          "type" : "ITestResource",
          "content" : "package pfc_project.PFC\n\nimport org.scalatest.{BeforeAndAfterEach, OneInstancePerTest}\nimport org.scalatest.funsuite.AnyFunSuite\nimport org.sireum.$internal.MutableMarker\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\nabstract class Filter_proc_filter_ScalaTest extends\n  AnyFunSuite with OneInstancePerTest with BeforeAndAfterEach with\n  Filter_proc_filter_TestApi {\n\n  var clonable: Boolean = true\n  var owned: Boolean = false\n\n  override def string: org.sireum.String = {\n    this.toString()\n  }\n\n  override def $clonable: Boolean = {\n    return clonable\n  }\n\n  override def $clonable_=(b: Boolean): MutableMarker = {\n    clonable = b\n    return this\n  }\n\n  override def $owned: Boolean = {\n    return owned\n  }\n\n  override def $owned_=(b: Boolean): MutableMarker = {\n    owned = b\n    return this\n  }\n\n  override def $clone: MutableMarker = {\n    \/\/ not expecting users to want to clone realizations of this abstract class\n    return this\n  }\n\n  override def beforeEach(): Unit = {\n    BeforeEntrypoint()\n  }\n\n  override def afterEach(): Unit = {\n    AfterEntrypoint()\n  }\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/test\/bridge\/pfc_project\/PFC\/Filter_proc_filter_Test.scala",
        {
          "type" : "ITestResource",
          "content" : "package pfc_project.PFC\n\nimport org.sireum._\nimport pfc_project.PFC._\n\n\/\/ This file will not be overwritten so is safe to edit\nclass Filter_proc_filter_Test extends Filter_proc_filter_ScalaTest {\n\n  test(\"Example Unit Test for Initialise Entry Point\"){\n    \/\/ Initialise Entry Point doesn't read input port values, so just proceed with\n    \/\/ launching the entry point code\n    testInitialise()\n    \/\/ use get_XXX methods and check_concrete_output() from test\/util\/..\/YYY_TestApi\n    \/\/ retrieve values from output ports and check against expected results\n  }\n\n  test(\"Example Unit Test for Compute Entry Point\"){\n    \/\/ use put_XXX methods from test\/util\/..\/YYY_TestApi to seed input ports with values\n    testCompute()\n    \/\/ use get_XXX methods and check_concrete_output() from test\/util\/..\/YYY_TestApi\n    \/\/ retrieve values from output ports and check against expected results\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/bridge\/pfc_project\/PFC\/Filter_proc_filter_Bridge.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage pfc_project.PFC\n\nimport org.sireum._\nimport art._\nimport pfc_project._\nimport pfc_project.PFC.{Filter_proc_filter => component}\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\n@datatype class Filter_proc_filter_Bridge(\n  val id: Art.BridgeId,\n  val name: String,\n  val dispatchProtocol: DispatchPropertyProtocol,\n  val dispatchTriggers: Option[ISZ[Art.PortId]],\n\n  from_producer_data: Port[Base_Types.Bits],\n  to_consumer: Port[Base_Types.Bits],\n  from_producer_event: Port[art.Empty]\n  ) extends Bridge {\n\n  val ports : Bridge.Ports = Bridge.Ports(\n    dataIns = ISZ[art.UPort](from_producer_data),\n\n    dataOuts = ISZ[art.UPort](),\n\n    eventIns = ISZ[art.UPort](from_producer_event),\n\n    eventOuts = ISZ[art.UPort](to_consumer)\n  )\n\n  val initialization_api : Filter_Initialization_Api = {\n    val api = Filter_Initialization_Api(\n      id,\n      from_producer_data.id,\n      to_consumer.id,\n      from_producer_event.id\n    )\n    Filter_proc_filter_Bridge.c_initialization_api = Some(api)\n    api\n  }\n\n  val operational_api : Filter_Operational_Api = {\n    val api = Filter_Operational_Api(\n      id,\n      from_producer_data.id,\n      to_consumer.id,\n      from_producer_event.id\n    )\n    Filter_proc_filter_Bridge.c_operational_api = Some(api)\n    api\n  }\n\n  val entryPoints : Bridge.EntryPoints =\n    Filter_proc_filter_Bridge.EntryPoints(\n      id,\n\n      from_producer_data.id,\n      to_consumer.id,\n      from_producer_event.id,\n\n      dispatchTriggers,\n\n      initialization_api,\n      operational_api)\n}\n\nobject Filter_proc_filter_Bridge {\n\n  var c_initialization_api: Option[Filter_Initialization_Api] = None()\n  var c_operational_api: Option[Filter_Operational_Api] = None()\n\n  @datatype class EntryPoints(\n    Filter_proc_filter_BridgeId : Art.BridgeId,\n    from_producer_data_Id : Art.PortId,\n    to_consumer_Id : Art.PortId,\n    from_producer_event_Id : Art.PortId,\n    dispatchTriggers : Option[ISZ[Art.PortId]],\n    initialization_api: Filter_Initialization_Api,\n    operational_api: Filter_Operational_Api) extends Bridge.EntryPoints {\n\n    val dataInPortIds: ISZ[Art.PortId] = IS(from_producer_data_Id)\n\n    val eventInPortIds: ISZ[Art.PortId] = IS(from_producer_event_Id)\n\n    val dataOutPortIds: ISZ[Art.PortId] = IS()\n\n    val eventOutPortIds: ISZ[Art.PortId] = IS(to_consumer_Id)\n\n    def initialise(): Unit = {\n      \/\/ implement the following method in 'component':  def initialise(api: Filter_Initialization_Api): Unit = {}\n      component.initialise(initialization_api)\n      Art.sendOutput(eventOutPortIds, dataOutPortIds)\n    }\n\n    def compute(): Unit = {\n      Art.receiveInput(eventInPortIds, dataInPortIds)\n\n      \/\/ implement the following in 'component':  def timeTriggered(api: Filter_Operational_Api): Unit = {}\n      component.timeTriggered(operational_api)\n\n      Art.sendOutput(eventOutPortIds, dataOutPortIds)\n    }\n\n    def activate(): Unit = {\n      \/\/ implement the following method in 'component':  def activate(api: Filter_Operational_Api): Unit = {}\n      component.activate(operational_api)\n    }\n\n    def deactivate(): Unit = {\n      \/\/ implement the following method in 'component':  def deactivate(api: Filter_Operational_Api): Unit = {}\n      component.deactivate(operational_api)\n    }\n\n    def finalise(): Unit = {\n      \/\/ implement the following method in 'component':  def finalise(api: Filter_Operational_Api): Unit = {}\n      component.finalise(operational_api)\n    }\n\n    def recover(): Unit = {\n      \/\/ implement the following method in 'component':  def recover(api: Filter_Operational_Api): Unit = {}\n      component.recover(operational_api)\n    }\n\n    override\n    def testInitialise(): Unit = {\n      \/\/ implement the following method in 'component':  def initialise(api: Filter_Initialization_Api): Unit = {}\n      component.initialise(initialization_api)\n      Art.releaseOutput(eventOutPortIds, dataOutPortIds)\n    }\n\n    override\n    def testCompute(): Unit = {\n      Art.receiveInput(eventInPortIds, dataInPortIds)\n\n      \/\/ implement the following in 'component':  def timeTriggered(api: Filter_Operational_Api): Unit = {}\n      component.timeTriggered(operational_api)\n\n      Art.releaseOutput(eventOutPortIds, dataOutPortIds)\n    }\n  }\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/bridge\/pfc_project\/PFC\/Filter_Api.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage pfc_project.PFC\n\nimport org.sireum._\nimport art._\nimport pfc_project._\n\n@sig trait Filter_Api {\n  def id: Art.BridgeId\n  def from_producer_data_Id : Art.PortId\n  def to_consumer_Id : Art.PortId\n  def from_producer_event_Id : Art.PortId\n\n  \/\/ Logika spec var representing port state for outgoing event data port\n  @spec var to_consumer: Option[Base_Types.Bits] = $\n\n  def put_to_consumer(value : Base_Types.Bits) : Unit = {\n    Contract(\n      Modifies(to_consumer),\n      Ensures(\n        to_consumer == Some(value)\n      )\n    )\n    Spec {\n      to_consumer = Some(value)\n    }\n\n    Art.putValue(to_consumer_Id, Base_Types.Bits_Payload(value))\n  }\n\n  def logInfo(msg: String): Unit = {\n    Art.logInfo(id, msg)\n  }\n\n  def logDebug(msg: String): Unit = {\n    Art.logDebug(id, msg)\n  }\n\n  def logError(msg: String): Unit = {\n    Art.logError(id, msg)\n  }\n}\n\n@datatype class Filter_Initialization_Api (\n  val id: Art.BridgeId,\n  val from_producer_data_Id : Art.PortId,\n  val to_consumer_Id : Art.PortId,\n  val from_producer_event_Id : Art.PortId) extends Filter_Api\n\n@datatype class Filter_Operational_Api (\n  val id: Art.BridgeId,\n  val from_producer_data_Id : Art.PortId,\n  val to_consumer_Id : Art.PortId,\n  val from_producer_event_Id : Art.PortId) extends Filter_Api {\n\n  \/\/ Logika spec var representing port state for incoming data port\n  @spec var from_producer_data: Base_Types.Bits = $\n\n  def get_from_producer_data() : Option[Base_Types.Bits] = {\n    Contract(\n      Ensures(\n        Res == Some(from_producer_data)\n      )\n    )\n    val value : Option[Base_Types.Bits] = Art.getValue(from_producer_data_Id) match {\n      case Some(Base_Types.Bits_Payload(v)) => Some(v)\n      case Some(v) =>\n        Art.logError(id, s\"Unexpected payload on port from_producer_data.  Expecting 'Base_Types.Bits_Payload' but received ${v}\")\n        None[Base_Types.Bits]()\n      case _ => None[Base_Types.Bits]()\n    }\n    return value\n  }\n\n  \/\/ Logika spec var representing port state for incoming event port\n  @spec var from_producer_event: Option[art.Empty] = $\n\n  def get_from_producer_event() : Option[art.Empty] = {\n    Contract(\n      Ensures(\n        Res == from_producer_event\n      )\n    )\n    val value : Option[art.Empty] = Art.getValue(from_producer_event_Id) match {\n      case Some(Empty()) => Some(Empty())\n      case Some(v) =>\n        Art.logError(id, s\"Unexpected payload on port from_producer_event.  Expecting 'Empty' but received ${v}\")\n        None[art.Empty]()\n      case _ => None[art.Empty]()\n    }\n    return value\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/component\/pfc_project\/PFC\/Filter_proc_filter.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage pfc_project.PFC\n\nimport org.sireum._\nimport pfc_project._\n\n\/\/ This file will not be overwritten so is safe to edit\nobject Filter_proc_filter {\n\n  def initialise(api: Filter_Initialization_Api): Unit = { }\n\n  def timeTriggered(api: Filter_Operational_Api): Unit = { }\n\n  def activate(api: Filter_Operational_Api): Unit = { }\n\n  def deactivate(api: Filter_Operational_Api): Unit = { }\n\n  def finalise(api: Filter_Operational_Api): Unit = { }\n\n  def recover(api: Filter_Operational_Api): Unit = { }\n}\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/test\/util\/pfc_project\/PFC\/Consumer_proc_consumer_TestApi.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage pfc_project.PFC\n\nimport org.sireum._\nimport art.Art\nimport pfc_project._\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n@msig trait Consumer_proc_consumer_TestApi {\n\n  def BeforeEntrypoint(): Unit = {\n    Art.initTest(Arch.PFC_Sys_Impl_Instance_proc_consumer)\n  }\n\n  def AfterEntrypoint(): Unit = {\n    Art.finalizeTest(Arch.PFC_Sys_Impl_Instance_proc_consumer)\n  }\n\n  def testCompute(): Unit = {\n    Art.manuallyClearOutput()\n    Art.testCompute(Arch.PFC_Sys_Impl_Instance_proc_consumer)\n  }\n\n  def testInitialise(): Unit = {\n    Art.manuallyClearOutput()\n    Art.testInitialise(Arch.PFC_Sys_Impl_Instance_proc_consumer)\n  }\n\n  \/** helper function to set the values of all input ports.\n   * @param from_filter payloads for event data port from_filter.\n   *   ART currently supports single element event data queues so\n   *   only the last element of from_filter will be used\n   *\/\n  def put_concrete_inputs(from_filter : ISZ[Base_Types.Bits]): Unit = {\n    for(v <- from_filter){\n      put_from_filter(v)\n    }\n  }\n\n\n  \/\/ setter for in EventDataPort\n  def put_from_filter(value : Base_Types.Bits): Unit = {\n    Art.insertInInfrastructurePort(Arch.PFC_Sys_Impl_Instance_proc_consumer.operational_api.from_filter_Id, Base_Types.Bits_Payload(value))\n  }\n\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/test\/util\/pfc_project\/PFC\/Consumer_proc_consumer_ScalaTest.scala",
        {
          "type" : "ITestResource",
          "content" : "package pfc_project.PFC\n\nimport org.scalatest.{BeforeAndAfterEach, OneInstancePerTest}\nimport org.scalatest.funsuite.AnyFunSuite\nimport org.sireum.$internal.MutableMarker\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\nabstract class Consumer_proc_consumer_ScalaTest extends\n  AnyFunSuite with OneInstancePerTest with BeforeAndAfterEach with\n  Consumer_proc_consumer_TestApi {\n\n  var clonable: Boolean = true\n  var owned: Boolean = false\n\n  override def string: org.sireum.String = {\n    this.toString()\n  }\n\n  override def $clonable: Boolean = {\n    return clonable\n  }\n\n  override def $clonable_=(b: Boolean): MutableMarker = {\n    clonable = b\n    return this\n  }\n\n  override def $owned: Boolean = {\n    return owned\n  }\n\n  override def $owned_=(b: Boolean): MutableMarker = {\n    owned = b\n    return this\n  }\n\n  override def $clone: MutableMarker = {\n    \/\/ not expecting users to want to clone realizations of this abstract class\n    return this\n  }\n\n  override def beforeEach(): Unit = {\n    BeforeEntrypoint()\n  }\n\n  override def afterEach(): Unit = {\n    AfterEntrypoint()\n  }\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/test\/bridge\/pfc_project\/PFC\/Consumer_proc_consumer_Test.scala",
        {
          "type" : "ITestResource",
          "content" : "package pfc_project.PFC\n\nimport org.sireum._\nimport pfc_project.PFC._\n\n\/\/ This file will not be overwritten so is safe to edit\nclass Consumer_proc_consumer_Test extends Consumer_proc_consumer_ScalaTest {\n\n  test(\"Example Unit Test for Initialise Entry Point\"){\n    \/\/ Initialise Entry Point doesn't read input port values, so just proceed with\n    \/\/ launching the entry point code\n    testInitialise()\n    \/\/ use get_XXX methods and check_concrete_output() from test\/util\/..\/YYY_TestApi\n    \/\/ retrieve values from output ports and check against expected results\n  }\n\n  test(\"Example Unit Test for Compute Entry Point\"){\n    \/\/ use put_XXX methods from test\/util\/..\/YYY_TestApi to seed input ports with values\n    testCompute()\n    \/\/ use get_XXX methods and check_concrete_output() from test\/util\/..\/YYY_TestApi\n    \/\/ retrieve values from output ports and check against expected results\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/bridge\/pfc_project\/PFC\/Consumer_proc_consumer_Bridge.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage pfc_project.PFC\n\nimport org.sireum._\nimport art._\nimport pfc_project._\nimport pfc_project.PFC.{Consumer_proc_consumer => component}\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\n@datatype class Consumer_proc_consumer_Bridge(\n  val id: Art.BridgeId,\n  val name: String,\n  val dispatchProtocol: DispatchPropertyProtocol,\n  val dispatchTriggers: Option[ISZ[Art.PortId]],\n\n  from_filter: Port[Base_Types.Bits]\n  ) extends Bridge {\n\n  val ports : Bridge.Ports = Bridge.Ports(\n    dataIns = ISZ[art.UPort](),\n\n    dataOuts = ISZ[art.UPort](),\n\n    eventIns = ISZ[art.UPort](from_filter),\n\n    eventOuts = ISZ[art.UPort]()\n  )\n\n  val initialization_api : Consumer_Initialization_Api = {\n    val api = Consumer_Initialization_Api(\n      id,\n      from_filter.id\n    )\n    Consumer_proc_consumer_Bridge.c_initialization_api = Some(api)\n    api\n  }\n\n  val operational_api : Consumer_Operational_Api = {\n    val api = Consumer_Operational_Api(\n      id,\n      from_filter.id\n    )\n    Consumer_proc_consumer_Bridge.c_operational_api = Some(api)\n    api\n  }\n\n  val entryPoints : Bridge.EntryPoints =\n    Consumer_proc_consumer_Bridge.EntryPoints(\n      id,\n\n      from_filter.id,\n\n      dispatchTriggers,\n\n      initialization_api,\n      operational_api)\n}\n\nobject Consumer_proc_consumer_Bridge {\n\n  var c_initialization_api: Option[Consumer_Initialization_Api] = None()\n  var c_operational_api: Option[Consumer_Operational_Api] = None()\n\n  @datatype class EntryPoints(\n    Consumer_proc_consumer_BridgeId : Art.BridgeId,\n    from_filter_Id : Art.PortId,\n    dispatchTriggers : Option[ISZ[Art.PortId]],\n    initialization_api: Consumer_Initialization_Api,\n    operational_api: Consumer_Operational_Api) extends Bridge.EntryPoints {\n\n    val dataInPortIds: ISZ[Art.PortId] = IS()\n\n    val eventInPortIds: ISZ[Art.PortId] = IS(from_filter_Id)\n\n    val dataOutPortIds: ISZ[Art.PortId] = IS()\n\n    val eventOutPortIds: ISZ[Art.PortId] = IS()\n\n    def initialise(): Unit = {\n      \/\/ implement the following method in 'component':  def initialise(api: Consumer_Initialization_Api): Unit = {}\n      component.initialise(initialization_api)\n      Art.sendOutput(eventOutPortIds, dataOutPortIds)\n    }\n\n    def compute(): Unit = {\n      \/\/ transpiler friendly filter\n      def filter(receivedEvents: ISZ[Art.PortId], triggers: ISZ[Art.PortId]): ISZ[Art.PortId] = {\n        var r = ISZ[Art.PortId]()\n        val opsTriggers = ops.ISZOps(triggers)\n        for(e <- receivedEvents) {\n          if(opsTriggers.contains(e)) {\n            r = r :+ e\n          }\n        }\n        return r\n      }\n\n      \/\/ fetch received events ordered by highest urgency then earliest arrival-time\n      val EventTriggered(receivedEvents) = Art.dispatchStatus(Consumer_proc_consumer_BridgeId)\n\n      \/\/ remove non-dispatching event ports\n      val dispatchableEventPorts: ISZ[Art.PortId] =\n        if(dispatchTriggers.isEmpty) receivedEvents\n        else filter(receivedEvents, dispatchTriggers.get)\n\n      Art.receiveInput(eventInPortIds, dataInPortIds)\n\n      for(portId <- dispatchableEventPorts) {\n        if(portId == from_filter_Id){\n          val Some(Base_Types.Bits_Payload(value)) = Art.getValue(from_filter_Id)\n\n          \/\/ implement the following in 'component':  def handle_from_filter(api: Consumer_Operational_Api, value: Base_Types.Bits): Unit = {}\n          component.handle_from_filter(operational_api, value)\n        }\n      }\n\n      Art.sendOutput(eventOutPortIds, dataOutPortIds)\n    }\n\n    def activate(): Unit = {\n      \/\/ implement the following method in 'component':  def activate(api: Consumer_Operational_Api): Unit = {}\n      component.activate(operational_api)\n    }\n\n    def deactivate(): Unit = {\n      \/\/ implement the following method in 'component':  def deactivate(api: Consumer_Operational_Api): Unit = {}\n      component.deactivate(operational_api)\n    }\n\n    def finalise(): Unit = {\n      \/\/ implement the following method in 'component':  def finalise(api: Consumer_Operational_Api): Unit = {}\n      component.finalise(operational_api)\n    }\n\n    def recover(): Unit = {\n      \/\/ implement the following method in 'component':  def recover(api: Consumer_Operational_Api): Unit = {}\n      component.recover(operational_api)\n    }\n\n    override\n    def testInitialise(): Unit = {\n      \/\/ implement the following method in 'component':  def initialise(api: Consumer_Initialization_Api): Unit = {}\n      component.initialise(initialization_api)\n      Art.releaseOutput(eventOutPortIds, dataOutPortIds)\n    }\n\n    override\n    def testCompute(): Unit = {\n      \/\/ transpiler friendly filter\n      def filter(receivedEvents: ISZ[Art.PortId], triggers: ISZ[Art.PortId]): ISZ[Art.PortId] = {\n        var r = ISZ[Art.PortId]()\n        val opsTriggers = ops.ISZOps(triggers)\n        for(e <- receivedEvents) {\n          if(opsTriggers.contains(e)) {\n            r = r :+ e\n          }\n        }\n        return r\n      }\n\n      \/\/ fetch received events ordered by highest urgency then earliest arrival-time\n      val EventTriggered(receivedEvents) = Art.dispatchStatus(Consumer_proc_consumer_BridgeId)\n\n      \/\/ remove non-dispatching event ports\n      val dispatchableEventPorts: ISZ[Art.PortId] =\n        if(dispatchTriggers.isEmpty) receivedEvents\n        else filter(receivedEvents, dispatchTriggers.get)\n\n      Art.receiveInput(eventInPortIds, dataInPortIds)\n\n      for(portId <- dispatchableEventPorts) {\n        if(portId == from_filter_Id){\n          val Some(Base_Types.Bits_Payload(value)) = Art.getValue(from_filter_Id)\n\n          \/\/ implement the following in 'component':  def handle_from_filter(api: Consumer_Operational_Api, value: Base_Types.Bits): Unit = {}\n          component.handle_from_filter(operational_api, value)\n        }\n      }\n\n      Art.releaseOutput(eventOutPortIds, dataOutPortIds)\n    }\n  }\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/bridge\/pfc_project\/PFC\/Consumer_Api.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage pfc_project.PFC\n\nimport org.sireum._\nimport art._\nimport pfc_project._\n\n@sig trait Consumer_Api {\n  def id: Art.BridgeId\n  def from_filter_Id : Art.PortId\n\n\n  def logInfo(msg: String): Unit = {\n    Art.logInfo(id, msg)\n  }\n\n  def logDebug(msg: String): Unit = {\n    Art.logDebug(id, msg)\n  }\n\n  def logError(msg: String): Unit = {\n    Art.logError(id, msg)\n  }\n}\n\n@datatype class Consumer_Initialization_Api (\n  val id: Art.BridgeId,\n  val from_filter_Id : Art.PortId) extends Consumer_Api\n\n@datatype class Consumer_Operational_Api (\n  val id: Art.BridgeId,\n  val from_filter_Id : Art.PortId) extends Consumer_Api {\n\n  \/\/ Logika spec var representing port state for incoming event data port\n  @spec var from_filter: Option[Base_Types.Bits] = $\n\n  def get_from_filter() : Option[Base_Types.Bits] = {\n    Contract(\n      Ensures(\n        Res == from_filter\n      )\n    )\n    val value : Option[Base_Types.Bits] = Art.getValue(from_filter_Id) match {\n      case Some(Base_Types.Bits_Payload(v)) => Some(v)\n      case Some(v) =>\n        Art.logError(id, s\"Unexpected payload on port from_filter.  Expecting 'Base_Types.Bits_Payload' but received ${v}\")\n        None[Base_Types.Bits]()\n      case _ => None[Base_Types.Bits]()\n    }\n    return value\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/component\/pfc_project\/PFC\/Consumer_proc_consumer.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage pfc_project.PFC\n\nimport org.sireum._\nimport pfc_project._\n\n\/\/ This file will not be overwritten so is safe to edit\nobject Consumer_proc_consumer {\n\n  def initialise(api: Consumer_Initialization_Api): Unit = { }\n\n  def handle_from_filter(api: Consumer_Operational_Api, value: Base_Types.Bits): Unit = { }\n\n  def activate(api: Consumer_Operational_Api): Unit = { }\n\n  def deactivate(api: Consumer_Operational_Api): Unit = { }\n\n  def finalise(api: Consumer_Operational_Api): Unit = { }\n\n  def recover(api: Consumer_Operational_Api): Unit = { }\n}\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/component\/pfc_project\/TranspilerToucher.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage pfc_project\n\nimport org.sireum._\n\n\/\/ This file will not be overwritten so is safe to edit\n\nobject TranspilerToucher {\n  def touch(): Unit = {\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/seL4Nix\/pfc_project\/Producer_proc_producer\/producer.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\npackage pfc_project.Producer_proc_producer\n\nimport org.sireum._\nimport art._\nimport art.Art.BridgeId._\nimport art.Art.PortId._\nimport art.DispatchPropertyProtocol._\nimport art.PortMode._\nimport pfc_project._\nimport pfc_project.PFC.Producer_proc_producer_seL4Nix\n\nobject producer extends App {\n\n  val producerBridge : pfc_project.PFC.Producer_proc_producer_Bridge = {\n    val to_filter_data = Port[Base_Types.Bits] (id = portId\"0\", name = \"PFC_Sys_Impl_Instance_proc_producer_to_filter_data\", mode = DataOut)\n    val to_filter_event = Port[art.Empty] (id = portId\"1\", name = \"PFC_Sys_Impl_Instance_proc_producer_to_filter_event\", mode = EventOut)\n\n    pfc_project.PFC.Producer_proc_producer_Bridge(\n      id = bridgeId\"0\",\n      name = \"PFC_Sys_Impl_Instance_proc_producer\",\n      dispatchProtocol = Periodic(period = 1000),\n      dispatchTriggers = None(),\n\n      to_filter_data = to_filter_data,\n      to_filter_event = to_filter_event\n    )\n  }\n\n  val entryPoints: Bridge.EntryPoints = producerBridge.entryPoints\n  val noData: Option[DataContent] = None()\n\n  \/\/ to_filter_data: Out DataPort Base_Types.Bits\n  val to_filter_data_id: Art.PortId = producerBridge.to_filter_data.id\n  var to_filter_data_port: Option[DataContent] = noData\n\n  \/\/ to_filter_event: Out EventPort art.Empty\n  val to_filter_event_id: Art.PortId = producerBridge.to_filter_event.id\n  var to_filter_event_port: Option[DataContent] = noData\n\n  def dispatchStatus(bridgeId: Art.BridgeId): DispatchStatus = {\n    return TimeTriggered()\n  }\n\n  def getValue(portId: Art.PortId): Option[DataContent] = {\n    halt(s\"Unexpected: producer.getValue called with: ${portId}\")\n  }\n\n  def receiveInput(eventPortIds: ISZ[Art.PortId], dataPortIds: ISZ[Art.PortId]): Unit = {\n    \/\/ ignore params\n\n\n  }\n\n  def putValue(portId: Art.PortId, data: DataContent): Unit = {\n    if(portId == to_filter_data_id) {\n      to_filter_data_port = Some(data)\n    } else if(portId == to_filter_event_id) {\n      to_filter_event_port = Some(data)\n    } else {\n      halt(s\"Unexpected: producer.putValue called with: ${portId}\")\n    }\n  }\n\n  def sendOutput(eventPortIds: ISZ[Art.PortId], dataPortIds: ISZ[Art.PortId]): Unit = {\n    \/\/ ignore params\n\n    if(to_filter_data_port.nonEmpty) {\n      Producer_proc_producer_seL4Nix.to_filter_data_Send(to_filter_data_port.get)\n      to_filter_data_port = noData\n    }\n\n    if(to_filter_event_port.nonEmpty) {\n      Producer_proc_producer_seL4Nix.to_filter_event_Send(to_filter_event_port.get)\n      to_filter_event_port = noData\n    }\n  }\n\n  def initialiseArchitecture(): Unit = {\n    \/\/ nothing to do - CAmkES is responsible for initialization\n  }\n\n  def initialiseEntryPoint(): Unit = { entryPoints.initialise() }\n\n  def computeEntryPoint(): Unit = { entryPoints.compute() }\n\n  def finaliseEntryPoint(): Unit = { entryPoints.finalise() }\n\n  def main(args: ISZ[String]): Z = {\n\n    \/\/ need to touch the following for transpiler\n    initialiseArchitecture()\n    initialiseEntryPoint()\n    computeEntryPoint()\n    finaliseEntryPoint()\n\n    touch()\n\n    return 0\n  }\n\n  def touch(): Unit = {\n    if(F) {\n      TranspilerToucher.touch()\n\n      \/\/ add types used in Platform.receive and Platform.receiveAsync\n      val mbox2Boolean_Payload: MBox2[Art.PortId, DataContent] = MBox2(portId\"0\", Base_Types.Boolean_Payload(T))\n      val mbox2OptionDataContent: MBox2[Art.PortId, Option[DataContent]] = MBox2(portId\"0\", None())\n\n      \/\/ touch each payload\/type in case some are only used as a field in a record\n      def printDataContent(a: art.DataContent): Unit = { println(s\"${a}\") }\n\n      printDataContent(Base_Types.Bits_Payload(Base_Types.Bits_example()))\n      printDataContent(art.Empty())\n\n      pfc_project.PFC.Producer_proc_producer_Bridge.c_initialization_api.get.logInfo(\"\")\n      pfc_project.PFC.Producer_proc_producer_Bridge.c_initialization_api.get.logDebug(\"\")\n      pfc_project.PFC.Producer_proc_producer_Bridge.c_initialization_api.get.logError(\"\")\n      pfc_project.PFC.Producer_proc_producer_Bridge.c_operational_api.get.logInfo(\"\")\n      pfc_project.PFC.Producer_proc_producer_Bridge.c_operational_api.get.logDebug(\"\")\n      pfc_project.PFC.Producer_proc_producer_Bridge.c_operational_api.get.logError(\"\")\n      pfc_project.PFC.Producer_proc_producer_Bridge.c_initialization_api.get.put_to_filter_data(Base_Types.Bits_example())\n      pfc_project.PFC.Producer_proc_producer_Bridge.c_operational_api.get.put_to_filter_data(Base_Types.Bits_example())\n      pfc_project.PFC.Producer_proc_producer_Bridge.c_initialization_api.get.put_to_filter_event()\n      pfc_project.PFC.Producer_proc_producer_Bridge.c_operational_api.get.put_to_filter_event()\n    }\n  }\n\n  def logInfo(title: String, msg: String): Unit = {\n    print(producerBridge.name)\n    print(\": \")\n    println(msg)\n  }\n\n  def logError(title: String, msg: String): Unit = {\n    eprint(producerBridge.name)\n    eprint(\": \")\n    eprintln(msg)\n  }\n\n  def logDebug(title: String, msg: String): Unit = {\n    print(producerBridge.name)\n    print(\": \")\n    println(msg)\n  }\n\n  def run(): Unit = {}\n\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/seL4Nix\/pfc_project\/PFC\/Producer_proc_producer_seL4Nix.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\npackage pfc_project.PFC\n\nimport org.sireum._\nimport art._\n\n@ext object Producer_proc_producer_seL4Nix {\n  \/\/ send payload 'd' to components connected to seL4's to_filter_data port\n  def to_filter_data_Send(d: DataContent): Unit = $\n\n  \/\/ send payload 'd' to components connected to seL4's to_filter_event port\n  def to_filter_event_Send(d: DataContent): Unit = $\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/seL4Nix\/pfc_project\/PFC\/Producer_proc_producer_seL4Nix_Ext.scala",
        {
          "type" : "ITestResource",
          "content" : "package pfc_project.PFC\n\nimport org.sireum._\nimport art._\n\nobject Producer_proc_producer_seL4Nix_Ext {\n  def to_filter_data_Send(d: DataContent): Unit = halt(\"stub\")\n\n  def to_filter_event_Send(d: DataContent): Unit = halt(\"stub\")\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/c\/ext-c\/Producer_proc_producer\/Producer_proc_producer.h",
        {
          "type" : "ITestResource",
          "content" : "#ifndef PRODUCER_PROC_PRODUCER_H\n#define PRODUCER_PROC_PRODUCER_H\n\n#include <all.h>\n\nUnit pfc_project_PFC_Producer_proc_producer_initialise_(STACK_FRAME_ONLY);\n\nUnit pfc_project_PFC_Producer_proc_producer_finalise_(STACK_FRAME_ONLY);\n\nUnit pfc_project_PFC_Producer_proc_producer_timeTriggered_(STACK_FRAME_ONLY);\n\n#endif\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/c\/ext-c\/Producer_proc_producer\/Producer_proc_producer.c",
        {
          "type" : "ITestResource",
          "content" : "#include <Producer_proc_producer_api.h>\n#include <Producer_proc_producer.h>\n#include <ext.h>\n\n\/\/ This file will not be overwritten so is safe to edit\n\nstatic char* component_id = \"PFC_Sys_Impl_Instance_proc_producer\";\n\nUnit pfc_project_PFC_Producer_proc_producer_initialise_(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer.c\", \"\", \"pfc_project_PFC_Producer_proc_producer_initialise_\", 0);\n\n  printf(\"%s: pfc_project_PFC_Producer_proc_producer_initialise_ called\\n\", component_id);\n\n  \/\/ example usage of api setters\n\n  uint8_t t0[numBytes_pfc_project_PFC_Mission];\n  byte_array_default(SF t0, numBits_pfc_project_PFC_Mission, numBytes_pfc_project_PFC_Mission);\n  api_put_to_filter_data__pfc_project_PFC_Producer_proc_producer(SF numBits_pfc_project_PFC_Mission, t0);\n\n  api_put_to_filter_event__pfc_project_PFC_Producer_proc_producer(SF_LAST);\n\n  \/* example usage of api loggers. Commented out as the constructed String may be too long\n  api_logInfo__pfc_project_PFC_Producer_proc_producer(SF string(\"Example logInfo\"));\n\n  api_logDebug__pfc_project_PFC_Producer_proc_producer(SF string(\"Example logDebug\"));\n\n  api_logError__pfc_project_PFC_Producer_proc_producer(SF string(\"Example logError\"));\n  *\/\n}\n\nUnit pfc_project_PFC_Producer_proc_producer_finalise_(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer.c\", \"\", \"pfc_project_PFC_Producer_proc_producer_finalise_\", 0);\n}\n\nUnit pfc_project_PFC_Producer_proc_producer_timeTriggered_(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer.c\", \"\", \"pfc_project_PFC_Producer_proc_producer_timeTriggered_\", 0);\n\n}\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/c\/ext-c\/Producer_proc_producer\/Producer_proc_producer_api.h",
        {
          "type" : "ITestResource",
          "content" : "#ifndef PRODUCER_PROC_PRODUCER_API_H\n#define PRODUCER_PROC_PRODUCER_API_H\n\n#include <all.h>\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\nvoid api_put_to_filter_data__pfc_project_PFC_Producer_proc_producer(\n  STACK_FRAME\n  size_t numBits,\n  uint8_t *byteArray);\n\nvoid api_put_to_filter_event__pfc_project_PFC_Producer_proc_producer(STACK_FRAME_ONLY);\n\nvoid api_logInfo__pfc_project_PFC_Producer_proc_producer(\n  STACK_FRAME\n  String str);\n\nvoid api_logDebug__pfc_project_PFC_Producer_proc_producer(\n  STACK_FRAME\n  String str);\n\nvoid api_logError__pfc_project_PFC_Producer_proc_producer(\n  STACK_FRAME\n  String str);\n\n#endif\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/c\/ext-c\/Producer_proc_producer\/Producer_proc_producer_api.c",
        {
          "type" : "ITestResource",
          "content" : "#include <Producer_proc_producer_api.h>\n#include <Producer_proc_producer.h>\n\nstatic bool apis_initialized = false;\nstatic struct pfc_project_PFC_Producer_Initialization_Api initialization_api;\nstatic struct pfc_project_PFC_Producer_Operational_Api operational_api;\n\nstatic void initialize_apis(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer.c\", \"\", \"initialize_apis\", 0);\n\n  \/\/ Option_B74437 = Option[pfc_project.PFC.Producer_Initialization_Api]\n  Option_B74437_get_(SF (pfc_project_PFC_Producer_Initialization_Api) &initialization_api, pfc_project_PFC_Producer_proc_producer_Bridge_c_initialization_api(SF_LAST));\n  \/\/ Option_8206DB = Option[pfc_project.PFC.Producer_Operational_Api]\n  Option_8206DB_get_(SF (pfc_project_PFC_Producer_Operational_Api) &operational_api, pfc_project_PFC_Producer_proc_producer_Bridge_c_operational_api(SF_LAST));\n  apis_initialized = true;\n}\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\nvoid api_put_to_filter_data__pfc_project_PFC_Producer_proc_producer(\n  STACK_FRAME\n  size_t numBits,\n  uint8_t *byteArray) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer_api.c\", \"\", \"api_put_to_filter_data__pfc_project_PFC_Producer_proc_producer\", 0);\n\n  sfAssert((Z) numBits >= 0, \"numBits must be non-negative for IS[Z, B].\")\n  sfAssert((Z) numBits <= MaxIS_C4F575, \"numBits too large for IS[Z, B].\")\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  DeclNewIS_C4F575(t_0);\n\n  t_0.size = numBits;\n  if(numBits > 0) {\n    size_t numBytes = (numBits - 1) \/ 8 + 1;\n    memcpy(&t_0.value, byteArray, numBytes);\n  }\n\n  pfc_project_PFC_Producer_Initialization_Api_put_to_filter_data_(\n    SF\n    &initialization_api,\n    &t_0);\n}\n\nvoid api_put_to_filter_event__pfc_project_PFC_Producer_proc_producer(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer_api.c\", \"\", \"api_put_to_filter_event__pfc_project_PFC_Producer_proc_producer\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  pfc_project_PFC_Producer_Initialization_Api_put_to_filter_event_(\n    SF\n    &initialization_api);\n}\n\nvoid api_logInfo__pfc_project_PFC_Producer_proc_producer(\n  STACK_FRAME\n  String str) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer_api.c\", \"\", \"api_logInfo__pfc_project_PFC_Producer_proc_producer\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  pfc_project_PFC_Producer_Initialization_Api_logInfo_(\n    SF\n    &initialization_api,\n    str);\n}\n\nvoid api_logDebug__pfc_project_PFC_Producer_proc_producer(\n  STACK_FRAME\n  String str) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer_api.c\", \"\", \"api_logDebug__pfc_project_PFC_Producer_proc_producer\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  pfc_project_PFC_Producer_Initialization_Api_logDebug_(\n    SF\n    &initialization_api,\n    str);\n}\n\nvoid api_logError__pfc_project_PFC_Producer_proc_producer(\n  STACK_FRAME\n  String str) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer_api.c\", \"\", \"api_logError__pfc_project_PFC_Producer_proc_producer\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  pfc_project_PFC_Producer_Initialization_Api_logError_(\n    SF\n    &initialization_api,\n    str);\n}\n\nUnit pfc_project_PFC_Producer_proc_producer_initialise(\n  STACK_FRAME\n  pfc_project_PFC_Producer_Initialization_Api api) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer_api.c\", \"\", \"pfc_project_PFC_Producer_proc_producer_initialise\", 0);\n\n  pfc_project_PFC_Producer_proc_producer_initialise_(SF_LAST);\n}\n\nUnit pfc_project_PFC_Producer_proc_producer_finalise(\n  STACK_FRAME\n  pfc_project_PFC_Producer_Operational_Api api) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer_api.c\", \"\", \"pfc_project_PFC_Producer_proc_producer_finalise\", 0);\n\n  pfc_project_PFC_Producer_proc_producer_finalise_(SF_LAST);\n}\n\nUnit pfc_project_PFC_Producer_proc_producer_timeTriggered(\n  STACK_FRAME\n  pfc_project_PFC_Producer_Operational_Api api) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer_api.c\", \"\", \"pfc_project_PFC_Producer_proc_producer_timeTriggered\", 0);\n\n  pfc_project_PFC_Producer_proc_producer_timeTriggered_(SF_LAST);\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/c\/etc_seL4\/adapters\/Producer_proc_producer\/Producer_proc_producer_adapter.c",
        {
          "type" : "ITestResource",
          "content" : "#include <Producer_proc_producer_adapter.h>\n\nUnit pfc_project_PFC_Producer_proc_producer_adapter_initialiseArchitecture(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer_adapter.c\", \"\", \"pfc_project_PFC_Producer_proc_producer_adapter_initialiseArchitecture\", 0);\n\n  pfc_project_Producer_proc_producer_producer_initialiseArchitecture(SF_LAST);\n}\n\nUnit pfc_project_PFC_Producer_proc_producer_adapter_initialiseEntryPoint(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer_adapter.c\", \"\", \"pfc_project_PFC_Producer_proc_producer_adapter_initialiseEntryPoint\", 0);\n\n  pfc_project_Producer_proc_producer_producer_initialiseEntryPoint(SF_LAST);\n}\n\nUnit pfc_project_PFC_Producer_proc_producer_adapter_computeEntryPoint(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer_adapter.c\", \"\", \"pfc_project_PFC_Producer_proc_producer_adapter_computeEntryPoint\", 0);\n\n  pfc_project_Producer_proc_producer_producer_computeEntryPoint(SF_LAST);\n}\n\nart_Bridge_EntryPoints pfc_project_PFC_Producer_proc_producer_adapter_entryPoints(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer_adapter.c\", \"\", \"pfc_project_PFC_Producer_proc_producer_adapter_entryPoints\", 0);\n\n  return pfc_project_Producer_proc_producer_producer_entryPoints(SF_LAST);\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/c\/etc_seL4\/adapters\/Producer_proc_producer\/Producer_proc_producer_adapter.h",
        {
          "type" : "ITestResource",
          "content" : "#ifndef PRODUCER_PROC_PRODUCER_ADAPTER_H\n#define PRODUCER_PROC_PRODUCER_ADAPTER_H\n\n#include <all.h>\n\nUnit pfc_project_PFC_Producer_proc_producer_adapter_initialiseArchitecture(STACK_FRAME_ONLY);\n\nUnit pfc_project_PFC_Producer_proc_producer_adapter_initialiseEntryPoint(STACK_FRAME_ONLY);\n\nUnit pfc_project_PFC_Producer_proc_producer_adapter_computeEntryPoint(STACK_FRAME_ONLY);\n\nart_Bridge_EntryPoints pfc_project_PFC_Producer_proc_producer_adapter_entryPoints(STACK_FRAME_ONLY);\n\n#endif\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/bin\/settings_Producer_proc_producer.cmake",
        {
          "type" : "ITestResource",
          "content" : "add_definitions(-DCAMKES)\n\nif(TARGET muslc)\n  target_link_libraries(Producer_proc_producer\n                        muslc)\nendif()",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/seL4Nix\/pfc_project\/Filter_proc_filter\/filter.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\npackage pfc_project.Filter_proc_filter\n\nimport org.sireum._\nimport art._\nimport art.Art.BridgeId._\nimport art.Art.PortId._\nimport art.DispatchPropertyProtocol._\nimport art.PortMode._\nimport pfc_project._\nimport pfc_project.PFC.Filter_proc_filter_seL4Nix\n\nobject filter extends App {\n\n  val filterBridge : pfc_project.PFC.Filter_proc_filter_Bridge = {\n    val from_producer_data = Port[Base_Types.Bits] (id = portId\"0\", name = \"PFC_Sys_Impl_Instance_proc_filter_from_producer_data\", mode = DataIn)\n    val to_consumer = Port[Base_Types.Bits] (id = portId\"1\", name = \"PFC_Sys_Impl_Instance_proc_filter_to_consumer\", mode = EventOut)\n    val from_producer_event = Port[art.Empty] (id = portId\"2\", name = \"PFC_Sys_Impl_Instance_proc_filter_from_producer_event\", mode = EventIn)\n\n    pfc_project.PFC.Filter_proc_filter_Bridge(\n      id = bridgeId\"0\",\n      name = \"PFC_Sys_Impl_Instance_proc_filter\",\n      dispatchProtocol = Periodic(period = 1000),\n      dispatchTriggers = None(),\n\n      from_producer_data = from_producer_data,\n      to_consumer = to_consumer,\n      from_producer_event = from_producer_event\n    )\n  }\n\n  val entryPoints: Bridge.EntryPoints = filterBridge.entryPoints\n  val noData: Option[DataContent] = None()\n\n  \/\/ from_producer_data: In DataPort Base_Types.Bits\n  val from_producer_data_id: Art.PortId = filterBridge.from_producer_data.id\n  var from_producer_data_port: Option[DataContent] = noData\n\n  \/\/ to_consumer: Out EventDataPort Base_Types.Bits\n  val to_consumer_id: Art.PortId = filterBridge.to_consumer.id\n  var to_consumer_port: Option[DataContent] = noData\n\n  \/\/ from_producer_event: In EventPort art.Empty\n  val from_producer_event_id: Art.PortId = filterBridge.from_producer_event.id\n  var from_producer_event_port: Option[DataContent] = noData\n\n  def dispatchStatus(bridgeId: Art.BridgeId): DispatchStatus = {\n    return TimeTriggered()\n  }\n\n  def getValue(portId: Art.PortId): Option[DataContent] = {\n    if(portId == from_producer_data_id) {\n      return from_producer_data_port\n    } else if(portId == from_producer_event_id) {\n      return from_producer_event_port\n    } else {\n      halt(s\"Unexpected: filter.getValue called with: ${portId}\")\n    }\n  }\n\n  def receiveInput(eventPortIds: ISZ[Art.PortId], dataPortIds: ISZ[Art.PortId]): Unit = {\n    \/\/ ignore params\n\n    from_producer_data_port = Filter_proc_filter_seL4Nix.from_producer_data_Receive()\n\n    from_producer_event_port = Filter_proc_filter_seL4Nix.from_producer_event_Receive()\n  }\n\n  def putValue(portId: Art.PortId, data: DataContent): Unit = {\n    if(portId == to_consumer_id) {\n      to_consumer_port = Some(data)\n    } else {\n      halt(s\"Unexpected: filter.putValue called with: ${portId}\")\n    }\n  }\n\n  def sendOutput(eventPortIds: ISZ[Art.PortId], dataPortIds: ISZ[Art.PortId]): Unit = {\n    \/\/ ignore params\n\n    if(to_consumer_port.nonEmpty) {\n      Filter_proc_filter_seL4Nix.to_consumer_Send(to_consumer_port.get)\n      to_consumer_port = noData\n    }\n  }\n\n  def initialiseArchitecture(): Unit = {\n    \/\/ nothing to do - CAmkES is responsible for initialization\n  }\n\n  def initialiseEntryPoint(): Unit = { entryPoints.initialise() }\n\n  def computeEntryPoint(): Unit = { entryPoints.compute() }\n\n  def finaliseEntryPoint(): Unit = { entryPoints.finalise() }\n\n  def main(args: ISZ[String]): Z = {\n\n    \/\/ need to touch the following for transpiler\n    initialiseArchitecture()\n    initialiseEntryPoint()\n    computeEntryPoint()\n    finaliseEntryPoint()\n\n    touch()\n\n    return 0\n  }\n\n  def touch(): Unit = {\n    if(F) {\n      TranspilerToucher.touch()\n\n      \/\/ add types used in Platform.receive and Platform.receiveAsync\n      val mbox2Boolean_Payload: MBox2[Art.PortId, DataContent] = MBox2(portId\"0\", Base_Types.Boolean_Payload(T))\n      val mbox2OptionDataContent: MBox2[Art.PortId, Option[DataContent]] = MBox2(portId\"0\", None())\n\n      \/\/ touch each payload\/type in case some are only used as a field in a record\n      def printDataContent(a: art.DataContent): Unit = { println(s\"${a}\") }\n\n      printDataContent(Base_Types.Bits_Payload(Base_Types.Bits_example()))\n      printDataContent(art.Empty())\n\n      pfc_project.PFC.Filter_proc_filter_Bridge.c_initialization_api.get.logInfo(\"\")\n      pfc_project.PFC.Filter_proc_filter_Bridge.c_initialization_api.get.logDebug(\"\")\n      pfc_project.PFC.Filter_proc_filter_Bridge.c_initialization_api.get.logError(\"\")\n      pfc_project.PFC.Filter_proc_filter_Bridge.c_operational_api.get.logInfo(\"\")\n      pfc_project.PFC.Filter_proc_filter_Bridge.c_operational_api.get.logDebug(\"\")\n      pfc_project.PFC.Filter_proc_filter_Bridge.c_operational_api.get.logError(\"\")\n      val apiUsage_from_producer_data: Option[Base_Types.Bits] = pfc_project.PFC.Filter_proc_filter_Bridge.c_operational_api.get.get_from_producer_data()\n      pfc_project.PFC.Filter_proc_filter_Bridge.c_initialization_api.get.put_to_consumer(Base_Types.Bits_example())\n      pfc_project.PFC.Filter_proc_filter_Bridge.c_operational_api.get.put_to_consumer(Base_Types.Bits_example())\n      val apiUsage_from_producer_event: Option[art.Empty] = pfc_project.PFC.Filter_proc_filter_Bridge.c_operational_api.get.get_from_producer_event()\n    }\n  }\n\n  def logInfo(title: String, msg: String): Unit = {\n    print(filterBridge.name)\n    print(\": \")\n    println(msg)\n  }\n\n  def logError(title: String, msg: String): Unit = {\n    eprint(filterBridge.name)\n    eprint(\": \")\n    eprintln(msg)\n  }\n\n  def logDebug(title: String, msg: String): Unit = {\n    print(filterBridge.name)\n    print(\": \")\n    println(msg)\n  }\n\n  def run(): Unit = {}\n\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/seL4Nix\/pfc_project\/PFC\/Filter_proc_filter_seL4Nix.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\npackage pfc_project.PFC\n\nimport org.sireum._\nimport art._\n\n@ext object Filter_proc_filter_seL4Nix {\n  \/\/ returns T if seL4's from_producer_data port is empty, F otherwise \n  def from_producer_data_IsEmpty(): B = $\n\n  \/\/ returns result of dequeuing seL4's from_producer_data port \n  def from_producer_data_Receive(): Option[DataContent] = $\n\n  \/\/ send payload 'd' to components connected to seL4's to_consumer port\n  def to_consumer_Send(d: DataContent): Unit = $\n\n  \/\/ returns T if seL4's from_producer_event port is empty, F otherwise \n  def from_producer_event_IsEmpty(): B = $\n\n  \/\/ returns result of dequeuing seL4's from_producer_event port \n  def from_producer_event_Receive(): Option[DataContent] = $\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/seL4Nix\/pfc_project\/PFC\/Filter_proc_filter_seL4Nix_Ext.scala",
        {
          "type" : "ITestResource",
          "content" : "package pfc_project.PFC\n\nimport org.sireum._\nimport art._\n\nobject Filter_proc_filter_seL4Nix_Ext {\n  def from_producer_data_IsEmpty(): B = halt(\"stub\")\n\n  def from_producer_data_Receive(): Option[DataContent] = halt(\"stub\")\n\n  def to_consumer_Send(d: DataContent): Unit = halt(\"stub\")\n\n  def from_producer_event_IsEmpty(): B = halt(\"stub\")\n\n  def from_producer_event_Receive(): Option[DataContent] = halt(\"stub\")\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/c\/ext-c\/Filter_proc_filter\/Filter_proc_filter.h",
        {
          "type" : "ITestResource",
          "content" : "#ifndef FILTER_PROC_FILTER_H\n#define FILTER_PROC_FILTER_H\n\n#include <all.h>\n\nUnit pfc_project_PFC_Filter_proc_filter_initialise_(STACK_FRAME_ONLY);\n\nUnit pfc_project_PFC_Filter_proc_filter_finalise_(STACK_FRAME_ONLY);\n\nUnit pfc_project_PFC_Filter_proc_filter_timeTriggered_(STACK_FRAME_ONLY);\n\n#endif\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/c\/ext-c\/Filter_proc_filter\/Filter_proc_filter.c",
        {
          "type" : "ITestResource",
          "content" : "#include <Filter_proc_filter_api.h>\n#include <Filter_proc_filter.h>\n#include <ext.h>\n\n\/\/ This file will not be overwritten so is safe to edit\n\nstatic char* component_id = \"PFC_Sys_Impl_Instance_proc_filter\";\n\nUnit pfc_project_PFC_Filter_proc_filter_initialise_(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter.c\", \"\", \"pfc_project_PFC_Filter_proc_filter_initialise_\", 0);\n\n  printf(\"%s: pfc_project_PFC_Filter_proc_filter_initialise_ called\\n\", component_id);\n\n  \/\/ example usage of api setters\n\n  uint8_t t0[numBytes_pfc_project_PFC_Mission];\n  byte_array_default(SF t0, numBits_pfc_project_PFC_Mission, numBytes_pfc_project_PFC_Mission);\n  api_put_to_consumer__pfc_project_PFC_Filter_proc_filter(SF numBits_pfc_project_PFC_Mission, t0);\n\n  \/* example usage of api loggers. Commented out as the constructed String may be too long\n  api_logInfo__pfc_project_PFC_Filter_proc_filter(SF string(\"Example logInfo\"));\n\n  api_logDebug__pfc_project_PFC_Filter_proc_filter(SF string(\"Example logDebug\"));\n\n  api_logError__pfc_project_PFC_Filter_proc_filter(SF string(\"Example logError\"));\n  *\/\n}\n\nUnit pfc_project_PFC_Filter_proc_filter_finalise_(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter.c\", \"\", \"pfc_project_PFC_Filter_proc_filter_finalise_\", 0);\n}\n\nUnit pfc_project_PFC_Filter_proc_filter_timeTriggered_(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter.c\", \"\", \"pfc_project_PFC_Filter_proc_filter_timeTriggered_\", 0);\n\n  \/\/ examples of api getter usage\n\n  uint8_t t0[numBytes_pfc_project_PFC_Mission];\n  size_t t0_numBits;\n  if(api_get_from_producer_data__pfc_project_PFC_Filter_proc_filter(SF &t0_numBits, t0)) {\n    \/\/ sanity check\n    sfAssert((Z) t0_numBits == numBits_pfc_project_PFC_Mission, \"numBits received does not match expected\")\n\n    printf(\"%s: Received data on data port from_producer_data: \\n\", component_id);\n    hex_dump(SF t0, numBytes_pfc_project_PFC_Mission);\n\n    \/* alternative using logInfo.  Commented out as the constructed String may be too large\n    DeclNewString(from_producer_data_str);\n    String__append(SF (String) &from_producer_data_str, string(\"Received data on data port from_producer_data: \"));\n    byte_array_string(SF (String) &from_producer_data_str, t0, numBytes_pfc_project_PFC_Mission);\n    api_logInfo__pfc_project_PFC_Filter_proc_filter(SF (String) &from_producer_data_str);\n    *\/\n  }\n\n  if(api_get_from_producer_event__pfc_project_PFC_Filter_proc_filter(SF_LAST )){\n    printf(\"%s: Received event on from_producer_event\\n\", component_id);\n\n    \/* alternative using logInfo.  Commented out as the constructed String may be too large\n    String from_producer_event_str = string(\"Received event on event port from_producer_event\");\n    api_logInfo__pfc_project_PFC_Filter_proc_filter(SF from_producer_event_str);\n    *\/\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/c\/ext-c\/Filter_proc_filter\/Filter_proc_filter_api.h",
        {
          "type" : "ITestResource",
          "content" : "#ifndef FILTER_PROC_FILTER_API_H\n#define FILTER_PROC_FILTER_API_H\n\n#include <all.h>\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\nbool api_get_from_producer_data__pfc_project_PFC_Filter_proc_filter(\n  STACK_FRAME\n  size_t *numBits,\n  uint8_t *byteArray);\n\nvoid api_put_to_consumer__pfc_project_PFC_Filter_proc_filter(\n  STACK_FRAME\n  size_t numBits,\n  uint8_t *byteArray);\n\nbool api_get_from_producer_event__pfc_project_PFC_Filter_proc_filter(STACK_FRAME_ONLY);\n\nvoid api_logInfo__pfc_project_PFC_Filter_proc_filter(\n  STACK_FRAME\n  String str);\n\nvoid api_logDebug__pfc_project_PFC_Filter_proc_filter(\n  STACK_FRAME\n  String str);\n\nvoid api_logError__pfc_project_PFC_Filter_proc_filter(\n  STACK_FRAME\n  String str);\n\n#endif\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/c\/ext-c\/Filter_proc_filter\/Filter_proc_filter_api.c",
        {
          "type" : "ITestResource",
          "content" : "#include <Filter_proc_filter_api.h>\n#include <Filter_proc_filter.h>\n\nstatic bool apis_initialized = false;\nstatic struct pfc_project_PFC_Filter_Initialization_Api initialization_api;\nstatic struct pfc_project_PFC_Filter_Operational_Api operational_api;\n\nstatic void initialize_apis(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter.c\", \"\", \"initialize_apis\", 0);\n\n  \/\/ Option_9757CA = Option[pfc_project.PFC.Filter_Initialization_Api]\n  Option_9757CA_get_(SF (pfc_project_PFC_Filter_Initialization_Api) &initialization_api, pfc_project_PFC_Filter_proc_filter_Bridge_c_initialization_api(SF_LAST));\n  \/\/ Option_742339 = Option[pfc_project.PFC.Filter_Operational_Api]\n  Option_742339_get_(SF (pfc_project_PFC_Filter_Operational_Api) &operational_api, pfc_project_PFC_Filter_proc_filter_Bridge_c_operational_api(SF_LAST));\n  apis_initialized = true;\n}\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\nbool api_get_from_producer_data__pfc_project_PFC_Filter_proc_filter(\n  STACK_FRAME\n  size_t *numBits,\n  uint8_t *byteArray){\n  DeclNewStackFrame(caller, \"Filter_proc_filter_api.c\", \"\", \"api_get_from_producer_data__pfc_project_PFC_Filter_proc_filter\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  \/\/ Option_30119F = Option[IS[Z, B]]\n  \/\/ Some_8D03B1 = Some[IS[Z, B]]\n  DeclNewOption_30119F(t_0);\n\n  pfc_project_PFC_Filter_Operational_Api_get_from_producer_data_(\n    SF\n    (Option_30119F) &t_0,\n    &operational_api);\n\n  if(t_0.type == TSome_8D03B1){\n    *numBits = t_0.Some_8D03B1.value.size;\n    if(*numBits > 0) {\n      size_t numBytes = (*numBits - 1) \/ 8 + 1;\n      memcpy(byteArray, &t_0.Some_8D03B1.value.value, numBytes);\n    }\n    return true;\n  } else {\n    return false;\n  }\n}\n\nvoid api_put_to_consumer__pfc_project_PFC_Filter_proc_filter(\n  STACK_FRAME\n  size_t numBits,\n  uint8_t *byteArray) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter_api.c\", \"\", \"api_put_to_consumer__pfc_project_PFC_Filter_proc_filter\", 0);\n\n  sfAssert((Z) numBits >= 0, \"numBits must be non-negative for IS[Z, B].\")\n  sfAssert((Z) numBits <= MaxIS_C4F575, \"numBits too large for IS[Z, B].\")\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  DeclNewIS_C4F575(t_0);\n\n  t_0.size = numBits;\n  if(numBits > 0) {\n    size_t numBytes = (numBits - 1) \/ 8 + 1;\n    memcpy(&t_0.value, byteArray, numBytes);\n  }\n\n  pfc_project_PFC_Filter_Initialization_Api_put_to_consumer_(\n    SF\n    &initialization_api,\n    &t_0);\n}\n\nbool api_get_from_producer_event__pfc_project_PFC_Filter_proc_filter(STACK_FRAME_ONLY){\n  DeclNewStackFrame(caller, \"Filter_proc_filter_api.c\", \"\", \"api_get_from_producer_event__pfc_project_PFC_Filter_proc_filter\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  \/\/ Option_C622DB = Option[art.Empty]\n  \/\/ Some_4782C6 = Some[art.Empty]\n  DeclNewOption_C622DB(t_0);\n  pfc_project_PFC_Filter_Operational_Api_get_from_producer_event_(\n    SF\n    (Option_C622DB) &t_0,\n    &operational_api);\n\n  if(t_0.type == TSome_4782C6){\n    return true;\n  } else {\n    return false;\n  }\n}\n\nvoid api_logInfo__pfc_project_PFC_Filter_proc_filter(\n  STACK_FRAME\n  String str) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter_api.c\", \"\", \"api_logInfo__pfc_project_PFC_Filter_proc_filter\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  pfc_project_PFC_Filter_Initialization_Api_logInfo_(\n    SF\n    &initialization_api,\n    str);\n}\n\nvoid api_logDebug__pfc_project_PFC_Filter_proc_filter(\n  STACK_FRAME\n  String str) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter_api.c\", \"\", \"api_logDebug__pfc_project_PFC_Filter_proc_filter\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  pfc_project_PFC_Filter_Initialization_Api_logDebug_(\n    SF\n    &initialization_api,\n    str);\n}\n\nvoid api_logError__pfc_project_PFC_Filter_proc_filter(\n  STACK_FRAME\n  String str) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter_api.c\", \"\", \"api_logError__pfc_project_PFC_Filter_proc_filter\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  pfc_project_PFC_Filter_Initialization_Api_logError_(\n    SF\n    &initialization_api,\n    str);\n}\n\nUnit pfc_project_PFC_Filter_proc_filter_initialise(\n  STACK_FRAME\n  pfc_project_PFC_Filter_Initialization_Api api) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter_api.c\", \"\", \"pfc_project_PFC_Filter_proc_filter_initialise\", 0);\n\n  pfc_project_PFC_Filter_proc_filter_initialise_(SF_LAST);\n}\n\nUnit pfc_project_PFC_Filter_proc_filter_finalise(\n  STACK_FRAME\n  pfc_project_PFC_Filter_Operational_Api api) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter_api.c\", \"\", \"pfc_project_PFC_Filter_proc_filter_finalise\", 0);\n\n  pfc_project_PFC_Filter_proc_filter_finalise_(SF_LAST);\n}\n\nUnit pfc_project_PFC_Filter_proc_filter_timeTriggered(\n  STACK_FRAME\n  pfc_project_PFC_Filter_Operational_Api api) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter_api.c\", \"\", \"pfc_project_PFC_Filter_proc_filter_timeTriggered\", 0);\n\n  pfc_project_PFC_Filter_proc_filter_timeTriggered_(SF_LAST);\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/c\/etc_seL4\/adapters\/Filter_proc_filter\/Filter_proc_filter_adapter.c",
        {
          "type" : "ITestResource",
          "content" : "#include <Filter_proc_filter_adapter.h>\n\nUnit pfc_project_PFC_Filter_proc_filter_adapter_initialiseArchitecture(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter_adapter.c\", \"\", \"pfc_project_PFC_Filter_proc_filter_adapter_initialiseArchitecture\", 0);\n\n  pfc_project_Filter_proc_filter_filter_initialiseArchitecture(SF_LAST);\n}\n\nUnit pfc_project_PFC_Filter_proc_filter_adapter_initialiseEntryPoint(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter_adapter.c\", \"\", \"pfc_project_PFC_Filter_proc_filter_adapter_initialiseEntryPoint\", 0);\n\n  pfc_project_Filter_proc_filter_filter_initialiseEntryPoint(SF_LAST);\n}\n\nUnit pfc_project_PFC_Filter_proc_filter_adapter_computeEntryPoint(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter_adapter.c\", \"\", \"pfc_project_PFC_Filter_proc_filter_adapter_computeEntryPoint\", 0);\n\n  pfc_project_Filter_proc_filter_filter_computeEntryPoint(SF_LAST);\n}\n\nart_Bridge_EntryPoints pfc_project_PFC_Filter_proc_filter_adapter_entryPoints(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter_adapter.c\", \"\", \"pfc_project_PFC_Filter_proc_filter_adapter_entryPoints\", 0);\n\n  return pfc_project_Filter_proc_filter_filter_entryPoints(SF_LAST);\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/c\/etc_seL4\/adapters\/Filter_proc_filter\/Filter_proc_filter_adapter.h",
        {
          "type" : "ITestResource",
          "content" : "#ifndef FILTER_PROC_FILTER_ADAPTER_H\n#define FILTER_PROC_FILTER_ADAPTER_H\n\n#include <all.h>\n\nUnit pfc_project_PFC_Filter_proc_filter_adapter_initialiseArchitecture(STACK_FRAME_ONLY);\n\nUnit pfc_project_PFC_Filter_proc_filter_adapter_initialiseEntryPoint(STACK_FRAME_ONLY);\n\nUnit pfc_project_PFC_Filter_proc_filter_adapter_computeEntryPoint(STACK_FRAME_ONLY);\n\nart_Bridge_EntryPoints pfc_project_PFC_Filter_proc_filter_adapter_entryPoints(STACK_FRAME_ONLY);\n\n#endif\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/bin\/settings_Filter_proc_filter.cmake",
        {
          "type" : "ITestResource",
          "content" : "add_definitions(-DCAMKES)\n\nif(TARGET muslc)\n  target_link_libraries(Filter_proc_filter\n                        muslc)\nendif()",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/seL4Nix\/pfc_project\/Consumer_proc_consumer\/consumer.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\npackage pfc_project.Consumer_proc_consumer\n\nimport org.sireum._\nimport art._\nimport art.Art.BridgeId._\nimport art.Art.PortId._\nimport art.DispatchPropertyProtocol._\nimport art.PortMode._\nimport pfc_project._\nimport pfc_project.PFC.Consumer_proc_consumer_seL4Nix\n\nobject consumer extends App {\n\n  val consumerBridge : pfc_project.PFC.Consumer_proc_consumer_Bridge = {\n    val from_filter = Port[Base_Types.Bits] (id = portId\"0\", name = \"PFC_Sys_Impl_Instance_proc_consumer_from_filter\", mode = EventIn)\n\n    pfc_project.PFC.Consumer_proc_consumer_Bridge(\n      id = bridgeId\"0\",\n      name = \"PFC_Sys_Impl_Instance_proc_consumer\",\n      dispatchProtocol = Sporadic(min = 1),\n      dispatchTriggers = None(),\n\n      from_filter = from_filter\n    )\n  }\n\n  val entryPoints: Bridge.EntryPoints = consumerBridge.entryPoints\n  val noData: Option[DataContent] = None()\n\n  \/\/ from_filter: In EventDataPort Base_Types.Bits\n  val from_filter_id: Art.PortId = consumerBridge.from_filter.id\n  var from_filter_port: Option[DataContent] = noData\n\n  def dispatchStatus(bridgeId: Art.BridgeId): DispatchStatus = {\n    var portIds: ISZ[Art.PortId] = IS()\n    if(!Consumer_proc_consumer_seL4Nix.from_filter_IsEmpty()) {\n      portIds = portIds :+ from_filter_id\n    }\n    return EventTriggered(portIds)\n  }\n\n  def getValue(portId: Art.PortId): Option[DataContent] = {\n    if(portId == from_filter_id) {\n      return from_filter_port\n    } else {\n      halt(s\"Unexpected: consumer.getValue called with: ${portId}\")\n    }\n  }\n\n  def receiveInput(eventPortIds: ISZ[Art.PortId], dataPortIds: ISZ[Art.PortId]): Unit = {\n    \/\/ ignore params\n\n    from_filter_port = Consumer_proc_consumer_seL4Nix.from_filter_Receive()\n  }\n\n  def putValue(portId: Art.PortId, data: DataContent): Unit = {\n    halt(s\"Unexpected: consumer.putValue called with: ${portId}\")\n  }\n\n  def sendOutput(eventPortIds: ISZ[Art.PortId], dataPortIds: ISZ[Art.PortId]): Unit = {\n    \/\/ ignore params\n\n\n  }\n\n  def initialiseArchitecture(): Unit = {\n    \/\/ nothing to do - CAmkES is responsible for initialization\n  }\n\n  def initialiseEntryPoint(): Unit = { entryPoints.initialise() }\n\n  def computeEntryPoint(): Unit = { entryPoints.compute() }\n\n  def finaliseEntryPoint(): Unit = { entryPoints.finalise() }\n\n  def main(args: ISZ[String]): Z = {\n\n    \/\/ need to touch the following for transpiler\n    initialiseArchitecture()\n    initialiseEntryPoint()\n    computeEntryPoint()\n    finaliseEntryPoint()\n\n    touch()\n\n    return 0\n  }\n\n  def touch(): Unit = {\n    if(F) {\n      TranspilerToucher.touch()\n\n      \/\/ add types used in Platform.receive and Platform.receiveAsync\n      val mbox2Boolean_Payload: MBox2[Art.PortId, DataContent] = MBox2(portId\"0\", Base_Types.Boolean_Payload(T))\n      val mbox2OptionDataContent: MBox2[Art.PortId, Option[DataContent]] = MBox2(portId\"0\", None())\n\n      \/\/ touch each payload\/type in case some are only used as a field in a record\n      def printDataContent(a: art.DataContent): Unit = { println(s\"${a}\") }\n\n      printDataContent(Base_Types.Bits_Payload(Base_Types.Bits_example()))\n      printDataContent(art.Empty())\n\n      pfc_project.PFC.Consumer_proc_consumer_Bridge.c_initialization_api.get.logInfo(\"\")\n      pfc_project.PFC.Consumer_proc_consumer_Bridge.c_initialization_api.get.logDebug(\"\")\n      pfc_project.PFC.Consumer_proc_consumer_Bridge.c_initialization_api.get.logError(\"\")\n      pfc_project.PFC.Consumer_proc_consumer_Bridge.c_operational_api.get.logInfo(\"\")\n      pfc_project.PFC.Consumer_proc_consumer_Bridge.c_operational_api.get.logDebug(\"\")\n      pfc_project.PFC.Consumer_proc_consumer_Bridge.c_operational_api.get.logError(\"\")\n      val apiUsage_from_filter: Option[Base_Types.Bits] = pfc_project.PFC.Consumer_proc_consumer_Bridge.c_operational_api.get.get_from_filter()\n    }\n  }\n\n  def logInfo(title: String, msg: String): Unit = {\n    print(consumerBridge.name)\n    print(\": \")\n    println(msg)\n  }\n\n  def logError(title: String, msg: String): Unit = {\n    eprint(consumerBridge.name)\n    eprint(\": \")\n    eprintln(msg)\n  }\n\n  def logDebug(title: String, msg: String): Unit = {\n    print(consumerBridge.name)\n    print(\": \")\n    println(msg)\n  }\n\n  def run(): Unit = {}\n\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/seL4Nix\/pfc_project\/PFC\/Consumer_proc_consumer_seL4Nix.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\npackage pfc_project.PFC\n\nimport org.sireum._\nimport art._\n\n@ext object Consumer_proc_consumer_seL4Nix {\n  \/\/ returns T if seL4's from_filter port is empty, F otherwise \n  def from_filter_IsEmpty(): B = $\n\n  \/\/ returns result of dequeuing seL4's from_filter port \n  def from_filter_Receive(): Option[DataContent] = $\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/seL4Nix\/pfc_project\/PFC\/Consumer_proc_consumer_seL4Nix_Ext.scala",
        {
          "type" : "ITestResource",
          "content" : "package pfc_project.PFC\n\nimport org.sireum._\nimport art._\n\nobject Consumer_proc_consumer_seL4Nix_Ext {\n  def from_filter_IsEmpty(): B = halt(\"stub\")\n\n  def from_filter_Receive(): Option[DataContent] = halt(\"stub\")\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/c\/ext-c\/Consumer_proc_consumer\/Consumer_proc_consumer.h",
        {
          "type" : "ITestResource",
          "content" : "#ifndef CONSUMER_PROC_CONSUMER_H\n#define CONSUMER_PROC_CONSUMER_H\n\n#include <all.h>\n\nUnit pfc_project_PFC_Consumer_proc_consumer_initialise_(STACK_FRAME_ONLY);\n\nUnit pfc_project_PFC_Consumer_proc_consumer_finalise_(STACK_FRAME_ONLY);\n\nUnit pfc_project_PFC_Consumer_proc_consumer_handle_from_filter_(\n  STACK_FRAME\n  IS_C4F575 value);\n\n#endif\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/c\/ext-c\/Consumer_proc_consumer\/Consumer_proc_consumer.c",
        {
          "type" : "ITestResource",
          "content" : "#include <Consumer_proc_consumer_api.h>\n#include <Consumer_proc_consumer.h>\n#include <ext.h>\n\n\/\/ This file will not be overwritten so is safe to edit\n\nstatic char* component_id = \"PFC_Sys_Impl_Instance_proc_consumer\";\n\nUnit pfc_project_PFC_Consumer_proc_consumer_initialise_(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer.c\", \"\", \"pfc_project_PFC_Consumer_proc_consumer_initialise_\", 0);\n\n  printf(\"%s: pfc_project_PFC_Consumer_proc_consumer_initialise_ called\\n\", component_id);\n\n  \/\/ example usage of api setters\n\n\n  \/* example usage of api loggers. Commented out as the constructed String may be too long\n  api_logInfo__pfc_project_PFC_Consumer_proc_consumer(SF string(\"Example logInfo\"));\n\n  api_logDebug__pfc_project_PFC_Consumer_proc_consumer(SF string(\"Example logDebug\"));\n\n  api_logError__pfc_project_PFC_Consumer_proc_consumer(SF string(\"Example logError\"));\n  *\/\n}\n\nUnit pfc_project_PFC_Consumer_proc_consumer_finalise_(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer.c\", \"\", \"pfc_project_PFC_Consumer_proc_consumer_finalise_\", 0);\n}\n\nUnit pfc_project_PFC_Consumer_proc_consumer_handle_from_filter_raw(\n  STACK_FRAME\n  size_t numBits,\n  uint8_t *byteArray) {\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer_api.c\", \"\", \"pfc_project_PFC_Consumer_proc_consumer_handle_from_filter_raw\", 0);\n\n  size_t numBytes = numBits == 0 ? 0 : (numBits - 1) \/ 8 + 1;\n\n  printf(\"%s: pfc_project_PFC_Consumer_proc_consumer_handle_from_filter_raw called with payload: \\n\", component_id);\n  hex_dump(SF byteArray, numBytes);\n\n  \/* alternative using logInfo.  Commented out as the constructed String may be too large\n  DeclNewString(from_filterString);\n  String__append(SF (String) &from_filterString, string(\"pfc_project_PFC_Consumer_proc_consumer_handle_from_filter_raw called with payload: \"));\n  byte_array_string(SF (String) &from_filterString, byteArray, numBytes);\n  api_logInfo__pfc_project_PFC_Consumer_proc_consumer (SF (String) &from_filterString);\n  *\/\n}\n\nUnit pfc_project_PFC_Consumer_proc_consumer_handle_from_filter_(\n  STACK_FRAME\n  IS_C4F575 value) {\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer.c\", \"\", \"pfc_project_PFC_Consumer_proc_consumer_handle_from_filter_\", 0);\n\n  pfc_project_PFC_Consumer_proc_consumer_handle_from_filter_raw(SF value->size, value->value);\n\n  \/\/ examples of api getter usage\n\n  uint8_t t0[numBytes_pfc_project_PFC_Mission];\n  size_t t0_numBits;\n  if(api_get_from_filter__pfc_project_PFC_Consumer_proc_consumer(SF &t0_numBits, t0)) {\n    \/\/ sanity check\n    sfAssert((Z) t0_numBits == numBits_pfc_project_PFC_Mission, \"numBits received does not match expected\")\n\n    printf(\"%s: Received data on event data port from_filter: \\n\", component_id);\n    hex_dump(SF t0, numBytes_pfc_project_PFC_Mission);\n\n    \/* alternative using logInfo.  Commented out as the constructed String may be too large\n    DeclNewString(from_filter_str);\n    String__append(SF (String) &from_filter_str, string(\"Received data on event data port from_filter: \"));\n    byte_array_string(SF (String) &from_filter_str, t0, numBytes_pfc_project_PFC_Mission);\n    api_logInfo__pfc_project_PFC_Consumer_proc_consumer(SF (String) &from_filter_str);\n    *\/\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/c\/ext-c\/Consumer_proc_consumer\/Consumer_proc_consumer_api.h",
        {
          "type" : "ITestResource",
          "content" : "#ifndef CONSUMER_PROC_CONSUMER_API_H\n#define CONSUMER_PROC_CONSUMER_API_H\n\n#include <all.h>\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\nbool api_get_from_filter__pfc_project_PFC_Consumer_proc_consumer(\n  STACK_FRAME\n  size_t *numBits,\n  uint8_t *byteArray);\n\nvoid api_logInfo__pfc_project_PFC_Consumer_proc_consumer(\n  STACK_FRAME\n  String str);\n\nvoid api_logDebug__pfc_project_PFC_Consumer_proc_consumer(\n  STACK_FRAME\n  String str);\n\nvoid api_logError__pfc_project_PFC_Consumer_proc_consumer(\n  STACK_FRAME\n  String str);\n\n#endif\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/c\/ext-c\/Consumer_proc_consumer\/Consumer_proc_consumer_api.c",
        {
          "type" : "ITestResource",
          "content" : "#include <Consumer_proc_consumer_api.h>\n#include <Consumer_proc_consumer.h>\n\nstatic bool apis_initialized = false;\nstatic struct pfc_project_PFC_Consumer_Initialization_Api initialization_api;\nstatic struct pfc_project_PFC_Consumer_Operational_Api operational_api;\n\nstatic void initialize_apis(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer.c\", \"\", \"initialize_apis\", 0);\n\n  \/\/ Option_904684 = Option[pfc_project.PFC.Consumer_Initialization_Api]\n  Option_904684_get_(SF (pfc_project_PFC_Consumer_Initialization_Api) &initialization_api, pfc_project_PFC_Consumer_proc_consumer_Bridge_c_initialization_api(SF_LAST));\n  \/\/ Option_EA1873 = Option[pfc_project.PFC.Consumer_Operational_Api]\n  Option_EA1873_get_(SF (pfc_project_PFC_Consumer_Operational_Api) &operational_api, pfc_project_PFC_Consumer_proc_consumer_Bridge_c_operational_api(SF_LAST));\n  apis_initialized = true;\n}\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\nbool api_get_from_filter__pfc_project_PFC_Consumer_proc_consumer(\n  STACK_FRAME\n  size_t *numBits,\n  uint8_t *byteArray){\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer_api.c\", \"\", \"api_get_from_filter__pfc_project_PFC_Consumer_proc_consumer\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  \/\/ Option_30119F = Option[IS[Z, B]]\n  \/\/ Some_8D03B1 = Some[IS[Z, B]]\n  DeclNewOption_30119F(t_0);\n\n  pfc_project_PFC_Consumer_Operational_Api_get_from_filter_(\n    SF\n    (Option_30119F) &t_0,\n    &operational_api);\n\n  if(t_0.type == TSome_8D03B1){\n    *numBits = t_0.Some_8D03B1.value.size;\n    if(*numBits > 0) {\n      size_t numBytes = (*numBits - 1) \/ 8 + 1;\n      memcpy(byteArray, &t_0.Some_8D03B1.value.value, numBytes);\n    }\n    return true;\n  } else {\n    return false;\n  }\n}\n\nvoid api_logInfo__pfc_project_PFC_Consumer_proc_consumer(\n  STACK_FRAME\n  String str) {\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer_api.c\", \"\", \"api_logInfo__pfc_project_PFC_Consumer_proc_consumer\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  pfc_project_PFC_Consumer_Initialization_Api_logInfo_(\n    SF\n    &initialization_api,\n    str);\n}\n\nvoid api_logDebug__pfc_project_PFC_Consumer_proc_consumer(\n  STACK_FRAME\n  String str) {\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer_api.c\", \"\", \"api_logDebug__pfc_project_PFC_Consumer_proc_consumer\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  pfc_project_PFC_Consumer_Initialization_Api_logDebug_(\n    SF\n    &initialization_api,\n    str);\n}\n\nvoid api_logError__pfc_project_PFC_Consumer_proc_consumer(\n  STACK_FRAME\n  String str) {\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer_api.c\", \"\", \"api_logError__pfc_project_PFC_Consumer_proc_consumer\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  pfc_project_PFC_Consumer_Initialization_Api_logError_(\n    SF\n    &initialization_api,\n    str);\n}\n\nUnit pfc_project_PFC_Consumer_proc_consumer_initialise(\n  STACK_FRAME\n  pfc_project_PFC_Consumer_Initialization_Api api) {\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer_api.c\", \"\", \"pfc_project_PFC_Consumer_proc_consumer_initialise\", 0);\n\n  pfc_project_PFC_Consumer_proc_consumer_initialise_(SF_LAST);\n}\n\nUnit pfc_project_PFC_Consumer_proc_consumer_finalise(\n  STACK_FRAME\n  pfc_project_PFC_Consumer_Operational_Api api) {\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer_api.c\", \"\", \"pfc_project_PFC_Consumer_proc_consumer_finalise\", 0);\n\n  pfc_project_PFC_Consumer_proc_consumer_finalise_(SF_LAST);\n}\n\nUnit pfc_project_PFC_Consumer_proc_consumer_handle_from_filter(\n  STACK_FRAME\n  pfc_project_PFC_Consumer_Operational_Api api,\n  IS_C4F575 value) {\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer_api.c\", \"\", \"pfc_project_PFC_Consumer_proc_consumer_handle_from_filter\", 0);\n\n  pfc_project_PFC_Consumer_proc_consumer_handle_from_filter_(SF value);\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/c\/etc_seL4\/adapters\/Consumer_proc_consumer\/Consumer_proc_consumer_adapter.c",
        {
          "type" : "ITestResource",
          "content" : "#include <Consumer_proc_consumer_adapter.h>\n\nUnit pfc_project_PFC_Consumer_proc_consumer_adapter_initialiseArchitecture(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer_adapter.c\", \"\", \"pfc_project_PFC_Consumer_proc_consumer_adapter_initialiseArchitecture\", 0);\n\n  pfc_project_Consumer_proc_consumer_consumer_initialiseArchitecture(SF_LAST);\n}\n\nUnit pfc_project_PFC_Consumer_proc_consumer_adapter_initialiseEntryPoint(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer_adapter.c\", \"\", \"pfc_project_PFC_Consumer_proc_consumer_adapter_initialiseEntryPoint\", 0);\n\n  pfc_project_Consumer_proc_consumer_consumer_initialiseEntryPoint(SF_LAST);\n}\n\nUnit pfc_project_PFC_Consumer_proc_consumer_adapter_computeEntryPoint(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer_adapter.c\", \"\", \"pfc_project_PFC_Consumer_proc_consumer_adapter_computeEntryPoint\", 0);\n\n  pfc_project_Consumer_proc_consumer_consumer_computeEntryPoint(SF_LAST);\n}\n\nart_Bridge_EntryPoints pfc_project_PFC_Consumer_proc_consumer_adapter_entryPoints(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer_adapter.c\", \"\", \"pfc_project_PFC_Consumer_proc_consumer_adapter_entryPoints\", 0);\n\n  return pfc_project_Consumer_proc_consumer_consumer_entryPoints(SF_LAST);\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/c\/etc_seL4\/adapters\/Consumer_proc_consumer\/Consumer_proc_consumer_adapter.h",
        {
          "type" : "ITestResource",
          "content" : "#ifndef CONSUMER_PROC_CONSUMER_ADAPTER_H\n#define CONSUMER_PROC_CONSUMER_ADAPTER_H\n\n#include <all.h>\n\nUnit pfc_project_PFC_Consumer_proc_consumer_adapter_initialiseArchitecture(STACK_FRAME_ONLY);\n\nUnit pfc_project_PFC_Consumer_proc_consumer_adapter_initialiseEntryPoint(STACK_FRAME_ONLY);\n\nUnit pfc_project_PFC_Consumer_proc_consumer_adapter_computeEntryPoint(STACK_FRAME_ONLY);\n\nart_Bridge_EntryPoints pfc_project_PFC_Consumer_proc_consumer_adapter_entryPoints(STACK_FRAME_ONLY);\n\n#endif\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/bin\/settings_Consumer_proc_consumer.cmake",
        {
          "type" : "ITestResource",
          "content" : "add_definitions(-DCAMKES)\n\nif(TARGET muslc)\n  target_link_libraries(Consumer_proc_consumer\n                        muslc)\nendif()",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/c\/ext-c\/ext.c",
        {
          "type" : "ITestResource",
          "content" : "#include <ext.h>\n\n\/\/ This file will not be overwritten so is safe to edit\n\n\/\/ add c extension code here\n\n\/\/ example method that sets the first numBits bits of byteArray to 1\nvoid byte_array_default(STACK_FRAME uint8_t* byteArray, size_t numBits, size_t numBytes) {\n  DeclNewStackFrame(caller, \"ext.c\", \"\", \"byte_array_default\", 0);\n\n  sfAssert((numBits - 1) \/ 8  + 1 <= numBytes, \"byte_array_default: numBytes * 8 must be at least numBits\")\n\n  for(size_t byte = 0; byte < numBytes; byte++) {\n    uint8_t v = 0;\n    for(uint8_t bit = 0; bit < 8; bit++) {\n      if(byte * 8 + bit < numBits) {\n        v |= 1UL << bit;\n      }\n    }\n    byteArray[byte] = v;\n  }\n}\n\n\/\/ example method that places the hex value of the bytes in byteArray into str\nvoid byte_array_string(STACK_FRAME String str, uint8_t* byteArray, size_t numBytes) {\n  DeclNewStackFrame(caller, \"ext.c\", \"\", \"byte_array_string\", 0);\n\n  sfAssert((str->size + numBytes) <= MaxString, \"byte_array_string: Insufficient maximum for String characters, consider increasing the --max-string-size option\")\n\n  for(size_t byte = 0; byte < numBytes; byte++) {\n    U8_string_(SF str, byteArray[byte]);\n    String__append(SF str, string(\" \"));\n  }\n}\n\n\/\/ example method that directly prints the hex values of the bytes in byte_array\nvoid hex_dump(STACK_FRAME uint8_t* byte_array, size_t numBytes) {\n  DeclNewStackFrame(caller, \"ext.c\", \"\", \"hex_dump\", 0);\n\n  printf(\"[ \");\n  for(size_t byte = 0; byte < numBytes; byte++) {\n    if(byte != 0 && byte % 16 == 0) { printf(\"\\n  \"); }\n    printf(\"%02X \", byte_array[byte]);\n  }\n  printf(\"]\\n\");\n}",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/c\/ext-c\/ext.h",
        {
          "type" : "ITestResource",
          "content" : "#ifndef EXT_H\n#define EXT_H\n\n\/\/ This file will not be overwritten so is safe to edit\n\n#include <all.h>\n\n\/\/ bit-codec size for pfc_project_PFC_Mission\n#define numBits_pfc_project_PFC_Mission 288\n#define numBytes_pfc_project_PFC_Mission ((numBits_pfc_project_PFC_Mission - 1) \/ 8 + 1)\n\nvoid byte_array_default(STACK_FRAME uint8_t* byteArray, size_t numBits, size_t numBytes);\n\nvoid byte_array_string(STACK_FRAME String str, uint8_t* byteArray, size_t numBytes);\n\nvoid hex_dump(STACK_FRAME uint8_t* byte_array, size_t numBytes);\n#endif",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/seL4Nix\/pfc_project\/SlangTypeLibrary\/SlangTypeLibrary.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage pfc_project.SlangTypeLibrary\n\nimport org.sireum._\nimport art._\nimport pfc_project._\n\nobject SlangTypeLibrary extends App {\n  def main(args: ISZ[String]): Z = {\n\n    \/\/ touch each payload\/type in case some are only used as a field in a record\n    def printDataContent(a: art.DataContent): Unit = { println(s\"${a}\") }\n\n    printDataContent(Base_Types.Bits_Payload(Base_Types.Bits_example()))\n    printDataContent(art.Empty())\n\n    return 0\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/bin\/settings_SlangTypeLibrary.cmake",
        {
          "type" : "ITestResource",
          "content" : "add_definitions(-DCAMKES)\n\nif(TARGET muslc)\n  target_link_libraries(SlangTypeLibrary\n                        muslc)\nendif()",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/bin\/transpile-sel4.cmd",
        {
          "type" : "ITestResource",
          "content" : "::\/*#! 2> \/dev\/null                                   #\r\n@ 2>\/dev\/null # 2>nul & echo off & goto BOF           #\r\nif [ -z ${SIREUM_HOME} ]; then                        #\r\n  echo \"Please set SIREUM_HOME env var\"               #\r\n  exit -1                                             #\r\nfi                                                    #\r\nexec ${SIREUM_HOME}\/bin\/sireum slang run \"$0\" \"$@\"    #\r\n:BOF\r\nsetlocal\r\nif not defined SIREUM_HOME (\r\n  echo Please set SIREUM_HOME env var\r\n  exit \/B -1\r\n)\r\n%SIREUM_HOME%\\\\bin\\\\sireum.bat slang run \"%0\" %*\r\nexit \/B %errorlevel%\r\n::!#*\/\r\n\/\/ #Sireum\r\n\r\nimport org.sireum._\r\n\r\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\r\n\r\nval SCRIPT_HOME: Os.Path = Os.slashDir\r\nval PATH_SEP: String = Os.pathSep\r\n\r\nval Producer_proc_producer: ISZ[String] = ISZ(\r\n  \"--sourcepath\", s\"${SCRIPT_HOME}\/..\/src\/main\/bridge${PATH_SEP}${SCRIPT_HOME}\/..\/src\/main\/component${PATH_SEP}${SCRIPT_HOME}\/..\/src\/main\/seL4Nix\/pfc_project\/PFC${PATH_SEP}${SCRIPT_HOME}\/..\/src\/main\/art${PATH_SEP}${SCRIPT_HOME}\/..\/src\/main\/data${PATH_SEP}${SCRIPT_HOME}\/..\/src\/main\/seL4Nix\/pfc_project\/Producer_proc_producer\",\r\n  \"--output-dir\", s\"${SCRIPT_HOME}\/..\/..\/camkes\/slang_libraries\/Producer_proc_producer\",\r\n  \"--name\", \"Producer_proc_producer\",\r\n  \"--apps\", \"pfc_project.Producer_proc_producer.producer\",\r\n  \"--fingerprint\", \"3\",\r\n  \"--bits\", \"64\",\r\n  \"--string-size\", \"300\",\r\n  \"--sequence-size\", \"1\",\r\n  \"--sequence\", s\"MS[Z,Option[art.Bridge]]=1;IS[Z,art.UPort]=2;IS[Z,art.Art.PortId]=2;IS[Z,B]=288\",\r\n  \"--constants\", s\"art.Art.numComponents=1;art.Art.numPorts=2;art.Art.numConnections=1\",\r\n  \"--cmake-includes\", s\"+${SCRIPT_HOME}\/settings_Producer_proc_producer.cmake\",\r\n  \"--forward\", \"art.ArtNative=pfc_project.Producer_proc_producer.producer\",\r\n  \"--stack-size\", \"61440\",\r\n  \"--stable-type-id\",\r\n  \"--exts\", s\"${SCRIPT_HOME}\/..\/src\/c\/ext-c\/ext.c${PATH_SEP}${SCRIPT_HOME}\/..\/src\/c\/ext-c\/ext.h${PATH_SEP}${SCRIPT_HOME}\/..\/src\/c\/ext-c\/Producer_proc_producer\/Producer_proc_producer.h${PATH_SEP}${SCRIPT_HOME}\/..\/src\/c\/ext-c\/Producer_proc_producer\/Producer_proc_producer.c${PATH_SEP}${SCRIPT_HOME}\/..\/src\/c\/ext-c\/Producer_proc_producer\/Producer_proc_producer_api.h${PATH_SEP}${SCRIPT_HOME}\/..\/src\/c\/ext-c\/Producer_proc_producer\/Producer_proc_producer_api.c${PATH_SEP}${SCRIPT_HOME}\/..\/src\/c\/etc_seL4\/adapters\/Producer_proc_producer\/Producer_proc_producer_adapter.h${PATH_SEP}${SCRIPT_HOME}\/..\/src\/c\/etc_seL4\/adapters\/Producer_proc_producer\/Producer_proc_producer_adapter.c\",\r\n  \"--exclude-build\", \"pfc_project.PFC.Producer_proc_producer,pfc_project.PFC.Filter_proc_filter,pfc_project.PFC.Consumer_proc_consumer\",\r\n  \"--lib-only\")\r\n\r\nval Filter_proc_filter: ISZ[String] = ISZ(\r\n  \"--sourcepath\", s\"${SCRIPT_HOME}\/..\/src\/main\/bridge${PATH_SEP}${SCRIPT_HOME}\/..\/src\/main\/component${PATH_SEP}${SCRIPT_HOME}\/..\/src\/main\/seL4Nix\/pfc_project\/PFC${PATH_SEP}${SCRIPT_HOME}\/..\/src\/main\/art${PATH_SEP}${SCRIPT_HOME}\/..\/src\/main\/data${PATH_SEP}${SCRIPT_HOME}\/..\/src\/main\/seL4Nix\/pfc_project\/Filter_proc_filter\",\r\n  \"--output-dir\", s\"${SCRIPT_HOME}\/..\/..\/camkes\/slang_libraries\/Filter_proc_filter\",\r\n  \"--name\", \"Filter_proc_filter\",\r\n  \"--apps\", \"pfc_project.Filter_proc_filter.filter\",\r\n  \"--fingerprint\", \"3\",\r\n  \"--bits\", \"64\",\r\n  \"--string-size\", \"300\",\r\n  \"--sequence-size\", \"1\",\r\n  \"--sequence\", s\"MS[Z,Option[art.Bridge]]=1;IS[Z,art.UPort]=2;IS[Z,art.Art.PortId]=2;IS[Z,B]=288\",\r\n  \"--constants\", s\"art.Art.numComponents=1;art.Art.numPorts=3;art.Art.numConnections=1\",\r\n  \"--cmake-includes\", s\"+${SCRIPT_HOME}\/settings_Filter_proc_filter.cmake\",\r\n  \"--forward\", \"art.ArtNative=pfc_project.Filter_proc_filter.filter\",\r\n  \"--stack-size\", \"61440\",\r\n  \"--stable-type-id\",\r\n  \"--exts\", s\"${SCRIPT_HOME}\/..\/src\/c\/ext-c\/ext.c${PATH_SEP}${SCRIPT_HOME}\/..\/src\/c\/ext-c\/ext.h${PATH_SEP}${SCRIPT_HOME}\/..\/src\/c\/ext-c\/Filter_proc_filter\/Filter_proc_filter.h${PATH_SEP}${SCRIPT_HOME}\/..\/src\/c\/ext-c\/Filter_proc_filter\/Filter_proc_filter.c${PATH_SEP}${SCRIPT_HOME}\/..\/src\/c\/ext-c\/Filter_proc_filter\/Filter_proc_filter_api.h${PATH_SEP}${SCRIPT_HOME}\/..\/src\/c\/ext-c\/Filter_proc_filter\/Filter_proc_filter_api.c${PATH_SEP}${SCRIPT_HOME}\/..\/src\/c\/etc_seL4\/adapters\/Filter_proc_filter\/Filter_proc_filter_adapter.h${PATH_SEP}${SCRIPT_HOME}\/..\/src\/c\/etc_seL4\/adapters\/Filter_proc_filter\/Filter_proc_filter_adapter.c\",\r\n  \"--exclude-build\", \"pfc_project.PFC.Producer_proc_producer,pfc_project.PFC.Filter_proc_filter,pfc_project.PFC.Consumer_proc_consumer\",\r\n  \"--lib-only\")\r\n\r\nval Consumer_proc_consumer: ISZ[String] = ISZ(\r\n  \"--sourcepath\", s\"${SCRIPT_HOME}\/..\/src\/main\/bridge${PATH_SEP}${SCRIPT_HOME}\/..\/src\/main\/component${PATH_SEP}${SCRIPT_HOME}\/..\/src\/main\/seL4Nix\/pfc_project\/PFC${PATH_SEP}${SCRIPT_HOME}\/..\/src\/main\/art${PATH_SEP}${SCRIPT_HOME}\/..\/src\/main\/data${PATH_SEP}${SCRIPT_HOME}\/..\/src\/main\/seL4Nix\/pfc_project\/Consumer_proc_consumer\",\r\n  \"--output-dir\", s\"${SCRIPT_HOME}\/..\/..\/camkes\/slang_libraries\/Consumer_proc_consumer\",\r\n  \"--name\", \"Consumer_proc_consumer\",\r\n  \"--apps\", \"pfc_project.Consumer_proc_consumer.consumer\",\r\n  \"--fingerprint\", \"3\",\r\n  \"--bits\", \"64\",\r\n  \"--string-size\", \"300\",\r\n  \"--sequence-size\", \"1\",\r\n  \"--sequence\", s\"MS[Z,Option[art.Bridge]]=1;IS[Z,art.UPort]=1;IS[Z,art.Art.PortId]=1;IS[Z,B]=288\",\r\n  \"--constants\", s\"art.Art.numComponents=1;art.Art.numPorts=1;art.Art.numConnections=1\",\r\n  \"--cmake-includes\", s\"+${SCRIPT_HOME}\/settings_Consumer_proc_consumer.cmake\",\r\n  \"--forward\", \"art.ArtNative=pfc_project.Consumer_proc_consumer.consumer\",\r\n  \"--stack-size\", \"61440\",\r\n  \"--stable-type-id\",\r\n  \"--exts\", s\"${SCRIPT_HOME}\/..\/src\/c\/ext-c\/ext.c${PATH_SEP}${SCRIPT_HOME}\/..\/src\/c\/ext-c\/ext.h${PATH_SEP}${SCRIPT_HOME}\/..\/src\/c\/ext-c\/Consumer_proc_consumer\/Consumer_proc_consumer.h${PATH_SEP}${SCRIPT_HOME}\/..\/src\/c\/ext-c\/Consumer_proc_consumer\/Consumer_proc_consumer.c${PATH_SEP}${SCRIPT_HOME}\/..\/src\/c\/ext-c\/Consumer_proc_consumer\/Consumer_proc_consumer_api.h${PATH_SEP}${SCRIPT_HOME}\/..\/src\/c\/ext-c\/Consumer_proc_consumer\/Consumer_proc_consumer_api.c${PATH_SEP}${SCRIPT_HOME}\/..\/src\/c\/etc_seL4\/adapters\/Consumer_proc_consumer\/Consumer_proc_consumer_adapter.h${PATH_SEP}${SCRIPT_HOME}\/..\/src\/c\/etc_seL4\/adapters\/Consumer_proc_consumer\/Consumer_proc_consumer_adapter.c\",\r\n  \"--exclude-build\", \"pfc_project.PFC.Producer_proc_producer,pfc_project.PFC.Filter_proc_filter,pfc_project.PFC.Consumer_proc_consumer\",\r\n  \"--lib-only\")\r\n\r\nval SlangTypeLibrary: ISZ[String] = ISZ(\r\n  \"--sourcepath\", s\"${SCRIPT_HOME}\/..\/src\/main\/art${PATH_SEP}${SCRIPT_HOME}\/..\/src\/main\/data${PATH_SEP}${SCRIPT_HOME}\/..\/src\/main\/seL4Nix\/pfc_project\/SlangTypeLibrary\",\r\n  \"--output-dir\", s\"${SCRIPT_HOME}\/..\/..\/camkes\/slang_libraries\/SlangTypeLibrary\",\r\n  \"--name\", \"SlangTypeLibrary\",\r\n  \"--apps\", \"pfc_project.SlangTypeLibrary.SlangTypeLibrary\",\r\n  \"--fingerprint\", \"3\",\r\n  \"--bits\", \"64\",\r\n  \"--string-size\", \"300\",\r\n  \"--sequence-size\", \"1\",\r\n  \"--sequence\", s\"IS[Z,B]=288\",\r\n  \"--cmake-includes\", s\"+${SCRIPT_HOME}\/settings_SlangTypeLibrary.cmake\",\r\n  \"--forward\", \"art.ArtNative=pfc_project.SlangTypeLibrary.SlangTypeLibrary\",\r\n  \"--stack-size\", \"16777216\",\r\n  \"--stable-type-id\",\r\n  \"--lib-only\")\r\n\r\nval projects: ISZ[ISZ[String]] = ISZ(\r\n  Producer_proc_producer,\r\n  Filter_proc_filter,\r\n  Consumer_proc_consumer,\r\n  SlangTypeLibrary\r\n)\r\n\r\nprintln(\"Initializing runtime library ...\")\r\nSireum.initRuntimeLibrary()\r\n\r\nvar result = 0\r\nfor(p <- projects if result == 0) {\r\n  result = Sireum.run(ISZ[String](\"slang\", \"transpilers\", \"c\") ++ p)\r\n}\r\n\r\n\/\/ops.ISZOps(projects).parMap(p =>\r\n\/\/  Sireum.run(ISZ[String](\"slang\", \"transpilers\", \"c\") ++ p)\r\n\/\/)\r\n\r\nOs.exit(result)\r\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : true,
          "makeCRLF" : true,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/architecture\/pfc_project\/Platform.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage pfc_project\n\nimport org.sireum._\n\n\/\/ This file will not be overwritten so is safe to edit\n\nobject Platform {\n\n  def setup(): Unit = {\n    \/\/ BEGIN MARKER PLATFORM SETUP\n    \/\/ END MARKER PLATFORM SETUP\n  }\n\n  def tearDown(): Unit = {\n    \/\/ BEGIN MARKER PLATFORM TEARDOWN\n    \/\/ END MARKER PLATFORM TEARDOWN\n  }\n}",
          "markers" : [
            {
              "type" : "TestMarker",
              "beginMarker" : "\/\/ BEGIN MARKER PLATFORM SETUP",
              "endMarker" : "\/\/ END MARKER PLATFORM SETUP"
            },
            {
              "type" : "TestMarker",
              "beginMarker" : "\/\/ BEGIN MARKER PLATFORM TEARDOWN",
              "endMarker" : "\/\/ END MARKER PLATFORM TEARDOWN"
            }
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/ArchitectureDescription.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art\n\nimport org.sireum._\n\n\n@datatype class ArchitectureDescription(components: IS[Art.BridgeId, Bridge],\n                                        connections: IS[Art.ConnectionId, UConnection]) {\n  @spec val allPorts: ISZ[UPort] = $\n\n  @spec def allPortsSpec(i: Z): ISZ[UPort] = $\n  \/*\n    l\"\"\"\n    = base:  ISZ[UPort](), if i == 0\n    = rec:   components(i).ports.all ++ allPorts(i - 1), if 0 < i \u2227 i < components.size\n  \"\"\"\n\n  l\"\"\" invariant\n\n         AllPorts:\n           allPorts \u2261 allPortsSpec(components.size - 1)\n\n         ComponentIdUnique:\n           \u2200i: [0, components.size)\n             \u2200j: [0, components.size)\n               i \u2260 j \u2192 components(i).id \u2260 components(j).id\n\n         PortIdUnique:\n           \u2200i: [0, allPorts.size)\n             \u2200j: [0, allPorts.size)\n               i \u2260 j \u2192 allPorts(i).id \u2260 allPorts(j).id\n   \"\"\"\n  *\/\n}\n\n@datatype trait UConnection {\n  \/*\n  l\"\"\" invariant\n         FromPortOut:   from.mode \u2261 PortMode.DataOut \u2228 from.mode \u2261 PortMode.EventOut\n         DataPort:    (from.mode \u2261 PortMode.DataOut) \u2261 (to.mode \u2261 PortMode.DataIn)\n         EventPort:  (from.mode \u2261 PortMode.EventOut) \u2261 (to.mode \u2261 PortMode.EventIn)  \"\"\"\n  *\/\n\n  def from: UPort\n\n  def to: UPort\n}\n\n@datatype class Connection(val from: UPort, val to: UPort)\n  extends UConnection\n\n\n@enum object PortMode {\n  'DataIn\n  'DataOut\n  'EventIn\n  'EventOut\n}\n\n@datatype trait UPort {\n  def id: Art.PortId\n\n  def name: String\n\n  def mode: PortMode.Type\n}\n\n@datatype trait PortProto extends UPort\n\n@datatype class Port[T](val id: Art.PortId,\n                        val name: String,\n                        val mode: PortMode.Type)\n  extends PortProto\n\n@datatype trait UrgentPortProto extends UPort {\n  def urgency: Z\n}\n\n@datatype class UrgentPort[T](val id: Art.PortId,\n                              val name: String,\n                              val mode: PortMode.Type,\n                              val urgency: Z)\n  extends UrgentPortProto\n\n@sig trait Bridge {\n  def id: Art.BridgeId\n\n  def name: String\n\n  def ports: Bridge.Ports\n\n  def entryPoints: Bridge.EntryPoints\n\n  def dispatchProtocol: DispatchPropertyProtocol\n}\n\n\nobject Bridge {\n\n  \/\/ initialise()  ( compute() | activate() deactivate() | recover() )* finalise()\n  @sig trait EntryPoints {\n\n    def initialise(): Unit\n\n    def activate(): Unit\n\n    def deactivate(): Unit\n\n    def compute(): Unit\n\n    def recover(): Unit\n\n    def finalise(): Unit\n\n    def testCompute(): Unit = {\n      println(\"Default testCompute\")\n    }\n\n    def testInitialise(): Unit = {\n      println(\"Default testInitialise\")\n    }\n  }\n\n  @datatype class Ports(dataIns: ISZ[UPort],\n                        dataOuts: ISZ[UPort],\n                        eventIns: ISZ[UPort],\n                        eventOuts: ISZ[UPort])\n\n}\n\n\n@datatype trait DispatchPropertyProtocol\n\nobject DispatchPropertyProtocol {\n\n  @datatype class Periodic(period: Z) extends DispatchPropertyProtocol\n\n  \/\/ @datatype class Aperiodic() extends DispatchPropertyProtocol\n\n  @datatype class Sporadic(min: Z) extends DispatchPropertyProtocol\n\n  \/\/ @datatype class Timed() extends DispatchPropertyProtocol\n\n  \/\/ @datatype class Hybrid() extends DispatchPropertyProtocol\n}\n\n@datatype trait DispatchStatus\n\n@datatype class TimeTriggered() extends DispatchStatus\n\n@datatype class EventTriggered(portIds: ISZ[Art.PortId]) extends DispatchStatus",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/Art.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art\n\nimport org.sireum._\nimport art.scheduling.Scheduler\n\nobject Art {\n\n  @range(min = 0, max = 2, index = T) class BridgeId\n\n  @range(min = 0, max = 5, index = T) class PortId\n\n  @range(min = 0, max = 2, index = T) class ConnectionId\n\n  type Time = S64 \/\/ Z might be too small after transpiling\n\n  val numComponents: Z = 3\n  val numPorts: Z = 6\n  val numConnections: Z = 3\n\n  val logTitle: String = \"Art\"\n\n  val bridges: MSZ[Option[Bridge]] = MS.create(numComponents, None[Bridge]())\n  val ports: MS[Art.PortId, Option[UPort]] = MS.create[Art.PortId, Option[UPort]](numPorts, None[UPort]())\n  val connections: MS[Art.PortId, IS[Art.ConnectionId, Art.PortId]] = MS.create[Art.PortId, IS[Art.ConnectionId, Art.PortId]](numPorts, IS())\n\n  \/\/ Note on transpiling:\n  \/\/ ports and connections are not touched\/transpiled when targeting seL4. Bridges\n  \/\/ are isolated when transpiling so BridgeId.Max could be 0, but changing Min\/Max is\n  \/\/ not currently supported by the transpiler so instead bridges is defined as an MSZ\n  \/\/ so that that its size can be set to 1 and thus reduce stack space requirements\n\n\n  @pure def bridge(bridgeId: Art.BridgeId): Bridge = {\n    return bridges(bridgeId.toZ).get\n  }\n\n  @pure def port(p: Art.PortId): UPort = {\n    return ports(p).get\n  }\n\n  def register(bridge: Bridge): Unit = {\n    bridges(bridge.id.toZ) = Some(bridge)\n    bridge.dispatchProtocol match {\n      case DispatchPropertyProtocol.Periodic(period) =>\n        ArtNative.logInfo(logTitle, s\"Registered component: ${bridge.name} (periodic: $period)\")\n      case DispatchPropertyProtocol.Sporadic(min) =>\n        ArtNative.logInfo(logTitle, s\"Registered component: ${bridge.name} (sporadic: $min)\")\n    }\n\n    def r(uports: ISZ[UPort]): Unit = {\n      for (port <- uports) {\n        ports(port.id) = Some(port)\n        \/* transpiler does not emit an extractor for matches in nested functions\n        port.mode match {\n          case PortMode.DataIn => ArtNative.logInfo(logTitle, s\"- Registered port: ${port.name} (data in)\")\n          case PortMode.DataOut => ArtNative.logInfo(logTitle, s\"- Registered port: ${port.name} (data out)\")\n          case PortMode.EventIn => ArtNative.logInfo(logTitle, s\"- Registered port: ${port.name} (event in)\")\n          case PortMode.EventOut => ArtNative.logInfo(logTitle, s\"- Registered port: ${port.name} (event out)\")\n        }\n        *\/\n        val typ: String = if (port.mode == PortMode.DataIn) \"(data in)\" else if (port.mode == PortMode.DataOut) \"(data out)\" else if (port.mode == PortMode.EventOut) \"(event out)\" else if (port.mode == PortMode.EventIn) \"(event in)\" else \"(infeasible)\"\n        ArtNative.logInfo(logTitle, s\"- Registered port: ${port.name} $typ\")\n      }\n    }\n\n    r(bridge.ports.dataIns)\n    r(bridge.ports.dataOuts)\n    r(bridge.ports.eventIns)\n    r(bridge.ports.eventOuts)\n  }\n\n  \/\/ can't find definition in the standard ??\n  def dispatchStatus(bridgeId: Art.BridgeId): DispatchStatus = { \/\/ DISPATCH_STATUS\n    return ArtNative.dispatchStatus(bridgeId)\n  }\n\n  def receiveInput(eventPortIds: ISZ[Art.PortId], dataPortIds: ISZ[Art.PortId]): Unit = { \/\/ RECEIVE_INPUT\n    ArtNative.receiveInput(eventPortIds, dataPortIds)\n  }\n\n  def putValue(portId: PortId, data: DataContent): Unit = { \/\/ PUT_VALUE\n    ArtNative.putValue(portId, data)\n  }\n\n  def getValue(portId: PortId): Option[DataContent] = { \/\/ GET_VALUE\n    return ArtNative.getValue(portId)\n  }\n\n  def sendOutput(eventPortIds: ISZ[Art.PortId], dataPortIds: ISZ[Art.PortId]): Unit = { \/\/ SEND_OUTPUT\n    ArtNative.sendOutput(eventPortIds, dataPortIds)\n  }\n\n  \/** The seL4 platform doesn't use the bridges data structure and its\n    * version of the loggers ignore the 'title' parameter. Not pattern matching\n    * here as that adds an Option to the stack which increases the stack size.\n    *\/\n  def logInfo(bridgeId: Art.BridgeId, msg: String): Unit = {\n    if (bridges(bridgeId.toZ).nonEmpty) {\n      ArtNative.logInfo(bridges(bridgeId.toZ).get.name, msg)\n    } else {\n      ArtNative.logInfo(\"\", msg)\n    }\n  }\n\n  def logError(bridgeId: Art.BridgeId, msg: String): Unit = {\n    if (bridges(bridgeId.toZ).nonEmpty) {\n      ArtNative.logError(bridges(bridgeId.toZ).get.name, msg)\n    } else {\n      ArtNative.logError(\"\", msg)\n    }\n  }\n\n  def logDebug(bridgeId: Art.BridgeId, msg: String): Unit = {\n    if (bridges(bridgeId.toZ).nonEmpty) {\n      ArtNative.logDebug(bridges(bridgeId.toZ).get.name, msg)\n    } else {\n      ArtNative.logDebug(\"\", msg)\n    }\n  }\n\n  def connect(from: UPort, to: UPort): Unit = {\n    connections(from.id) = connections(from.id) :+ to.id\n    ArtNative.logInfo(logTitle, s\"Connected ports: ${from.name} -> ${to.name}\")\n  }\n\n  \/\/ JH: Refactor\n  \/\/ Define explicit assemble phase (to support both test and execution modes)\n  def assemble(system: ArchitectureDescription): Unit = {\n    for (component <- system.components) {\n      register(component)\n    }\n\n    for (connection <- system.connections) {\n      connect(connection.from, connection.to)\n    }\n  }\n\n  def run(system: ArchitectureDescription,\n          scheduler: Scheduler): Unit = {\n\n    assemble(system)\n\n    setUpArchitecture()\n    setUpPlatform()\n    setUpSystemState(scheduler)\n\n    initializePhase(scheduler)\n    computePhase(scheduler)\n    finalizePhase(scheduler)\n\n    tearDownSystemState()\n    tearDownPlatform()\n    tearDownArchitecture()\n  }\n\n  def initializePhase(scheduler: Scheduler): Unit = {\n    ArtNative.initializePhase()\n    scheduler.initializationPhase()\n  }\n\n  def computePhase(scheduler: Scheduler): Unit = {\n    ArtNative.computePhase()\n    scheduler.computePhase()\n  }\n\n  def finalizePhase(scheduler: Scheduler): Unit = {\n    ArtNative.finalizePhase()\n    scheduler.finalizePhase()\n  }\n\n  def setUpArchitecture(): Unit = {}\n\n  def tearDownArchitecture(): Unit = {}\n\n  def setUpPlatform(): Unit = {}\n\n  def tearDownPlatform(): Unit = {}\n\n  def setUpSystemState(scheduler: Scheduler): Unit = {\n    ArtNative.setUpSystemState()\n    scheduler.initialize()\n  }\n\n  def tearDownSystemState(): Unit = {\n    ArtNative.tearDownSystemState()\n  }\n\n  def time(): Time = {\n    return ArtNative.time()\n  }\n\n  \/\/\/\/\/\/\/\/\/\/\/\/\/\n  \/\/ TESTING \/\/\n  \/\/\/\/\/\/\/\/\/\/\/\/\/\n\n  \/**\n   * Clears any existing ports and bridges, then sets up ports\/bridges for the next test.\n   *\n   * Automatically called by BridgeTestSuite before each test.\n   *\/\n  def initTest(bridge: Bridge): Unit = {\n    \/\/ remove all bridges\n    for (i <- bridges.indices) {\n      bridges(i) = None()\n    }\n\n    \/\/ remove all connections\n    for (i <- connections.indices) {\n      connections(i) = IS()\n    }\n\n    \/\/ remove all ports\n    for (i <- ports.indices) {\n      ports(i) = None()\n    }\n\n    \/\/ register bridge passed to this method\n    register(bridge)\n\n    \/\/ call ArtNative to reset the state of the specific thread component\n    ArtNative.initTest(bridge)\n  }\n\n  \/**\n  * Executes a component (identified by bridge) Initialize Entry Point (application code)\n  * for the purposes of unit testing.\n  *\n  * This infrastructure method is called with automatically generated unit testing support code.\n  * The developer-facing version of this method (called by a developer unit test)\n  * provided by the unit testing support code hides the bridge argument.  The bridge\n  * value is retrieved from the testing infrastructure code before passing the call\n  * through to this method.\n  *\/\n  def testInitialise(bridge: Bridge): Unit = {\n    ArtNative.testInitialise(bridge)\n  }\n\n  \/**\n   * Executes a component (identified by bridge) Compute Entry Point (application code)\n   * for the purposes of unit testing.\n   *\n   * This infrastructure method is called with automatically generated unit testing support code.\n   * The developer-facing version of this method (called by a developer unit test)\n   * provided by the unit testing support code hides the bridge argument.  The bridge\n   * value is retrieved from the testing infrastructure code before passing the call\n   * through to this method.\n   *\/\n  def testCompute(bridge: Bridge): Unit = {\n    ArtNative.testCompute(bridge)\n  }\n\n\n  def finalizeTest(bridge: Bridge): Unit = {\n    ArtNative.finalizeTest(bridge)\n  }\n\n  \/\/ JH: Refactored\n  \/\/   add system test capability\n  def initSystemTest(system: ArchitectureDescription,\n                     scheduler: Scheduler): Unit = {\n    \/\/ remove all bridges\n    for (i <- bridges.indices) {\n      bridges(i) = None()\n    }\n\n    \/\/ remove all ports\n    for (i <- ports.indices) {\n      ports(i) = None()\n    }\n    \/\/ It seems to me that it might be best to do this once and for all (not for every test) as it is really\n    \/\/ a static description of the model that will not be changing.\n    assemble(system)\n\n    \/\/ let ArtNative reset itself as well\n    ArtNative.initSystemTest(scheduler)\n  }\n\n  \/\/  def executeSystemTest(): Unit = {\n  \/\/    ArtNative.executeTest()\n  \/\/  }\n\n  \/\/ JH: Refactored\n  \/\/   add system test capability\n  def finalizeSystemTest(): Unit = {\n    ArtNative.finalizeSystemTest()\n  }\n\n  def releaseOutput(eventPortIds: ISZ[Art.PortId], dataPortIds: ISZ[Art.PortId]): Unit = {\n    ArtNative.releaseOutput(eventPortIds, dataPortIds)\n  }\n\n  def manuallyClearOutput(): Unit = {\n    ArtNative.manuallyClearOutput()\n  }\n\n  def insertInInfrastructurePort(dstPortId: Art.PortId, data: DataContent): Unit = {\n    ArtNative.insertInInfrastructurePort(dstPortId, data)\n  }\n\n  def observeInInfrastructurePort(portId: Art.PortId): Option[DataContent] = {\n    return ArtNative.observeInInfrastructurePort(portId)\n  }\n\n  def observeOutInfrastructurePort(portId: Art.PortId): Option[DataContent] = {\n    return ArtNative.observeOutInfrastructurePort(portId)\n  }\n\n  def observeInPortVariable(portId: Art.PortId): Option[DataContent] = {\n    return ArtNative.observeInPortVariable(portId)\n  }\n\n  def observeOutPortVariable(portId: Art.PortId): Option[DataContent] = {\n    return ArtNative.observeOutPortVariable(portId)\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/ArtDebug.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art\n\nimport org.sireum._\n\n@ext object ArtDebug {\n\n  def injectPort(bridgeId: Art.BridgeId, port: Art.PortId, data: DataContent): Unit = $\n\n  def registerListener(listener: ArtListener): Unit = $\n\n  def setDebugObject[T](key: String, o: T): Unit = $\n\n  def getDebugObject[T](key: String): Option[T] = $\n}\n\n@msig trait ArtListener {\n\n  \/\/ lifecycle information\n  def start(time: Art.Time): Unit\n\n  def stop(time: Art.Time): Unit\n\n  \/\/ communication information\n  def output(src: Art.PortId, dst: Art.PortId, data: DataContent, time: Art.Time): Unit\n\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/ArtDebug_Ext.scala",
        {
          "type" : "ITestResource",
          "content" : "package art\n\nimport org.sireum._\nimport art.Art.Time\nimport scala.collection.mutable.{Map => MMap, Set => MSet}\n\nobject ArtDebug_Ext {\n  private val debugObjects: MMap[String, Any] = ArtNative_Ext.concMap()\n  private val listeners: MSet[ArtListener] = concSet()\n\n  protected[art] def start(): Unit = {\n    val time = Art.time()\n    listeners.foreach((listener: ArtListener) => listener.start(time))\n  }\n\n  protected[art] def stop(): Unit = {\n    val time = Art.time()\n    listeners.foreach((listener: ArtListener) => listener.stop(time))\n  }\n\n  protected[art] def outputCallback(src: Art.PortId, dst: Art.PortId, data: DataContent, time: Time): Unit = {\n    listeners.foreach((listener: ArtListener) => listener.output(src, dst, data, time))\n  }\n\n  def setDebugObject[T](key: String, o: T): Unit = {\n    ArtNative.logDebug(Art.logTitle, s\"Set debug object for $key\")\n    debugObjects(key) = o\n  }\n\n  def getDebugObject[T](key: String): Option[T] = {\n    debugObjects.get(key) match {\n      case scala.Some(o) => Some(o.asInstanceOf[T])\n      case _ => None[T]()\n    }\n  }\n\n  def injectPort(bridgeId: Art.BridgeId, port: Art.PortId, data: DataContent): Unit = {\n\n    val bridge = Art.bridges(bridgeId.toZ).get\n\n    if (bridge.ports.dataOuts.elements.map(_.id).contains(port) ||\n      bridge.ports.eventOuts.elements.map(_.id).contains(port)) {\n\n      ArtNative.logDebug(Art.logTitle, s\"Injecting from port ${Art.ports(port).get.name}\")\n\n      ArtNative.putValue(port, data)\n\n      ArtNative.sendOutput(bridge.ports.eventOuts.map(_.id), bridge.ports.dataOuts.map(_.id))\n    } else {\n      ArtNative.logDebug(Art.logTitle, s\"Injecting to port ${Art.ports(port).get.name}\")\n\n      \/\/ right now, there is no difference between treatment of data and event ports, but keep the logic\n      \/\/ separate for further refactoring\n      if (bridge.ports.dataIns.elements.map(_.id).contains(port)) {\n        ArtNative_Ext.inInfrastructurePorts(port.toZ) = ArtMessage(data)\n      } else {\n        ArtNative_Ext.inInfrastructurePorts(port.toZ) = ArtMessage(data)\n      }\n    }\n  }\n\n  def registerListener(listener: ArtListener): Unit = {\n    listeners.add(listener)\n  }\n\n  def concSet[K](): MSet[K] = {\n    import org.sireum.$internal.CollectionCompat.Converters._\n    val m: java.util.Set[K] = java.util.concurrent.ConcurrentHashMap.newKeySet()\n    m.asScala\n  }\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/ArtNative.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art\n\nimport org.sireum._\nimport art.scheduling.Scheduler\n\n@ext object ArtNative {\n\n  def shouldDispatch(bridgeId: Art.BridgeId): B = $\n\n  def dispatchStatus(bridgeId: Art.BridgeId): DispatchStatus = $\n\n\n  def receiveInput(eventPortIds: ISZ[Art.PortId], dataPortIds: ISZ[Art.PortId]): Unit = $\n\n  def putValue(portId: Art.PortId, data: DataContent): Unit = $\n\n  def getValue(portId: Art.PortId): Option[DataContent] = $\n\n  def sendOutput(eventPortIds: ISZ[Art.PortId], dataPortIds: ISZ[Art.PortId]): Unit = $\n\n\n  def logInfo(title: String, msg: String): Unit = $\n\n  def logError(title: String, msg: String): Unit = $\n\n  def logDebug(title: String, msg: String): Unit = $\n\n\n  def tearDownSystemState(): Unit = $\n\n  def setUpSystemState(): Unit = $\n\n  \/\/ JH: Refactor\n  def initializePhase(): Unit = $\n\n  \/\/ JH: Refactor\n  def computePhase(): Unit = $\n\n  \/\/ JH: Refactor\n  def finalizePhase(): Unit = $\n\n  def time(): Art.Time = $\n\n  \/\/\/\/\/\/\/\/\/\/\/\/\/\n  \/\/ TESTING \/\/\n  \/\/\/\/\/\/\/\/\/\/\/\/\/\n\n  \/**\n   * Calls the initialize entry points on all registered bridges.\n   *\n   * An analogue to this method does not show up in developer-written unit tests because\n   * the it's invoked behind the scenes by the automatically generated unit test infrastructure\n   * as a prelude to each test.\n   *\n   *\/\n  def initTest(bridge: Bridge): Unit = $\n\n  \/**\n   * Executes the application code in the Initialize Entry Point for the component (identified\n   * by given bridge) for the purposes of testing.\n   *\n   * Precondition: testInit() has been called prior.\n   *\n   * Unlike [[Art.run()]], this method does NOT wrap compute calls in a try-catch block.\n   * This is to ensure no exceptions are overlooked during testing.\n  *\/\n  def testInitialise(bridge: Bridge): Unit = $\n\n  \/**\n   * Executes the application code in the Compute Entry Point for the component (identified\n   * by given bridge) for the purposes of testing.\n   *\n   * Precondition: initTest() has been called prior.\n   *\n   * Unlike [[Art.run()]], this method does NOT wrap compute calls in a try-catch block.\n   * This is to ensure no exceptions are overlooked during testing.\n   *\/\n  def testCompute(bridge: Bridge): Unit = $\n\n  \/**\n   * Calls the finalize entry points on all registered bridges.\n   *\n   * An analogue to this method does not show up in developer-written unit tests because\n   * the it's invoked behind the scenes by the automatically generated unit test infrastructure\n   * as a postlude to each test.\n   *\/\n  def finalizeTest(bridge: Bridge): Unit = $\n\n  \/\/ JH: Refactored\n  \/\/   add system test capability\n  def initSystemTest(scheduler: Scheduler): Unit = $\n\n  \/\/  def executeSystemTest(): Unit = $\n\n  \/\/ JH: Refactored\n  \/\/   add system test capability\n  def finalizeSystemTest(): Unit = $\n\n  \/**\n   * A method that replaces bridge.compute()'s calls to [[Art.sendOutput()]] in its equivalent testCompute() method.\n   *\n   * This method is currently a NO-OP, but may gain functionality later.\n   *\n   * @param eventPortIds the event ports to be \"copied and cleared\" (but currently nothing happens)\n   * @param dataPortIds the data ports to be \"copied and cleared\" (but currently nothing happens)\n   *\/\n  def releaseOutput(eventPortIds: ISZ[Art.PortId], dataPortIds: ISZ[Art.PortId]): Unit = $\n\n  \/**\n   * Because a bridge's testCompute() doesn't clear outputs, this method can be used by users to manually\n   * clear the output if desired. This is useful for tests involving multiple dispatches.\n   *\/\n  def manuallyClearOutput(): Unit = $\n\n  \/**\n   * Inserts a value into an \"infrastructure in\" port. For testing only, normally this is handled by Art.\n   *\n   * @param dstPortId the portId to place the passed [[DataContent]] into\n   * @param data the [[DataContent]] which will be placed in the dstPort\n   *\/\n  def insertInInfrastructurePort(dstPortId: Art.PortId, data: DataContent): Unit = $\n\n  \/**\n   * Returns the value of an infrastructure in port.\n   *\n   * @param portId the id of the INPUT infrastructure port to return a value from\n   * @return If the port is non-empty, a [[Some]] of [[DataContent]]. Otherwise [[None]].\n   *\/\n  def observeInInfrastructurePort(portId: Art.PortId): Option[DataContent] = $\n\n  \/**\n   * Returns the value of an infrastructure out port.\n   *\n   * @param portId the id of the OUTPUT port to return a value from\n   * @return If the port is non-empty, a [[Some]] of [[DataContent]]. Otherwise [[None]].\n   *\/\n  def observeOutInfrastructurePort(portId: Art.PortId): Option[DataContent] = $\n\n  \/**\n     * Returns the value of an application in port.\n     *\n     * @param portId the id of the INPUT port to return a value from\n     * @return If the port is non-empty, a [[Some]] of [[DataContent]]. Otherwise [[None]].\n     *\/\n  def observeInPortVariable(portId: Art.PortId): Option[DataContent] = $\n\n  \/**\n     * Returns the value of an application out port.\n     *\n     * @param portId the id of the OUTPUT port to return a value from\n     * @return If the port is non-empty, a [[Some]] of [[DataContent]]. Otherwise [[None]].\n     *\/\n  def observeOutPortVariable(portId: Art.PortId): Option[DataContent] = $\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/ArtNativeSlang.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art\n\nimport org.sireum._\nimport art.DispatchPropertyProtocol.{Periodic, Sporadic}\nimport org.sireum.S64._\n\nobject ArtSlangMessage {\n  val UNSET_TIME: Art.Time = s64\"-1\"\n}\n\n@datatype class ArtSlangMessage(data: DataContent,\n\n                                srcPortId: Art.PortId,\n                                dstPortId: Option[Art.PortId],\n\n                                \/\/ when putValue was called by producer\n                                putValueTimestamp: Art.Time,\n\n                                \/\/ when sendOutput transferred message from out port var of producer\n                                sendOutputTimestamp: Art.Time,\n\n                                \/\/ when message arrived via transport layer\n                                dstArrivalTimestamp: Art.Time,\n\n                                \/\/ when receiveInput transferred message to in port vars of consumer\n                                receiveInputTimestamp: Art.Time\n                               )\n\nobject ArtNativeSlang {\n\n  var inInfrastructurePorts: Map[Z, ArtSlangMessage] = Map.empty\n  var outInfrastructurePorts: Map[Z, ArtSlangMessage] = Map.empty\n  var inPortVariables: Map[Z, ArtSlangMessage] = Map.empty\n  var outPortVariables: Map[Z, ArtSlangMessage] = Map.empty\n\n  def shouldDispatch(bridgeId: Art.BridgeId): B = {\n    assert(Art.bridges(bridgeId.toZ).nonEmpty, s\"Bridge ${bridgeId} does not exist\")\n\n    Art.bridges(bridgeId.toZ).get.dispatchProtocol match {\n      case DispatchPropertyProtocol.Periodic(_) => return T\n      case DispatchPropertyProtocol.Sporadic(minRate) =>\n\n        val eventIns = Art.bridges(bridgeId.toZ).get.ports.eventIns\n\n        var hasEvents = F\n        \/\/ transpiler workaround -- doesn't support .exists\n        for (e <- eventIns) {\n          if (inInfrastructurePorts.contains(e.id.toZ)) {\n            hasEvents = T\n          }\n        }\n        return hasEvents\n    }\n  }\n\n  \/\/ transpiler friendly comparator\n  def lt(a: art.UPort, b: art.UPort): B = { \/\/ reverse sort\n    val r: B = (a, b) match {\n      \/\/ sorting function to make prioritized sequence of event port ids\n      \/\/   compare p1 to p2  (p1 represents the port to process earlier, i.e., should have priority)\n      case (p1: UrgentPortProto, p2: UrgentPortProto) =>\n        \/\/ if p1 has a strictly less urgency it comes after p2\n        if (p1.urgency < p2.urgency) F\n        \/\/ if p1 has a strictly greater urgency, it comes before p2\n        else if (p1.urgency > p2.urgency) T\n        \/\/ if p1 and p2 have the same urgency, the ordering is determined by arrival timestamps\n        else inInfrastructurePorts.get(p1.id.toZ).get.dstArrivalTimestamp < inInfrastructurePorts.get(p2.id.toZ).get.dstArrivalTimestamp\n      case (_: UrgentPortProto, _: PortProto) => T \/\/ urgent ports take precedence\n      case (_: PortProto, _: UrgentPortProto) => F \/\/ urgent ports take precedence\n      case (p1: PortProto, p2: PortProto) =>\n        inInfrastructurePorts.get(p1.id.toZ).get.dstArrivalTimestamp < inInfrastructurePorts.get(p2.id.toZ).get.dstArrivalTimestamp\n    }\n    return r\n  }\n\n  \/\/ transpiler friendly sort\n  def sort(ports: ISZ[UPort]): ISZ[UPort] = {\n    def insert(p: UPort, sorted: ISZ[UPort]): ISZ[UPort] = {\n      if (sorted.isEmpty) {\n        return ISZ[UPort](p)\n      }\n      else {\n        if (lt(sorted(0), p)) {\n          return sorted(0) +: insert(p, ops.ISZOps(sorted).tail)\n        }\n        else {\n          return p +: sorted\n        }\n      }\n    }\n\n    if (ports.isEmpty) {\n      return ports\n    }\n    else {\n      val sorted = sort(ops.ISZOps(ports).tail)\n      return insert(ports(0), sorted)\n    }\n  }\n\n  def dispatchStatus(bridgeId: Art.BridgeId): DispatchStatus = {\n    val ret: DispatchStatus = Art.bridges(bridgeId.toZ).get.dispatchProtocol match {\n      case Periodic(_) => TimeTriggered()\n      case Sporadic(_) =>\n        \/\/ get ids for non-empty input event ports\n        val uports: ISZ[UPort] =\n          for (p <- Art.bridges(bridgeId.toZ).get.ports.eventIns if inInfrastructurePorts.get(p.id.toZ).nonEmpty) yield p\n\n        if (uports.isEmpty) {\n          halt(s\"Unexpected: shouldDispatch() should have returned true in order to get here, however the incoming event ports are empty for bridge id ${bridgeId}\")\n        }\n\n        val urgentFifo = sort(uports)\n        EventTriggered(for (p <- urgentFifo) yield p.id)\n    }\n    return ret\n  }\n\n  def receiveInput(eventPortIds: ISZ[Art.PortId], dataPortIds: ISZ[Art.PortId]): Unit = {\n    \/\/ remove any old events from previous dispatch\n    for (portId <- eventPortIds if inPortVariables.contains(portId.toZ)) {\n      inPortVariables = inPortVariables - ((portId.toZ, inPortVariables.get(portId.toZ).get))\n    }\n\n    \/\/ transfer received data\/events from the infrastructure ports to the port variables\n    for (portId <- eventPortIds) {\n      inInfrastructurePorts.get(portId.toZ) match {\n        case Some(data) =>\n          inInfrastructurePorts = inInfrastructurePorts - ((portId.toZ, data))\n          inPortVariables = inPortVariables + (portId.toZ ~> data(receiveInputTimestamp = Art.time()))\n        case _ =>\n      }\n    }\n    for (portId <- dataPortIds) {\n      inInfrastructurePorts.get(portId.toZ) match {\n        case Some(data) =>\n          inPortVariables = inPortVariables + (portId.toZ ~> data)\n        case _ =>\n      }\n    }\n  }\n\n  def putValue(portId: Art.PortId, data: DataContent): Unit = {\n    \/\/ wrap the Art.DataContent value into an ArtMessage with time stamps\n    outPortVariables = outPortVariables + (portId.toZ ~>\n      ArtSlangMessage(data = data, srcPortId = portId, putValueTimestamp = Art.time(),\n        dstPortId = None(), sendOutputTimestamp = ArtSlangMessage.UNSET_TIME, dstArrivalTimestamp = ArtSlangMessage.UNSET_TIME, receiveInputTimestamp = ArtSlangMessage.UNSET_TIME))\n  }\n\n  def getValue(portId: Art.PortId): Option[DataContent] = {\n    \/\/ To return the value of the port to the application code, project\n    \/\/ out the actual payload value (v.data) from ArtMessage (which includes timestamps, etc.)\n    \/\/ to Art.DataContent (the \"top\"\/union data type supported by Art.\n    \/\/ The projecting preserves the option of structure of ArtMessage value.\n    if (inPortVariables.contains(portId.toZ)) {\n      return Some(inPortVariables.get(portId.toZ).get.data)\n    } else {\n      return None()\n    }\n  }\n\n  def sendOutput(eventPortIds: ISZ[Art.PortId], dataPortIds: ISZ[Art.PortId]): Unit = {\n    for (srcPortId <- eventPortIds ++ dataPortIds) {\n      outPortVariables.get(srcPortId.toZ) match {\n        case Some(msg) => {\n\n          \/\/ move payload from out port port variables to the out infrastructure ports\n          outInfrastructurePorts = outInfrastructurePorts + (srcPortId.toZ ~> msg)\n          outPortVariables = outPortVariables - ((srcPortId.toZ, msg))\n\n          \/\/ simulate sending msg via transport middleware\n          for (dstPortId <- Art.connections(srcPortId)) {\n            val _msg = msg(dstPortId = Some(dstPortId), sendOutputTimestamp = Art.time())\n\n            \/\/ send via middleware\n\n            inInfrastructurePorts = inInfrastructurePorts + (dstPortId.toZ ~>\n              _msg(dstArrivalTimestamp = Art.time()))\n          }\n\n          \/\/ payload delivered so remove it from out infrastructure port\n          outInfrastructurePorts = outInfrastructurePorts - ((srcPortId.toZ, msg))\n        }\n        case _ =>\n      }\n    }\n    \/\/ could clear outPortVariables for passed in portids but not strictly necessary\n  }\n\n  \/**\n   * Returns the value of an in infrastructure port.\n   *\n   * @param portId the id of the INPUT port to return a value from\n   * @return If the port is non-empty, a [[Some]] of [[DataContent]]. Otherwise [[None]].\n   *\/\n  def observeInInfrastructurePort(portId: Art.PortId): Option[DataContent] = {\n    \/\/ right now, with event data port queues limited to size one, there is no difference in the logic\n    \/\/ between how data ports are treated, and how event\/event data ports are treated.\n    Art.port(portId).mode match {\n      case PortMode.DataIn =>\n        inInfrastructurePorts.get(portId.toZ) match {\n          case Some(value) => return Some(value.data)\n          case _ => return None()\n        }\n      case PortMode.EventIn =>\n        inInfrastructurePorts.get(portId.toZ) match {\n          case Some(value) => return Some(value.data)\n          case _ => return None()\n        }\n      case _ => {\n        assert(false, \"expecting in port\")\n        return None()\n      }\n    }\n  }\n\n  \/**\n   * Returns the value of an infrastructure out port.\n   *\n   * @param portId the id of the OUTPUT port to return a value from\n   * @return If the port is non-empty, a [[Some]] of [[DataContent]]. Otherwise [[None]].\n   *\/\n  def observeOutInfrastructurePort(portId: Art.PortId): Option[DataContent] = {\n    \/\/ note: would be changed when we refactor to support event queues of size > 1\n    outInfrastructurePorts.get(portId.toZ) match {\n      case Some(value) => return Some(value.data)\n      case _ => return None()\n    }\n  }\n\n  \/**\n   * Returns the value of an application in port.\n   *\n   * @param portId the id of the INPUT port to return a value from\n   * @return If the port is non-empty, a [[Some]] of [[DataContent]]. Otherwise [[None]].\n   *\/\n  def observeInPortVariable(portId: Art.PortId): Option[DataContent] = {\n    \/\/ right now, with event data port queues limited to size one, there is no difference in the logic\n    \/\/ between how data ports are treated, and how event\/event data ports are treated.\n    Art.port(portId).mode match {\n      case PortMode.DataIn =>\n        inPortVariables.get(portId.toZ) match {\n          case Some(value) => return Some(value.data)\n          case _ => return None()\n        }\n      case PortMode.EventIn =>\n        inPortVariables.get(portId.toZ) match {\n          case Some(value) => return Some(value.data)\n          case _ => return None()\n        }\n      case _ => {\n        assert(false, \"expecting in port\")\n        return None()\n      }\n    }\n  }\n\n  \/**\n     * Returns the value of an application out port.\n     *\n     * @param portId the id of the OUTPUT port to return a value from\n     * @return If the port is non-empty, a [[Some]] of [[DataContent]]. Otherwise [[None]].\n     *\/\n  def observeOutPortVariable(portId: Art.PortId): Option[DataContent] = {\n    \/\/ note: would be changed when we refactor to support event queues of size > 1\n    outPortVariables.get(portId.toZ) match {\n      case Some(value) => return Some(value.data)\n      case _ => return None()\n    }\n  }\n\n  def logInfo(title: String, msg: String): Unit = {\n    print(title)\n    print(\": \")\n    println(msg)\n  }\n\n  def logDebug(title: String, msg: String): Unit = {\n    eprint(title)\n    eprint(\": \")\n    eprintln(msg)\n  }\n\n  def logError(title: String, msg: String): Unit = {\n    print(title)\n    print(\": \")\n    println(msg)\n  }\n\n\n  def setUpSystemState(): Unit = {\n    \/\/ probably nothing to do here\n  }\n\n  def tearDownSystemState(): Unit = {\n    \/\/ probably nothing to do here\n  }\n\n\n  def initializePhase(): Unit = {\n    \/\/ probably nothing to do here\n  }\n\n  def computePhase(): Unit = {\n    \/\/ probably nothing to do here\n  }\n\n  def finalizePhase(): Unit = {\n    \/\/ probably nothing to do here\n  }\n\n\n  def time(): Art.Time = {\n    return Process.time()\n  }\n}\n\n@ext(name = \"art.ArtNative_Ext\") object Process {\n  def time(): Art.Time = $\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/ArtNative_Ext.scala",
        {
          "type" : "ITestResource",
          "content" : "package art\n\nimport org.sireum._\nimport art.DispatchPropertyProtocol.{Periodic, Sporadic}\nimport art.scheduling.Scheduler\nimport org.sireum.S64._\nimport scala.collection.mutable.{Map => MMap}\n\nobject ArtMessage {\n  val UNSET_TIME: Art.Time = s64\"-1\"\n}\n\ncase class ArtMessage(data: DataContent,\n\n                      var srcPortId: Option[Art.PortId] = None(),\n                      var dstPortId: Option[Art.PortId] = None(),\n\n                      \/\/ when putValue was called by producer\n                      var putValueTimestamp: Art.Time = ArtMessage.UNSET_TIME,\n\n                      \/\/ when sendOutput transferred message from out port var of producer\n                      var sendOutputTimestamp: Art.Time = ArtMessage.UNSET_TIME,\n\n                      \/\/ when message arrived via transport layer\n                      var dstArrivalTimestamp: Art.Time = ArtMessage.UNSET_TIME,\n\n                      \/\/ when receiveInput transferred message to in port vars of consumer\n                      var receiveInputTimestamp: Art.Time = ArtMessage.UNSET_TIME\n                     )\n\nobject ArtNative_Ext {\n  val noTime: Art.Time = s64\"0\"\n\n  val slowdown: Z = 1\n\n  \/\/================================================================\n  \/\/   A r c h i t e c t u r e     D e s c r i p t i o n\n  \/\/================================================================\n\n  \/\/ Architecture description includes any data structures built from Arch information\n  \/\/ to support system execution (i.e., by making certain types of lookup of Arch\n  \/\/ information easier).   This information persists across runs, i.e., it doesn't\n  \/\/ need to be changed between different runs of the system as long as the architecture\n  \/\/ has not changed.\n\n  \/\/ JH: Refactored - moved out of legacy run method to enable separate\n  \/\/ init\/compute\/finalize phase methods.\n  \/\/    This structure is essentially a helper for accessing the Arch description.\n  \/\/    We should study the Arch description to assess (more systematically)\n  \/\/    what types of helpers are needed and where they would go.\n  \/*\n  var activeBridges: IS[Art.BridgeId, Art.BridgeId] = ISZ()\n  def setUpArchitecture() : Unit = {\n    for(e <- Art.bridges.elements if(e.nonEmpty)) {\n      activeBridges = activeBridges :+ e.get.id\n    }\n  }\n  def tearDownArchitecture() : Unit = {\n    activeBridges = IS[Art.BridgeId, Art.BridgeId]()\n  }\n  *\/\n\n  \/\/================================================================\n  \/\/   P l a t f o r m     S t a t e\n  \/\/================================================================\n\n  \/\/ Architecture description includes any infrastructure necessary to\n  \/\/ support the platform including communication instrastructure and\n  \/\/ other resources that may exist across multiple executions\n\n  \/*\n  def setUpPlatform() : Unit = {\n  }\n  def tearDownPlatform() : Unit = {\n  }\n  *\/\n\n  \/\/================================================================\n  \/\/   S y s t e m     S t a t e\n  \/\/================================================================\n\n  val inInfrastructurePorts: MMap[Z, ArtMessage] = concMap()\n  val outInfrastructurePorts: MMap[Z, ArtMessage] = concMap()\n  val inPortVariables: MMap[Z, ArtMessage] = concMap()\n  val outPortVariables: MMap[Z, ArtMessage] = concMap()\n\n\n  \/\/ Initializes system state in preparation for execution of initialize, compute, and finalize phases\n  \/\/ System state includes any state associated with system execution, e.g., things that would need to be\n  \/\/ set up and cleared between runs, but does not include things related to system architecture or platform\n  \/\/ infrastructure that could persist between runs.\n\n  def setUpSystemState(): Unit = {\n    inInfrastructurePorts.clear()\n    inPortVariables.clear()\n    outPortVariables.clear()\n    outInfrastructurePorts.clear()\n\n    \/\/ cancel pending ArtTimer callbacks (also done after a test completes)\n    ArtTimer_Ext.scheduledCallbacks.keys.foreach(ArtTimer_Ext.cancel)\n\n    \/\/scheduler.initialize()\n  }\n\n  def tearDownSystemState(): Unit = {\n    inInfrastructurePorts.clear()\n    inPortVariables.clear()\n    outPortVariables.clear()\n    outInfrastructurePorts.clear()\n\n    \/\/ cancel pending ArtTimer callbacks (also done after a test completes)\n    ArtTimer_Ext.scheduledCallbacks.keys.foreach(ArtTimer_Ext.cancel)\n  }\n\n\n  \/\/===============================================================================\n  \/\/  Port-related AADL run-time services\n  \/\/===============================================================================\n\n  \/\/ JH: Refactored -- renamed port data structures\n  \/\/ TODO -- Consider whether changing the value from ArtMessage to Art.DataContent should happen here (instead of in getValue)\n  def receiveInput(eventPortIds: ISZ[Art.PortId], dataPortIds: ISZ[Art.PortId]): Unit = {\n    \/\/ remove any old events from previous dispatch\n    for (portId <- eventPortIds if inPortVariables.contains(portId.toZ)) {\n      inPortVariables -= portId.toZ\n    }\n\n    \/\/ transfer received data\/events from the infrastructure ports to the port variables\n    for (portId <- eventPortIds) {\n      inInfrastructurePorts.get(portId.toZ) match {\n        case scala.Some(data) =>\n          inInfrastructurePorts -= portId.toZ \/\/ dequeue from infrastructure port\n          inPortVariables(portId.toZ) = data \/\/ when we shift to queue size greater than 1, we would enqueue here\n        case _ =>\n      }\n    }\n    for (portId <- dataPortIds) {\n      inInfrastructurePorts.get(portId.toZ) match {\n        case scala.Some(data) =>\n          \/\/ for data ports, we don't dequeue from infrastastructure ports\n          inPortVariables(portId.toZ) = data\n        case _ =>\n      }\n    }\n  }\n\n  def putValue(portId: Art.PortId, data: DataContent): Unit = {\n    \/\/ wrap the Art.DataContent value into an ArtMessage with time stamps\n    outPortVariables(portId.toZ) = ArtMessage(data = data, srcPortId = Some(portId), putValueTimestamp = Art.time())\n  }\n\n  def getValue(portId: Art.PortId): Option[DataContent] = {\n    \/\/ To return the value of the port to the application code, project\n    \/\/ out the actual payload value (v.data) from ArtMessage (which includes timestamps, etc.)\n    \/\/ to Art.DataContent (the \"top\"\/union data type supported by Art.\n    \/\/ The projecting preserves the option of structure of ArtMessage value.\n    val data = inPortVariables.get(portId.toZ) match {\n      case scala.Some(v) => org.sireum.Some(v.data)\n      case _ => org.sireum.None[DataContent]()\n    }\n    return data\n  }\n\n  \/\/ JH: Refactored\n  \/\/      - change names of port data structures\n  \/\/      - introduce a distinction between output port variables and output infrastructure ports\n  \/\/ ToDo: Introduce the concept of a distinct transfer method.\n  \/\/  The way that implementation treats outPortVariables and outInfrastructurePorts is almost nonsensical\n  \/\/  until that refactoring is made.\n  def sendOutput(eventPortIds: ISZ[Art.PortId], dataPortIds: ISZ[Art.PortId]): Unit = { \/\/ SEND_OUTPUT\n    for (srcPortId <- eventPortIds ++ dataPortIds) {\n      outPortVariables.get(srcPortId.toZ) match {\n        case scala.Some(msg) =>\n          \/\/ move payload from out port port variables to the out infrastructure ports\n          outInfrastructurePorts(srcPortId.toZ) = outPortVariables(srcPortId.toZ)\n          outPortVariables -= srcPortId.toZ\n\n          \/\/ simulate sending msg via transport middleware\n          for (dstPortId <- Art.connections(srcPortId).elements) {\n\n            val _msg = msg.copy(dstPortId = Some(dstPortId), sendOutputTimestamp = Art.time())\n\n            Art.port(dstPortId).mode match {\n              \/\/ right now, there is no difference in the logic between data and event ports,\n              \/\/ but keep the code separate for future refactorings\n              case PortMode.DataIn | PortMode.DataOut =>\n                inInfrastructurePorts(dstPortId.toZ) = _msg\n              case PortMode.EventIn | PortMode.EventOut =>\n                inInfrastructurePorts(dstPortId.toZ) = _msg\n            }\n\n            _msg.dstArrivalTimestamp = Art.time()\n\n            ArtDebug_Ext.outputCallback(srcPortId, dstPortId, _msg.data, _msg.dstArrivalTimestamp)\n          }\n\n          \/\/ payload delivered so remove it from out infrastructure port\n          outInfrastructurePorts -= srcPortId.toZ\n        case _ =>\n      }\n    }\n  }\n\n  \/\/ JH: Refactor\n  \/\/ Manually added by JH to support debugging framework\n  \/\/  -- to support being able to see inputs and outputs of a a thread (before\/after compute),\n  \/\/     clearing of output ports is removed from send_output.\n  \/\/  This function is called by scheduler, before calling compute to initialize the\n  \/\/  component port state\n  def clearPortVariables(bridgeId: Art.BridgeId): Unit = {\n    \/\/ val b = Art.bridge(bridgeId) -- refactor\n    \/\/ ToDo: the computation of input\/output port ids should be helper functions in Bridge\n    \/\/ compute inPortIds\n    val inPortIds = Art.bridges(bridgeId.toZ).get.ports.eventIns.elements.map(_.id) ++ Art.bridges(bridgeId.toZ).get.ports.dataIns.elements.map(_.id)\n    \/\/ iterate through inPortIds and clear the value of each corresponding port variable\n    for (portId <- inPortIds) {\n      inPortVariables -= portId.toZ;\n    }\n    \/\/ compute outPortIds\n    val outPortIds = Art.bridges(bridgeId.toZ).get.ports.eventOuts.elements.map(_.id) ++ Art.bridges(bridgeId.toZ).get.ports.dataOuts.elements.map(_.id)\n    \/\/ iterate through outPortIds and clear the value of each corresponding port variable\n    for (portId <- outPortIds) {\n      outPortVariables -= portId.toZ\n    }\n  }\n\n  \/\/===============================================================================\n  \/\/  HAMR Library Services\n  \/\/===============================================================================\n\n  def logInfo(title: String, msg: String): Unit = log(\"info\", title, msg)\n\n  def logError(title: String, msg: String): Unit = log(\"error\", title, msg)\n\n  def logDebug(title: String, msg: String): Unit = log(\"debug\", title, msg)\n\n  def time(): Art.Time = toS64(System.currentTimeMillis())\n\n  \/\/===============================================================================\n  \/\/  AADL Thread\/Scheduling services\n  \/\/===============================================================================\n\n  \/\/ JH: Refactor to match logic in semantics, group with dispatch status\n  def shouldDispatch(bridgeId: Art.BridgeId): B = {\n    assert(Art.bridges(bridgeId.toZ).nonEmpty, s\"Bridge ${bridgeId} does not exist\")\n\n    Art.bridges(bridgeId.toZ).get.dispatchProtocol match {\n      case DispatchPropertyProtocol.Periodic(_) => return T\n      case DispatchPropertyProtocol.Sporadic(minRate) =>\n        return Art.bridges(bridgeId.toZ).get.ports.eventIns.elements.exists(\n          port => inInfrastructurePorts.contains(port.id.toZ))\n    }\n  }\n\n  \/\/ JH: Refactored -- renamed port data structures\n  \/\/     ToDo: add comments justifying various sections of the logic by reference to standard clauses\n  def dispatchStatus(bridgeId: Art.BridgeId): DispatchStatus = {\n    val ret: DispatchStatus = Art.bridges(bridgeId.toZ).get.dispatchProtocol match {\n      case Periodic(_) => TimeTriggered()\n      case Sporadic(_) =>\n        \/\/ get ids for non-empty input event ports\n        val portIds = ISZ[Art.PortId](Art.bridges(bridgeId.toZ).get.ports.eventIns.map((u: UPort) => u.id).elements.filter((i: Art.PortId) => inInfrastructurePorts.get(i.toZ).nonEmpty): _*)\n        val urgentFifo: Seq[Art.PortId] = portIds.map((pid: Art.PortId) => Art.port(pid)).elements.sortWith { \/\/ reverse sort\n          \/\/ sorting function to make prioritized sequence of event port ids\n          \/\/   compare p1 to p2  (p1 represents the port to process earlier, i.e., should have priority)\n          case (p1: UrgentPort[_], p2: UrgentPort[_]) => Z\n            \/\/ if p1 has a strictly less urgency it comes after p2\n            if (p1.urgency < p2.urgency) F\n            \/\/ if p1 has a strictly greater urgency, it comes before p2\n            else if (p1.urgency > p2.urgency) T\n            \/\/ if p1 and p2 have the same urgency, the ordering is determined by arrival timestamps\n            else inInfrastructurePorts(p1.id.toZ).dstArrivalTimestamp < inInfrastructurePorts(p2.id.toZ).dstArrivalTimestamp\n          case (_: UrgentPort[_], _: Port[_]) => T \/\/ urgent ports take precedence\n          case (_: Port[_], _: UrgentPort[_]) => F \/\/ urgent ports take precedence\n          case (p1: Port[_], p2: Port[_]) =>\n            inInfrastructurePorts(p1.id.toZ).dstArrivalTimestamp < inInfrastructurePorts(p2.id.toZ).dstArrivalTimestamp\n        }.map(_.id)\n        EventTriggered(ISZ[Art.PortId](urgentFifo: _*))\n    }\n    return ret\n  }\n\n  \/\/===============================================================================\n  \/\/  AADL Execution Phases\n  \/\/\n  \/\/   Note: this could be synchronized a bit more with thread states \/ hybrid automata\n  \/\/   in AADL standard\n  \/\/===============================================================================\n\n  def initializePhase(): Unit = {\n    logInfo(Art.logTitle, s\"Initializing component...\")\n  }\n\n  def computePhase(): Unit = {\n    logInfo(Art.logTitle, s\"Begin execution...\")\n  }\n\n  def finalizePhase(): Unit = {\n    logInfo(Art.logTitle, s\"End execution...\")\n\n    ArtTimer_Ext.finalise()\n  }\n\n  var logStream: java.io.PrintStream = System.out\n\n  def log(kind: String, title: String, msg: String): Unit = {\n    logStream.println(st\"\"\"{ \"log\" : \"$kind\", \"title\" : ${Json.Printer.printString(title)}, \"msg\" : ${Json.Printer.printString(msg)}, \"time\" : \"${time()}\" }\"\"\".render)\n    logStream.flush()\n  }\n\n  def toS64(value: Long): S64 = S64(value)\n\n  def concMap[K, V](): MMap[K, V] = {\n    import org.sireum.$internal.CollectionCompat.Converters._\n    new java.util.concurrent.ConcurrentHashMap[K, V].asInstanceOf[java.util.Map[K, V]].asScala\n  }\n\n\n\n\n  \/\/\/\/\/\/\/\/\/\/\/\/\/\n  \/\/ TESTING \/\/\n  \/\/\/\/\/\/\/\/\/\/\/\/\/\n\n  \/**\n   * Sets up the state of a thread component (identified by bridge) for the purpose of\n   * testing.\n   *\n   * An analogue to this method does not show up in developer-written unit tests because\n   * it's invoked behind the scenes by the automatically generated unit test infrastructure\n   * as a prelude to each test.\n   *\/\n  def initTest(bridge: Bridge): Unit = {\n    \/\/ delete ALL port values\n    inInfrastructurePorts.clear()\n    inPortVariables.clear()\n    outPortVariables.clear()\n    outInfrastructurePorts.clear()\n\n    \/\/ cancel pending ArtTimer callbacks (also done after a test completes)\n    ArtTimer_Ext.scheduledCallbacks.keys.foreach(ArtTimer_Ext.cancel)\n\n    bridge.entryPoints.testInitialise()\n    logInfo(Art.logTitle, s\"Initialized bridge: ${bridge.name}\")\n  }\n\n  \/**\n   * Executes the application code in the Initialize Entry Point for the component (identified\n   * by given bridge) for the purposes of testing.  This is achieved by\n   * calling the testInitialise() method on given bridge.\n   *\n   * Precondition: initTest() has been called prior.\n   *\n   * Unlike [[Art.run()]], this method does NOT wrap compute calls in a try-catch block.\n   * This is to ensure no exceptions are overlooked during testing.\n   *\/\n  def testInitialise(bridge: Bridge): Unit = {\n    bridge.entryPoints.testInitialise()\n  }\n\n  \/**\n   * Executes the application code in the Compute Entry Point for the component (identified\n   * by given bridge) for the purposes of testing.  This is achieved by\n   * calling the testCompute() method on given bridge.\n   *\n   * Precondition: initTest() has been called prior.\n   *\n   * Unlike [[Art.run()]], this method does NOT wrap compute calls in a try-catch block.\n   * This is to ensure no exceptions are overlooked during testing.\n   *\/\n  def testCompute(bridge: Bridge): Unit = {\n    bridge.entryPoints.testCompute()\n  }\n\n  \/**\n   * Calls the finalize entry points on all registered bridges.\n   * Testers should NOT call this method because BridgeTestSuite will automatically call this method after each test.\n   *\n   *\/\n  def finalizeTest(bridge: Bridge): Unit = {\n    bridge.entryPoints.finalise()\n    logInfo(Art.logTitle, s\"Finalized bridge: ${bridge.name}\")\n\n    \/\/ cancel pending ArtTimer callbacks (also done before a test begins)\n    ArtTimer_Ext.scheduledCallbacks.keys.foreach(ArtTimer_Ext.cancel)\n  }\n\n  \/\/ JH: Refactored\n  \/\/   add system test capability\n  def initSystemTest(scheduler: Scheduler): Unit = {\n    Art.setUpArchitecture()\n    Art.setUpPlatform()\n    Art.setUpSystemState(scheduler)\n    logInfo(Art.logTitle, s\"Initialized system for system test\")\n  }\n\n  \/\/  def executeSystemTest(): Unit = $\n\n  \/\/ JH: Refactored\n  \/\/   add system test capability\n  def finalizeSystemTest(): Unit = {\n    Art.tearDownSystemState()\n    Art.tearDownPlatform()\n    Art.tearDownArchitecture()\n  }\n\n  \/\/ JH: Refactor\n  \/\/  Add code to address the fact that out port variables are now distinct from\n  \/\/  out infrastructure ports,  i.e., we must copy from out port variables to\n  \/\/  out infrastructure ports\n  \/**\n   * A method that replaces bridge.compute()'s calls to [[Art.sendOutput()]] in\n   * its equivalent testCompute() method.\n   *\n   * This method is currently a NO-OP, but may gain functionality later.\n   *\n   * @param eventPortIds the event ports to be \"copied and cleared\" (but currently nothing happens)\n   * @param dataPortIds the data ports to be \"copied and cleared\" (but currently nothing happens)\n   *\/\n  def releaseOutput(eventPortIds: ISZ[Art.PortId], dataPortIds: ISZ[Art.PortId]): Unit = { \/\/ testing SEND_OUTPUT\n    \/\/ note: sendOutput is usually accessed via:\n    \/\/   Art.sendOutput -> ArtNative.sendOutput -> ArtNative_Ext.sendOutput\n    \/\/JH added:\n    for (srcPortId <- eventPortIds ++ dataPortIds) {\n      outPortVariables.get(srcPortId.toZ) match {\n        case scala.Some(msg) =>\n          outInfrastructurePorts(srcPortId.toZ) = outPortVariables(srcPortId.toZ)\n        case _ =>\n      }\n    }\n  }\n\n  \/**\n   * Because a bridge's testCompute() doesn't clear outputs, this method can be\n   * used by users to manually clear the output if desired. This is useful for\n   * tests involving multiple dispatches.\n   *\/\n  def manuallyClearOutput(): Unit = {\n    outPortVariables.clear()\n  }\n\n  \/\/ JH: Refactor\n  \/\/ ToDo: Rename the functions below to align with the variable names inInfrastructurePort, etc.\n  \/**\n   * Inserts a value into an \"infrastructure in\" port. For testing only, normally\n   * this is handled by Art.\n   *\n   * @param dstPortId the portId to place the passed [[DataContent]] into\n   * @param data the [[DataContent]] which will be placed in the dstPort\n   *\/\n  def insertInInfrastructurePort(dstPortId: Art.PortId, data: DataContent): Unit = {\n    \/\/ note: that could would be changed when we refactor to support event queues of size > 1\n    val artMessage = ArtMessage(data = data, dstPortId = Some(dstPortId), dstArrivalTimestamp = Art.time())\n    \/\/ note: right now, there is no difference in the logic between data and event ports, but keep the\n    \/\/ logic separate for future refactoring\n    Art.port(dstPortId).mode match {\n      case PortMode.DataIn | PortMode.DataOut =>\n        inInfrastructurePorts(dstPortId.toZ) = artMessage\n      case PortMode.EventIn | PortMode.EventOut =>\n        inInfrastructurePorts(dstPortId.toZ) = artMessage\n    }\n  }\n\n\n  \/**\n   * Returns the value of an in infrastructure port.\n   *\n   * @param portId the id of the INPUT port to return a value from\n   * @return If the port is non-empty, a [[Some]] of [[DataContent]]. Otherwise [[None]].\n   *\/\n  def observeInInfrastructurePort(portId: Art.PortId): Option[DataContent] = {\n    \/\/ right now, with event data port queues limited to size one, there is no difference in the logic\n    \/\/ between how data ports are treated, and how event\/event data ports are treated.\n    Art.port(portId).mode match {\n      case PortMode.DataIn =>\n        inInfrastructurePorts.get(portId.toZ) match {\n          case scala.Some(value: ArtMessage) => org.sireum.Some[DataContent](value.data)\n          case scala.None => org.sireum.None[DataContent]()\n        }\n      case PortMode.EventIn =>\n        inInfrastructurePorts.get(portId.toZ) match {\n          case scala.Some(value: ArtMessage) => org.sireum.Some[DataContent](value.data)\n          case scala.None => org.sireum.None[DataContent]()\n        }\n      case _ => {\n        assert(false, \"expecting in port\")\n        org.sireum.None[DataContent]()\n      }\n    }\n  }\n\n  \/**\n   * Returns the value of an infrastructure out port.\n   *\n   * @param portId the id of the OUTPUT port to return a value from\n   * @return If the port is non-empty, a [[Some]] of [[DataContent]]. Otherwise [[None]].\n   *\/\n  def observeOutInfrastructurePort(portId: Art.PortId): Option[DataContent] = {\n    \/\/ note: would be changed when we refactor to support event queues of size > 1\n    outInfrastructurePorts.get(portId.toZ) match {\n      case scala.Some(value: ArtMessage) => org.sireum.Some[DataContent](value.data)\n      case scala.None => org.sireum.None[DataContent]()\n    }\n  }\n\n  \/**\n   * Returns the value of an application in port.\n   *\n   * @param portId the id of the INPUT port to return a value from\n   * @return If the port is non-empty, a [[Some]] of [[DataContent]]. Otherwise [[None]].\n   *\/\n  def observeInPortVariable(portId: Art.PortId): Option[DataContent] = {\n    \/\/ right now, with event data port queues limited to size one, there is no difference in the logic\n    \/\/ between how data ports are treated, and how event\/event data ports are treated.\n    Art.port(portId).mode match {\n      case PortMode.DataIn =>\n        inPortVariables.get(portId.toZ) match {\n          case scala.Some(value: ArtMessage) => org.sireum.Some[DataContent](value.data)\n          case scala.None => org.sireum.None[DataContent]()\n        }\n      case PortMode.EventIn =>\n        inPortVariables.get(portId.toZ) match {\n          case scala.Some(value: ArtMessage) => org.sireum.Some[DataContent](value.data)\n          case scala.None => org.sireum.None[DataContent]()\n        }\n      case _ => {\n        assert(false, \"expecting in port\")\n        org.sireum.None[DataContent]()\n      }\n    }\n  }\n\n  \/**\n     * Returns the value of an application out port.\n     *\n     * @param portId the id of the OUTPUT port to return a value from\n     * @return If the port is non-empty, a [[Some]] of [[DataContent]]. Otherwise [[None]].\n     *\/\n  def observeOutPortVariable(portId: Art.PortId): Option[DataContent] = {\n    \/\/ note: that could would be changed when we refactor to support event queues of size > 1\n    outPortVariables.get(portId.toZ) match {\n      case scala.Some(value: ArtMessage) => org.sireum.Some[DataContent](value.data)\n      case scala.None => org.sireum.None[DataContent]()\n    }\n  }\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/ArtTimer.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art\n\nimport org.sireum._\n\n@sig trait TimerCallback {\n  def callback(): Unit\n}\n\n@ext object ArtTimer {\n\n  def schedule(id: String, replaceExisting: B, delay: Art.Time, callback: () => Unit): Unit = $\n\n  \/\/ if transpiling then use this version as transpiler does not support function passing\n  def scheduleTrait(id: String, replaceExisting: B, delay: Art.Time, callback: TimerCallback): Unit = $\n\n  def cancel(id: String): Unit = $\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/ArtTimer_Ext.scala",
        {
          "type" : "ITestResource",
          "content" : "package art\n\nimport org.sireum.S64._\nimport org.sireum.{B, F, String, T}\n\nimport java.util.concurrent.atomic.AtomicBoolean\nimport java.util.concurrent.{Executors, TimeUnit}\nimport scala.collection.mutable.{Map => MMap}\n\nobject ArtTimer_Ext {\n\n  protected[art] val scheduledCallbacks: MMap[String, AtomicBoolean] = ArtNative_Ext.concMap()\n  private val executor = Executors.newSingleThreadScheduledExecutor()\n\n  def finalise(): Unit = {\n    executor.shutdownNow()\n    ArtNative.logInfo(Art.logTitle, \"Finalized ArtTimer\")\n  }\n\n  def cancel(id: String): Unit = {\n    scheduledCallbacks.get(id) match {\n      case Some(b) =>\n        val userRequested = b.get()\n        b.set(F)\n        scheduledCallbacks.remove(id)\n        if (userRequested) {\n          ArtNative.logInfo(Art.logTitle, s\"Callback cleared for $id\")\n        }\n      case _ =>\n    }\n  }\n\n  def scheduleTrait(id: String, replaceExisting: B, delay: Art.Time, callback: TimerCallback): Unit = {\n    schedule(id, replaceExisting, delay, callback.callback _)\n  }\n\n  def schedule(id: String, replaceExisting: B, delay: Art.Time, callback: () => Unit): Unit = {\n    if (scheduledCallbacks.get(id).nonEmpty) {\n      if (!replaceExisting) {\n        ArtNative.logInfo(Art.logTitle, s\"Callback already scheduled for $id\")\n        return\n      } else {\n        cancel(id)\n      }\n    }\n\n    if (delay < s64\"0\") {\n      ArtNative.logInfo(Art.logTitle, s\"Invalid delay time: ${delay}.  Value must be non-negative.\")\n      return\n    }\n\n    \/\/ the below runnable will be run in a separate thread when it's\n    \/\/ dispatched by the executor. If the user requests to cancel the\n    \/\/ timeout before that then shouldInvokeCallback will be set to\n    \/\/ false and therefore the callback will not be invoked\n    val shouldInvokeCallback = new AtomicBoolean(T)\n\n    val task = new Runnable {\n      override def run(): Unit = {\n        if (shouldInvokeCallback.get()) {\n          shouldInvokeCallback.set(F)\n          cancel(id)\n\n          callback()\n        }\n      }\n    }\n\n    scheduledCallbacks.put(id, shouldInvokeCallback)\n\n    val adjusted = delay.toMP.toLong * ArtNative_Ext.slowdown.toMP.toLong\n    executor.schedule(task, adjusted, TimeUnit.MILLISECONDS)\n\n    ArtNative.logInfo(Art.logTitle, s\"Callback scheduled for $id: $delay ms\")\n  }\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/DataContent.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art\n\nimport org.sireum._\n\n@sig trait DataContent\n\n@datatype class Empty extends art.DataContent",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : true
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/Scheduler.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art.scheduling\n\nimport org.sireum._\n\n\/\/ msig to allow schedulers to have mutable state\n@msig trait Scheduler {\n\n  def initialize(): Unit\n\n  def initializationPhase(): Unit\n\n  def computePhase(): Unit\n\n  def finalizePhase(): Unit\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/legacy\/Legacy.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art.scheduling.legacy\n\nimport org.sireum._\nimport art.Art\nimport art.scheduling.Scheduler\n\n@record class Legacy(bridges: IS[Art.BridgeId, art.Bridge]) extends Scheduler {\n\n  override def initialize(): Unit = {}\n\n  override def initializationPhase(): Unit = {\n    for (bridge <- bridges) {\n      bridge.entryPoints.initialise()\n      Art.logInfo(bridge.id, s\"Initialized bridge: ${bridge.name}\")\n    }\n  }\n\n  override def computePhase(): Unit = {\n    LegacyInterface.computePhase(bridges)\n  }\n\n  override def finalizePhase(): Unit = {\n    for (bridge <- bridges) {\n      bridge.entryPoints.finalise()\n      Art.logInfo(bridge.id, s\"Finalized bridge: ${bridge.name}\")\n    }\n  }\n}\n\n@ext object LegacyInterface {\n  def computePhase(bridges: IS[Art.BridgeId, art.Bridge]): Unit = $\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/legacy\/LegacyInterface_Ext.scala",
        {
          "type" : "ITestResource",
          "content" : "package art.scheduling.legacy\n\nimport art.{Art, ArtNative, ArtNative_Ext, DispatchPropertyProtocol}\nimport scala.collection.mutable.{Map => MMap}\nimport org.sireum._\n\nobject LegacyInterface_Ext {\n  val slowdown: Z = 1\n\n  def computePhase(bridges: IS[Art.BridgeId, art.Bridge]): Unit = {\n    var terminated = false\n    var numTerminated: Z = 0\n\n    for (bridge <- bridges) {\n\n      val (rate, isSporadic) = bridge.dispatchProtocol match {\n        case DispatchPropertyProtocol.Periodic(period) => (period, F)\n        case DispatchPropertyProtocol.Sporadic(min) => (min, T)\n      }\n\n      new Thread(() => {\n        ArtNative.logInfo(Art.logTitle, s\"Thread for ${bridge.name} instantiated.\")\n        ArtNative_Ext.synchronized {\n          ArtNative_Ext.wait()\n        }\n        while (!terminated) {\n          Thread.sleep((rate * slowdown).toMP.toLong)\n          if (ArtNative.shouldDispatch(bridge.id)) {\n            try {\n              bridge.synchronized {\n                bridge.entryPoints.compute()\n              }\n            }\n            catch {\n              case x: Throwable =>\n                x.printStackTrace()\n                terminated = true\n            }\n          }\n        }\n        ArtNative_Ext.synchronized {\n          numTerminated += 1\n        }\n      }).start()\n    }\n\n    Thread.sleep(1000)\n\n    ArtNative.logInfo(Art.logTitle, s\"Start execution (press Enter twice to terminate) ...\")\n\n    ArtNative_Ext.synchronized {\n      ArtNative_Ext.notifyAll()\n    }\n\n    Console.in.readLine()\n    terminated = true\n\n    while (numTerminated != bridges.size) {\n      Thread.sleep(1000)\n    }\n  }\n\n  def concMap[K, V](): MMap[K, V] = {\n    import org.sireum.$internal.CollectionCompat.Converters._\n    new java.util.concurrent.ConcurrentHashMap[K, V].asInstanceOf[java.util.Map[K, V]].asScala\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/nop\/NopScheduler.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art.scheduling.nop\n\nimport org.sireum._\nimport art.scheduling.Scheduler\n\n@record class NopScheduler extends Scheduler {\n\n  override def initialize(): Unit = {}\n\n  override def initializationPhase(): Unit = {}\n\n  override def computePhase(): Unit = {}\n\n  override def finalizePhase(): Unit = {}\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/roundrobin\/RoundRobin.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\npackage art.scheduling.roundrobin\n\nimport org.sireum._\nimport art.scheduling.Scheduler\nimport art.{Art, ArtNative, DispatchPropertyProtocol}\nimport org.sireum.S64._\n\n@record class RoundRobin(schedule: ISZ[Art.BridgeId]) extends Scheduler {\n\n  var lastDispatch: MS[Art.BridgeId, Art.Time] = MS.create[Art.BridgeId, Art.Time](schedule.size, s64\"0\")\n  var lastSporadic: MS[Art.BridgeId, Art.Time] = MS.create[Art.BridgeId, Art.Time](schedule.size, s64\"0\")\n\n  override def initialize(): Unit = {\n    RoundRobinExtensions.init()\n  }\n\n  override def initializationPhase(): Unit = {\n    for (bridgeId <- schedule) {\n      Art.bridges(bridgeId.toZ).get.entryPoints.initialise()\n      Art.logInfo(bridgeId, s\"Initialized bridge: ${Art.bridges(bridgeId.toZ).get.name}\")\n    }\n  }\n\n  def shouldDispatch(bridgeId: Art.BridgeId): B = {\n    Art.bridges(bridgeId.toZ).get.dispatchProtocol match {\n      case DispatchPropertyProtocol.Periodic(period) =>\n        if (Art.time() - lastDispatch(bridgeId) > conversions.Z.toS64(period)) {\n          return ArtNative.shouldDispatch(bridgeId) \/\/ will always return true\n        } else {\n          return F\n        }\n      case DispatchPropertyProtocol.Sporadic(minRate) =>\n        if (Art.time() - lastSporadic(bridgeId) < conversions.Z.toS64(minRate)) {\n          return F\n        } else {\n          \/\/ check if there are events waiting in incoming infrastructure port\n          return ArtNative.shouldDispatch(bridgeId)\n        }\n    }\n  }\n\n  override def computePhase(): Unit = {\n    while (!RoundRobinExtensions.shouldStop()) {\n      for (bridgeId <- schedule) {\n        if (shouldDispatch(bridgeId)) {\n          lastDispatch(bridgeId) = Art.time()\n          Art.bridges(bridgeId.toZ).get.entryPoints.compute()\n\n          if (Art.bridges(bridgeId.toZ).get.dispatchProtocol.isInstanceOf[DispatchPropertyProtocol.Sporadic]) {\n            lastSporadic(bridgeId) = Art.time()\n          }\n        }\n      }\n    }\n  }\n\n  override def finalizePhase(): Unit = {\n    for (bridgeId <- schedule) {\n      Art.bridges(bridgeId.toZ).get.entryPoints.finalise()\n      Art.logInfo(bridgeId, s\"Finalized bridge: ${Art.bridges(bridgeId.toZ).get.name}\")\n    }\n  }\n}\n\n@ext object RoundRobinExtensions {\n  def init(): Unit = $\n\n  def shouldStop(): B = $\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/roundrobin\/RoundRobinExtensions_Ext.scala",
        {
          "type" : "ITestResource",
          "content" : "package art.scheduling.roundrobin\n\nimport art.{Art, ArtNative}\nimport org.sireum.B\nimport java.util.concurrent.atomic.AtomicBoolean\n\nobject RoundRobinExtensions_Ext {\n  var terminated = new AtomicBoolean(false)\n\n  def init(): Unit = {\n    ArtNative.logInfo(Art.logTitle, s\"Start execution (press Enter twice to terminate) ...\")\n\n    new Thread(() => {\n      Console.in.readLine()\n      terminated.set(true)\n    }).start()\n  }\n\n  def shouldStop(): B = {\n    return terminated.get()\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/static\/CliCommandProvider.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art.scheduling.static\n\nimport org.sireum._\n\n@record class CliCommandProvider extends CommandProvider {\n  override def nextCommand(): Command = {\n    return getCommand()\n  }\n\n  def getCommand(): Command = {\n    val cmdString: String = cliIO.getCommand(\"HAMR> \")\n    val args: ISZ[String] = ops.StringOps(cmdString).split(c => c == ' ')\n    val arg0: String = args(0)\n    if (arg0 == \"x\") {\n      return Stop()\n    } else if (arg0 == \"s\") {\n      var numSteps: Z = 1\n      if (args.size > 1) {\n        Z(args(1)) match {\n          case Some(numStepsCli) => numSteps = numStepsCli\n          case None() => return Unsupported()\n        }\n      }\n      return Sstep(numSteps)\n    } else if (arg0 == \"help\") {\n      return Help()\n    } else if (arg0 == \"h\") {\n      var numSteps: Z = 1\n      if (args.size > 1) {\n        Z(args(1)) match {\n          case Some(numStepsCli) => numSteps = numStepsCli\n          case None() => return Unsupported()\n        }\n      }\n      return Hstep(numSteps)\n    } else if (arg0 == \"i\") {\n      if (args.size < 2) {\n        println(\"i requires a second option\")\n        return Help()\n      }\n      \/\/ need to insert a check for size greater than 1\n      if (args(1) == \"st\") {\n        return Infostate()\n      } else if (args(1) == \"sc\") {\n        return Infoschedule()\n      } else if (args(1) == \"out\") {\n        return InfoOutputs()\n      } else if (args(1) == \"in\") {\n        return InfoInputs()\n      } else if (args(1) == \"cpn\") {\n        if (args.size > 2) {\n          Z(args(2)) match {\n            case Some(bridgeId) => return InfoComponentStateId(bridgeId)\n            case None() => return Unsupported() \/\/ expected bridgeId arg is not an integer\n          }\n        }\n        return Unsupported() \/\/ incorrect number of arguments for \"i cp\" (missing bridge id arg)\n      } else if (args(1) == \"cp\") {\n        if (args.size > 2) {\n          return InfoComponentState(args(2))\n        }\n        return Unsupported() \/\/ incorrect number of arguments for \"i cp\" (missing bridge id arg)\n      } else if (args(1) == \"nn\") {\n        return InfoThreadNickNames()\n      } \/\/ incorrect number of arguments for \"i cp\" (missing bridge id arg)\n      else { \/\/ ... no other info commands supported\n        return Unsupported()\n      }\n    } else if (arg0 == \"rh\") {\n      Z(args(1)) match {\n        case Some(hpTarget) => return RunToHP(hpTarget)\n        case None() => return Unsupported()\n      }\n    } else if (arg0 == \"rd\") {\n      Z(args(1)) match {\n        case Some(domainIdTarget) => return RunToDomain(domainIdTarget)\n        case None() => return Unsupported()\n      }\n    } else if (arg0 == \"rt\") {\n      val threadNickName = args(1)\n      return RunToThread(threadNickName)\n    } else if (arg0 == \"rs\") {\n      if (args.size == 2) { \/\/ run to slot\n        Z(args(1)) match {\n          case Some(slotNumTarget) => return RunToSlot(slotNumTarget)\n          case None() => return Unsupported()\n        }\n      } else if (args.size == 3) { \/\/ run to state\n        (Z(args(1)), Z(args(2))) match {\n          case (Some(hpNum), Some(slotNum)) => return RunToState(hpNum, slotNum)\n          case _ => return Unsupported()\n        }\n      } else {\n        return Unsupported()\n      }\n    } else {\n      return Unsupported()\n    }\n  }\n}\n\n@ext(\"CliIOExt\") object cliIO {\n  def getCommand(prompt: String): String = $\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/static\/CliIOExt.scala",
        {
          "type" : "ITestResource",
          "content" : "package art.scheduling.static\n\nimport org.sireum._\n\nimport scala.io.StdIn.readLine\n\nobject CliIOExt {\n  def getCommand(prompt: String): String = {\n    print(prompt)\n    val command = readLine()\n    return command\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/static\/CliInfoProvider.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\npackage art.scheduling.static\n\nimport org.sireum._\nimport art.Art.BridgeId\nimport art.scheduling.static.Schedule.DScheduleSpec\n\nobject CliInfoProvider {\n\n  \/\/ prototyping APIs that any HAMR debugging interface should support\n  def message(m: String): Unit = {\n    println(m)\n  }\n\n  def printHelpMessage(): Unit = {\n    println(\"s <n?>     - step n slots (default 0)\")\n    println(\"h <n?>     - step n hyper-periods (default 0)\")\n    println(\"rs <n>     - run to slot n (wrap to next hyper-period if needed)\")\n    println(\"rs <h> <n> - run to state hyperperiod h and slot n (do nothing if past this state)\")\n    println(\"rh <n>     - run to hyper-period n (do nothing if already past the beginning of hyper-period n)\")\n    println(\"rt <name>  - run to slot containing thread with nickname <name>\")\n    println(\"i st       - show current state\")\n    println(\"i sc       - show schedule and current position\")\n    println(\"i out      - show output port values of most recently run thread\")\n    println(\"i in       - show input  port values of next thread to run\")\n    println(\"i cp <nickname> - show port values of component with given nickname\")\n    println(\"i nn       - show thread nicknames\")\n    println(\"x          - exit\")\n    println()\n  }\n\n  def formatState(scheduleState: Explorer.ScheduleState, domain: Z, bridgeId: BridgeId, threadNickName: String): String = {\n    \/\/ val outString = \"STATE: slot#: \" + scheduleState.slotNum.toString + \" ; HP#: \" + scheduleState.hyperperiodNum.toString\n    return s\"STATE: HP#: ${scheduleState.hyperperiodNum} slot#: ${scheduleState.slotNum} domain: $domain  thread: $threadNickName ($bridgeId)\"\n  }\n\n  def formatStateH(scheduleState: Explorer.ScheduleState): String = {\n    val domain = Schedule.getDomainFromScheduleState(scheduleState)\n    val bridgeId = Schedule.getBridgeIdFromScheduleState(scheduleState)\n    val threadNickName = Schedule.getThreadNickNameFromScheduleState(scheduleState)\n    return formatState(scheduleState, domain, bridgeId, threadNickName)\n  }\n\n  \/\/ The \"show\" methods below need to be refactored to better support MVC\n\n  def showNickNames(): Unit = {\n    message(\" Thread Nicknames\")\n    message(\"-------------------\")\n    for (e <- StaticScheduler.threadNickNames.keys) {\n      message(e)\n    }\n  }\n\n  def showState(scheduleState: Explorer.ScheduleState, domain: Z, bridgeId: BridgeId, threadNickName: String): Unit = {\n    message(formatState(scheduleState, domain, bridgeId, threadNickName))\n  }\n\n  def showStateH(scheduleState: Explorer.ScheduleState): Unit = {\n    message(formatStateH(scheduleState))\n  }\n\n  def showSchedule(scheduleState: Explorer.ScheduleState, dScheduleSpec: Schedule.DScheduleSpec): Unit = {\n    val slots = dScheduleSpec.schedule.slots\n    val hyperPeriodLength = dScheduleSpec.hyperPeriod\n    val hyperPeriodNum = scheduleState.hyperperiodNum\n    val stateSlotNum = scheduleState.slotNum\n    message(s\" Schedule ($hyperPeriodLength tot ticks) HP#: $hyperPeriodNum\")\n    message(\"-------------------------------------------------\")\n    var slotNum: Z = 0\n    for (s <- slots) {\n      var prefix: String = \"  \"\n      var suffix: String = \"\"\n      if (slotNum == stateSlotNum) {\n        val (elaspedHPTicks, remainingHPTicks) = Schedule.computeElaspedRemainingHPTicks(slotNum, dScheduleSpec)\n        prefix = \" *\"\n        suffix = s\"(elapsed= $elaspedHPTicks, remaining=$remainingHPTicks)\"\n      }\n      message(s\"${prefix}$slotNum [domain=${s.domain},length=${s.length}] $suffix\")\n      slotNum = slotNum + 1\n    }\n    message(\"-------------------------------------------------\")\n  }\n\n  def showStep(preScheduleState: Explorer.ScheduleState,\n               postScheduleState: Explorer.ScheduleState,\n               dScheduleSpec: DScheduleSpec): Unit = {\n    val slotNum = preScheduleState.slotNum\n    val slot = dScheduleSpec.schedule.slots(slotNum)\n    val domain = slot.domain\n    val bridgeId = Schedule.getBridgeIdFromSlotNumber(slotNum)\n    val length = slot.length\n    message(\"============= S t e p =============\")\n    message(s\"PRE-${formatState(preScheduleState, Schedule.getDomainFromScheduleState(preScheduleState), Schedule.getBridgeIdFromScheduleState(preScheduleState), Schedule.getThreadNickNameFromScheduleState(preScheduleState))}\")\n    message(s\"   Executing:  Domain#: $domain   Max Duration: $length\")\n    message(s\"POST-${formatState(postScheduleState, Schedule.getDomainFromScheduleState(postScheduleState), Schedule.getBridgeIdFromScheduleState(postScheduleState), Schedule.getThreadNickNameFromScheduleState(postScheduleState))}\")\n  }\n\n  def showHyperPeriodBoundary(scheduleState: Explorer.ScheduleState): Unit = {\n    message(s\"********* Hyper-Period ${scheduleState.hyperperiodNum} (beginning) **********\")\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/static\/Command.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art.scheduling.static\n\nimport org.sireum._\n\n@msig trait CommandProvider {\n  def nextCommand(): Command\n}\n\n@msig trait InfoCommandProvider extends CommandProvider {\n  def threadNickNames: Map[String, art.Art.BridgeId]\n  def numSlots: Z\n  def displayOrder: ISZ[art.Art.BridgeId]\n\n  def init(threadNickNames: Map[String, art.Art.BridgeId], numSlots: Z, displayOrder: ISZ[art.Art.BridgeId]): CommandProvider\n}\n\n@datatype trait Command\n\n@datatype class Unrecognized extends Command\n\n@datatype class Unsupported extends Command\n\n\/\/ end debugging session\n@datatype class Stop extends Command\n\n\/\/ display support commands\n@datatype class Help extends Command\n\n\/\/ step numSteps of slots\n@datatype class Sstep(numSteps: Z) extends Command\n\n\/\/ step numSteps of hyper-periods\n@datatype class Hstep(numSteps: Z) extends Command\n\n\/\/ run to hp#\n@datatype class RunToHP(hpNum: Z) extends Command\n\n\/\/ run to scheduler state (hp#,slot#)\n@datatype class RunToState(hpNum: Z, slotNum: Z) extends Command\n\n\/\/ run to domain\n@datatype class RunToDomain(domainId: Z) extends Command\n\n\/\/ run to thread\n@datatype class RunToSlot(slotNum: Z) extends Command\n\n\/\/ run to thread\n@datatype class RunToThread(ThreadId: String) extends Command\n\n\/\/ get info current state (hyper-period number, slot number)\n@datatype class Infostate extends Command\n\n\/\/ get info of domain schedule with next slot to be executed marked\n@datatype class Infoschedule extends Command\n\n\/\/ get values of input ports of component to be executed in the next slot\n@datatype class InfoInputs extends Command\n\n\/\/ get values of output ports of component that was executed in the previous slot\n@datatype class InfoOutputs extends Command\n\n\/\/ get values of input and outputs ports for the given component the last time that it was executed\n@datatype class InfoComponentStateId(bridgeId: Z) extends Command\n\n@datatype class InfoComponentState(threadNickName: String) extends Command\n\n\/\/ show thread nicknames\n@datatype class InfoThreadNickNames extends Command\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/static\/CommandInterpreter.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\npackage art.scheduling.static\n\nimport org.sireum._\nimport art.Art.BridgeId\n\nobject CommandInterpreter {\n\n  def message(str: String): Unit = {\n    CliInfoProvider.message(str)\n  }\n\n  def interpretCmd(cmd: Command): B = {\n    var done: B = false\n    cmd match {\n      case _: Help =>\n        CliInfoProvider.printHelpMessage()\n\n      case Sstep(n) =>\n        assert(n >= 1)\n        message(s\"...Stepping $n slot(s)\")\n        Explorer.stepSystemNSlotsIMP(n)\n\n      case Hstep(n) =>\n        assert(n >= 1)\n        message(s\"...Stepping $n hyper-period(s)\")\n        if (n == 1) {\n          Explorer.stepSystemOneHPIMP()\n        } else if (Explorer.isHyperPeriodBoundaryH()) {\n          Explorer.stepSystemNHPIMP(n)\n        } else {\n          message(\"Command not applicable: not on hyper-period boundary\")\n        }\n\n      case RunToHP(hpNum) =>\n        assert(hpNum >= 0 & hpNum <= 1000)\n        Explorer.runToHP(hpNum)\n\n      case RunToSlot(slotNum) =>\n        assert(slotNum >= 0 & slotNum < Schedule.dScheduleSpec.schedule.slots.size)\n        message(s\"...Running to slot# $slotNum\")\n        Explorer.runToSlot(slotNum)\n\n      case RunToThread(threadNickName) =>\n        Explorer.runToThread(threadNickName)\n\n      case RunToState(hpNum, slotNum) =>\n        assert(hpNum >= 0 & hpNum <= 1000)\n        assert(slotNum >= 0 & slotNum < Schedule.dScheduleSpec.schedule.slots.size)\n        Explorer.runToState(hpNum, slotNum)\n\n      case RunToDomain(domainId) =>\n        assert(0 <= domainId & domainId <= Schedule.dScheduleSpec.maxDomain)\n        Explorer.runToDomain(domainId)\n\n      case _: Stop => done = T\n\n      case _: Infostate =>\n        val s = Explorer.scheduleState\n        CliInfoProvider.showState(s, Schedule.getDomainFromScheduleState(s), Schedule.getBridgeIdFromScheduleState(s), Schedule.threadNickName(Schedule.getBridgeIdFromScheduleState(s)))\n\n      case _: Infoschedule =>\n        CliInfoProvider.showSchedule(Explorer.scheduleState, Schedule.dScheduleSpec)\n\n      case _: InfoInputs =>\n        StateObserver.printPortContentsInputsCurrent()\n\n      case _: InfoOutputs =>\n        StateObserver.printPortContentsOutputsCurrent()\n\n      case InfoComponentStateId(bridgId) =>\n        StateObserver.printPortContents(BridgeId.fromZ(bridgId))\n\n      case InfoComponentState(threadNickName) =>\n        StateObserver.printPortContentsByNickName(threadNickName)\n\n      case _: InfoThreadNickNames =>\n        CliInfoProvider.showNickNames()\n\n      case _: Unrecognized => message(\"Unrecognized command\")\n\n      case _: Unsupported => message(\"Unsupported command\")\n\n      case _ =>\n    }\n    return done\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/static\/DefaultCommandProvider.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\npackage art.scheduling.static\n\nimport org.sireum._\n\n@record class DefaultCommandProvider extends CommandProvider {\n  override def nextCommand(): Command = {\n    return Hstep(1)\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/static\/Explorer.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art.scheduling.static\n\nimport org.sireum._\nimport art.{Art, ArtNative}\nimport art.scheduling.static.Schedule._\n\n\/\/ Possible commands\/concepts\n\/\/\n\/\/ init system\n\/\/ s n - step n slots; n >= 1, if n >= remaining slots in hyper-period, then run to end of hyper-period\n\/\/ h n - step n hyper-periods; n >= 1\n\/\/ executing info display mode\n\/\/  show domain \/ bridge\n\/\/  show infrastructure input \/ output ports\n\/\/  show in\/out ports for selected components\n\/\/  inject certain values on input ports (random, specific, random with constraints, generator, seeded from test vector)\n\/\/ run until various conditions\n\/\/ check contract \/ constraint (component-wise or global)\n\/\/ checkpoint state, rollback to checkpointed state\n\/\/ save step as unit tests\n\/\/ calculate dependences during execution\n\n\n\/\/ stepDSchedule(2,dScheduleSpec1)\n\n\/\/ var inpt: Z = 0\n\/\/ inpt = readInt()\n\nobject Explorer {\n\n  \/\/================ schedule state ====================\n\n  \/\/ data structure for schedule state\n  \/\/   - zero-based indexing into the time-line of the scheduler\n  @datatype class ScheduleState(slotNum: Z, hyperperiodNum: Z)\n\n  \/\/ \"invariant\" for schedule state\n  def validState(state: ScheduleState, dScheduleSpec: DScheduleSpec): B = {\n    val slotNum = state.slotNum\n    \/\/ TODO: also check valid scheduleSpec??\n    val slotInRange: B = slotNum >= 0 & slotNum < dScheduleSpec.schedule.slots.size\n    val hyperperiodInRange: B = state.hyperperiodNum >= 0\n    return slotInRange & hyperperiodInRange\n  }\n\n  def isHyperPeriodBoundary(state: ScheduleState): B = {\n    return state.slotNum == 0\n  }\n\n  def isHyperPeriodBoundaryH(): B = {\n    return isHyperPeriodBoundary(scheduleState)\n  }\n\n  \/\/ schedule state \"global\" variable\n  var scheduleState: ScheduleState = initialScheduleState()\n\n  \/\/ helper method to define initial state value\n  def initialScheduleState(): ScheduleState = {\n    return ScheduleState(0, 0)\n  }\n\n  \/\/ method to initialize schedule state\n  def initializeScheduleStateIMP(): Unit = {\n    scheduleState = initialScheduleState()\n  }\n\n  def isInitial(scheduleState: ScheduleState): B = {\n    return scheduleState == initialScheduleState()\n  }\n\n  def isInitialIMP(): B = {\n    return isInitial(scheduleState)\n  }\n\n  \/\/=============== stepping functions ===================\n\n  \/\/ -- methods for executing thread in a particular slot in the schedule.\n  \/\/    A thread can be referenced by slot data structure or by slot number (two different methods)\n\n  \/\/ execute thread by slot data structure\n  def executeSlotIMP(slot: Slot): Unit = {\n    val domainId: Z = slot.domain\n    val bridgeId: Art.BridgeId = Schedule.domainToBridgeIdMap(domainId)\n    \/\/ val bridge: Bridge = Art.bridges(bridgeId).get  -- debug with Robby\n    \/\/ This is cause an Invalid 'None' operation 'get' exception\n    \/\/ Art.clearPortVariables(bridgeId)\n    \/\/ bridge.entryPoints.compute()  -- debug with Robby\n    \/\/ Art.bridges(bridgeId).asInstanceOf[MSome[Bridge]].value.entryPoints.compute()\n    if (ArtNative.shouldDispatch(bridgeId)) {\n      Art.bridges(bridgeId.toZ).get.entryPoints.compute()\n    }\n  }\n\n  \/\/ execute thread by slot number\n  def executeSlotNumIMP(slotNum: Z): Unit = {\n    \/\/ pre-condition\n    assert(slotNum >= 0 & slotNum < dScheduleSpec.schedule.slots.size, s\"slotNum: ${slotNum}, Slot Size: ${dScheduleSpec.schedule.slots.size}\")\n    \/\/ body\n    val slots = dScheduleSpec.schedule.slots\n    executeSlotIMP(slots(slotNum))\n  }\n\n  \/\/ -- methods for updating schedule state (these do not actually execute the thread)\n\n  \/\/ purely functional method to compute the next schedule state\n  def nextState(state: ScheduleState, dScheduleSpec: DScheduleSpec): ScheduleState = {\n    \/\/ pre-condition\n    assert(validState(state, dScheduleSpec))\n    \/\/ body\n    val slots = dScheduleSpec.schedule.slots\n    var nextSlotNum = state.slotNum + 1\n    var nextHyperPeriodNum = state.hyperperiodNum\n    \/\/ handle wrap around\n    if (nextSlotNum == slots.size) {\n      nextSlotNum = 0\n      nextHyperPeriodNum = nextHyperPeriodNum + 1\n    }\n    return ScheduleState(nextSlotNum, nextHyperPeriodNum)\n  }\n\n  \/\/ purely functional method to compute the next schedule state\n  def previousState(state: ScheduleState, dScheduleSpec: DScheduleSpec): Option[ScheduleState] = {\n    \/\/ pre-condition\n    assert(validState(state, dScheduleSpec))\n    \/\/ body\n    if (isInitial(state)) {\n      return None()\n    }\n\n    val slots = dScheduleSpec.schedule.slots\n\n    var nextSlotNum = state.slotNum - 1 \/\/ assume for now we don't wrap around\n    var nextHyperPeriodNum = state.hyperperiodNum \/\/ assume for now we stay at same hyper-period\n\n    \/\/ handle wrap around\n    if (state.slotNum == 0) { \/\/ if current state has initial slot number, then wrap to end\n      nextSlotNum = slots.size - 1 \/\/ set nextSlotNum to last slot number\n      nextHyperPeriodNum = nextHyperPeriodNum - 1 \/\/ this is sound since we already checked that current state is not initial\n    }\n    return Some(ScheduleState(nextSlotNum, nextHyperPeriodNum))\n  }\n\n  \/\/ advance the state to the next schedule slot (side-effecting schedule state)\n  def advanceStateIMP(): Unit = {\n    scheduleState = nextState(scheduleState, dScheduleSpec)\n  }\n\n  def stepSystemOneSlotIMP(info: B): Unit = {\n    \/\/ pre-condition (invariants on scheduleState and dScheduleSpec)\n    \/\/ assert(validDScheduleSpec(dScheduleSpec))\n    assert(validState(scheduleState, dScheduleSpec))\n    \/\/ body\n    \/\/   execute thread in current slot\n    val preScheduleState = scheduleState\n    executeSlotNumIMP(scheduleState.slotNum)\n    \/\/   advance the schedule state\n    advanceStateIMP()\n    val postScheduleState = scheduleState\n    if (info) {\n      CliInfoProvider.showStep(preScheduleState, postScheduleState, dScheduleSpec)\n    }\n  }\n\n  def stepSystemNSlotsIMP(numSlots: Z): Unit = {\n    \/\/ pre-condition\n    assert(numSlots > 0)\n    \/\/ pre-condition (invariants on scheduleState and dScheduleSpec)\n    assert(validState(scheduleState, dScheduleSpec))\n    \/\/ body\n    for (i <- 1 to numSlots) {\n      stepSystemOneSlotIMP(T)\n    }\n  }\n\n  \/\/ Steps the system one hyper-period.\n  \/\/ Does not require the system to be on a hyper-period boundary.\n  \/\/ If state indicates that hyper-period is already in progress, the method will run to the start of the next hyper-period.\n  def stepSystemOneHPIMP(): Unit = {\n    \/\/ pre-condition (invariants on scheduleState and dScheduleSpec)\n    assert(validState(scheduleState, dScheduleSpec))\n    \/\/ var currentSlotNum: Z = scheduleState.slotNum\n    val numStepsToStartOfHP: Z = dScheduleSpec.schedule.slots.size - scheduleState.slotNum\n    stepSystemNSlotsIMP(numStepsToStartOfHP)\n    \/\/ assert that current state is at the beginning of a HP\n    assert(isHyperPeriodBoundary(scheduleState))\n\n    CliInfoProvider.showHyperPeriodBoundary(scheduleState)\n  }\n\n  \/\/ Steps the system N hyper-periods.\n  \/\/ Make an somewhat arbitrary but rational decision that this method should not be\n  \/\/ called when the system is not on a hyper-period boundary (start of hyper-period)\n  def stepSystemNHPIMP(numHyperPeriods: Z): Unit = {\n    for (hpcount <- 1 to numHyperPeriods) {\n      stepSystemOneHPIMP()\n    }\n  }\n\n  \/\/ Runs the system to the start of the given hyper-period number\n  def runToHP(hpNum: Z): Unit = {\n    \/\/ pre-condition (invariants on scheduleState and dScheduleSpec)\n    assert(validState(scheduleState, dScheduleSpec))\n    assert(hpNum >= 0)\n    \/\/ body\n\n    CliInfoProvider.message(s\"...Running to beginning of hyper-period# $hpNum\")\n\n    while (scheduleState.hyperperiodNum < hpNum) {\n      stepSystemOneSlotIMP(F)\n    }\n\n    CliInfoProvider.message(\"*********** Run to ... Completed *************\")\n\n    CliInfoProvider.showStateH(scheduleState)\n  }\n\n  \/\/ Runs the system to the start of the given state (hp# and slot#)\n  def runToState(hpNum: Z, slotNum: Z): Unit = {\n    \/\/ pre-condition (invariants on scheduleState and dScheduleSpec)\n    assert(validState(scheduleState, dScheduleSpec))\n    assert(hpNum >= 0)\n    assert(slotNum >= 0 & slotNum < Schedule.dScheduleSpec.schedule.slots.size)\n    \/\/ body\n\n    CliInfoProvider.message(s\"...Running to state [hp = $hpNum, slot = $slotNum]\")\n\n    while (scheduleState.hyperperiodNum < hpNum) {\n      stepSystemOneSlotIMP(F)\n    }\n    while (scheduleState.slotNum < slotNum) {\n      stepSystemOneSlotIMP(F)\n    }\n\n    CliInfoProvider.message(\"*********** Run to ... Completed *************\")\n\n    CliInfoProvider.showStateH(scheduleState)\n  }\n\n  \/\/ Runs the system to the start of the given slot#\n  def runToSlot(slotNum: Z): Unit = {\n    \/\/ pre-condition (invariants on scheduleState and dScheduleSpec)\n    assert(validState(scheduleState, dScheduleSpec))\n    assert(slotNum >= 0 & slotNum < Schedule.dScheduleSpec.schedule.slots.size)\n    \/\/ body\n    while (scheduleState.slotNum != slotNum) {\n      stepSystemOneSlotIMP(F)\n    }\n\n    CliInfoProvider.message(\"*********** Run to ... Completed *************\")\n\n    CliInfoProvider.showStateH(scheduleState)\n  }\n\n  \/\/ Runs the system to the start of the given domain\n  def runToDomain(domainId: Z): Unit = {\n    \/\/ pre-condition (invariants on scheduleState and dScheduleSpec)\n    assert(validState(scheduleState, dScheduleSpec))\n    assert(domainId >= 0 & domainId <= Schedule.dScheduleSpec.maxDomain)\n    \/\/ body\n    CliInfoProvider.message(s\"...Running to domain $domainId\")\n\n    while (Schedule.dScheduleSpec.schedule.slots(scheduleState.slotNum).domain != domainId) {\n      stepSystemOneSlotIMP(F)\n    }\n\n    CliInfoProvider.message(\"*********** Run to ... Completed *************\")\n\n    CliInfoProvider.showStateH(scheduleState)\n  }\n\n\n  \/\/ Runs the system to the start of the given domain\n  def runToThread(threadNickName: String): Unit = {\n    \/\/ pre-condition (invariants on scheduleState and dScheduleSpec)\n    assert(validState(scheduleState, dScheduleSpec))\n    val bridgeId = StaticScheduler.threadNickNames.get(threadNickName).get \/\/ ToDo: fix error handling\n    val domainId = StaticScheduler.bridgeIdToDomainMap(bridgeId)\n\n    CliInfoProvider.message(s\"...Running to thread $threadNickName (domain $domainId)\")\n    while (Schedule.dScheduleSpec.schedule.slots(scheduleState.slotNum).domain != domainId) {\n      stepSystemOneSlotIMP(F)\n    }\n    CliInfoProvider.message(\"*********** Run to ... Completed *************\")\n\n    CliInfoProvider.showStateH(scheduleState)\n  }\n\n\n  \/\/ Runs the system according to the static schedule without debugging, but still uses the debugging scheduling state\n  def runSystem(): Unit = {\n    \/\/ pre-condition (invariants on scheduleState and dScheduleSpec)\n    \/\/ assert valid schedule\n    \/\/ body\n    CliInfoProvider.message (s\"...Running system according to static schedule\")\n\n    Explorer.initializeScheduleStateIMP()\n    var systemStopCondition: B = false \/\/ right now we don't have a system stop condition\n    while (!systemStopCondition) {\n      executeSlotNumIMP(scheduleState.slotNum)\n      advanceStateIMP()\n      for (i <- 1 to 100000) {\n        None[String]()\n      }\n    }\n  }\n}\n\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/static\/ISZCommandProvider.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\npackage art.scheduling.static\n\nimport org.sireum._\n\n@record class ISZCommandProvider(commands: ISZ[Command]) extends CommandProvider {\n\n  var index: Z = 0\n\n  override def nextCommand(): Command = {\n    assert(commands.nonEmpty, \"commands must be non-empty\")\n    assert(index >= 0 && index < commands.size, s\"index must be >= 0 and < ${commands.size}\")\n\n    if (index == commands.size - 1 && !commands(index).isInstanceOf[Stop]) {\n      assert(F, \"Last command must be Stop\")\n      halt(\"Last command must be Stop\")\n    }\n    index = index + 1\n    return commands(index - 1)\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/static\/Schedule.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art.scheduling.static\n\nimport org.sireum._\nimport art.Art\nimport art.scheduling.static.Explorer.ScheduleState\n\nobject Schedule {\n\n  \/\/ const dschedule_t ksDomSchedule[] = { \/\/ (1 tick == 2ms)\n  \/\/  { .domain = 0, .length = 100 }, \/\/ all other seL4 threads, init, 200ms\n  \/\/  { .domain = 1, .length =   5 }, \/\/ pacer        10ms\n  \/\/  { .domain = 0, .length =  95 }, \/\/ domain0     190ms\n  \/\/  { .domain = 2, .length =   5 }, \/\/ source       10ms\n  \/\/  { .domain = 0, .length =  95 }, \/\/ domain0     190ms\n  \/\/  { .domain = 3, .length =   5 }, \/\/ destination  10ms\n  \/\/  { .domain = 0, .length = 195 }, \/\/ domain0     390ms\n  \/\/ };\n\n  \/\/ const word_t ksDomScheduleLength = sizeof(ksDomSchedule) \/ sizeof(dschedule_t);\n\n  @datatype class DScheduleSpec(maxDomain: Z, \/\/ the highest domain # used\n                                hyperPeriod: Z, \/\/ the hyper period in ticks\n                                schedule: DSchedule)\n\n  \/\/ contract invariants on schedule\n\n  @datatype class DSchedule(slots: ISZ[Slot])\n\n  \/\/ contract invariants on schedule\n\n  @datatype class Slot(domain: Z, length: Z)\n\n  val emptyDScheduleSpec: DScheduleSpec = DScheduleSpec(0, 0, DSchedule(ISZ()))\n\n  \/\/ ---------- schedule structure\n\n  var dScheduleSpec: DScheduleSpec = emptyDScheduleSpec\n  var domainToBridgeIdMap: ISZ[Art.BridgeId] = ISZ()\n\n  def setSchedule(spec: DScheduleSpec,\n                  domainsToBridgeMap: ISZ[Art.BridgeId]): Unit = {\n    \/\/ pre-condition -- all structural invariants for the domain schedule hold\n    validDScheduleSpec(spec)\n    \/\/ checking period for each thread requires alignment with model -- cannot check that here -- client should guarantee\n    \/\/ body\n    dScheduleSpec = spec\n    domainToBridgeIdMap = domainsToBridgeMap\n    \/\/\n    \/\/ Technically, after this point, the schedule is \"frozen\" and we should have to check the invariant properties on the\n    \/\/ schedule again.\n  }\n\n  \/\/ --------- helper method for accessing schedule info\n\n  def getBridgeIdFromSlot(slot: Slot): Art.BridgeId = {\n    return domainToBridgeIdMap(slot.domain)\n  }\n\n  def getBridgeIdFromSlotNumber(slotNum: Z): Art.BridgeId = {\n    return getBridgeIdFromSlot(dScheduleSpec.schedule.slots(slotNum))\n  }\n\n  def getBridgeIdFromScheduleState(scheduleState: ScheduleState): Art.BridgeId = {\n    return getBridgeIdFromSlotNumber(scheduleState.slotNum)\n  }\n\n  def getDomainFromSlotNum(slotNum: Z): Z = {\n    return dScheduleSpec.schedule.slots(slotNum).domain\n  }\n\n  def getDomainFromScheduleState(scheduleState: Explorer.ScheduleState): Z = {\n    return getDomainFromSlotNum(scheduleState.slotNum)\n  }\n\n  def threadNickName(bridgeId: Art.BridgeId): String = {\n    for (e <- StaticScheduler.threadNickNames.entries) {\n      if (e._2 == bridgeId) {\n        return e._1\n      }\n    }\n    return \"<not found>\"\n  }\n\n  def getThreadNickNameFromScheduleState(scheduleState: Explorer.ScheduleState): String = {\n    val bridgeId = Schedule.getBridgeIdFromSlotNumber(scheduleState.slotNum)\n    return threadNickName(bridgeId)\n  }\n\n  \/\/ ------------- contract invariants on schedule -------------\n\n  \/\/ aggregate invariant on static schedule\n  def validDScheduleSpec(dScheduleSpec: DScheduleSpec): B = {\n    return checkMaxDomain(dScheduleSpec) &&\n      checkNoMissingDomain(dScheduleSpec) &&\n      checkHyperPeriodTicks(dScheduleSpec)\n  }\n\n  \/\/ Invariant: no domain id referenced in a slot exceeds the specified max domain\n  def checkMaxDomain(dScheduleSpec: DScheduleSpec): B = {\n    \/\/ Note: transpiler doesn't current support function passing\n    \/\/return All(dScheduleSpec.schedule.slots)(s => s.domain <= dScheduleSpec.maxDomain)\n    for (s <- dScheduleSpec.schedule.slots if s.domain > dScheduleSpec.maxDomain) {\n      return F\n    }\n    return T\n  }\n\n  \/\/ Invariant: every domain 0 .. maxDomain is referenced by at least one slot\n  def checkNoMissingDomain(dScheduleSpec: DScheduleSpec): B = {\n    \/\/ NOTE: transpiler doesn't currently support function passing\n    \/\/return All(0 until dScheduleSpec.maxDomain)(d =>\n    \/\/  Exists(dScheduleSpec.schedule.slots)(s => s.domain == d)\n    \/\/)\n    for (d <- 0 until dScheduleSpec.maxDomain) {\n      var exists: B = F\n      for (s <- dScheduleSpec.schedule.slots if !exists) {\n        exists = exists || s.domain == d\n      }\n      if (!exists) {\n        return F\n      }\n    }\n    return T\n  }\n\n  \/\/ Invariant: the total time (in ticks) across all slots matches the specified hyper-period\n  def checkHyperPeriodTicks(dScheduleSpec: DScheduleSpec): B = {\n    var computedHyperPeriod: Z = 0\n    for (s <- dScheduleSpec.schedule.slots) {\n      computedHyperPeriod = computedHyperPeriod + s.length\n    }\n    return (computedHyperPeriod == dScheduleSpec.hyperPeriod)\n  }\n\n\n  \/\/ add Clock period\n\n  \/\/ This property is not an invariant per se, but rather a consistency property between the model-specified\n  \/\/ thread periods and the implied periods in the static schedule.  Thus, this property is omitted from the\n  \/\/ structural invariant on the static schedule.\n  \/\/\n  \/\/ Model-consistency: for a given domain, the period implied by the schedule (calculated period) matches\n  \/\/ the period (parameter) specified in the model\n  \/*\n   * @param domain identifier of domain to be checked\n   * @param period specified period of domain in ticks\n   * @param dScheduleSpec static schedule\n   *\/\n  def checkPeriodTicks(domain: Z, period: Z, dScheduleSpec: DScheduleSpec): B = {\n    var computedPeriod: Z = 0 \/\/ computed period in ticks\n    var computedTicksBeforeOccurrence: Z = 0\n    \/\/ number of ticks before first occurrence\n    \/\/ used to determine period, when periods \"wraps around\" the schedule\n    var occurrence: Z = 0 \/\/ how many times has domain occurred so far in schedule\n\n    for (s <- dScheduleSpec.schedule.slots) {\n      \/\/ println(occurrence, \", \", computedTicksBeforeOccurrence, \", \", computedPeriod)\n      if (s.domain == domain) { \/\/ if we are at a slot for the domain in the schedule\n        \/\/ if this is not the first occurrence, then we have computed the time (in ticks)\n        \/\/ since the last occurrence, so compare computed period to specified period\n        if (occurrence > 0) {\n          if (computedPeriod != period) {\n            return false\n          }\n        }\n        \/\/ at all occurrences (first or otherwise), increment the occurrence counter\n        occurrence = occurrence + 1\n        \/\/ re-start the accumulation of time leading to period\n        computedPeriod = s.length \/\/ \"initialize\" the computed period with length of domain's time slot\n      } else {\n        \/\/\n        if (occurrence > 0) { \/\/ if we have previously encountered the domain in the schedule\n          computedPeriod = computedPeriod + s.length \/\/ add current time slice\n        } else {\n          \/\/ if we haven't see the domain yet, add the time to the \"before occurrence\" accumulator\n          computedTicksBeforeOccurrence = computedTicksBeforeOccurrence + s.length\n        }\n      }\n    }\n    \/\/ println(occurrence, \", \", computedTicksBeforeOccurrence, \", \", computedPeriod)\n    \/\/ at this point, we have reached the end of the schedule.  We need to check for the domain\n    \/\/ as it wraps around.  Given our other invariants, we know that the domain occurs at least\n    \/\/ once.  So computedPeriod should hold the time since it was seen, whereas\n    \/\/ computedTicksBeforeOccurrence should hold the time before it was seen.\n    \/\/ The sum of these values should equal the period.\n    return (computedPeriod + computedTicksBeforeOccurrence == period)\n  }\n\n  def computeElaspedRemainingHPTicks(slotNum: Z, dScheduleSpec: DScheduleSpec): (Z, Z) = {\n    \/\/ pre-condition\n    \/\/  TODO: well-formed dScheduleSpec\n    \/\/  TODO: valid slotNum (define function for below)\n    assert(0 <= slotNum & slotNum < dScheduleSpec.schedule.slots.size)\n    \/\/ body\n    var elaspedHPTicks: Z = 0\n    for (s <- 0 until slotNum) {\n      elaspedHPTicks = elaspedHPTicks + dScheduleSpec.schedule.slots(0).length\n    }\n    val remainingHPTicks: Z = dScheduleSpec.hyperPeriod - elaspedHPTicks\n    return (elaspedHPTicks, remainingHPTicks)\n  }\n}\n\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/static\/StateObserver.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art.scheduling.static\n\nimport org.sireum._\nimport art.{Art, DataContent}\n\nobject StateObserver {\n\n  def observeInPortValue(bridgeId: Art.BridgeId, portId: Art.PortId): Option[DataContent] = {\n    return Art.observeInInfrastructurePort(portId)\n  }\n\n  def observeOutPortValue(bridgeId: Art.BridgeId, portId: Art.PortId): Option[DataContent] = {\n    return Art.observeOutPortVariable(portId)\n  }\n\n  def observeInPortValues(bridgeId: Art.BridgeId): ISZ[(String, Option[DataContent])] = {\n    val bridge = Art.bridges(bridgeId.toZ).get\n    var portValues: ISZ[(String, Option[DataContent])] = ISZ()\n\n    for (port <- bridge.ports.dataIns) {\n      portValues = portValues :+ ((port.name, Art.observeInInfrastructurePort(port.id)))\n    }\n\n    for (port <- bridge.ports.eventIns) {\n      portValues = portValues :+ ((port.name, Art.observeInInfrastructurePort(port.id)))\n    }\n    return portValues\n  }\n\n  def observeOutPortValues(bridgeId: Art.BridgeId): ISZ[(String, Option[DataContent])] = {\n    val bridge = Art.bridges(bridgeId.toZ).get\n    var portValues: ISZ[(String, Option[DataContent])] = ISZ()\n\n    for (port <- bridge.ports.dataOuts) {\n      portValues = portValues :+ ((port.name, Art.observeOutPortVariable(port.id)))\n    }\n\n    for (port <- bridge.ports.eventOuts) {\n      portValues = portValues :+ ((port.name, Art.observeOutPortVariable(port.id)))\n    }\n    return portValues\n  }\n\n  def observeInPortValuesByNickName(threadNickName: String): ISZ[(String, Option[DataContent])] = {\n    halt(\"TODO\")\n    \/\/val bridgeId = art.StaticScheduling.threadNickNames.get(threadNickName).get \/\/ ToDo: fix error handling\n    \/\/return observeInPortValues(bridgeId)\n  }\n\n  def observeOutPortValuesByNickName(threadNickName: String): ISZ[(String, Option[DataContent])] = {\n    halt(\"TODO\")\n    \/\/val bridgeId = art.StaticScheduling.threadNickNames.get(threadNickName).get \/\/ ToDo: fix error handling\n    \/\/return observeOutPortValues(bridgeId)\n  }\n\n  \/\/=======================================================================\n  \/\/ State Observations (primary methods for interpreting debug commands)\n  \/\/=======================================================================\n\n  def printPortContentsInputsCurrent(): Unit = {\n    val bridgeId = Schedule.getBridgeIdFromSlotNumber(Explorer.scheduleState.slotNum)\n    val inPortInfo = observeInPortValues(bridgeId)\n\n    println(\"****************************\")\n    println(s\"   Next Component: ${Schedule.threadNickName(bridgeId)} (id = $bridgeId)\")\n    println(\"****************************\")\n    println(\" Input Ports\")\n    println(\" ===============\")\n    printPortInfo(inPortInfo)\n  }\n\n  def printPortContentsOutputsCurrent(): Unit = {\n    val previousStateOpt: Option[Explorer.ScheduleState] =\n      Explorer.previousState(Explorer.scheduleState, Schedule.dScheduleSpec)\n\n    previousStateOpt match {\n      case Some(previousState) => {\n        val bridgeId = Schedule.getBridgeIdFromSlotNumber(previousState.slotNum)\n        val outPortInfo = observeOutPortValues(bridgeId)\n        println(\"****************************\")\n        println(s\"   Previous Component: ${Schedule.threadNickName(bridgeId)} (id = $bridgeId)\")\n        println(\"****************************\")\n        println(\" Output Ports\")\n        println(\" ===============\")\n        printPortInfo(outPortInfo)\n      }\n      case None() => {\n        println(\"(initial state - no previous state to show)\")\n      }\n    }\n  }\n\n  def printPortInfo(portVals: ISZ[(String, Option[DataContent])]): Unit = {\n    for (e <- portVals) {\n      println(s\"${e._1} = ${e._2}\")\n    }\n  }\n\n  def printPortContents(bridgeId: Art.BridgeId): Unit = {\n    val inPortInfo = observeInPortValues(bridgeId)\n    val outPortInfo = observeOutPortValues(bridgeId)\n    println(\"****************************\")\n    println(s\"   Component: ${Schedule.threadNickName(bridgeId)} (id = $bridgeId)\")\n    println(\"****************************\")\n    println(\" Input Ports\")\n    println(\" ===============\")\n    println(s\"  ${printPortInfo(inPortInfo)}\")\n    println()\n    println(\" Output Ports\")\n    println(\" ================\")\n    printPortInfo(outPortInfo)\n  }\n\n  def printPortContentsByNickName(threadNickName: String): Unit = {\n    val bridgeId = StaticScheduler.threadNickNames.get(threadNickName).get \/\/ ToDo: fix error handling\n    printPortContents(bridgeId)\n  }\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/static\/StaticScheduler.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\npackage art.scheduling.static\n\nimport org.sireum._\nimport art.Art\nimport art.scheduling.Scheduler\nimport art.scheduling.static.Schedule.DScheduleSpec\n\nobject StaticScheduler {\n  var threadNickNames: Map[String, Art.BridgeId] = Map.empty\n  var domainToBridgeIdMap: ISZ[Art.BridgeId] = ISZ()\n\n  def bridgeIdToDomainMap(bridgeId: Art.BridgeId): Z = {\n    for (i <- 0 until domainToBridgeIdMap.size if bridgeId == domainToBridgeIdMap(i)) {\n      return i\n    }\n    assert(F, s\"domain for $bridgeId not found\")\n    halt(s\"domain for $bridgeId not found\")\n  }\n}\n\n@record class StaticScheduler(staticSchedule: DScheduleSpec,\n                              bridges: IS[Art.BridgeId, art.Bridge],\n                              domainToBridgeIdMap: ISZ[Art.BridgeId],\n                              threadNickNames: Map[String, Art.BridgeId],\n                              commandProvider: CommandProvider) extends Scheduler {\n\n  override def initialize(): Unit = {\n    StaticScheduler.threadNickNames = threadNickNames\n    StaticScheduler.domainToBridgeIdMap = domainToBridgeIdMap\n\n    Schedule.setSchedule(staticSchedule, domainToBridgeIdMap)\n\n    Explorer.initializeScheduleStateIMP()\n  }\n\n  override def initializationPhase(): Unit = {\n    for (bridgeId <- domainToBridgeIdMap) {\n      bridges(bridgeId).entryPoints.initialise()\n      art.Art.logInfo(bridgeId, s\"Initialized bridge: ${bridges(bridgeId).name}\")\n    }\n  }\n\n  override def computePhase(): Unit = {\n    var done: B = F\n    while (!done) {\n      done = CommandInterpreter.interpretCmd(commandProvider.nextCommand())\n    }\n  }\n\n  override def finalizePhase(): Unit = {\n    for (bridgeId <- domainToBridgeIdMap) {\n      bridges(bridgeId).entryPoints.finalise()\n      art.Art.logInfo(bridgeId, s\"Finalized bridge: ${bridges(bridgeId).name}\")\n    }\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/data\/pfc_project\/Aux_Types.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage pfc_project\n\nimport org.sireum._\n\n\/\/ This file will not be overwritten so is safe to edit\n\n\/\/ Any datatype definitions placed in this file will be processed by sergen and SlangCheck\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : true
        }
      ],
      [
        "slang\/bin\/sergen.cmd",
        {
          "type" : "ITestResource",
          "content" : "::\/*#! 2> \/dev\/null                                   #\r\n@ 2>\/dev\/null # 2>nul & echo off & goto BOF           #\r\nif [ -z ${SIREUM_HOME} ]; then                        #\r\n  echo \"Please set SIREUM_HOME env var\"               #\r\n  exit -1                                             #\r\nfi                                                    #\r\nexec ${SIREUM_HOME}\/bin\/sireum slang run \"$0\" \"$@\"    #\r\n:BOF\r\nsetlocal\r\nif not defined SIREUM_HOME (\r\n  echo Please set SIREUM_HOME env var\r\n  exit \/B -1\r\n)\r\n%SIREUM_HOME%\\\\bin\\\\sireum.bat slang run \"%0\" %*\r\nexit \/B %errorlevel%\r\n::!#*\/\r\n\/\/ #Sireum\r\n\r\nimport org.sireum._\r\n\r\nval sireum = Os.path(Os.env(\"SIREUM_HOME\").get) \/ \"bin\" \/ (if (Os.isWin) \"sireum.bat\" else \"sireum\")\r\n\r\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\r\n\r\n\/\/ create serializers\/deserializers for the Slang types used in the project\r\n\r\nval files: ISZ[String] = ISZ(\"..\/src\/main\/data\/pfc_project\/Base_Types.scala\",\r\n                             \"..\/src\/main\/art\/art\/DataContent.scala\",\r\n                             \"..\/src\/main\/data\/pfc_project\/Aux_Types.scala\")\r\n\r\nval toolargs: String = st\"${(files, \" \")}\".render\r\n\r\n(Os.slashDir.up \/ \"src\" \/ \"main\" \/ \"util\" \/ \"pfc_project\").mkdirAll()\r\n\r\nproc\"$sireum tools sergen -p pfc_project -m json,msgpack -o ${Os.slashDir.up}\/src\/main\/util\/pfc_project $toolargs\".at(Os.slashDir).console.runCheck()\r\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : true,
          "makeCRLF" : true,
          "isDatatype" : false
        }
      ],
      [
        "slang\/bin\/slangcheck.cmd",
        {
          "type" : "ITestResource",
          "content" : "::\/*#! 2> \/dev\/null                                   #\r\n@ 2>\/dev\/null # 2>nul & echo off & goto BOF           #\r\nif [ -z ${SIREUM_HOME} ]; then                        #\r\n  echo \"Please set SIREUM_HOME env var\"               #\r\n  exit -1                                             #\r\nfi                                                    #\r\nexec ${SIREUM_HOME}\/bin\/sireum slang run \"$0\" \"$@\"    #\r\n:BOF\r\nsetlocal\r\nif not defined SIREUM_HOME (\r\n  echo Please set SIREUM_HOME env var\r\n  exit \/B -1\r\n)\r\n%SIREUM_HOME%\\\\bin\\\\sireum.bat slang run \"%0\" %*\r\nexit \/B %errorlevel%\r\n::!#*\/\r\n\/\/ #Sireum\r\n\r\nimport org.sireum._\r\n\r\nval sireum = Os.path(Os.env(\"SIREUM_HOME\").get) \/ \"bin\" \/ (if (Os.isWin) \"sireum.bat\" else \"sireum\")\r\n\r\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\r\n\r\n\/\/ create SlangCheck artifacts for the Slang types used in the project\r\n\r\nval files: ISZ[String] = ISZ(\"..\/src\/main\/data\/pfc_project\/Base_Types.scala\",\r\n                             \"..\/src\/main\/art\/art\/DataContent.scala\",\r\n                             \"..\/src\/main\/data\/pfc_project\/Aux_Types.scala\")\r\n\r\nval toolargs: String = st\"${(files, \" \")}\".render\r\n\r\n(Os.slashDir.up \/ \"src\" \/ \"main\" \/ \"util\" \/ \"pfc_project\").mkdirAll()\r\n\r\nproc\"$sireum proyek slangcheck -p pfc_project -o ${Os.slashDir.up}\/src\/main\/util\/pfc_project ${Os.slashDir.up} $toolargs\".at(Os.slashDir).console.runCheck()\r\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : true,
          "makeCRLF" : true,
          "isDatatype" : false
        }
      ],
      [
        "slang\/bin\/project.cmd",
        {
          "type" : "ITestResource",
          "content" : "::\/*#! 2> \/dev\/null                                   #\r\n@ 2>\/dev\/null # 2>nul & echo off & goto BOF           #\r\nif [ -z ${SIREUM_HOME} ]; then                        #\r\n  echo \"Please set SIREUM_HOME env var\"               #\r\n  exit -1                                             #\r\nfi                                                    #\r\nexec ${SIREUM_HOME}\/bin\/sireum slang run \"$0\" \"$@\"    #\r\n:BOF\r\nsetlocal\r\nif not defined SIREUM_HOME (\r\n  echo Please set SIREUM_HOME env var\r\n  exit \/B -1\r\n)\r\n%SIREUM_HOME%\\\\bin\\\\sireum.bat slang run \"%0\" %*\r\nexit \/B %errorlevel%\r\n::!#*\/\r\n\/\/ #Sireum\r\n\r\n\/\/ Example Sireum Proyek build definitions -- the contents of this file will not be overwritten\r\n\/\/\r\n\/\/ To install Sireum (Proyek and IVE) see https:\/\/sireum.org\/getting-started\/\r\n\/\/\r\n\/\/ The following commands should be executed in the parent of the 'bin' directory.\r\n\/\/\r\n\/\/ Command Line:\r\n\/\/   To run the demo from the command line using the default scheduler:\r\n\/\/     sireum proyek run . pfc_project.Demo\r\n\/\/\r\n\/\/   To see the available CLI options:\r\n\/\/     sireum proyek run . pfc_project.Demo -h\r\n\/\/\r\n\/\/   To run the example unit tests from the command line:\r\n\/\/     sireum proyek test .\r\n\/\/\r\n\/\/   To build an executable jar:\r\n\/\/     sireum proyek assemble --uber --main pfc_project.Demo .\r\n\/\/\r\n\/\/ Sireum IVE:\r\n\/\/\r\n\/\/   Create the IVE project if Codegen was not run locally or if its no-proyek-ive\r\n\/\/   option was used:\r\n\/\/     sireum proyek ive .\r\n\/\/\r\n\/\/   Then in IVE select 'File > Open ...' and navigate to the parent of the\r\n\/\/   'bin' directory and click 'OK'.\r\n\/\/\r\n\/\/   To run the demo from within Sireum IVE:\r\n\/\/     Right click src\/main\/architecture\/pfc_project\/Demo.scala and choose \"Run 'Demo'\"\r\n\/\/\r\n\/\/   To run the unit test cases from within Sireum IVE:\r\n\/\/     Right click the src\/test\/bridge and choose \"Run ScalaTests in bridge\"\r\n\r\nimport org.sireum._\r\nimport org.sireum.project.{Module, Project, Target}\r\n\r\nval home: Os.Path = Os.slashDir.up.canon\r\n\r\nval slangModule: Module = Module(\r\n  id = \"PFC_Sys_Impl_Instance\",\r\n  basePath = (home \/ \"src\").string,\r\n  subPathOpt = None(),\r\n  deps = ISZ(),\r\n  targets = ISZ(Target.Jvm),\r\n  ivyDeps = ISZ(\"org.sireum.kekinian::library:\",\r\n                \"org.sireum.kekinian::hamr-vision:\"),\r\n  sources = for(m <- ISZ(\"art\", \"architecture\", \"bridge\", \"component\", \"data\", \"nix\", \"seL4Nix\", \"util\")) yield (Os.path(\"main\") \/ m).string,\r\n  resources = ISZ(),\r\n  testSources = for (m <- ISZ(\"bridge\", \"system\", \"util\")) yield (Os.path(\"test\") \/ m).string,\r\n  testResources = ISZ(),\r\n  publishInfoOpt = None()\r\n)\r\n\r\nval inspectorModule: Module = slangModule(\r\n  sources = slangModule.sources :+ (Os.path(\"main\") \/ \"inspector\").string,\r\n  ivyDeps = slangModule.ivyDeps ++ ISZ(\"org.sireum:inspector-capabilities:\", \"org.sireum:inspector-gui:\", \"org.sireum:inspector-services-jvm:\")\r\n)\r\n\r\nval slangProject: Project = Project.empty + slangModule\r\nval inspectorProject: Project = Project.empty + inspectorModule\r\n\r\nval prj: Project = slangProject\r\n\/\/val prj: Project = inspectorProject()\r\n\r\nprintln(project.JSON.fromProject(prj, T))\r\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : true,
          "makeCRLF" : true,
          "isDatatype" : false
        }
      ],
      [
        "slang\/versions.properties",
        {
          "type" : "ITestResource",
          "content" : "org.sireum.slang-embedded-art%%slang-embedded-art%=6021d37\n\norg.sireum%inspector-capabilities%=0.6-SNAPSHOT\norg.sireum%inspector-gui%=0.6-SNAPSHOT\norg.sireum%inspector-services-jvm%=0.6-SNAPSHOT\n\norg.sireum.kekinian%%hamr-vision%=4d1963b251\n\n# remove the following entries if you want to use the versions\n# that ship with sireum (i.e. $SIREUM_HOME\/bin\/sireum --version)\n\n# Scala compiler plugin for Slang\norg.sireum%%scalac-plugin%=4.20231110.ad6e0a5\n\norg.sireum.kekinian%%library%=4d1963b251\n\norg.scala-lang%scala-library%=2.13.12\norg.scalatest%%scalatest%%=3.2.17\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/build.sc",
        {
          "type" : "ITestResource",
          "content" : "import mill._\nimport scalalib._\n\n\/\/ Example mill build -- the contents of this file will not be overwritten.\n\/\/\n\/\/ A custom mill build for Sireum can be obtained from https:\/\/github.com\/sireum\/rolling\/releases\/tag\/mill\n\/\/ On Windows, rename 'mill' to 'mill.bat'\n\/\/\n\/\/ To run the demo from the command line:\n\/\/   mill pfc_project.run\n\/\/\n\/\/ To run the example unit tests:\n\/\/   mill pfc_project.tests\n\/\/\n\/\/ Sireum IVE: Installation instructions available at https:\/\/sireum.org\/getting-started\/\n\/\/\n\/\/   First cd to the directory containing this file and execute the following:\n\/\/\n\/\/     $SIREUM_HOME\/bin\/sireum tools ivegen -f -m mill -n slang ..\/\n\/\/\n\/\/   Then in IVE select 'File > Open ...' and navigate to the directory\n\/\/   containing this file then click 'OK'.  To have the codebase and its\n\/\/   test suites recompiled upon changes, run:\n\/\/\n\/\/     $SIREUM_HOME\/bin\/mill -w pfc_project.tests.compile\n\/\/\n\/\/ Visual Studio Code:\n\/\/   Follow Sireum Kekinian's instructions for setting up a development\n\/\/   environment using Scala Metals: https:\/\/github.com\/sireum\/kekinian#scala-metals\n\/\/   Then open the folder containing this file in VS Code and import the\n\/\/   mill build when asked.\n\n\nobject `pfc_project` extends slangEmbeddedProject\n\ntrait SlangEmbeddedModule extends ScalaModule {\n\n  \/\/ refer to https:\/\/github.com\/sireum\/kekinian\/blob\/master\/versions.properties\n  \/\/ to get the most recent versions of the following dependencies\n\n  \/\/ versions.properties key: org.scala-lang%scala-library%\n  val scalaVer = \"2.13.12\"\n\n  \/\/ versions.properties key: org.scalatest%%scalatest%%\n  val scalaTestVersion = \"3.2.17\"\n\n  \/\/ versions.properties key: org.sireum%%scalac-plugin%\n  \/\/ https:\/\/github.com\/sireum\/scalac-plugin\/tree\/4.20231110.ad6e0a5\n  val sireumScalacVersion = \"4.20231110.ad6e0a5\"\n\n\n  \/\/ refer to https:\/\/github.com\/sireum\/kekinian\/releases to get the latest\n  \/\/ Sireum Kekinian release: https:\/\/github.com\/sireum\/kekinian\/tree\/4d1963b251\n  val kekinianVersion = \"4d1963b251\"\n\n\n  val inspectorVersion = \"0.6-SNAPSHOT\"\n\n  val formsRtVersion = \"7.0.3\"\n\n\n  def scalaVersion = scalaVer\n\n  override def javacOptions = T { Seq(\"-source\", \"1.8\", \"-target\", \"1.8\", \"-encoding\", \"utf8\") }\n\n  override def scalacOptions = T { Seq(\n    \"-release:8\",\n    \"-deprecation\",\n    \"-Yrangepos\",\n    \"-Ydelambdafy:method\",\n    \"-feature\",\n    \"-unchecked\",\n    \"-Xfatal-warnings\",\n    \"-language:postfixOps\"\n  ) }\n\n  override def ivyDeps = Agg(\n    ivy\"org.sireum.kekinian::library::${kekinianVersion}\",\n    ivy\"org.sireum.kekinian::hamr-vision::${kekinianVersion}\",\n\n    \/\/ Jetbrains UI Designer\n    ivy\"com.intellij:forms_rt:${formsRtVersion}\"\n  )\n\n  override def scalacPluginIvyDeps = Agg(ivy\"org.sireum::scalac-plugin::${sireumScalacVersion}\")\n\n  override def repositories = super.repositories :+ coursier.Repositories.jitpack\n\n  override def mainClass = T { Some(\"pfc_project.Demo\") }\n\n  implicit def osPath2PathRef(p: os.Path): PathRef = PathRef(p)\n}\n\ntrait slangEmbeddedProject extends SlangEmbeddedModule {\n\n  def contributedSources: Seq[PathRef] = Seq(\n    millSourcePath \/ os.up \/ \"src\" \/ \"main\" \/ \"architecture\",\n    millSourcePath \/ os.up \/ \"src\" \/ \"main\" \/ \"art\",\n    millSourcePath \/ os.up \/ \"src\" \/ \"main\" \/ \"bridge\",\n    millSourcePath \/ os.up \/ \"src\" \/ \"main\" \/ \"component\",\n    millSourcePath \/ os.up \/ \"src\" \/ \"main\" \/ \"data\",\n    millSourcePath \/ os.up \/ \"src\" \/ \"main\" \/ \"nix\",\n    millSourcePath \/ os.up \/ \"src\" \/ \"main\" \/ \"seL4Nix\",\n    millSourcePath \/ os.up \/ \"src\" \/ \"main\" \/ \"util\"\n  )\n\n  override def sources = T.sources(contributedSources)\n\n  object tests extends Tests {\n\n    final override def millSourcePath = super.millSourcePath \/ os.up \/ os.up \/ \"src\" \/ \"test\"\n\n    override def sources = T.sources( millSourcePath \/ \"bridge\",\n                                      millSourcePath \/ \"system\",\n                                      millSourcePath \/ \"util\" )\n\n    override def ivyDeps = Agg(ivy\"org.scalatest::scalatest::${scalaTestVersion}\")\n\n    override def testFrameworks = T { Seq(\"org.scalatest.tools.Framework\") }\n  }\n}\n\ntrait slangEmbeddedInspectorProject extends slangEmbeddedProject {\n\n  override def mainClass = T { Some(\"pfc_project.InspectorDemo\") }\n\n  override def contributedSources =\n    super.contributedSources :+ millSourcePath \/ os.up \/ \"src\" \/ \"main\" \/ \"inspector\"\n\n  \/\/ FIXME: 2021.01.04 - the following doesn't work due to javafx\/mill resolution issue\n  \/\/        -- refer to https:\/\/github.com\/lihaoyi\/mill\/issues\/767\n  \/\/ override def ivyDeps = Agg(\n  \/\/   ivy\"org.sireum::inspector-capabilities::${inspectorVersion}\",\n  \/\/   ivy\"org.sireum::inspector-gui::${inspectorVersion}\",\n  \/\/   ivy\"org.sireum::inspector-services-jvm::${inspectorVersion}\"\n\n  \/\/ workaround to #767 -- refer to https:\/\/github.com\/lihaoyi\/mill\/issues\/767#issuecomment-652799588\n  override def unmanagedClasspath = T {\n    import coursier._\n\n    val files = Fetch().addDependencies(\n      dep\"org.sireum:inspector-capabilities:0.6-SNAPSHOT\",\n      dep\"org.sireum:inspector-gui:0.6-SNAPSHOT\",\n      dep\"org.sireum:inspector-services-jvm:0.6-SNAPSHOT\"\n    ).addRepositories(\n      Repositories.sonatype(\"releases\"),\n      Repositories.jitpack\n    ).run()\n    val pathRefs = files.map(f => PathRef(os.Path(f)))\n    Agg(pathRefs : _*)\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/build.sbt",
        {
          "type" : "ITestResource",
          "content" : "\/\/ Example sbt build definitions -- the contents of this file will not be overwritten\n\/\/\n\/\/ sbt can be obtained from https:\/\/www.scala-sbt.org\/download.html\n\/\/\n\/\/ To run the demo from the command line using the default scheduler:\n\/\/   sbt run\n\/\/\n\/\/ To see the available CLI options:\n\/\/   sbt \"run -h\"\n\/\/\n\/\/ To run the example unit tests from the command line:\n\/\/   sbt test\n\/\/\n\/\/ To build a runnable\/executable jar:\n\/\/   sbt assembly\n\/\/\n\/\/ To skip running the unit tests while building the executable jar:\n\/\/   sbt 'set test in assembly := {}' assembly\n\/\/ on Linux\/Mac, or\n\/\/   sbt \"set test in assembly := {}\" assembly\n\/\/ on Windows\n\/\/\n\/\/ Sireum IVE: Installation instructions available at https:\/\/sireum.org\/getting-started\/\n\/\/\n\/\/   In IVE select 'File > Open ...' and navigate to the directory containing\n\/\/   this file then click 'OK'.\n\/\/\n\/\/   To run the demo from within Sireum IVE:\n\/\/     Right click src\/main\/architecture\/pfc_project\/Demo.scala and choose \"Run 'Demo'\"\n\/\/\n\/\/   To run the unit test cases from within Sireum IVE:\n\/\/     Right click the src\/test\/bridge directory and choose \"Run ScalaTests in bridge\"\n\/\/\n\/\/   NOTE: A ClassNotFoundException may be raised the first time you try to\n\/\/         run the demo or unit tests.  If this occurs simply delete the directory\n\/\/         named 'target' and retry\n\n\nlazy val PFC_Sys_Impl_Instance = slangEmbeddedProject(\"PFC_Sys_Impl_Instance\", \".\")\n\n\/\/ refer to https:\/\/github.com\/sireum\/kekinian\/blob\/master\/versions.properties\n\/\/ to get the most recent versions of the following dependencies\n\n\/\/ versions.properties key: org.scala-lang%scala-library%\nval scalaVer = \"2.13.12\"\n\n\/\/ versions.properties key: org.scalatest%%scalatest%%\nval scalaTestVersion = \"3.2.17\"\n\n\/\/ versions.properties key: org.sireum%%scalac-plugin%\n\/\/ https:\/\/github.com\/sireum\/scalac-plugin\/tree\/4.20231110.ad6e0a5\nval sireumScalacVersion = \"4.20231110.ad6e0a5\"\n\n\n\/\/ refer to https:\/\/github.com\/sireum\/kekinian\/releases to get the latest\n\/\/ Sireum Kekinian release: https:\/\/github.com\/sireum\/kekinian\/tree\/4d1963b251\nval kekinianVersion = \"4d1963b251\"\n\n\nval inspectorVersion = \"0.6-SNAPSHOT\"\n\nval formsRtVersion = \"7.0.3\"\n\n\n\nval commonSettings = Seq(\n  organization := \"org.sireum\",\n  incOptions := incOptions.value.withLogRecompileOnMacro(false),\n  scalaVersion := scalaVer,\n  scalacOptions := Seq(\"-release:8\", \"-deprecation\",\n    \"-Ydelambdafy:method\", \"-feature\", \"-unchecked\", \"-Xfatal-warnings\"),\n  Test \/ parallelExecution := true,\n  resolvers ++= Resolver.sonatypeOssRepos(\"public\") ++ Seq(\"jitpack\" at \"https:\/\/jitpack.io\"),\n  addCompilerPlugin(\"org.sireum\" %% \"scalac-plugin\" % sireumScalacVersion),\n  ThisBuild \/ evictionErrorLevel := Level.Warn,\n  libraryDependencies ++= Seq(\n    \"org.sireum.kekinian\" %% \"library\" % kekinianVersion withSources(),\n    \"org.sireum.kekinian\" %% \"hamr-vision\" % kekinianVersion withSources()\n  )\n)\n\nimport sbtassembly.AssemblyPlugin.defaultUniversalScript\nval slangEmbeddedSettings = Seq(\n  Compile \/ unmanagedSourceDirectories += baseDirectory.value \/ \"src\/main\/art\",\n  Compile \/ unmanagedSourceDirectories += baseDirectory.value \/ \"src\/main\/architecture\",\n  Compile \/ unmanagedSourceDirectories += baseDirectory.value \/ \"src\/main\/bridge\",\n  Compile \/ unmanagedSourceDirectories += baseDirectory.value \/ \"src\/main\/component\",\n  Compile \/ unmanagedSourceDirectories += baseDirectory.value \/ \"src\/main\/data\",\n  Compile \/ unmanagedSourceDirectories += baseDirectory.value \/ \"src\/main\/nix\",\n  Compile \/ unmanagedSourceDirectories += baseDirectory.value \/ \"src\/main\/seL4Nix\",\n  Compile \/ unmanagedSourceDirectories += baseDirectory.value \/ \"src\/main\/util\",\n\n  Compile \/ unmanagedSourceDirectories in Test += baseDirectory.value \/ \"src\/test\/bridge\",\n  Compile \/ unmanagedSourceDirectories in Test += baseDirectory.value \/ \"src\/test\/system\",\n  Compile \/ unmanagedSourceDirectories in Test += baseDirectory.value \/ \"src\/test\/util\",\n\n  libraryDependencies += \"org.scalatest\" %% \"scalatest\" % scalaTestVersion % \"test\",\n\n  \/\/ Jetbrains UI Designer\n  libraryDependencies += \"com.intellij\" % \"forms_rt\" % formsRtVersion,\n\n  mainClass in (Compile, run) := Some(\"pfc_project.Demo\"),\n\n  mainClass in assembly := Some(\"pfc_project.Demo\"),\n  assemblyJarName in assembly := \"PFC_Sys_Impl_Instance.jar\",\n  assemblyOption in assembly := (assemblyOption in assembly).value.copy(prependShellScript = Some(defaultUniversalScript(shebang = false))),\n\n  assemblyMergeStrategy in assembly := {\n    case PathList(\"META-INF\", xs @ _*) => MergeStrategy.discard\n    case x => MergeStrategy.first\n  }\n)\n\nval slangEmbeddedInspectorSettings = Seq(\n  Compile \/ unmanagedSourceDirectories += baseDirectory.value \/ \"src\/main\/inspector\",\n\n  libraryDependencies += \"org.sireum\" % \"inspector-capabilities\" % inspectorVersion withSources(),\n  libraryDependencies += \"org.sireum\" % \"inspector-gui\" % inspectorVersion withSources(),\n  libraryDependencies += \"org.sireum\" % \"inspector-services-jvm\" % inspectorVersion withSources(),\n\n  mainClass in (Compile, run) := Some(\"pfc_project.InspectorDemo\"),\n)\n\ndef slangEmbeddedProject(projId: String, projectDirectory: String) =\n  Project(id = projId, base = file(projectDirectory)).\n    settings(commonSettings ++ slangEmbeddedSettings)\n\ndef slangEmbeddedInspectorProject(projId: String, projectDirectory: String) = {\n  Project(id = projId, base = file(projectDirectory)).\n    settings(commonSettings ++ slangEmbeddedSettings ++ slangEmbeddedInspectorSettings)\n}\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/project\/build.properties",
        {
          "type" : "ITestResource",
          "content" : "sbt.version=1.9.0\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/project\/plugins.sbt",
        {
          "type" : "ITestResource",
          "content" : "addSbtPlugin(\"com.eed3si9n\" % \"sbt-assembly\" % \"0.15.0\")\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "camkes\/components\/Producer_proc_producer\/Producer_proc_producer.camkes",
        {
          "type" : "ITestResource",
          "content" : "import <std_connector.camkes>;\ncomponent Producer_proc_producer {\n  include <sb_types.h>;\n  include <sp_union_art_DataContent.h>;\n  include <sb_event_counter.h>;\n  control;\n  emits ReceiveEvent sb_to_filter_event;\n  consumes Notification sb_periodic_dispatch_notification;\n  dataport sp_union_art_DataContent_t sb_to_filter_data;\n  dataport sb_event_counter_t sb_to_filter_event_counter;\n  has semaphore sb_dispatch_sem;\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "camkes\/components\/Filter_proc_filter\/Filter_proc_filter.camkes",
        {
          "type" : "ITestResource",
          "content" : "import <std_connector.camkes>;\ncomponent Filter_proc_filter {\n  include <sb_types.h>;\n  include <sp_union_art_DataContent.h>;\n  include <sb_queue_union_art_DataContent_1.h>;\n  include <sb_event_counter.h>;\n  control;\n  emits ReceiveEvent sb_to_consumer_1_notification;\n  consumes ReceiveEvent sb_from_producer_event;\n  consumes Notification sb_periodic_dispatch_notification;\n  dataport sp_union_art_DataContent_t sb_from_producer_data;\n  dataport sb_queue_union_art_DataContent_1_t sb_to_consumer_queue_1;\n  dataport sb_event_counter_t sb_from_producer_event_counter;\n  has semaphore sb_dispatch_sem;\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "camkes\/components\/Consumer_proc_consumer\/Consumer_proc_consumer.camkes",
        {
          "type" : "ITestResource",
          "content" : "component Consumer_proc_consumer {\n  include <sb_types.h>;\n  include <sb_queue_union_art_DataContent_1.h>;\n  control;\n  consumes ReceiveEvent sb_from_filter_notification;\n  dataport sb_queue_union_art_DataContent_1_t sb_from_filter_queue;\n  has semaphore sb_dispatch_sem;\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "camkes\/components\/dispatch_periodic\/dispatch_periodic.camkes",
        {
          "type" : "ITestResource",
          "content" : "import <global-connectors.camkes>;\ncomponent dispatch_periodic {\n  control;\n  uses Timer timer;\n  emits Notification sb_proc_producer_periodic_dispatch_notification;\n  emits Notification sb_proc_filter_periodic_dispatch_notification;\n  consumes Notification timer_complete;\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "camkes\/PFC_Sys_Impl_Instance.camkes",
        {
          "type" : "ITestResource",
          "content" : "\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\nimport <std_connector.camkes>;\nimport <global-connectors.camkes>;\nimport <TimeServer\/TimeServer.camkes>;;\nimport \"components\/Producer_proc_producer\/Producer_proc_producer.camkes\";\nimport \"components\/Filter_proc_filter\/Filter_proc_filter.camkes\";\nimport \"components\/Consumer_proc_consumer\/Consumer_proc_consumer.camkes\";\nimport \"components\/dispatch_periodic\/dispatch_periodic.camkes\";\n\nassembly {\n  composition {\n    component Producer_proc_producer proc_producer;\n    component Filter_proc_filter proc_filter;\n    component Consumer_proc_consumer proc_consumer;\n    component dispatch_periodic dispatch_periodic_inst;\n    component TimeServer time_server;\n\n    connection seL4SharedData conn1(from proc_producer.sb_to_filter_data, to proc_filter.sb_from_producer_data);\n    connection seL4Notification conn2(from proc_producer.sb_to_filter_event, to proc_filter.sb_from_producer_event);\n    connection seL4SharedData conn3(from proc_producer.sb_to_filter_event_counter, to proc_filter.sb_from_producer_event_counter);\n    connection seL4Notification conn4(from proc_filter.sb_to_consumer_1_notification, to proc_consumer.sb_from_filter_notification);\n    connection seL4SharedData conn5(from proc_filter.sb_to_consumer_queue_1, to proc_consumer.sb_from_filter_queue);\n    connection seL4Notification conn6(from dispatch_periodic_inst.sb_proc_producer_periodic_dispatch_notification, to proc_producer.sb_periodic_dispatch_notification);\n    connection seL4Notification conn7(from dispatch_periodic_inst.sb_proc_filter_periodic_dispatch_notification, to proc_filter.sb_periodic_dispatch_notification);\n    connection seL4TimeServer conn8(from dispatch_periodic_inst.timer, to time_server.the_timer);\n    connection seL4GlobalAsynchCallback conn9(from time_server.timer_notification, to dispatch_periodic_inst.timer_complete);\n  }\n\n  configuration {\n    proc_producer._stack_size = 61440;\n    proc_filter._stack_size = 61440;\n    proc_consumer._stack_size = 61440;\n    conn1.size = 4096;\n    proc_producer.sb_to_filter_data_access = \"W\";\n    proc_filter.sb_from_producer_data_access = \"R\";\n    proc_producer.sb_to_filter_event_counter_access = \"W\";\n    proc_filter.sb_from_producer_event_counter_access = \"R\";\n    conn5.size = 4096;\n    proc_filter.sb_to_consumer_queue_1_access = \"W\";\n    proc_consumer.sb_from_filter_queue_access = \"R\";\n    time_server.timers_per_client = 1;\n    dispatch_periodic_inst.timer_attributes = 1;\n    dispatch_periodic_inst.priority = 201;\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "camkes\/types\/includes\/seqNum.h",
        {
          "type" : "ITestResource",
          "content" : "#ifndef _SEQNUM_H_\n#define _SEQNUM_H_\n\n\/\/ Typedef for seqNum to make it easy to change the type. Keep these consistent!\ntypedef uintmax_t seqNum_t;\n#define SEQNUM_MAX UINTMAX_MAX\n#define PRIseqNum PRIuMAX\n\n\/\/ DIRTY_SEQ_NUM is used to mark a sampling port message as dirty while it is\n\/\/ being writen. DIRTY_SEQ_NUM is not a valid sequence number. Valid sequence\n\/\/ numbers are from 0 to DIRTY_SEQ_NUM-1 is never a valid sequence number.\nstatic const seqNum_t DIRTY_SEQ_NUM = SEQNUM_MAX;\n\n#endif",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "camkes\/types\/includes\/sp_union_art_DataContent.h",
        {
          "type" : "ITestResource",
          "content" : "#ifndef SP_UNION_ART_DATACONTENT_H\n#define SP_UNION_ART_DATACONTENT_H\n\n#include <sb_types.h>\n#include <seqNum.h>\n\n\/\/ Sampling port message with bool data\ntypedef struct sp_union_art_DataContent {\n\n  \/\/ The sampling port message data.\n  \/\/\n  union_art_DataContent data;\n\n  \/\/ Sequence number incremented by the writer every time the sampling port is\n  \/\/ written. Read by the receiver to detect dropped messages and incoherent\n  \/\/ message reads.  An incoherent message is one that is formed of parts of\n  \/\/ more than one message.  An incoherent message can occur when writing\n  \/\/ happens during read. If the component runs long enough, this counter\n  \/\/ will wrap back to zero.  This causes no problems unless the receiver is\n  \/\/ delayed for the wrap time. In that case the receiver may not detect\n  \/\/ dropped or incoherent message. But if the receiver is delayed for that\n  \/\/ long the system is probably in a very bad state. Also see DIRTY_SEQ_NUM\n  \/\/ above.\n  \/\/\n  \/\/ TODO: Currently using ggc builtin _Atomic. Would like to use c11 std, but\n  \/\/ have not figured out how to do this int the seL4 cmake build environment.\n  _Atomic seqNum_t seqNum;  \n\n} sp_union_art_DataContent_t;\n\nvoid init_sp_union_art_DataContent(sp_union_art_DataContent_t *port, seqNum_t *seqNum);\n\nbool write_sp_union_art_DataContent(sp_union_art_DataContent_t *port, const union_art_DataContent *data, seqNum_t *seqNum);\n\nbool read_sp_union_art_DataContent(sp_union_art_DataContent_t *port, union_art_DataContent *data, seqNum_t *seqNum);\n\nbool is_empty_sp_union_art_DataContent(sp_union_art_DataContent_t *port);\n\n#endif\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "camkes\/types\/src\/sp_union_art_DataContent.c",
        {
          "type" : "ITestResource",
          "content" : "#include <sp_union_art_DataContent.h>\n\nvoid init_sp_union_art_DataContent(sp_union_art_DataContent_t *port, seqNum_t *seqNum) {\n  *seqNum = 0; \/\/ First message sequence number will be 1.\n  port->seqNum = DIRTY_SEQ_NUM;\n}\n\n\/\/ Write message to a sampling port (data type: int)\n\/\/\n\/\/ Returns true when successful. Otherwise returns false. Currently there is no\n\/\/ way to fail and true is always returned. But this may change in the\n\/\/ future. seqNum is incremented when a message is successfully sent. seqNum\n\/\/ should not be modified otherwise.\n\/\/\n\/\/ TODO: Encapsulate this better. seqNum state should be maintained internally. Possible solutions:\n\/\/\n\/\/    - Allow write to have read access to dataport. Then seqNum is simply in the data port.\n\/\/\n\/\/    - Create a wrapper struct.\n\/\/\n\/\/ TODO: Currently using ggc builtin __atomic_thread_fence(__ATOMIC_RELEASE).\n\/\/ Would like to use c11 std, but have not figured out how to do this int the\n\/\/ seL4 cmake build environment.\nbool write_sp_union_art_DataContent(sp_union_art_DataContent_t *port, const union_art_DataContent *data, seqNum_t *seqNum) {\n  \/\/ Mark the message dirty BEFORE we start writing.\n  port->seqNum = DIRTY_SEQ_NUM;\n  \/\/ Release memory fence - ensure write above to seqNum happens BEFORE reading data\n  __atomic_thread_fence(__ATOMIC_RELEASE);\n  \/\/ Write the data\n  port->data = *data;\n  \/\/ Increment the sequence number. We are the only writer of seqNum, so\n  \/\/ increment does not have to be atomic.\n  *seqNum = (*seqNum + 1) % DIRTY_SEQ_NUM;\n  port->seqNum = *seqNum;\n  \/\/ Release memory fence - ensure write above to seqNum happens BEFORE continuing\n  __atomic_thread_fence(__ATOMIC_RELEASE);\n  \/\/ Can't fail for now.\n  return true;\n}\n\n\/\/ Read a message from a sampling port (data type: int)\n\/\/\n\/\/ Return true upon successful read. Data is updated with the read\n\/\/ message. The sequence number of the message is also returned. The message,\n\/\/ might be tha same previously read. The sequences number can be used to\n\/\/ detect rereading the same message or dropped messages.\n\/\/\n\/\/ Return false if we fail to read a message. For now the only way to fail is\n\/\/ when we detect the possibility of a write during read. In this case data\n\/\/ may be incoherent and should not be used. Sequence number is set to\n\/\/ DIRTY_SEQ_NUM;\n\/\/\n\/\/ TODO: Currently using ggc builtin __atomic_thread_fence(__ATOMIC_ACQUIRE).\n\/\/ Would like to use c11 std, but have not figured out how to do this int the\n\/\/ seL4 cmake build environment.\nbool read_sp_union_art_DataContent(sp_union_art_DataContent_t *port, union_art_DataContent *data, seqNum_t *seqNum) {\n  seqNum_t newSeqNum = port->seqNum;\n  \/\/ Acquire memory fence - Read seqNum BEFORE reading data\n  __atomic_thread_fence(__ATOMIC_ACQUIRE);\n  *data = port->data;\n  \/\/ Acquire memory fence - Read data BEFORE reading seqNum again \n  \/\/atomic_thread_fence(memory_order_acquire);\n  __atomic_thread_fence(__ATOMIC_ACQUIRE);\n  \/\/ The following logic will NOT catch case where the writer wrapped\n  \/\/ sequence numbers since our last read. For this to happen, this reader\n  \/\/ would have to be delayed for the entire time to wrap. \n  if (newSeqNum != DIRTY_SEQ_NUM && newSeqNum == port->seqNum) {\n    \/\/ Message data is good.  Write did not occur during read. \n    *seqNum = newSeqNum;\n    return true;\n  } else {\n    \/\/ Writer may have updated data while we were reading. Do not use possibly incoherent data.\n    *seqNum = DIRTY_SEQ_NUM;\n    return false;\n  }\n}\n\nbool is_empty_sp_union_art_DataContent(sp_union_art_DataContent_t *port) {\n  return port->seqNum == DIRTY_SEQ_NUM;\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "camkes\/CMake_TranspilerOptions.cmake",
        {
          "type" : "ITestResource",
          "content" : "option(BOUND_CHECK\n       \"Build the program with sequence bound checking.\"\n       OFF)\n\nif(BOUND_CHECK OR \"$ENV{BOUND_CHECK}\" STREQUAL \"ON\")\n   add_definitions(-DSIREUM_BOUND_CHECK)\nendif()\n\noption(NO_PRINT\n       \"Build the program without console output.\"\n       OFF)\n\nif(NO_PRINT OR \"$ENV{NO_PRINT}\" STREQUAL \"ON\")\n   add_definitions(-DSIREUM_NO_PRINT)\nendif()\n\noption(RANGE_CHECK\n       \"Build the program with range checking.\"\n       OFF)\n\nif(RANGE_CHECK OR \"$ENV{RANGE_CHECK}\" STREQUAL \"ON\")\n   add_definitions(-DSIREUM_RANGE_CHECK)\nendif()\n\noption(WITH_LOC\n       \"Build the program with Slang location info.\"\n       OFF)\n\nif(WITH_LOC OR \"$ENV{WITH_LOC}\" STREQUAL \"ON\")\n   add_definitions(-DSIREUM_LOC)\nendif()",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "camkes\/CMakeLists.txt",
        {
          "type" : "ITestResource",
          "content" : "# Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\ncmake_minimum_required(VERSION 3.8.2)\n\nproject (PFC_Sys_Impl_Instance C)\n\nadd_definitions(-DCAMKES)\n\ninclude(${CMAKE_CURRENT_LIST_DIR}\/CMake_TranspilerOptions.cmake)\n\nif (\"${CMAKE_CXX_COMPILER_ID}\" MATCHES \"(C|c?)lang\")\n  add_compile_options(\"$<$<CONFIG:Release>:-Oz>\")\nelseif (\"${CMAKE_CXX_COMPILER_ID}\" STREQUAL \"GNU\")\n  add_compile_options(-fstack-usage)\n  add_compile_options(\"$<$<CONFIG:Release>:-Os>\")\nendif()\n\nincludeGlobalComponents()\n\nadd_subdirectory(${CMAKE_CURRENT_LIST_DIR}\/slang_libraries\/Producer_proc_producer)\n\nadd_subdirectory(${CMAKE_CURRENT_LIST_DIR}\/slang_libraries\/Filter_proc_filter)\n\nadd_subdirectory(${CMAKE_CURRENT_LIST_DIR}\/slang_libraries\/Consumer_proc_consumer)\n\nadd_subdirectory(${CMAKE_CURRENT_LIST_DIR}\/slang_libraries\/SlangTypeLibrary)\n\nadd_subdirectory(${CMAKE_CURRENT_LIST_DIR}\/types)\n\nDeclareCAmkESComponent(Producer_proc_producer\n  SOURCES components\/Producer_proc_producer\/src\/sb_Producer.c types\/src\/sp_union_art_DataContent.c\n  INCLUDES components\/Producer_proc_producer\/includes\/ types\/includes types\/includes\n  LIBS Producer_proc_producer\n)\n\nDeclareCAmkESComponent(Filter_proc_filter\n  SOURCES components\/Filter_proc_filter\/src\/sb_Filter.c types\/src\/sp_union_art_DataContent.c types\/src\/sb_queue_union_art_DataContent_1.c\n  INCLUDES components\/Filter_proc_filter\/includes\/ types\/includes types\/includes\n  LIBS Filter_proc_filter\n)\n\nDeclareCAmkESComponent(Consumer_proc_consumer\n  SOURCES components\/Consumer_proc_consumer\/src\/sb_Consumer.c types\/src\/sb_queue_union_art_DataContent_1.c\n  INCLUDES components\/Consumer_proc_consumer\/includes\/ types\/includes\n  LIBS Consumer_proc_consumer\n)\n\nDeclareCAmkESComponent(dispatch_periodic\n  SOURCES components\/dispatch_periodic\/src\/sb_dispatch_periodic.c\n  LIBS SB_Type_Library SlangTypeLibrary\n)\n\nDeclareCAmkESRootserver(PFC_Sys_Impl_Instance.camkes)\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "camkes\/bin\/run-camkes.sh",
        {
          "type" : "ITestResource",
          "content" : "#!\/usr\/bin\/env bash\n\nset -o errexit -o pipefail -o nounset\n\nexport SCRIPT_HOME=$( cd \"$( dirname \"$0\" )\" &> \/dev\/null && pwd )\nexport PROJECT_HOME=$( cd \"$( dirname \"$0\" )\/..\" &> \/dev\/null && pwd )\ncd ${PROJECT_HOME}\n\n! getopt --test > \/dev\/null\nif [[ ${PIPESTATUS[0]} -ne 4 ]]; then\n  echo '`getopt --test` failed in this environment.'\n  exit 1\nfi\n\nNON_INTERACTIVE=false\nCAMKES_DIR=\"\"\nSIMULATE=false\nCAMKES_OPTIONS=\"\"\n\nOPTIONS=c:no:sh\nLONGOPTS=camkes-dir:,non-interactive,camkes-options:,simulate,help\n\nfunction usage {\n  echo \"\"\n  echo \"Usage: <option>*\"\n  echo \"\"\n  echo \"Available Options:\"\n  echo \"-c, --camkes-dir       Location of CAmkES project\"\n  echo \"-n, --non-interactive  Non-interactive mode.  Symlink in apps directory will be replaced\"\n  echo \"                         if present\"\n  echo \"-o, --camkes-options   CAmkES options (e.g -o \\\"-DWITH_LOC=ON -DCapDLLoaderMaxObjects=40000\\\")\"\n  echo \"-s, --simulate         Simulate via QEMU\"\n  echo \"-h, --help             Display this information\"\n}\n\n! PARSED=$(getopt --options=$OPTIONS --longoptions=$LONGOPTS --name \"$0\" -- \"$@\")\nif [[ ${PIPESTATUS[0]} -ne 0 ]]; then\n    usage\n    exit 2\nfi\n\neval set -- \"$PARSED\"\n\nwhile true; do\n  case \"$1\" in\n    -c|--camkes-dir) CAMKES_DIR=\"$2\"; shift 2 ;;\n    -n|--non-interactive) NON_INTERACTIVE=true; shift ;;\n    -o|--camkes-options) CAMKES_OPTIONS=\"$2\"; shift 2 ;;\n    -s|--simulate) SIMULATE=true; shift ;;\n    -h|--help) usage; exit 0 ;;\n    --) shift; break ;;\n  esac\ndone\n\n# handle non-option arguments\nif [[ $# -ne 0 ]]; then\n  echo \"$0: Unexpected non-option arguments\"\n  usage\n  exit 3\nfi\n\n# if CAMKES_DIR option not set then look in some common locations\nif [[ -z \"${CAMKES_DIR}\" && -d \"\/host\/camkes-project\" ]]; then\n  # docker location\n  CAMKES_DIR=\"\/host\/camkes-project\"\nelif [[ -z \"$CAMKES_DIR\" && -d \"${HOME}\/CASE\/camkes\" ]]; then\n  # CASE Vagrant VM location\n  CAMKES_DIR=\"${HOME}\/CASE\/camkes\"\nfi\n\nif [[ -z \"${CAMKES_DIR}\" || ! -d \"${CAMKES_DIR}\" ]]; then\n  echo \"Directory '${CAMKES_DIR}' does not exist.  Please specify the location of your camkes project directory.\"\n  echo \"See https:\/\/docs.sel4.systems\/projects\/camkes\"\n  exit -1\nfi\n\n\n# use the directory name for the CAmkES apps directory name\nHAMR_CAMKES_PROJ=${PWD##*\/}\n\n\nCAMKES_APPS_DIR=${CAMKES_DIR}\/projects\/camkes\/apps\/$HAMR_CAMKES_PROJ\n\n# create a sym-link to the project in the CAmkES app directory\nif [ -e \"${CAMKES_APPS_DIR}\" ]; then\n  if [ \"${NON_INTERACTIVE}\" = true ]; then\n    rm -rf ${CAMKES_APPS_DIR}\n  else\n    read -p \"The following app directory already exists, replace ${CAMKES_APPS_DIR} [Y|y]? \" -n 1 -r; echo\n    if [[ $REPLY =~ ^[Yy]$ ]]; then\n      rm -rf ${CAMKES_APPS_DIR}\n    else\n      exit -1\n    fi\n  fi\nfi\n\nln -sv $PROJECT_HOME $CAMKES_APPS_DIR\n\n########################\n# run CAmkES\/seL4 build\n########################\n\nBUILD_DIR=${CAMKES_DIR}\/build_$HAMR_CAMKES_PROJ\n\nif [ -e \"${BUILD_DIR}\" ]; then\n  if [ \"${NON_INTERACTIVE}\" = true ];then\n    rm -rf ${BUILD_DIR}\n    mkdir ${BUILD_DIR}\n  else\n    read -p \"The following build directory already exists, replace ${BUILD_DIR} [Y|y]? \" -n 1 -r; echo\n    if [[ $REPLY =~ ^[Yy]$ ]]; then\n      rm -rf ${BUILD_DIR}\n      mkdir ${BUILD_DIR}\n    fi\n  fi\nelse\n  mkdir ${BUILD_DIR}\nfi\n\ncd ${BUILD_DIR}\n\n..\/init-build.sh ${CAMKES_OPTIONS} -DCAMKES_APP=$HAMR_CAMKES_PROJ\n\nninja\n\n########################\n# simulate via QEMU\n########################\n\ncat >${BUILD_DIR}\/sim << EOL\n#!\/usr\/bin\/env bash\n\nexport SCRIPT_HOME=\\$( cd \"\\$( dirname \"\\$0\" )\" &> \/dev\/null && pwd )\ncd \\${SCRIPT_HOME}\n\n# console output from simulation disappears when QEMU shuts down when run from\n# the CAmkES generated .\/simulate script. Instead call QEMU directly using the\n# default values .\/simulate would pass\n\nqemu-system-x86_64 \\\\\n    -cpu Nehalem,-vme,+pdpe1gb,-xsave,-xsaveopt,-xsavec,-fsgsbase,-invpcid,enforce \\\\\n    -nographic \\\\\n    -serial mon:stdio \\\\\n    -m size=512M \\\\\n    -kernel images\/kernel-x86_64-pc99 \\\\\n    -initrd images\/capdl-loader-image-x86_64-pc99\nEOL\n\nchmod 700 ${BUILD_DIR}\/sim\necho \"Wrote: ${BUILD_DIR}\/sim\"\n\nif [ \"${SIMULATE}\" = true ]; then\n  # ${BUILD_DIR}\/simulate\n  ${BUILD_DIR}\/sim\nfi\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : true,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "camkes\/components\/Producer_proc_producer\/src\/sb_Producer.c",
        {
          "type" : "ITestResource",
          "content" : "\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\n#include <sb_Producer.h>\n#include <sb_event_counter.h>\n#include <Producer_proc_producer_adapter.h>\n#include <string.h>\n#include <camkes.h>\n\nstatic bool sb_occurred_periodic_dispatcher;\nstatic int64_t sb_time_periodic_dispatcher;\n\n\/************************************************************************\n * periodic_dispatcher_write_int64_t\n * Invoked from remote periodic dispatch thread.\n *\n * This function records the current time and triggers the active thread\n * dispatch from a periodic event.  Note that the periodic dispatch\n * thread is the *only* thread that triggers a dispatch, so we do not\n * mutex lock the function.\n *\n ************************************************************************\/\n\nbool periodic_dispatcher_write_int64_t(const int64_t * arg) {\n    sb_occurred_periodic_dispatcher = true;\n    sb_time_periodic_dispatcher = *arg;\n    MUTEXOP(sb_dispatch_sem_post());\n    return true;\n}\n\nvoid sb_periodic_dispatch_notification_callback(void *_ UNUSED) {\n   \/\/ we want time in microseconds, not nanoseconds, so we divide by 1000.\n   int64_t sb_time_periodic_dispatcher = 0; \/\/ sb_timer_time() \/ 1000LL -- timer connection disabled;\n   (void)periodic_dispatcher_write_int64_t(&sb_time_periodic_dispatcher);\n   CALLBACKOP(sb_periodic_dispatch_notification_reg_callback(sb_periodic_dispatch_notification_callback, NULL));\n}\n\n\nseqNum_t sb_to_filter_data_seqNum;\n\nbool sb_to_filter_data_write(const union_art_DataContent * value) {\n  return write_sp_union_art_DataContent(sb_to_filter_data, value, &sb_to_filter_data_seqNum);\n}\n\n\/************************************************************************\n * sb_to_filter_event_enqueue\n * Invoked from user code in the local thread.\n *\n * This is the function invoked by the local thread to make a\n * call to send to a remote event port.\n *\n ************************************************************************\/\nbool sb_to_filter_event_enqueue(void) {\n  \/\/ sb_to_filter_event_counter is a dataport (shared memory) that is written by the sender\n  \/\/ and read by the receiver(s). This counter is monotonicly increasing,\n  \/\/ but can wrap.\n  (*sb_to_filter_event_counter)++;\n\n  \/\/ Release memory fence - ensure subsequent write occurs after any preceeding read or write\n  sb_to_filter_event_counter_release();\n\n  sb_to_filter_event_emit();\n\n  return true;\n}\n\n\n\/\/ send to_filter_data: Out DataPort PFC__Mission\nUnit pfc_project_PFC_Producer_proc_producer_seL4Nix_to_filter_data_Send(\n  STACK_FRAME\n  art_DataContent d) {\n  DeclNewStackFrame(caller, \"sb_Producer.c\", \"\", \"pfc_project_PFC_Producer_proc_producer_seL4Nix_to_filter_data_Send\", 0);\n\n  sb_to_filter_data_write(d);\n}\n\n\/\/ send to_filter_event: Out EventPort\nUnit pfc_project_PFC_Producer_proc_producer_seL4Nix_to_filter_event_Send(\n  STACK_FRAME\n  art_DataContent d) {\n  DeclNewStackFrame(caller, \"sb_Producer.c\", \"\", \"pfc_project_PFC_Producer_proc_producer_seL4Nix_to_filter_event_Send\", 0);\n\n  \/\/ event port - can ignore the Slang Empty payload\n  art_Empty payload = (art_Empty) d;\n\n  \/\/ send event via CAmkES\n  sb_to_filter_event_enqueue();\n}\n\nvoid pre_init(void) {\n  DeclNewStackFrame(NULL, \"sb_Producer.c\", \"\", \"pre_init\", 0);\n\n  printf(\"Entering pre-init of Producer_proc_producer\\n\");\n\n  \/\/ initialise data structure for data port to_filter_data\n  init_sp_union_art_DataContent(sb_to_filter_data, &sb_to_filter_data_seqNum);\n\n  \/\/ initialise shared counter for event port to_filter_event\n  *sb_to_filter_event_counter = 0;\n\n  \/\/ initialise slang-embedded components\/ports\n  pfc_project_PFC_Producer_proc_producer_adapter_initialiseArchitecture(SF_LAST);\n\n  \/\/ call the component's initialise entrypoint\n  pfc_project_PFC_Producer_proc_producer_adapter_initialiseEntryPoint(SF_LAST);\n\n  printf(\"Leaving pre-init of Producer_proc_producer\\n\");\n}\n\n\/************************************************************************\n * int run(void)\n * Main active thread function.\n ************************************************************************\/\nint run(void) {\n  DeclNewStackFrame(NULL, \"sb_Producer.c\", \"\", \"run\", 0);\n\n\n  CALLBACKOP(sb_periodic_dispatch_notification_reg_callback(sb_periodic_dispatch_notification_callback, NULL));\n  MUTEXOP(sb_dispatch_sem_wait())\n  for(;;) {\n    MUTEXOP(sb_dispatch_sem_wait())\n    \/\/ call the component's compute entrypoint\n    pfc_project_PFC_Producer_proc_producer_adapter_computeEntryPoint(SF_LAST);\n  }\n  return 0;\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "camkes\/components\/Producer_proc_producer\/includes\/sb_Producer.h",
        {
          "type" : "ITestResource",
          "content" : "\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\n#ifndef SB_PRODUCER_H\n#define SB_PRODUCER_H\n\n#include <sb_types.h>\n\nbool sb_to_filter_data_write(const union_art_DataContent * value);\n\nbool sb_to_filter_event_enqueue(void);\n\n#endif \/\/ SB_PRODUCER_H\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "camkes\/components\/Filter_proc_filter\/src\/sb_Filter.c",
        {
          "type" : "ITestResource",
          "content" : "\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\n#include <sb_Filter.h>\n#include <sb_queue_union_art_DataContent_1.h>\n#include <sb_event_counter.h>\n#include <Filter_proc_filter_adapter.h>\n#include <string.h>\n#include <camkes.h>\n\nstatic bool sb_occurred_periodic_dispatcher;\nstatic int64_t sb_time_periodic_dispatcher;\n\n\/************************************************************************\n * periodic_dispatcher_write_int64_t\n * Invoked from remote periodic dispatch thread.\n *\n * This function records the current time and triggers the active thread\n * dispatch from a periodic event.  Note that the periodic dispatch\n * thread is the *only* thread that triggers a dispatch, so we do not\n * mutex lock the function.\n *\n ************************************************************************\/\n\nbool periodic_dispatcher_write_int64_t(const int64_t * arg) {\n    sb_occurred_periodic_dispatcher = true;\n    sb_time_periodic_dispatcher = *arg;\n    MUTEXOP(sb_dispatch_sem_post());\n    return true;\n}\n\nvoid sb_periodic_dispatch_notification_callback(void *_ UNUSED) {\n   \/\/ we want time in microseconds, not nanoseconds, so we divide by 1000.\n   int64_t sb_time_periodic_dispatcher = 0; \/\/ sb_timer_time() \/ 1000LL -- timer connection disabled;\n   (void)periodic_dispatcher_write_int64_t(&sb_time_periodic_dispatcher);\n   CALLBACKOP(sb_periodic_dispatch_notification_reg_callback(sb_periodic_dispatch_notification_callback, NULL));\n}\n\n\nseqNum_t sb_from_producer_data_seqNum;\n\n\/*****************************************************************\n * sb_from_producer_data_is_empty:\n *\n * Helper method to determine if the data infrastructure port has\n * received data\n *\n ****************************************************************\/\nbool sb_from_producer_data_is_empty() {\n  return is_empty_sp_union_art_DataContent(sb_from_producer_data);\n}\n\nbool sb_from_producer_data_read(union_art_DataContent * value) {\n  seqNum_t new_seqNum;\n  if ( read_sp_union_art_DataContent(sb_from_producer_data, value, &new_seqNum) ) {\n    sb_from_producer_data_seqNum = new_seqNum;\n    return true;\n  } else {\n    return false;\n  }\n}\n\nbool sb_to_consumer_enqueue(const union_art_DataContent *data) {\n  sb_queue_union_art_DataContent_1_enqueue(sb_to_consumer_queue_1, (union_art_DataContent*) data);\n  sb_to_consumer_1_notification_emit();\n\n  return true;\n}\n\n\/************************************************************************\n *\n * Static variables and queue management functions for event port:\n *     from_producer_event\n *\n ************************************************************************\/\nstatic sb_event_counter_t sb_from_producer_event_received_events = 0;\nstatic sb_event_counter_t sb_from_producer_event_last_counter = 0;\n\n\/************************************************************************\n * sb_from_producer_event_dequeue:\n * Invoked from local active thread.\n *\n * This is the function invoked by the active thread to decrement the\n * input event index.\n *\n ************************************************************************\/\nbool sb_from_producer_event_dequeue() {\n  if(sb_from_producer_event_received_events > 0) {\n    sb_from_producer_event_received_events--;\n    return true;\n  } else {\n    return false;\n  }\n}\n\n\/************************************************************************\n * sb_from_producer_event_is_empty;\n *\n * Helper method to determine if infrastructure port has not received\n * any new events since the last dispatch\n *\n ************************************************************************\/\nbool sb_from_producer_event_is_empty() {\n  return sb_from_producer_event_received_events == 0;\n}\n\nvoid sb_freeze_event_port_from_producer_event() {\n  sb_event_counter_t current_sb_from_producer_event_counter;\n\n  sb_from_producer_event_received_events = 0; \/\/ drop any events not handled during last dispatch\n\n  \/\/ get current shared counter value\n  current_sb_from_producer_event_counter = *sb_from_producer_event_counter;\n\n  \/\/ Acquire memory fence - ensure preceding read occurs before any subsequent read or write\n  sb_from_producer_event_counter_acquire();\n\n  \/\/ NOTE: Counters can wrap, so we must use != below instead of >\n  while(current_sb_from_producer_event_counter != sb_from_producer_event_last_counter){\n    sb_from_producer_event_last_counter++;\n    sb_from_producer_event_received_events++;\n  }\n\n  if(sb_from_producer_event_received_events > 0) {\n\n    \/\/ from_producer_event's queue size is 1\n    if(sb_from_producer_event_received_events > 1) {\n      \/\/printf(\"Filter: dropping %i event(s) from incoming event port from_producer_event\\n\", (sb_from_producer_event_received_events - 1));\n\n      \/\/ drop events\n      sb_from_producer_event_received_events = 1;\n    }\n  }\n}\n\n\/\/ send to_consumer: Out EventDataPort PFC__Mission\nUnit pfc_project_PFC_Filter_proc_filter_seL4Nix_to_consumer_Send(\n  STACK_FRAME\n  art_DataContent d) {\n  DeclNewStackFrame(caller, \"sb_Filter.c\", \"\", \"pfc_project_PFC_Filter_proc_filter_seL4Nix_to_consumer_Send\", 0);\n\n  sb_to_consumer_enqueue(d);\n}\n\n\/\/ is_empty from_producer_data: In DataPort\nB pfc_project_PFC_Filter_proc_filter_seL4Nix_from_producer_data_IsEmpty(STACK_FRAME_ONLY) {\n  return sb_from_producer_data_is_empty();\n}\n\n\/\/ receive from_producer_data: In DataPort union_art_DataContent\nUnit pfc_project_PFC_Filter_proc_filter_seL4Nix_from_producer_data_Receive(\n  STACK_FRAME\n  Option_8E9F45 result) {\n  DeclNewStackFrame(caller, \"sb_Filter.c\", \"\", \"pfc_project_PFC_Filter_proc_filter_seL4Nix_from_producer_data_Receive\", 0);\n\n  union_art_DataContent val;\n  if(sb_from_producer_data_read((union_art_DataContent *) &val)) {\n    \/\/ wrap payload in Some and place in result\n    DeclNewSome_D29615(some);\n    Some_D29615_apply(SF &some, (art_DataContent) &val);\n    Type_assign(result, &some, sizeof(union Option_8E9F45));\n  } else {\n    \/\/ put None in result\n    DeclNewNone_964667(none);\n    Type_assign(result, &none, sizeof(union Option_8E9F45));\n  }\n}\n\n\n\/\/ is_empty from_producer_event: In EventPort\nB pfc_project_PFC_Filter_proc_filter_seL4Nix_from_producer_event_IsEmpty(STACK_FRAME_ONLY) {\n  return sb_from_producer_event_is_empty();\n}\n\n\/\/ receive from_producer_event: In EventPort\nUnit pfc_project_PFC_Filter_proc_filter_seL4Nix_from_producer_event_Receive(STACK_FRAME\n  Option_8E9F45 result) {\n  DeclNewStackFrame(caller, \"sb_Filter.c\", \"\", \"pfc_project_PFC_Filter_proc_filter_seL4Nix_from_producer_event_Receive\", 0);\n\n  if(sb_from_producer_event_dequeue()) {\n    \/\/ event port - ART requires an Empty payload be sent\n    DeclNewart_Empty(payload);\n\n    \/\/ wrap it in Some and place in result\n    DeclNewSome_D29615(some);\n    Some_D29615_apply(SF &some, (art_DataContent) &payload);\n    Type_assign(result, &some, sizeof(union Option_8E9F45));\n  } else {\n    \/\/ put None in result\n    DeclNewNone_964667(none);\n    Type_assign(result, &none, sizeof(union Option_8E9F45));\n  }\n} \n\nvoid pre_init(void) {\n  DeclNewStackFrame(NULL, \"sb_Filter.c\", \"\", \"pre_init\", 0);\n\n  printf(\"Entering pre-init of Filter_proc_filter\\n\");\n\n  \/\/ initialise data structure for outgoing event data port to_consumer\n  sb_queue_union_art_DataContent_1_init(sb_to_consumer_queue_1);\n\n  \/\/ initialise slang-embedded components\/ports\n  pfc_project_PFC_Filter_proc_filter_adapter_initialiseArchitecture(SF_LAST);\n\n  \/\/ call the component's initialise entrypoint\n  pfc_project_PFC_Filter_proc_filter_adapter_initialiseEntryPoint(SF_LAST);\n\n  printf(\"Leaving pre-init of Filter_proc_filter\\n\");\n}\n\n\/************************************************************************\n * int run(void)\n * Main active thread function.\n ************************************************************************\/\nint run(void) {\n  DeclNewStackFrame(NULL, \"sb_Filter.c\", \"\", \"run\", 0);\n\n\n  CALLBACKOP(sb_periodic_dispatch_notification_reg_callback(sb_periodic_dispatch_notification_callback, NULL));\n  MUTEXOP(sb_dispatch_sem_wait())\n  for(;;) {\n    MUTEXOP(sb_dispatch_sem_wait())\n    sb_freeze_event_port_from_producer_event();\n    \/\/ call the component's compute entrypoint\n    pfc_project_PFC_Filter_proc_filter_adapter_computeEntryPoint(SF_LAST);\n  }\n  return 0;\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "camkes\/components\/Filter_proc_filter\/includes\/sb_Filter.h",
        {
          "type" : "ITestResource",
          "content" : "\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\n#ifndef SB_FILTER_H\n#define SB_FILTER_H\n\n#include <sb_types.h>\n\nbool sb_from_producer_data_read(union_art_DataContent * value);\n\nbool sb_to_consumer_enqueue(const union_art_DataContent *);\n\nbool sb_from_producer_event_dequeue(void);\n\n#endif \/\/ SB_FILTER_H\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "camkes\/components\/Consumer_proc_consumer\/src\/sb_Consumer.c",
        {
          "type" : "ITestResource",
          "content" : "\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\n#include <sb_Consumer.h>\n#include <sb_queue_union_art_DataContent_1.h>\n#include <sb_event_counter.h>\n#include <Consumer_proc_consumer_adapter.h>\n#include <string.h>\n#include <camkes.h>\n\nsb_queue_union_art_DataContent_1_Recv_t sb_from_filter_recv_queue;\n\n\/************************************************************************\n * sb_from_filter_dequeue_poll:\n ************************************************************************\/\nbool sb_from_filter_dequeue_poll(sb_event_counter_t *numDropped, union_art_DataContent *data) {\n  return sb_queue_union_art_DataContent_1_dequeue(&sb_from_filter_recv_queue, numDropped, data);\n}\n\n\/************************************************************************\n * sb_from_filter_dequeue:\n ************************************************************************\/\nbool sb_from_filter_dequeue(union_art_DataContent *data) {\n  sb_event_counter_t numDropped;\n  return sb_from_filter_dequeue_poll(&numDropped, data);\n}\n\n\/************************************************************************\n * sb_from_filter_is_empty:\n *\n * Helper method to determine if infrastructure port has received new\n * events\n ************************************************************************\/\nbool sb_from_filter_is_empty(){\n  return sb_queue_union_art_DataContent_1_is_empty(&sb_from_filter_recv_queue);\n}\n\n\/************************************************************************\n * sb_from_filter_notification_handler:\n * Invoked by: seL4 notification callback\n *\n * This is the function invoked by an seL4 notification callback to \n * dispatch the component due to the arrival of an event on port\n * sb_from_filter\n *\n ************************************************************************\/\nstatic void sb_from_filter_notification_handler(void * unused) {\n  MUTEXOP(sb_dispatch_sem_post())\n  CALLBACKOP(sb_from_filter_notification_reg_callback(sb_from_filter_notification_handler, NULL));\n}\n\n\/\/ is_empty from_filter: In EventDataPort\nB pfc_project_PFC_Consumer_proc_consumer_seL4Nix_from_filter_IsEmpty(STACK_FRAME_ONLY) {\n  return sb_from_filter_is_empty();\n}\n\n\/\/ receive from_filter: In EventDataPort union_art_DataContent\nUnit pfc_project_PFC_Consumer_proc_consumer_seL4Nix_from_filter_Receive(\n  STACK_FRAME\n  Option_8E9F45 result) {\n  DeclNewStackFrame(caller, \"sb_Consumer.c\", \"\", \"pfc_project_PFC_Consumer_proc_consumer_seL4Nix_from_filter_Receive\", 0);\n\n  union_art_DataContent val;\n  if(sb_from_filter_dequeue((union_art_DataContent *) &val)) {\n    \/\/ wrap payload in Some and place in result\n    DeclNewSome_D29615(some);\n    Some_D29615_apply(SF &some, (art_DataContent) &val);\n    Type_assign(result, &some, sizeof(union Option_8E9F45));\n  } else {\n    \/\/ put None in result\n    DeclNewNone_964667(none);\n    Type_assign(result, &none, sizeof(union Option_8E9F45));\n  }\n}\n\n\nvoid pre_init(void) {\n  DeclNewStackFrame(NULL, \"sb_Consumer.c\", \"\", \"pre_init\", 0);\n\n  printf(\"Entering pre-init of Consumer_proc_consumer\\n\");\n\n  \/\/ initialise data structure for incoming event data port from_filter\n  sb_queue_union_art_DataContent_1_Recv_init(&sb_from_filter_recv_queue, sb_from_filter_queue);\n\n  \/\/ initialise slang-embedded components\/ports\n  pfc_project_PFC_Consumer_proc_consumer_adapter_initialiseArchitecture(SF_LAST);\n\n  \/\/ call the component's initialise entrypoint\n  pfc_project_PFC_Consumer_proc_consumer_adapter_initialiseEntryPoint(SF_LAST);\n\n  printf(\"Leaving pre-init of Consumer_proc_consumer\\n\");\n}\n\nvoid post_init(void) {\n  DeclNewStackFrame(NULL, \"sb_Consumer.c\", \"\", \"post_init\", 0);\n\n  \/\/ register callback for EventDataPort port from_filter\n  CALLBACKOP(sb_from_filter_notification_reg_callback(sb_from_filter_notification_handler, NULL));\n}\n\n\/************************************************************************\n * int run(void)\n * Main active thread function.\n ************************************************************************\/\nint run(void) {\n  DeclNewStackFrame(NULL, \"sb_Consumer.c\", \"\", \"run\", 0);\n\n  MUTEXOP(sb_dispatch_sem_wait())\n  for(;;) {\n    MUTEXOP(sb_dispatch_sem_wait())\n    \/\/ call the component's compute entrypoint\n    pfc_project_PFC_Consumer_proc_consumer_adapter_computeEntryPoint(SF_LAST);\n  }\n  return 0;\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "camkes\/components\/Consumer_proc_consumer\/includes\/sb_Consumer.h",
        {
          "type" : "ITestResource",
          "content" : "\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\n#ifndef SB_CONSUMER_H\n#define SB_CONSUMER_H\n\n#include <sb_types.h>\n\nbool sb_from_filter_dequeue(union_art_DataContent *);\n\n#endif \/\/ SB_CONSUMER_H\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "camkes\/components\/dispatch_periodic\/src\/sb_dispatch_periodic.c",
        {
          "type" : "ITestResource",
          "content" : "#include <string.h>\n#include <camkes.h>\n#include <sb_types.h>\n\n\/\/ prototypes for clock functions\nvoid clock_init();\nvoid clock_set_interval_in_ms(uint32_t interval);\nvoid clock_start_timer(void);\nvoid clock_irq_callback(void);\nuint64_t clock_get_time();\n\n\/\/ Declarations for managing periodic thread dispatch\nconst uint32_t aadl_tick_interval = 1;\nuint32_t aadl_calendar_counter = 0;\n\nvoid sb_thread_calendar() {\n  if ((aadl_calendar_counter % (1000 \/ aadl_tick_interval)) == 0) {\n    sb_proc_producer_periodic_dispatch_notification_emit();\n  }\n  if ((aadl_calendar_counter % (1000 \/ aadl_tick_interval)) == 0) {\n    sb_proc_filter_periodic_dispatch_notification_emit();\n  }\n\n  aadl_calendar_counter++;\n}\n\nvoid timer_complete_callback() {\n  sb_thread_calendar();\n}\n\n\/\/ no op under the new time server scheme.\nvoid clock_init() { }\n\n\/\/ Set interrupt interval, in milliseconds.\nvoid clock_set_interval_in_ms(uint32_t interval) {\n  timer_periodic(0, ((uint64_t)interval) * NS_IN_MS);\n}\n\n\/\/ no op under the new time server scheme\nvoid clock_start_timer(void) { }\n\n\/\/ defer to time server\nuint64_t clock_get_time() {\n  return (timer_time() \/ NS_IN_MS);\n}\n\nint run(void) {\n  clock_init();\n  clock_set_interval_in_ms(1);\n  clock_start_timer();\n  return 0;\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "camkes\/types\/includes\/sb_queue_union_art_DataContent_1.h",
        {
          "type" : "ITestResource",
          "content" : "\/*\n * Copyright 2017, Data61\n * Commonwealth Scientific and Industrial Research Organisation (CSIRO)\n * ABN 41 687 119 230.\n *\n * Copyright 2019 Adventium Labs\n * Modifications made to original\n *\n * This software may be distributed and modified according to the terms of\n * the BSD 2-Clause license. Note that NO WARRANTY is provided.\n * See \"LICENSE_BSD2.txt\" for details.\n *\n * @TAG(DATA61_Adventium_BSD)\n *\/\n\n\/\/ Single sender multiple receiver Queue implementation for AADL Event Data\n\/\/ Ports. Every receiver receives the sent data (ie broadcast). The queue\n\/\/ operations are all non-blocking. The sender enqueue always succeeds. A\n\/\/ receiver dequeue can fail and drop data if the sender writes while the\n\/\/ receiver is reading. This situation is detected unless the sender gets\n\/\/ ahead of a receiver by more than COUNTER_MAX. Since COUNTER_MAX is typically\n\/\/ 2^64 (see sb_event_counter.h), this is extremely unlikely. If it does happen the\n\/\/ only adverse effect is that the receiver will not detect all dropped\n\/\/ elements.\n\n#pragma once\n\n#include <sb_event_counter.h>\n#include <sb_types.h>\n#include <stdbool.h>\n\n\/\/ Queue size must be an integer factor of the size for sb_event_counter_t (an unsigned\n\/\/ integer type). Since we are using standard C unsigned integers for the\n\/\/ counter, picking a queue size that is a power of 2 is a good choice. We\n\/\/ could alternatively set the size of our counter to the largest possible\n\/\/ multiple of queue size. But then we would need to do our own modulo\n\/\/ operations on the counter rather than depending on c's unsigned integer\n\/\/ operations.\n\/\/\n\/\/ Note: One cell in the queue is always considered dirty. Its the next\n\/\/ element to be written. Thus the queue can only contain\n\/\/ SB_QUEUE_UNION_ART_DATACONTENT_1_SIZE-1 elements.\n#define SB_QUEUE_UNION_ART_DATACONTENT_1_SIZE 2\n\n\/\/ This is the type of the seL4 dataport (shared memory) that is shared by the\n\/\/ sender and all receivers. This type is referenced in the sender and receiver\n\/\/ CAmkES component definition files. The seL4 CAmkES runtime creates an\n\/\/ instance of this struct.\ntypedef struct sb_queue_union_art_DataContent_1 {\n  \/\/ Number of elements enqueued since the sender. The implementation depends\n  \/\/ on C's standard module behaviour for unsigned integers. The counter never\n  \/\/ overflows. It just wraps modulo the size of the counter type. The counter\n  \/\/ is typically very large (see sb_event_counter.h), so this should happen very\n  \/\/ infrequently. Depending in C to initialize this to zero.\n  _Atomic sb_event_counter_t numSent;\n\n  \/\/ Queue of elements of type union_art_DataContent\n  \/\/ (see sb_types.h) implemented as a ring buffer.\n  \/\/ No initialization necessary.\n  union_art_DataContent elt[SB_QUEUE_UNION_ART_DATACONTENT_1_SIZE];\n\n} sb_queue_union_art_DataContent_1_t;\n\n\/\/------------------------------------------------------------------------------\n\/\/ Sender API\n\/\/\n\/\/ Could split this into separate header and source file since only sender\n\/\/ code needs this.\n\n\/\/ Initialize the queue. Sender must call this exactly once before any calls to queue_enqueue();\nvoid sb_queue_union_art_DataContent_1_init(sb_queue_union_art_DataContent_1_t *queue);\n\n\/\/ Enqueue data. This always succeeds and never blocks. Data is copied.\nvoid sb_queue_union_art_DataContent_1_enqueue(\n  sb_queue_union_art_DataContent_1_t *queue,\n  union_art_DataContent *data);\n\n\/\/------------------------------------------------------------------------------\n\/\/ Receiver API\n\/\/\n\/\/ Could split this into separate header and source file since only receiver\n\/\/ code needs this.\n\n\/\/ Each receiver needs to create an instance of this.\ntypedef struct sb_queue_union_art_DataContent_1_Recv {\n  \/\/ Number of elements dequeued (or dropped) by a receiver. The implementation\n  \/\/ depends on C's standard module behaviour for unsigned integers. The\n  \/\/ counter never overflows. It just wraps modulo the size of the counter\n  \/\/ type. The counter is typically very large (see counter.h), so this should\n  \/\/ happen very infrequently.\n  sb_event_counter_t numRecv;\n\n  \/\/ Pointer to the actual queue. This is the seL4 dataport (shared memory)\n  \/\/ that is shared by the sender and all receivers.\n  sb_queue_union_art_DataContent_1_t *queue;\n\n} sb_queue_union_art_DataContent_1_Recv_t;\n\n\/\/ Each receiver must call this exactly once before any calls to other queue\n\/\/ API functions.\nvoid sb_queue_union_art_DataContent_1_Recv_init(\n  sb_queue_union_art_DataContent_1_Recv_t *recvQueue,\n  sb_queue_union_art_DataContent_1_t *queue);\n\n\/\/ Dequeue data. Never blocks but can fail if the sender writes at same\n\/\/ time.\n\n\/\/ When successful returns true. The dequeued data will be copied to\n\/\/ *data. *numDropped will contain the number of elements that were dropped\n\/\/ since the last call to queue_dequeue().\n\/\/\n\/\/ When queue is empty, returns false and *numDropped is zero. *data is left in\n\/\/ unspecified state.\n\/\/\n\/\/ When dequeue fails due to possible write of data being read, returns false\n\/\/ and *numDropped will be >= 1 specifying the number of elements that were\n\/\/ dropped since the last call to sb_queue_union_art_DataContent_1_dequeue(). *data is left in\n\/\/ unspecified state.\n\/\/\n\/\/ If the sender ever gets ahead of a receiver by more than COUNTER_MAX,\n\/\/ sb_queue_union_art_DataContent_1_dequeue will fail to count a multiple of COUNTER_MAX in\n\/\/ numDropped. Since COUNTER_MAX is very large (typically on the order of 2^64,\n\/\/ see sb_event_counter.h), this is very unlikely.  If the sender is ever this far\n\/\/ ahead of a receiver the system is probably in a very bad state.\nbool sb_queue_union_art_DataContent_1_dequeue(\n  sb_queue_union_art_DataContent_1_Recv_t *recvQueue,\n  sb_event_counter_t *numDropped,\n  union_art_DataContent *data);\n\n\/\/ Is queue empty? If the queue is not empty, it will stay that way until the\n\/\/ receiver dequeues all data. If the queue is empty you can make no\n\/\/ assumptions about how long it will stay empty.\nbool sb_queue_union_art_DataContent_1_is_empty(sb_queue_union_art_DataContent_1_Recv_t *recvQueue);\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "camkes\/types\/src\/sb_queue_union_art_DataContent_1.c",
        {
          "type" : "ITestResource",
          "content" : "\/*\n * Copyright 2017, Data61\n * Commonwealth Scientific and Industrial Research Organisation (CSIRO)\n * ABN 41 687 119 230.\n *\n * Copyright 2019 Adventium Labs\n * Modifications made to original\n *\n * This software may be distributed and modified according to the terms of\n * the BSD 2-Clause license. Note that NO WARRANTY is provided.\n * See \"LICENSE_BSD2.txt\" for details.\n *\n * @TAG(DATA61_Adventium_BSD)\n *\/\n\n#include <sb_queue_union_art_DataContent_1.h>\n#include <stdint.h>\n#include <stddef.h>\n\n\/\/------------------------------------------------------------------------------\n\/\/ Sender API\n\/\/\n\/\/ See sb_queue_union_art_DataContent_1.h for API documentation. Only implementation details are documented here.\n\nvoid sb_queue_union_art_DataContent_1_init(sb_queue_union_art_DataContent_1_t *queue) {\n  \/\/ NOOP for now. C's struct initialization is sufficient.  If we ever do need\n  \/\/ initialization logic, we may also need to synchronize with receiver\n  \/\/ startup.\n}\n\nvoid sb_queue_union_art_DataContent_1_enqueue(\n  sb_queue_union_art_DataContent_1_t *queue,\n  union_art_DataContent *data) {\n\n  \/\/ Simple ring with one dirty element that will be written next. Only one\n  \/\/ writer, so no need for any synchronization.\n  \/\/ elt[queue->numSent % SB_QUEUE_UNION_ART_DATACONTENT_1_SIZE]\n  \/\/ is always considered dirty. So do not advance queue->NumSent\n  \/\/ till AFTER data is copied.\n\n  size_t index = queue->numSent % SB_QUEUE_UNION_ART_DATACONTENT_1_SIZE;\n\n  queue->elt[index] = *data; \/\/ Copy data into queue\n\n  \/\/ Release memory fence - ensure that data write above completes BEFORE we advance queue->numSent\n  __atomic_thread_fence(__ATOMIC_RELEASE);\n\n  ++(queue->numSent);\n}\n\n\/\/------------------------------------------------------------------------------\n\/\/ Receiver API\n\/\/\n\/\/ See sb_queue_union_art_DataContent_1.h for API documentation. Only implementation details are documented here.\n\nvoid sb_queue_union_art_DataContent_1_Recv_init(\n  sb_queue_union_art_DataContent_1_Recv_t *recvQueue,\n  sb_queue_union_art_DataContent_1_t *queue) {\n\n  recvQueue->numRecv = 0;\n  recvQueue->queue = queue;\n}\n\nbool sb_queue_union_art_DataContent_1_dequeue(\n  sb_queue_union_art_DataContent_1_Recv_t *recvQueue,\n  sb_event_counter_t *numDropped,\n  union_art_DataContent *data) {\n\n  sb_event_counter_t *numRecv = &recvQueue->numRecv;\n  sb_queue_union_art_DataContent_1_t *queue = recvQueue->queue;\n\n  \/\/ Get a copy of numSent so we can see if it changes during read\n  sb_event_counter_t numSent = queue->numSent;\n\n  \/\/ Acquire memory fence - ensure read of queue->numSent BEFORE reading data\n  __atomic_thread_fence(__ATOMIC_ACQUIRE);\n\n  \/\/ How many new elements have been sent? Since we are using unsigned\n  \/\/ integers, this correctly computes the value as counters wrap.\n  sb_event_counter_t numNew = numSent - *numRecv;\n  if (0 == numNew) {\n    \/\/ Queue is empty\n    return false;\n  }\n\n  \/\/ One element in the ring buffer is always considered dirty. Its the next\n  \/\/ element we will write.  It's not safe to read it until numSent has been\n  \/\/ incremented. Thus there are really only (SB_QUEUE_UNION_ART_DATACONTENT_1_SIZE - 1)\n  \/\/ elements in the queue.\n  *numDropped = (numNew <= SB_QUEUE_UNION_ART_DATACONTENT_1_SIZE - 1) ? 0 : numNew - SB_QUEUE_UNION_ART_DATACONTENT_1_SIZE + 1;\n\n  \/\/ Increment numRecv by *numDropped plus one for the element we are about to read.\n  *numRecv += *numDropped + 1;\n\n  \/\/ UNUSED - number of elements left to be consumed\n  \/\/sb_event_counter_t numRemaining = numSent - *numRecv;\n\n  size_t index = (*numRecv - 1) % SB_QUEUE_UNION_ART_DATACONTENT_1_SIZE;\n  *data = queue->elt[index]; \/\/ Copy data\n\n  \/\/ Acquire memory fence - ensure read of data BEFORE reading queue->numSent again\n  __atomic_thread_fence(__ATOMIC_ACQUIRE);\n\n  if (queue->numSent - *numRecv + 1 < SB_QUEUE_UNION_ART_DATACONTENT_1_SIZE) {\n    \/\/ Sender did not write element we were reading. Copied data is coherent.\n    return true;\n  } else {\n    \/\/ Sender may have written element we were reading. Copied data may be incoherent.\n    \/\/ We dropped the element we were trying to read, so increment *numDropped.\n    ++(*numDropped);\n    return false;\n  }\n}\n\nbool sb_queue_union_art_DataContent_1_is_empty(sb_queue_union_art_DataContent_1_Recv_t *recvQueue) {\n  return (recvQueue->queue->numSent == recvQueue->numRecv);\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "camkes\/types\/includes\/sb_types.h",
        {
          "type" : "ITestResource",
          "content" : "#ifndef SB_TYPES_H\n#define SB_TYPES_H\n\n#include <stdio.h>\n#include <stdbool.h>\n#include <stdint.h>\n#include <all.h>\n\n#ifndef SB_VERIFY\n#include <stddef.h>\n#endif \/\/ SB_VERIFY\n\n#define __SB_OS_CAMKES__\n\n#ifndef SB_VERIFY\n#define MUTEXOP(OP)\\\nif((OP) != 0) {\\\n  fprintf(stderr,\"Operation \" #OP \" failed in %s at %d.\\n\",__FILE__,__LINE__);\\\n  *((int*)0)=0xdeadbeef;\\\n}\n#else\n#define MUTEXOP(OP) OP\n#endif \/\/ SB_VERIFY\n#ifndef SB_VERIFY\n#define CALLBACKOP(OP)\\\nif((OP) != 0) {\\\n  fprintf(stderr,\"Operation \" #OP \" failed in %s at %d.\\n\",__FILE__,__LINE__);\\\n  *((int*)0)=0xdeadbeef;\\\n}\n#else\n#define CALLBACKOP(OP) OP\n#endif \/\/ SB_VERIFY\n\ntypedef union art_DataContent union_art_DataContent;\n\n#endif \/\/ SB_TYPES_H\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "camkes\/types\/includes\/sb_event_counter.h",
        {
          "type" : "ITestResource",
          "content" : "#pragma once\n\n#include <stdint.h>\n\ntypedef _Atomic uintmax_t sb_event_counter_t;\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "camkes\/settings.cmake",
        {
          "type" : "ITestResource",
          "content" : "# This file will not be overwritten so is safe to edit\n\ncmake_minimum_required(VERSION 3.8.2)\n\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "camkes\/types\/CMakeLists.txt",
        {
          "type" : "ITestResource",
          "content" : "# Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\ncmake_minimum_required(VERSION 3.8.2)\n\nproject(SB_Type_Library)\n\nset(CMAKE_C_STANDARD 99)\n\nadd_compile_options(-Werror)\n\nif (\"${CMAKE_CXX_COMPILER_ID}\" MATCHES \"(C|c?)lang\")\n  add_compile_options(\"$<$<CONFIG:Release>:-Oz>\")\nelseif (\"${CMAKE_CXX_COMPILER_ID}\" STREQUAL \"GNU\")\n  add_compile_options(-fstack-usage)\n  add_compile_options(\"$<$<CONFIG:Release>:-Os>\")\nendif()\n\nadd_library(SB_Type_Library\n            src\/sb_queue_union_art_DataContent_1.c\n            src\/sp_union_art_DataContent.c)\n\n# Assume that if the muslc target exists then this project is in an seL4 native\n# component build environment, otherwise it is in a linux userlevel environment.\n# In the linux userlevel environment, the C library will be linked automatically.\nif(TARGET muslc)\n  target_link_libraries(SB_Type_Library\n                        muslc)\nendif()\n\nadd_definitions(-DCAMKES)\n\nif(TARGET SlangTypeLibrary)\n  target_link_libraries(SB_Type_Library\n                        SlangTypeLibrary)\nendif()\n\ntarget_include_directories(SB_Type_Library\n                           PUBLIC includes)\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "camkes\/proof\/smt2_case.smt2",
        {
          "type" : "ITestResource",
          "content" : "(set-logic ALL)\n\n(declare-datatypes ((Option 1))\n  ((par (T) ((Some (value T))\n             (None)))))\n\n(declare-datatypes ((Mode 0)) ((\n  (SeL4)\n  (SeL4_Only)\n  (SeL4_TB))))\n\n(declare-datatypes ((ComponentCategory 0)) ((\n  (Abstract)\n  (Bus)\n  (Data)\n  (Device)\n  (Memory)\n  (Process)\n  (Processor)\n  (Subprogram)\n  (SubprogramGroup)\n  (System)\n  (Thread)\n  (ThreadGroup)\n  (VirtualBus)\n  (VirtualProcessor))))\n\n(declare-datatypes ((DispatchProtocol 0)) ((\n  (Periodic)\n  (Sporadic))))\n\n(declare-datatypes ((SchedulingType 0)) ((\n  (Pacing)\n  (SelfPacing)\n  (PeriodicDispatching)\n  (UNSPECIFIED_SCHEDULING_TYPE))))\n\n(declare-datatypes ((Direction 0)) ((\n  (In)\n  (Out)\n  (InOut))))\n\n(declare-datatypes ((FeatureCategory 0)) ((\n  (AbstractFeature)\n  (BusAccess)\n  (DataAccess)\n  (DataPort)\n  (EventPort)\n  (EventDataPort)\n  (FeatureGroup)\n  (Parameter)\n  (SubprogramAccess)\n  (SubprogramAccessGroup))))\n\n\n(declare-const CodegenMode Mode)\n(assert (= CodegenMode SeL4))\n\n(declare-const ModelSchedulingType SchedulingType)\n(assert (= ModelSchedulingType PeriodicDispatching))\n\n;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n;;                                                                        ;;\n;;                                AADL Model                              ;;\n;;                                                                        ;;\n;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(declare-datatypes ((AadlComponent 0)) ((\n  (PFC_Sys_Impl_Instance_proc_producer)\n  (PFC_Sys_Impl_Instance_proc_filter)\n  (PFC_Sys_Impl_Instance_proc_consumer)\n)))\n(declare-const AadlComponent_count Int)\n(assert (= 3 AadlComponent_count))\n\n(declare-const AadlComponentCategory (Array AadlComponent (Option ComponentCategory)))\n  (assert (= (Some Thread) (select AadlComponentCategory PFC_Sys_Impl_Instance_proc_producer)))\n  (assert (= (Some Thread) (select AadlComponentCategory PFC_Sys_Impl_Instance_proc_filter)))\n  (assert (= (Some Thread) (select AadlComponentCategory PFC_Sys_Impl_Instance_proc_consumer)))\n\n(declare-const ProcessorBindings (Array AadlComponent (Option AadlComponent)))\n\n(declare-const AadlDispatchProtocol (Array AadlComponent (Option DispatchProtocol)))\n  (assert (= (Some Periodic) (select AadlDispatchProtocol PFC_Sys_Impl_Instance_proc_producer)))\n  (assert (= (Some Periodic) (select AadlDispatchProtocol PFC_Sys_Impl_Instance_proc_filter)))\n  (assert (= (Some Sporadic) (select AadlDispatchProtocol PFC_Sys_Impl_Instance_proc_consumer)))\n(declare-const AadlDispatchProtocol_size Int)\n(assert (= 3 AadlDispatchProtocol_size))\n\n(declare-datatypes ((AadlPort 0)) ((\n  (PFC_Sys_Impl_Instance_proc_producer_to_filter_data)\n  (PFC_Sys_Impl_Instance_proc_producer_to_filter_event)\n  (PFC_Sys_Impl_Instance_proc_filter_from_producer_data)\n  (PFC_Sys_Impl_Instance_proc_filter_to_consumer)\n  (PFC_Sys_Impl_Instance_proc_filter_from_producer_event)\n  (PFC_Sys_Impl_Instance_proc_consumer_from_filter))))\n(declare-const AadlPort_count Int)\n(assert (= 6 AadlPort_count))\n\n(declare-const AadlPortComponent (Array AadlPort (Option AadlComponent)))\n  (assert (= (Some PFC_Sys_Impl_Instance_proc_producer) (select AadlPortComponent PFC_Sys_Impl_Instance_proc_producer_to_filter_data)))\n  (assert (= (Some PFC_Sys_Impl_Instance_proc_producer) (select AadlPortComponent PFC_Sys_Impl_Instance_proc_producer_to_filter_event)))\n  (assert (= (Some PFC_Sys_Impl_Instance_proc_filter) (select AadlPortComponent PFC_Sys_Impl_Instance_proc_filter_from_producer_data)))\n  (assert (= (Some PFC_Sys_Impl_Instance_proc_filter) (select AadlPortComponent PFC_Sys_Impl_Instance_proc_filter_to_consumer)))\n  (assert (= (Some PFC_Sys_Impl_Instance_proc_filter) (select AadlPortComponent PFC_Sys_Impl_Instance_proc_filter_from_producer_event)))\n  (assert (= (Some PFC_Sys_Impl_Instance_proc_consumer) (select AadlPortComponent PFC_Sys_Impl_Instance_proc_consumer_from_filter)))\n(declare-const AadlPortComponent_size Int)\n(assert (= 6 AadlPortComponent_size))\n\n(declare-const AadlFeatureCategory (Array AadlPort FeatureCategory))\n  (assert (= DataPort (select AadlFeatureCategory PFC_Sys_Impl_Instance_proc_producer_to_filter_data)))\n  (assert (= EventPort (select AadlFeatureCategory PFC_Sys_Impl_Instance_proc_producer_to_filter_event)))\n  (assert (= DataPort (select AadlFeatureCategory PFC_Sys_Impl_Instance_proc_filter_from_producer_data)))\n  (assert (= EventDataPort (select AadlFeatureCategory PFC_Sys_Impl_Instance_proc_filter_to_consumer)))\n  (assert (= EventPort (select AadlFeatureCategory PFC_Sys_Impl_Instance_proc_filter_from_producer_event)))\n  (assert (= EventDataPort (select AadlFeatureCategory PFC_Sys_Impl_Instance_proc_consumer_from_filter)))\n(declare-const AadlFeatureCategory_size Int)\n(assert (= 6 AadlFeatureCategory_size))\n\n(declare-const AadlPortDirection (Array AadlPort Direction))\n  (assert (= Out (select AadlPortDirection PFC_Sys_Impl_Instance_proc_producer_to_filter_data)))\n  (assert (= Out (select AadlPortDirection PFC_Sys_Impl_Instance_proc_producer_to_filter_event)))\n  (assert (= In (select AadlPortDirection PFC_Sys_Impl_Instance_proc_filter_from_producer_data)))\n  (assert (= Out (select AadlPortDirection PFC_Sys_Impl_Instance_proc_filter_to_consumer)))\n  (assert (= In (select AadlPortDirection PFC_Sys_Impl_Instance_proc_filter_from_producer_event)))\n  (assert (= In (select AadlPortDirection PFC_Sys_Impl_Instance_proc_consumer_from_filter)))\n(declare-const AadlPortDirection_size Int)\n(assert (= 6 AadlPortDirection_size))\n\n(define-fun AadlConnectionFlowTos ((p1 AadlPort) (p2 AadlPort)) Bool\n  (or\n    (and (= p1 PFC_Sys_Impl_Instance_proc_producer_to_filter_data) (= p2 PFC_Sys_Impl_Instance_proc_filter_from_producer_data))\n    (and (= p1 PFC_Sys_Impl_Instance_proc_producer_to_filter_event) (= p2 PFC_Sys_Impl_Instance_proc_filter_from_producer_event))\n    (and (= p1 PFC_Sys_Impl_Instance_proc_filter_to_consumer) (= p2 PFC_Sys_Impl_Instance_proc_consumer_from_filter))\n    false))\n(declare-const AadlConnectionFlowsTos_count Int)\n(assert (= 3 AadlConnectionFlowsTos_count))\n\n\n;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n;;                                                                        ;;\n;;                              CAmkES Model                              ;;\n;;                                                                        ;;\n;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(declare-datatypes ((AccessType 0)) ((\n  (R)\n  (W)\n  (RW))))\n\n(declare-datatypes ((seL4ConnectorType 0)) ((\n  (seL4GlobalAsynch)\n  (seL4GlobalAsynchCallback)\n  (seL4Notification)\n  (seL4RPCCall)\n  (seL4RPCDataport)\n  (seL4SharedData)\n  (seL4SharedDataWithCaps)\n  (seL4SerialServer)\n  (seL4TimeServer)\n  (seL4VMDTBPassthrough)\n  (CASE_AADL_EventDataport))))\n\n(declare-datatypes ((CAmkESComponent 0)) ((\n  (proc_producer)\n  (proc_filter)\n  (proc_consumer)\n  (dispatch_periodic_inst)\n  (time_server))))\n(declare-const CAmkESComponent_count Int)\n(assert (= 5 CAmkESComponent_count))\n\n(define-fun isPeriodicDispatcher ((_component CAmkESComponent)) Bool\n  (and (= ModelSchedulingType PeriodicDispatching)\n       (= _component dispatch_periodic_inst)))\n\n(define-fun isPacer ((_component CAmkESComponent)) Bool\n  (and (= ModelSchedulingType Pacing)\n       false))\n\n(define-fun isFileServer ((_component CAmkESComponent)) Bool\n  (and ; TODO: list scenarios where a file server is expected\n       false))\n\n(define-fun isTimeServer ((_component CAmkESComponent)) Bool\n  (and ; TODO: list scenarios where a time server is expected\n       (= _component time_server)))\n\n(define-fun isSerialServer ((_component CAmkESComponent)) Bool\n  (and ; TODO: list scenarios where a serial server is expected\n       false))\n\n(declare-datatypes ((CAmkESPort 0)) ((\n  (proc_producer_sb_to_filter_data)\n  (proc_producer_sb_to_filter_event_counter)\n  (proc_producer_sb_to_filter_event)\n  (proc_producer_sb_periodic_dispatch_notification)\n  (proc_filter_sb_from_producer_data)\n  (proc_filter_sb_to_consumer_queue_1)\n  (proc_filter_sb_from_producer_event_counter)\n  (proc_filter_sb_to_consumer_1_notification)\n  (proc_filter_sb_from_producer_event)\n  (proc_filter_sb_periodic_dispatch_notification)\n  (proc_consumer_sb_from_filter_queue)\n  (proc_consumer_sb_from_filter_notification)\n  (dispatch_periodic_inst_sb_proc_producer_periodic_dispatch_notification)\n  (dispatch_periodic_inst_sb_proc_filter_periodic_dispatch_notification)\n  (dispatch_periodic_inst_timer)\n  (dispatch_periodic_inst_timer_complete)\n  (time_server_timer_notification)\n  (time_server_the_timer))))\n(declare-const CAmkESPort_count Int)\n(assert (= 18 CAmkESPort_count))\n\n(declare-const CAmkESAccessRestrictions (Array CAmkESPort AccessType))\n  (assert (= W (select CAmkESAccessRestrictions proc_producer_sb_to_filter_data)))\n  (assert (= R (select CAmkESAccessRestrictions proc_filter_sb_from_producer_data)))\n  (assert (= W (select CAmkESAccessRestrictions proc_producer_sb_to_filter_event_counter)))\n  (assert (= R (select CAmkESAccessRestrictions proc_filter_sb_from_producer_event_counter)))\n  (assert (= W (select CAmkESAccessRestrictions proc_filter_sb_to_consumer_queue_1)))\n  (assert (= R (select CAmkESAccessRestrictions proc_consumer_sb_from_filter_queue)))\n(declare-const CAmkESAccessRestrictions_size Int)\n(assert (= 6 CAmkESAccessRestrictions_size))\n\n(declare-datatypes ((CAmkESConnection 0)) ((\n  (conn1)\n  (conn2)\n  (conn3)\n  (conn4)\n  (conn5)\n  (conn6)\n  (conn7)\n  (conn8)\n  (conn9))))\n(declare-const CAmkESConnection_count Int)\n(assert (= 9 CAmkESConnection_count))\n\n(define-fun isSelfPacingConnection ((_conn CAmkESConnection)) Bool\n  (and (= ModelSchedulingType SelfPacing)\n       (or \n           false)))\n\n(define-fun isPacingConnection ((_conn CAmkESConnection)) Bool\n  (and (= ModelSchedulingType Pacing)\n       (or \n           false)))\n\n(define-fun isPeriodicDispatchingConnection ((_conn CAmkESConnection)) Bool\n  (and (= ModelSchedulingType PeriodicDispatching)\n       (or (= _conn conn6)\n           (= _conn conn7)\n           (= _conn conn8)\n           (= _conn conn9)\n           false)))\n(declare-const PeriodicDispatchingConnection_count Int)\n(assert (= 4 PeriodicDispatchingConnection_count))\n\n; non Aadl connection refinement connections required by a VM\n(define-fun isVMAuxConnection ((_conn CAmkESConnection)) Bool\n  (or \n      false))\n\n(declare-const CAmkESConnectionType (Array CAmkESConnection seL4ConnectorType))\n  (assert (= seL4SharedData (select CAmkESConnectionType conn1)))\n  (assert (= seL4Notification (select CAmkESConnectionType conn2)))\n  (assert (= seL4SharedData (select CAmkESConnectionType conn3)))\n  (assert (= seL4Notification (select CAmkESConnectionType conn4)))\n  (assert (= seL4SharedData (select CAmkESConnectionType conn5)))\n  (assert (= seL4Notification (select CAmkESConnectionType conn6)))\n  (assert (= seL4Notification (select CAmkESConnectionType conn7)))\n  (assert (= seL4TimeServer (select CAmkESConnectionType conn8)))\n  (assert (= seL4GlobalAsynchCallback (select CAmkESConnectionType conn9)))\n(declare-const CAmkESConnectionType_count Int)\n(assert (= 9 CAmkESConnectionType_count))\n\n(declare-const CAmkESPortComponent (Array CAmkESPort CAmkESComponent))\n  (assert (= proc_producer (select CAmkESPortComponent proc_producer_sb_to_filter_data)))\n  (assert (= proc_producer (select CAmkESPortComponent proc_producer_sb_to_filter_event_counter)))\n  (assert (= proc_producer (select CAmkESPortComponent proc_producer_sb_to_filter_event)))\n  (assert (= proc_producer (select CAmkESPortComponent proc_producer_sb_periodic_dispatch_notification)))\n  (assert (= proc_filter (select CAmkESPortComponent proc_filter_sb_from_producer_data)))\n  (assert (= proc_filter (select CAmkESPortComponent proc_filter_sb_to_consumer_queue_1)))\n  (assert (= proc_filter (select CAmkESPortComponent proc_filter_sb_from_producer_event_counter)))\n  (assert (= proc_filter (select CAmkESPortComponent proc_filter_sb_to_consumer_1_notification)))\n  (assert (= proc_filter (select CAmkESPortComponent proc_filter_sb_from_producer_event)))\n  (assert (= proc_filter (select CAmkESPortComponent proc_filter_sb_periodic_dispatch_notification)))\n  (assert (= proc_consumer (select CAmkESPortComponent proc_consumer_sb_from_filter_queue)))\n  (assert (= proc_consumer (select CAmkESPortComponent proc_consumer_sb_from_filter_notification)))\n  (assert (= dispatch_periodic_inst (select CAmkESPortComponent dispatch_periodic_inst_sb_proc_producer_periodic_dispatch_notification)))\n  (assert (= dispatch_periodic_inst (select CAmkESPortComponent dispatch_periodic_inst_sb_proc_filter_periodic_dispatch_notification)))\n  (assert (= dispatch_periodic_inst (select CAmkESPortComponent dispatch_periodic_inst_timer)))\n  (assert (= dispatch_periodic_inst (select CAmkESPortComponent dispatch_periodic_inst_timer_complete)))\n  (assert (= time_server (select CAmkESPortComponent time_server_timer_notification)))\n  (assert (= time_server (select CAmkESPortComponent time_server_the_timer)))\n(declare-const CAmkESPortComponent_size Int)\n(assert (= 18 CAmkESPortComponent_size))\n\n(define-fun CAmkESConnectionFlowTos ((_conn CAmkESConnection) (_p1 CAmkESPort) (_p2 CAmkESPort)) Bool\n  (or\n    (and (= _conn conn1) (= _p1 proc_producer_sb_to_filter_data) (= _p2 proc_filter_sb_from_producer_data))\n    (and (= _conn conn2) (= _p1 proc_producer_sb_to_filter_event) (= _p2 proc_filter_sb_from_producer_event))\n    (and (= _conn conn3) (= _p1 proc_producer_sb_to_filter_event_counter) (= _p2 proc_filter_sb_from_producer_event_counter))\n    (and (= _conn conn4) (= _p1 proc_filter_sb_to_consumer_1_notification) (= _p2 proc_consumer_sb_from_filter_notification))\n    (and (= _conn conn5) (= _p1 proc_filter_sb_to_consumer_queue_1) (= _p2 proc_consumer_sb_from_filter_queue))\n    (and (= _conn conn6) (= _p1 dispatch_periodic_inst_sb_proc_producer_periodic_dispatch_notification) (= _p2 proc_producer_sb_periodic_dispatch_notification))\n    (and (= _conn conn7) (= _p1 dispatch_periodic_inst_sb_proc_filter_periodic_dispatch_notification) (= _p2 proc_filter_sb_periodic_dispatch_notification))\n    (and (= _conn conn8) (= _p1 dispatch_periodic_inst_timer) (= _p2 time_server_the_timer))\n    (and (= _conn conn9) (= _p1 time_server_timer_notification) (= _p2 dispatch_periodic_inst_timer_complete))\n    false))\n(declare-const CAmkESConnectionFlowTos_count Int)\n(assert (= 9 CAmkESConnectionFlowTos_count))\n\n(define-fun ComponentRefinement ((ac (Option AadlComponent)) (cc CAmkESComponent)) Bool\n  (or\n    (and (= ac (Some PFC_Sys_Impl_Instance_proc_producer)) (= cc proc_producer))\n    (and (= ac (Some PFC_Sys_Impl_Instance_proc_filter)) (= cc proc_filter))\n    (and (= ac (Some PFC_Sys_Impl_Instance_proc_consumer)) (= cc proc_consumer))\n    false))\n(declare-const ComponentRefinement_count Int)\n(assert (= 3 ComponentRefinement_count))\n\n(define-fun PortRefinement ((ap AadlPort) (cp CAmkESPort)) Bool\n  (or\n    (and (= ap PFC_Sys_Impl_Instance_proc_producer_to_filter_data) (= cp proc_producer_sb_to_filter_data))\n    (and (= ap PFC_Sys_Impl_Instance_proc_producer_to_filter_event) (= cp proc_producer_sb_to_filter_event_counter))\n    (and (= ap PFC_Sys_Impl_Instance_proc_producer_to_filter_event) (= cp proc_producer_sb_to_filter_event))\n    (and (= ap PFC_Sys_Impl_Instance_proc_filter_from_producer_data) (= cp proc_filter_sb_from_producer_data))\n    (and (= ap PFC_Sys_Impl_Instance_proc_filter_to_consumer) (= cp proc_filter_sb_to_consumer_queue_1))\n    (and (= ap PFC_Sys_Impl_Instance_proc_filter_from_producer_event) (= cp proc_filter_sb_from_producer_event_counter))\n    (and (= ap PFC_Sys_Impl_Instance_proc_filter_to_consumer) (= cp proc_filter_sb_to_consumer_1_notification))\n    (and (= ap PFC_Sys_Impl_Instance_proc_filter_from_producer_event) (= cp proc_filter_sb_from_producer_event))\n    (and (= ap PFC_Sys_Impl_Instance_proc_consumer_from_filter) (= cp proc_consumer_sb_from_filter_queue))\n    (and (= ap PFC_Sys_Impl_Instance_proc_consumer_from_filter) (= cp proc_consumer_sb_from_filter_notification))\n    false))\n(declare-const PortRefinement_count Int)\n(assert (= 10 PortRefinement_count))\n\n(define-fun isVMAuxPort ((cp CAmkESPort)) Bool\n  (exists ((cc CAmkESComponent))\n    (and (= cc (select CAmkESPortComponent cp))\n         (or \n             false))))\n\n\n;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n;;                                                                        ;;\n;;                             Proof Functions                            ;;\n;;                                                                        ;;\n;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(define-fun isVMComponent ((cc CAmkESComponent)) Bool\n  (exists ((ap AadlComponent))\n    (and (ComponentRefinement (Some ap) cc)                   ; cc refines ap\n         (= (Some Process) (select AadlComponentCategory ap)) ; ap is a process\n         (match (select ProcessorBindings ap) (\n           ((Some x) (= (Some VirtualProcessor) (select AadlComponentCategory x))) ; ap is bound to virtual processor\n           (None false))))))\n\n(define-fun AadlFlowDirectionality () Bool\n  (forall ((p1 AadlPort) (p2 AadlPort))\n    (=> (AadlConnectionFlowTos p1 p2)\n        (and (= Out (select AadlPortDirection p1)) (= In (select AadlPortDirection p2))))))\n\n(define-fun AadlFlowNoSelfConnection () Bool\n  (forall ((p1 AadlPort) (p2 AadlPort))\n    (=> (AadlConnectionFlowTos p1 p2)\n        (not (= p1 p2)))))\n\n(define-fun AadlConnectedPortTypeMatch () Bool\n  (forall ((src AadlPort) (dst AadlPort))\n    (=> (AadlConnectionFlowTos src dst)\n        (or (and (= AbstractFeature (select AadlFeatureCategory src)) (= AbstractFeature (select AadlFeatureCategory dst)))\n            (and (= BusAccess (select AadlFeatureCategory src)) (= BusAccess (select AadlFeatureCategory dst)))\n            (and (= DataAccess (select AadlFeatureCategory src)) (= DataAccess (select AadlFeatureCategory dst)))\n            (and (= DataPort (select AadlFeatureCategory src)) (= DataPort (select AadlFeatureCategory dst)))\n            (and (= EventPort (select AadlFeatureCategory src)) (= EventPort (select AadlFeatureCategory dst)))\n            (and (= EventDataPort (select AadlFeatureCategory src)) (= EventDataPort (select AadlFeatureCategory dst)))\n            (and (= FeatureGroup (select AadlFeatureCategory src)) (= FeatureGroup (select AadlFeatureCategory dst)))\n            (and (= Parameter (select AadlFeatureCategory src)) (= Parameter (select AadlFeatureCategory dst)))\n            (and (= SubprogramAccess (select AadlFeatureCategory src)) (= SubprogramAccess (select AadlFeatureCategory dst)))\n            (and (= SubprogramAccessGroup (select AadlFeatureCategory src)) (= SubprogramAccessGroup (select AadlFeatureCategory dst)))\n             false))))\n(declare-const AadlConnectedPortTypeMatch_count Int)\n(assert (= 10 AadlConnectedPortTypeMatch_count))\n\n(define-fun AadlDispatchProtocolSpecified () Bool\n  (forall ((_comp AadlComponent))\n    (match (select AadlComponentCategory _comp) (\n      ((Some _category_) (\n        ; threads and virtual processors must have an assigned dispatch protocol, all others are 'don't care'\n        match _category_ (\n          (Thread (not (= (as None (Option DispatchProtocol)) (select AadlDispatchProtocol _comp))))\n          (VirtualProcessor (not (= (as None (Option DispatchProtocol)) (select AadlDispatchProtocol _comp))))\n          (_z_ true)\n        )))\n      (None false) ; sanity check: all AADL components must have an assigned component category\n      ))))\n\n(define-fun AadlAllPortsAssigned () Bool\n  (forall ((_p AadlPort))\n    (not (= (as None (Option AadlComponent)) (select AadlPortComponent _p)))))\n\n(define-fun AADLWellFormedness () Bool\n  (and\n    (= AadlPort_count AadlPortComponent_size) ; all Aadl ports belong to an Aadl component\n    AadlAllPortsAssigned\n    AadlDispatchProtocolSpecified\n    AadlFlowDirectionality\n    AadlFlowNoSelfConnection\n    AadlConnectedPortTypeMatch))\n\n\n(define-fun CAmkESFlowNoSelfConnection () Bool\n  (forall ((_conn CAmkESConnection) (_p1 CAmkESPort) (_p2 CAmkESPort))\n    (=> (CAmkESConnectionFlowTos _conn _p1 _p2)\n        (not (= _p1 _p2)))))\n\n(define-fun CAmkESDataPortAccess () Bool\n  (forall ((_conn CAmkESConnection) (_src CAmkESPort) (_dst CAmkESPort))\n    (=> (CAmkESConnectionFlowTos _conn _src _dst)\n        (and\n             (=> (= seL4SharedData (select CAmkESConnectionType _conn))\n                 (and (= W (select CAmkESAccessRestrictions _src))\n                      (= R (select CAmkESAccessRestrictions _dst))))\n             (=> (= seL4SharedDataWithCaps (select CAmkESConnectionType _conn))\n                 (and (ite (isVMComponent (select CAmkESPortComponent _src))\n                           (= RW (select CAmkESAccessRestrictions _src))\n                           (= W (select CAmkESAccessRestrictions _src)))\n                      (= R (select CAmkESAccessRestrictions _dst))))))))\n\n(define-fun UniqueComponentRefinements () Bool\n  (forall ((aadlComponent1 AadlComponent) (camkesComponent CAmkESComponent))\n    (=> (ComponentRefinement (Some aadlComponent1) camkesComponent)\n        (not (exists ((aadlComponent2 AadlComponent))\n               (and (not (= aadlComponent1 aadlComponent2))\n                    (ComponentRefinement (Some aadlComponent2) camkesComponent)))))))\n\n(define-fun UniquePortRefinements () Bool\n  (forall ((aadlPort1 AadlPort) (camkesPort CAmkESPort))\n    (=> (PortRefinement aadlPort1 camkesPort)\n        (not (exists ((aadlPort2 AadlPort))\n               (and (not (= aadlPort1 aadlPort2))\n                    (PortRefinement aadlPort2 camkesPort)))))))\n\n(define-fun CAmkESWellFormedness () Bool\n  (and\n    (= CAmkESPort_count CAmkESPortComponent_size) ; all CAmkES ports belong to a CAmkES component\n    CAmkESDataPortAccess\n    CAmkESFlowNoSelfConnection))\n\n; helper method: if either port belongs to a VM component then any data connection between the two of them\n; must be seL4SharedDataWithCaps, seL4SharedData otherwise\n(define-fun getExpectedDataConnectionType ((camkesSource CAmkESPort) (camkesDest CAmkESPort)) seL4ConnectorType\n  (ite (or (isVMComponent (select CAmkESPortComponent camkesSource))\n           (isVMComponent (select CAmkESPortComponent camkesDest))\n           false)\n       seL4SharedDataWithCaps\n       seL4SharedData))\n\n; helper method: if the destination port belongs to a VM component than any event connection between the two ports\n; must be seL4GlobalAsynch, seL4Notification otherwise\n(define-fun getExpectedEventConnectionType ((camkesSource CAmkESPort) (camkesDest CAmkESPort)) seL4ConnectorType\n  (ite (isVMComponent (select CAmkESPortComponent camkesDest))\n       seL4GlobalAsynch\n       seL4Notification))\n\n(define-fun SB_DataPortRefinement ((aadlSource AadlPort) (aadlDest AadlPort)) Bool\n  (exists ((conn CAmkESConnection) (camkesSource CAmkESPort) (camkesDest CAmkESPort))\n      (and (CAmkESConnectionFlowTos conn camkesSource camkesDest)\n           (= (select CAmkESConnectionType conn) (getExpectedDataConnectionType camkesSource camkesDest)) ; actual connector type must match expected\n           (PortRefinement aadlSource camkesSource)\n           (PortRefinement aadlDest  camkesDest)\n           (ComponentRefinement (select AadlPortComponent aadlSource) (select CAmkESPortComponent camkesSource))\n           (ComponentRefinement (select AadlPortComponent aadlDest) (select CAmkESPortComponent camkesDest)))))\n\n(define-fun SB_EventPortRefinement ((aadlSource AadlPort) (aadlDest AadlPort)) Bool\n  (exists ((conn CAmkESConnection) (camkesSource CAmkESPort) (camkesDest CAmkESPort))\n    (and\n      (CAmkESConnectionFlowTos conn camkesSource camkesDest)\n      (= (select CAmkESConnectionType conn) (getExpectedEventConnectionType camkesSource camkesDest)) ; actual connector type must match expected\n      (PortRefinement aadlSource camkesSource)\n      (PortRefinement aadlDest camkesDest)\n      (ComponentRefinement (select AadlPortComponent aadlSource) (select CAmkESPortComponent camkesSource))\n      (ComponentRefinement (select AadlPortComponent aadlDest) (select CAmkESPortComponent camkesDest)))))\n\n(define-fun SB_Refinement ((aadlSource AadlPort) (aadlDest AadlPort)) Bool\n  (and (or (= CodegenMode SeL4) (= CodegenMode SeL4_Only) false)\n       (or\n         (and\n           (= DataPort (select AadlFeatureCategory aadlSource))\n           (SB_DataPortRefinement aadlSource aadlDest)) ; payload\n         (and\n           (= EventPort (select AadlFeatureCategory aadlSource))\n           (SB_DataPortRefinement aadlSource aadlDest)   ; event counter\n           (SB_EventPortRefinement aadlSource aadlDest)) ; event\n         (and\n           (= EventDataPort (select AadlFeatureCategory aadlSource))\n           (SB_DataPortRefinement aadlSource aadlDest)   ; payload\n           (SB_EventPortRefinement aadlSource aadlDest)) ; event\n         false)))\n\n(define-fun ConnectionPreservation () Bool\n  (forall ((aadlSource AadlPort) (aadlDest AadlPort))\n    (=> (AadlConnectionFlowTos aadlSource aadlDest)\n        (and (or (= CodegenMode SeL4) (= CodegenMode SeL4_Only) false)\n             (SB_Refinement aadlSource aadlDest)))))\n\n\n(define-fun isAadl_SB_ConnectionRefinement ((camkesSource CAmkESPort) (camkesDest CAmkESPort)) Bool\n  (and (or (= CodegenMode SeL4) (= CodegenMode SeL4_Only) false)\n       (exists ((aadlSource AadlPort) (aadlDest AadlPort))\n         (and\n           (PortRefinement aadlSource camkesSource)\n           (PortRefinement aadlDest camkesDest)\n           (ComponentRefinement (select AadlPortComponent aadlSource) (select CAmkESPortComponent camkesSource))\n           (ComponentRefinement (select AadlPortComponent aadlDest) (select CAmkESPortComponent camkesDest))\n           (AadlConnectionFlowTos aadlSource aadlDest)))))\n\n(define-fun isCAmkESSchedulingConnection ((_conn CAmkESConnection)) Bool\n  (or\n    (isSelfPacingConnection _conn)\n    (isPacingConnection _conn)\n    (isPeriodicDispatchingConnection _conn)\n    false))\n\n(define-fun isVirtualMachineInducedConnection ((conn CAmkESConnection) (camkesSource CAmkESPort) (camkesDest CAmkESPort)) Bool\n  (or\n    (and (isVMAuxConnection conn)\n         (or (isVMAuxPort camkesSource)\n             (isVMAuxPort camkesDest)\n             false))\n    (and (isSerialServer (select CAmkESPortComponent camkesSource)) ; connection b\/w serial and time server\n         (isTimeServer (select CAmkESPortComponent camkesDest)))\n    false))\n\n(define-fun NoNewConnections () Bool\n  (forall ((conn CAmkESConnection) (camkesSource CAmkESPort) (camkesDest CAmkESPort))\n    (=> (CAmkESConnectionFlowTos conn camkesSource camkesDest)\n      (or\n        (isAadl_SB_ConnectionRefinement camkesSource camkesDest)\n        (isCAmkESSchedulingConnection conn)\n        (isVirtualMachineInducedConnection conn camkesSource camkesDest)\n        false))))\n\n;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n;;                                                                        ;;\n;;                              Proof                                     ;;\n;;                                                                        ;;\n;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(echo \"RefinementProof: Shows that there is a model satisfying all the constraints (should be sat):\")\n(push)\n(assert (and\n  AADLWellFormedness\n  CAmkESWellFormedness\n  ConnectionPreservation\n  UniqueComponentRefinements\n  UniquePortRefinements\n  NoNewConnections\n))\n(check-sat)\n;(get-model)\n(pop)\n\n(echo \"AADLWellFormedness: Proves that the generated AADL evidence is well-formed (should be unsat):\")\n(push)\n(assert (not AADLWellFormedness))\n(check-sat)\n(pop)\n\n(echo \"CAmkESWellFormedness: Proves that the generated CAmkES evidence is well-formed (should be unsat):\")\n(push)\n(assert (not CAmkESWellFormedness))\n(check-sat)\n(pop)\n\n(echo \"ConnectionPreservation: Proves that the generated CAmkES connections preserve AADL's (should be unsat):\")\n(push)\n(assert (not ConnectionPreservation))\n(check-sat)\n(pop)\n\n(echo \"NoNewConnections: Proves that the generated CAmkES connections does not contain more than AADL's (should be unsat):\")\n(push)\n(assert (not NoNewConnections))\n(check-sat)\n(pop)\n\n\n(exit)",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ]
    ]
  }
}