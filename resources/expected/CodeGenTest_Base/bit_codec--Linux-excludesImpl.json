{
  "type" : "TestResult",
  "map" : {
    "type" : "Map",
    "entries" : [
      [
        "slang\/src\/main\/data\/bit_codec\/Base_Types.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage bit_codec\n\nimport org.sireum._\nimport org.sireum.S8._\nimport org.sireum.S16._\nimport org.sireum.S32._\nimport org.sireum.S64._\nimport org.sireum.U8._\nimport org.sireum.U16._\nimport org.sireum.U32._\nimport org.sireum.U64._\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\nobject Base_Types {\n\n  type Boolean = B\n\n  type Integer = Z\n\n  type Integer_8 = S8\n  type Integer_16 = S16\n  type Integer_32 = S32\n  type Integer_64 = S64\n\n  type Unsigned_8 = U8\n  type Unsigned_16 = U16\n  type Unsigned_32 = U32\n  type Unsigned_64 = U64\n\n  \/\/ TODO: Base_Types::Natural\n\n  type Float = R\n  type Float_32 = F32\n  type Float_64 = F64\n\n  type Character = C\n  type String = org.sireum.String\n\n  type Bits = org.sireum.ISZ[B]\n\n  @datatype class Boolean_Payload(value: B) extends art.DataContent\n\n  @datatype class Integer_Payload(value: Z) extends art.DataContent\n\n  @datatype class Integer_8_Payload(value: S8) extends art.DataContent\n  @datatype class Integer_16_Payload(value: S16) extends art.DataContent\n  @datatype class Integer_32_Payload(value: S32) extends art.DataContent\n  @datatype class Integer_64_Payload(value: S64) extends art.DataContent\n\n  @datatype class Unsigned_8_Payload(value: U8) extends art.DataContent\n  @datatype class Unsigned_16_Payload(value: U16) extends art.DataContent\n  @datatype class Unsigned_32_Payload(value: U32) extends art.DataContent\n  @datatype class Unsigned_64_Payload(value: U64) extends art.DataContent\n\n  @datatype class Float_Payload(value: R) extends art.DataContent\n  @datatype class Float_32_Payload(value: F32) extends art.DataContent\n  @datatype class Float_64_Payload(value: F64) extends art.DataContent\n\n  @datatype class Character_Payload(value: C) extends art.DataContent\n  @datatype class String_Payload(value: String) extends art.DataContent\n\n  @datatype class Bits_Payload(value: ISZ[B]) extends art.DataContent\n\n  def Boolean_example(): Boolean = {\n    Contract(Ensures(Res == F))\n    return F\n  }\n\n\n  def Integer_example(): Integer = {\n    Contract(Ensures(Res == z\"0\"))\n    return z\"0\"\n  }\n\n  def Integer_8_example(): Integer_8 = {\n    Contract(Ensures(Res == s8\"0\"))\n    return s8\"0\"\n  }\n\n  def Integer_16_example(): Integer_16 = {\n    Contract(Ensures(Res == s16\"0\"))\n    return s16\"0\"\n  }\n\n  def Integer_32_example(): Integer_32 = {\n    Contract(Ensures(Res == s32\"0\"))\n    return s32\"0\"\n  }\n\n  def Integer_64_example(): Integer_64 = {\n    Contract(Ensures(Res == s64\"0\"))\n    return s64\"0\"\n  }\n\n\n  def Unsigned_8_example(): Unsigned_8 = {\n    Contract(Ensures(Res == u8\"0\"))\n    return u8\"0\"\n  }\n\n  def Unsigned_16_example(): Unsigned_16 = {\n    Contract(Ensures(Res == u16\"0\"))\n    return u16\"0\"\n  }\n\n  def Unsigned_32_example(): Unsigned_32 = {\n    Contract(Ensures(Res == u32\"0\"))\n    return u32\"0\"\n  }\n\n  def Unsigned_64_example(): Unsigned_64 = {\n    Contract(Ensures(Res == u64\"0\"))\n    return u64\"0\"\n  }\n\n\n  def Float_example(): Float = {\n    Contract(Ensures(Res == r\"0\"))\n    return r\"0\"\n  }\n\n  def Float_32_example(): Float_32 = {\n    Contract(Ensures(Res == f32\"0\"))\n    return f32\"0\"\n  }\n\n  def Float_64_example(): Float_64 = {\n    Contract(Ensures(Res == f64\"0\"))\n    return f64\"0\"\n  }\n\n\n  def Character_example(): Character = {\n    Contract(Ensures(Res == ' '))\n    return ' '\n  }\n\n  def String_example(): String = {\n    Contract(Ensures(Res == \"\"))\n    return \"\"\n  }\n\n\n  def Bits_example(): Bits = {\n    Contract(Ensures(Res == ISZ[B]()))\n    return ISZ[B]()\n  }\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : true
        }
      ],
      [
        "slang\/src\/main\/architecture\/bit_codec\/Arch.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage bit_codec\n\nimport org.sireum._\nimport art._\nimport art.PortMode._\nimport art.DispatchPropertyProtocol._\nimport art.Art.BridgeId._\nimport art.Art.PortId._\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\nobject Arch {\n  val Bit_Codec_Sys_Impl_Instance_proc_producer : bit_codec.Bit_Codec.Producer_proc_producer_Bridge = {\n    val to_filter_u32 = Port[Base_Types.Bits] (id = portId\"0\", name = \"Bit_Codec_Sys_Impl_Instance_proc_producer_to_filter_u32\", mode = DataOut)\n    val to_filter_latitude = Port[Base_Types.Bits] (id = portId\"1\", name = \"Bit_Codec_Sys_Impl_Instance_proc_producer_to_filter_latitude\", mode = DataOut)\n    val to_filter_longitude = Port[Base_Types.Bits] (id = portId\"2\", name = \"Bit_Codec_Sys_Impl_Instance_proc_producer_to_filter_longitude\", mode = DataOut)\n    val to_filter_coordinate = Port[Base_Types.Bits] (id = portId\"3\", name = \"Bit_Codec_Sys_Impl_Instance_proc_producer_to_filter_coordinate\", mode = DataOut)\n    val to_filter_mission = Port[Base_Types.Bits] (id = portId\"4\", name = \"Bit_Codec_Sys_Impl_Instance_proc_producer_to_filter_mission\", mode = EventOut)\n    val to_filter_event = Port[art.Empty] (id = portId\"5\", name = \"Bit_Codec_Sys_Impl_Instance_proc_producer_to_filter_event\", mode = EventOut)\n\n    bit_codec.Bit_Codec.Producer_proc_producer_Bridge(\n      id = bridgeId\"0\",\n      name = \"Bit_Codec_Sys_Impl_Instance_proc_producer\",\n      dispatchProtocol = Periodic(period = 1000),\n      dispatchTriggers = None(),\n\n      to_filter_u32 = to_filter_u32,\n      to_filter_latitude = to_filter_latitude,\n      to_filter_longitude = to_filter_longitude,\n      to_filter_coordinate = to_filter_coordinate,\n      to_filter_mission = to_filter_mission,\n      to_filter_event = to_filter_event\n    )\n  }\n  val Bit_Codec_Sys_Impl_Instance_proc_filter : bit_codec.Bit_Codec.Filter_proc_filter_Bridge = {\n    val from_producer_u32 = Port[Base_Types.Bits] (id = portId\"6\", name = \"Bit_Codec_Sys_Impl_Instance_proc_filter_from_producer_u32\", mode = DataIn)\n    val from_producer_latitude = Port[Base_Types.Bits] (id = portId\"7\", name = \"Bit_Codec_Sys_Impl_Instance_proc_filter_from_producer_latitude\", mode = DataIn)\n    val from_producer_longitude = Port[Base_Types.Bits] (id = portId\"8\", name = \"Bit_Codec_Sys_Impl_Instance_proc_filter_from_producer_longitude\", mode = DataIn)\n    val from_producer_coordinate = Port[Base_Types.Bits] (id = portId\"9\", name = \"Bit_Codec_Sys_Impl_Instance_proc_filter_from_producer_coordinate\", mode = DataIn)\n    val to_consumer_u32 = Port[Base_Types.Bits] (id = portId\"10\", name = \"Bit_Codec_Sys_Impl_Instance_proc_filter_to_consumer_u32\", mode = DataOut)\n    val to_consumer_latitude = Port[Base_Types.Bits] (id = portId\"11\", name = \"Bit_Codec_Sys_Impl_Instance_proc_filter_to_consumer_latitude\", mode = DataOut)\n    val to_consumer_longitude = Port[Base_Types.Bits] (id = portId\"12\", name = \"Bit_Codec_Sys_Impl_Instance_proc_filter_to_consumer_longitude\", mode = DataOut)\n    val to_consumer_coordinate = Port[Base_Types.Bits] (id = portId\"13\", name = \"Bit_Codec_Sys_Impl_Instance_proc_filter_to_consumer_coordinate\", mode = DataOut)\n    val from_producer_mission = Port[Base_Types.Bits] (id = portId\"14\", name = \"Bit_Codec_Sys_Impl_Instance_proc_filter_from_producer_mission\", mode = EventIn)\n    val to_consumer_mission = Port[Base_Types.Bits] (id = portId\"15\", name = \"Bit_Codec_Sys_Impl_Instance_proc_filter_to_consumer_mission\", mode = EventOut)\n    val from_producer_event = Port[art.Empty] (id = portId\"16\", name = \"Bit_Codec_Sys_Impl_Instance_proc_filter_from_producer_event\", mode = EventIn)\n    val to_consumer_event = Port[art.Empty] (id = portId\"17\", name = \"Bit_Codec_Sys_Impl_Instance_proc_filter_to_consumer_event\", mode = EventOut)\n\n    bit_codec.Bit_Codec.Filter_proc_filter_Bridge(\n      id = bridgeId\"1\",\n      name = \"Bit_Codec_Sys_Impl_Instance_proc_filter\",\n      dispatchProtocol = Sporadic(min = 1000),\n      dispatchTriggers = None(),\n\n      from_producer_u32 = from_producer_u32,\n      from_producer_latitude = from_producer_latitude,\n      from_producer_longitude = from_producer_longitude,\n      from_producer_coordinate = from_producer_coordinate,\n      to_consumer_u32 = to_consumer_u32,\n      to_consumer_latitude = to_consumer_latitude,\n      to_consumer_longitude = to_consumer_longitude,\n      to_consumer_coordinate = to_consumer_coordinate,\n      from_producer_mission = from_producer_mission,\n      to_consumer_mission = to_consumer_mission,\n      from_producer_event = from_producer_event,\n      to_consumer_event = to_consumer_event\n    )\n  }\n  val Bit_Codec_Sys_Impl_Instance_proc_consumer : bit_codec.Bit_Codec.Consumer_proc_consumer_Bridge = {\n    val from_filter_u32 = Port[Base_Types.Bits] (id = portId\"18\", name = \"Bit_Codec_Sys_Impl_Instance_proc_consumer_from_filter_u32\", mode = DataIn)\n    val from_filter_latitude = Port[Base_Types.Bits] (id = portId\"19\", name = \"Bit_Codec_Sys_Impl_Instance_proc_consumer_from_filter_latitude\", mode = DataIn)\n    val from_filter_longitude = Port[Base_Types.Bits] (id = portId\"20\", name = \"Bit_Codec_Sys_Impl_Instance_proc_consumer_from_filter_longitude\", mode = DataIn)\n    val from_filter_coordinate = Port[Base_Types.Bits] (id = portId\"21\", name = \"Bit_Codec_Sys_Impl_Instance_proc_consumer_from_filter_coordinate\", mode = DataIn)\n    val from_filter_mission = Port[Base_Types.Bits] (id = portId\"22\", name = \"Bit_Codec_Sys_Impl_Instance_proc_consumer_from_filter_mission\", mode = EventIn)\n    val from_filter_event = Port[art.Empty] (id = portId\"23\", name = \"Bit_Codec_Sys_Impl_Instance_proc_consumer_from_filter_event\", mode = EventIn)\n\n    bit_codec.Bit_Codec.Consumer_proc_consumer_Bridge(\n      id = bridgeId\"2\",\n      name = \"Bit_Codec_Sys_Impl_Instance_proc_consumer\",\n      dispatchProtocol = Periodic(period = 1000),\n      dispatchTriggers = None(),\n\n      from_filter_u32 = from_filter_u32,\n      from_filter_latitude = from_filter_latitude,\n      from_filter_longitude = from_filter_longitude,\n      from_filter_coordinate = from_filter_coordinate,\n      from_filter_mission = from_filter_mission,\n      from_filter_event = from_filter_event\n    )\n  }\n\n  val ad : ArchitectureDescription = {\n    TranspilerUtil.touch()\n\n    ArchitectureDescription(\n      components = IS[Art.BridgeId, Bridge] (Bit_Codec_Sys_Impl_Instance_proc_producer, Bit_Codec_Sys_Impl_Instance_proc_filter, Bit_Codec_Sys_Impl_Instance_proc_consumer),\n\n      connections = IS[Art.ConnectionId, UConnection] (Connection(from = Bit_Codec_Sys_Impl_Instance_proc_producer.to_filter_u32, to = Bit_Codec_Sys_Impl_Instance_proc_filter.from_producer_u32),\n                                                       Connection(from = Bit_Codec_Sys_Impl_Instance_proc_producer.to_filter_latitude, to = Bit_Codec_Sys_Impl_Instance_proc_filter.from_producer_latitude),\n                                                       Connection(from = Bit_Codec_Sys_Impl_Instance_proc_producer.to_filter_longitude, to = Bit_Codec_Sys_Impl_Instance_proc_filter.from_producer_longitude),\n                                                       Connection(from = Bit_Codec_Sys_Impl_Instance_proc_producer.to_filter_coordinate, to = Bit_Codec_Sys_Impl_Instance_proc_filter.from_producer_coordinate),\n                                                       Connection(from = Bit_Codec_Sys_Impl_Instance_proc_producer.to_filter_mission, to = Bit_Codec_Sys_Impl_Instance_proc_filter.from_producer_mission),\n                                                       Connection(from = Bit_Codec_Sys_Impl_Instance_proc_producer.to_filter_event, to = Bit_Codec_Sys_Impl_Instance_proc_filter.from_producer_event),\n                                                       Connection(from = Bit_Codec_Sys_Impl_Instance_proc_filter.to_consumer_u32, to = Bit_Codec_Sys_Impl_Instance_proc_consumer.from_filter_u32),\n                                                       Connection(from = Bit_Codec_Sys_Impl_Instance_proc_filter.to_consumer_latitude, to = Bit_Codec_Sys_Impl_Instance_proc_consumer.from_filter_latitude),\n                                                       Connection(from = Bit_Codec_Sys_Impl_Instance_proc_filter.to_consumer_longitude, to = Bit_Codec_Sys_Impl_Instance_proc_consumer.from_filter_longitude),\n                                                       Connection(from = Bit_Codec_Sys_Impl_Instance_proc_filter.to_consumer_coordinate, to = Bit_Codec_Sys_Impl_Instance_proc_consumer.from_filter_coordinate),\n                                                       Connection(from = Bit_Codec_Sys_Impl_Instance_proc_filter.to_consumer_mission, to = Bit_Codec_Sys_Impl_Instance_proc_consumer.from_filter_mission),\n                                                       Connection(from = Bit_Codec_Sys_Impl_Instance_proc_filter.to_consumer_event, to = Bit_Codec_Sys_Impl_Instance_proc_consumer.from_filter_event))\n    )\n  }\n}\n\nobject TranspilerUtil {\n  def touch(): Unit = {\n    if(F) {\n      TranspilerToucher.touch()\n\n      \/\/ add types used in Platform.receive and Platform.receiveAsync\n      val mbox2Boolean_Payload: MBox2[Art.PortId, DataContent] = MBox2(portId\"0\", Base_Types.Boolean_Payload(T))\n      val mbox2OptionDataContent: MBox2[Art.PortId, Option[DataContent]] = MBox2(portId\"0\", None())\n\n      \/\/ touch process\/thread timing properties\n      println(Schedulers.Bit_Codec_Sys_Impl_Instance_proc_producer_timingProperties)\n      println(Schedulers.Bit_Codec_Sys_Impl_Instance_proc_filter_timingProperties)\n      println(Schedulers.Bit_Codec_Sys_Impl_Instance_proc_consumer_timingProperties)\n\n      \/\/ touch each payload\/type in case some are only used as a field in a record\n      def printDataContent(a: art.DataContent): Unit = { println(s\"${a}\") }\n\n      printDataContent(Base_Types.Bits_Payload(Base_Types.Bits_example()))\n      printDataContent(art.Empty())\n\n      {\n        bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_initialization_api.get.logInfo(\"\")\n        bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_initialization_api.get.logDebug(\"\")\n        bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_initialization_api.get.logError(\"\")\n        bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_operational_api.get.logInfo(\"\")\n        bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_operational_api.get.logDebug(\"\")\n        bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_operational_api.get.logError(\"\")\n        bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_initialization_api.get.put_to_filter_u32(Base_Types.Bits_example())\n        bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_operational_api.get.put_to_filter_u32(Base_Types.Bits_example())\n        bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_initialization_api.get.put_to_filter_latitude(Base_Types.Bits_example())\n        bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_operational_api.get.put_to_filter_latitude(Base_Types.Bits_example())\n        bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_initialization_api.get.put_to_filter_longitude(Base_Types.Bits_example())\n        bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_operational_api.get.put_to_filter_longitude(Base_Types.Bits_example())\n        bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_initialization_api.get.put_to_filter_coordinate(Base_Types.Bits_example())\n        bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_operational_api.get.put_to_filter_coordinate(Base_Types.Bits_example())\n        bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_initialization_api.get.put_to_filter_mission(Base_Types.Bits_example())\n        bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_operational_api.get.put_to_filter_mission(Base_Types.Bits_example())\n        bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_initialization_api.get.put_to_filter_event()\n        bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_operational_api.get.put_to_filter_event()\n      }\n      {\n        bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_initialization_api.get.logInfo(\"\")\n        bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_initialization_api.get.logDebug(\"\")\n        bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_initialization_api.get.logError(\"\")\n        bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_operational_api.get.logInfo(\"\")\n        bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_operational_api.get.logDebug(\"\")\n        bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_operational_api.get.logError(\"\")\n        val apiUsage_from_producer_u32: Option[Base_Types.Bits] = bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_operational_api.get.get_from_producer_u32()\n        val apiUsage_from_producer_latitude: Option[Base_Types.Bits] = bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_operational_api.get.get_from_producer_latitude()\n        val apiUsage_from_producer_longitude: Option[Base_Types.Bits] = bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_operational_api.get.get_from_producer_longitude()\n        val apiUsage_from_producer_coordinate: Option[Base_Types.Bits] = bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_operational_api.get.get_from_producer_coordinate()\n        bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_initialization_api.get.put_to_consumer_u32(Base_Types.Bits_example())\n        bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_operational_api.get.put_to_consumer_u32(Base_Types.Bits_example())\n        bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_initialization_api.get.put_to_consumer_latitude(Base_Types.Bits_example())\n        bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_operational_api.get.put_to_consumer_latitude(Base_Types.Bits_example())\n        bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_initialization_api.get.put_to_consumer_longitude(Base_Types.Bits_example())\n        bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_operational_api.get.put_to_consumer_longitude(Base_Types.Bits_example())\n        bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_initialization_api.get.put_to_consumer_coordinate(Base_Types.Bits_example())\n        bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_operational_api.get.put_to_consumer_coordinate(Base_Types.Bits_example())\n        val apiUsage_from_producer_mission: Option[Base_Types.Bits] = bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_operational_api.get.get_from_producer_mission()\n        bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_initialization_api.get.put_to_consumer_mission(Base_Types.Bits_example())\n        bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_operational_api.get.put_to_consumer_mission(Base_Types.Bits_example())\n        val apiUsage_from_producer_event: Option[art.Empty] = bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_operational_api.get.get_from_producer_event()\n        bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_initialization_api.get.put_to_consumer_event()\n        bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_operational_api.get.put_to_consumer_event()\n      }\n      {\n        bit_codec.Bit_Codec.Consumer_proc_consumer_Bridge.c_initialization_api.get.logInfo(\"\")\n        bit_codec.Bit_Codec.Consumer_proc_consumer_Bridge.c_initialization_api.get.logDebug(\"\")\n        bit_codec.Bit_Codec.Consumer_proc_consumer_Bridge.c_initialization_api.get.logError(\"\")\n        bit_codec.Bit_Codec.Consumer_proc_consumer_Bridge.c_operational_api.get.logInfo(\"\")\n        bit_codec.Bit_Codec.Consumer_proc_consumer_Bridge.c_operational_api.get.logDebug(\"\")\n        bit_codec.Bit_Codec.Consumer_proc_consumer_Bridge.c_operational_api.get.logError(\"\")\n        val apiUsage_from_filter_u32: Option[Base_Types.Bits] = bit_codec.Bit_Codec.Consumer_proc_consumer_Bridge.c_operational_api.get.get_from_filter_u32()\n        val apiUsage_from_filter_latitude: Option[Base_Types.Bits] = bit_codec.Bit_Codec.Consumer_proc_consumer_Bridge.c_operational_api.get.get_from_filter_latitude()\n        val apiUsage_from_filter_longitude: Option[Base_Types.Bits] = bit_codec.Bit_Codec.Consumer_proc_consumer_Bridge.c_operational_api.get.get_from_filter_longitude()\n        val apiUsage_from_filter_coordinate: Option[Base_Types.Bits] = bit_codec.Bit_Codec.Consumer_proc_consumer_Bridge.c_operational_api.get.get_from_filter_coordinate()\n        val apiUsage_from_filter_mission: Option[Base_Types.Bits] = bit_codec.Bit_Codec.Consumer_proc_consumer_Bridge.c_operational_api.get.get_from_filter_mission()\n        val apiUsage_from_filter_event: Option[art.Empty] = bit_codec.Bit_Codec.Consumer_proc_consumer_Bridge.c_operational_api.get.get_from_filter_event()\n      }\n    }\n  }\n}\n\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/architecture\/bit_codec\/Demo.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage bit_codec\n\nimport org.sireum._\nimport art.scheduling.Scheduler\n\n\/\/ This file will not be overwritten so is safe to edit\n\nobject Demo extends App {\n\n  \/** @return the scheduler to use for JVM based simulation as well as the 'default' scheduler\n    *         that will be used when taking this program down to C\/Linux.  Refer to\n    *         'bin\/run.sh -h' if you want to use a specific scheduler for C.  If the scheduler\n    *         accepts a schedule and you want to provide that in C then just pass None()\n    *\n    *         If you want to use the legacy scheduler for C then you must use\n    *           bin\/transpile.cmd --legacy\n    *           bin\/compile.cmd\n    *           bin\/run.sh --legacy\n    *\/\n  def defaultScheduler(): Scheduler = {\n    return Schedulers.getRoundRobinScheduler(None())\n  }\n\n  def main(args: ISZ[String]): Z = {\n    Cli(' ').parseRun(args, 0) match {\n      case Some(o: Cli.RunOption) =>\n        val scheduler: Scheduler = o.scheduler match {\n          case Cli.RunChoice.Default => defaultScheduler()\n          case Cli.RunChoice.RoundRobin => Schedulers.getRoundRobinScheduler(None())\n          case Cli.RunChoice.Static => Schedulers.getStaticSchedulerH(MNone())\n          case Cli.RunChoice.Legacy => Schedulers.getLegacyScheduler()\n        }\n\n        Platform.setup()\n\n        art.Art.run(Arch.ad, scheduler)\n\n        Platform.tearDown()\n      case Some(o: Cli.HelpOption) =>\n      case _ => return 1\n    }\n    return 0\n  }\n}\n\nobject Cli {\n\n  @datatype trait RunTopOption\n\n  @datatype class HelpOption extends RunTopOption\n\n  @enum object RunChoice {\n    'Default\n    'RoundRobin\n    'Static\n    'Legacy\n  }\n\n  @datatype class RunOption(\n                             val help: String,\n                             val args: ISZ[String],\n                             val scheduler: RunChoice.Type\n                           ) extends RunTopOption\n}\n\nimport Cli._\n\n@record class Cli(val pathSep: C) {\n\n  def parseRunChoiceH(arg: String): Option[RunChoice.Type] = {\n    arg match {\n      case \"default\" => return Some(RunChoice.Default)\n      case \"roundRobin\" => return Some(RunChoice.RoundRobin)\n      case \"static\" => return Some(RunChoice.Static)\n      case \"legacy\" => return Some(RunChoice.Legacy)\n      case s =>\n        eprintln(s\"Expecting one of the following: { default, roundRobin, static, legacy }, but found '$s'.\")\n        return None()\n    }\n  }\n\n  def parseRunChoice(args: ISZ[String], i: Z): Option[RunChoice.Type] = {\n    if (i >= args.size) {\n      eprintln(\"Expecting one of the following: { default, roundRobin, static, legacy }, but none found.\")\n      return None()\n    }\n    val r = parseRunChoiceH(args(i))\n    return r\n  }\n\n  def parseRun(args: ISZ[String], i: Z): Option[RunTopOption] = {\n\n    def help(): Unit = {\n      println(\"Run Slang Embedded Program\")\n      println()\n      println(\"Usage: <option>*\")\n      println()\n      println(\"Available Options:\")\n      println(\"-s, --scheduler          The scheduler to use.  See Demo.scala for information\")\n      println(\"                           on 'default' (expects one of { default, roundRobin,\")\n      println(\"                           static, legacy }; default: default)\")\n      println(\"-h, --help               Display this information\")\n    }\n\n    var scheduler: RunChoice.Type = RunChoice.Default\n    var j = i\n    var isOption = T\n    while (j < args.size && isOption) {\n      var arg = args(j)\n      if (arg == \"-h\" || arg == \"--help\") {\n        help()\n        return Some(HelpOption())\n      } else if (arg == \"-s\" || arg == \"--scheduler\") {\n        val o: Option[RunChoice.Type] = parseRunChoice(args, j + 1)\n        o match {\n          case Some(v) => scheduler = v\n          case _ => return None()\n        }\n      } else {\n        eprintln(s\"Unrecognized option '$arg'.\")\n        return None()\n      }\n      j = j + 2\n    }\n\n    return Some(RunOption(\"\", args, scheduler))\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/architecture\/bit_codec\/Schedulers.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\npackage bit_codec\n\nimport org.sireum._\nimport art.Art\nimport art.scheduling.legacy.Legacy\nimport art.scheduling.roundrobin.RoundRobin\nimport art.scheduling.static.Schedule.{DSchedule, DScheduleSpec}\nimport art.scheduling.static._\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\n@datatype class ProcessorTimingProperties(val clockPeriod: Option[Z],\n                                          val framePeriod: Option[Z],\n                                          val maxDomain: Option[Z],\n                                          val slotTime: Option[Z])\n\n@datatype class ThreadTimingProperties(val domain: Option[Z],\n                                       val computeExecutionTime: Option[(Z, Z)])\n\nobject Schedulers {\n\n  val threadNickNames: Map[String, Art.BridgeId] = Map(\n    ISZ(\n      Arch.Bit_Codec_Sys_Impl_Instance_proc_producer.name ~> Arch.Bit_Codec_Sys_Impl_Instance_proc_producer.id,\n      Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.name ~> Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.id,\n      Arch.Bit_Codec_Sys_Impl_Instance_proc_consumer.name ~> Arch.Bit_Codec_Sys_Impl_Instance_proc_consumer.id)\n  )\n\n  val revThreadNickNames: Map[Art.BridgeId, String] = Map.empty[Art.BridgeId, String] ++ (for (e <- threadNickNames.entries) yield e._2 ~> e._1)\n\n\n  val Bit_Codec_Sys_Impl_Instance_proc_producer_timingProperties: ThreadTimingProperties = ThreadTimingProperties(\n    computeExecutionTime = None(),\n    domain = None())\n\n  val Bit_Codec_Sys_Impl_Instance_proc_filter_timingProperties: ThreadTimingProperties = ThreadTimingProperties(\n    computeExecutionTime = None(),\n    domain = None())\n\n  val Bit_Codec_Sys_Impl_Instance_proc_consumer_timingProperties: ThreadTimingProperties = ThreadTimingProperties(\n    computeExecutionTime = None(),\n    domain = None())\n\n\n  \/**********************************************************************\n   * Round Robin Scheduler\n   *********************************************************************\/\n\n  \/\/ roundRobinSchedule represents the component dispatch order\n  val roundRobinSchedule: ISZ[Art.BridgeId] = {\n    \/\/ convert IS[Art.BridgeId, art.Bridge] to an IS[Z, Art.BridgeId] to allow bridges to be dispatched\n    \/\/ multiple times during a hyper-period\n    var ret: ISZ[Art.BridgeId] = ISZ()\n    for (e <- Arch.ad.components) {\n      ret = ret :+ e.id\n    }\n    ret\n  }\n\n  def getRoundRobinScheduler(schedule: Option[ISZ[Art.BridgeId]]): RoundRobin = {\n    if (roundRobinSchedule.isEmpty) {} \/\/ line needed for transpiler; do not remove\n    schedule match {\n      case Some(s) => return RoundRobin(s)\n      case _ => return RoundRobin(ScheduleProviderI.getRoundRobinOrder())\n    }\n  }\n\n  \/**********************************************************************\n   * Static Scheduler\n   *********************************************************************\/\n\n  val framePeriod: Z = 1000\n  val numComponents: Z = Arch.ad.components.size\n  val maxExecutionTime: Z = numComponents \/ framePeriod\n\n  \/\/ defaultStaticSchedule represents the component dispatch order\n  val defaultStaticSchedule: DScheduleSpec = DScheduleSpec(0, 0, DSchedule(ISZ(\n    Schedule.Slot(0, maxExecutionTime),\n    Schedule.Slot(1, maxExecutionTime),\n    Schedule.Slot(2, maxExecutionTime)\n  )))\n\n  val defaultDomainToBridgeIdMap: ISZ[Art.BridgeId] = ISZ(\n    \/* domain 0 *\/ Arch.Bit_Codec_Sys_Impl_Instance_proc_producer.id,\n    \/* domain 1 *\/ Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.id,\n    \/* domain 2 *\/ Arch.Bit_Codec_Sys_Impl_Instance_proc_consumer.id\n  )\n\n  def getStaticSchedulerH(userProvided: MOption[(DScheduleSpec, ISZ[Art.BridgeId], Map[String, Art.BridgeId], CommandProvider)]): StaticScheduler = {\n    if (defaultStaticSchedule.schedule.slots.isEmpty && defaultDomainToBridgeIdMap.isEmpty && threadNickNames.isEmpty) {} \/\/ line needed for transpiler; do not remove\n    userProvided match {\n      case MSome((schedule_, domainToBridgeIdMap_, threadNickNames_, commandProvider)) =>\n        return getStaticScheduler(schedule_, domainToBridgeIdMap_, threadNickNames_, commandProvider)\n      case _ =>\n        return getStaticScheduler(\n          ScheduleProviderI.getStaticSchedule(),\n          \/\/ TODO: get the following from extension so they can be customized via C\n          defaultDomainToBridgeIdMap,\n          threadNickNames,\n          DefaultCommandProvider())\n    }\n  }\n\n  def getStaticScheduler(schedule: DScheduleSpec,\n                         domainToBridgeIdMap: ISZ[Art.BridgeId],\n                         threadNickNames: Map[String, Art.BridgeId],\n                         commandProvider: CommandProvider): StaticScheduler = {\n    return StaticScheduler(schedule, Arch.ad.components, domainToBridgeIdMap, threadNickNames,\n      if (commandProvider.isInstanceOf[InfoCommandProvider])\n        commandProvider.asInstanceOf[InfoCommandProvider].init(\n          threadNickNames,\n          schedule.schedule.slots.size,\n          domainToBridgeIdMap\n        )\n      else commandProvider)\n  }\n\n\n  \/**********************************************************************\n   * Legacy Scheduler\n   *********************************************************************\/\n\n  def getLegacyScheduler(): Legacy = {\n    return Legacy(Arch.ad.components)\n  }\n}\n\n\/\/ the purpose of this extension is to allow users to provide custom schedules\n\/\/ at the C level after transpiling\n@ext(name = \"ScheduleProvider\") object ScheduleProviderI {\n  def getRoundRobinOrder(): ISZ[Art.BridgeId] = $\n\n  def getStaticSchedule(): DScheduleSpec = $\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/architecture\/bit_codec\/ScheduleProvider.scala",
        {
          "type" : "ITestResource",
          "content" : "package bit_codec\n\nimport org.sireum._\nimport art.Art\nimport art.scheduling.static.Schedule.DScheduleSpec\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\nobject ScheduleProvider {\n\n  def getRoundRobinOrder(): ISZ[Art.BridgeId] = {\n    return Schedulers.roundRobinSchedule\n  }\n\n  def getStaticSchedule(): DScheduleSpec = {\n    return Schedulers.defaultStaticSchedule\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/inspector\/bit_codec\/InspectorDemo.scala",
        {
          "type" : "ITestResource",
          "content" : "package bit_codec\n\nimport art.{ArchitectureDescription, Bridge, DataContent, UPort}\nimport org.reactivestreams.Publisher\nimport org.sireum.hamr.inspector.common.{Filter, Injection, InspectionBlueprint, Msg, Rule}\nimport org.sireum.hamr.inspector.capabilities.InspectorCapabilitiesLauncher\nimport org.sireum.hamr.inspector.gui.InspectorGUILauncher\nimport org.sireum.hamr.inspector.stream.Flux\n\nobject InspectorDemo extends App {\n\n  {\n    InspectorCapabilitiesLauncher.run(Blueprint)\n\n    val filters: Set[Filter] = Set(NoFilter, EvensOnly)\n    val rules: Set[Rule] = Set(Require100OrMore)\n    val injections: Set[Injection] = Set()\n\n    InspectorGUILauncher.run(Blueprint, filters, rules, injections, args)\n  }\n\n  object Blueprint extends InspectionBlueprint {\n    override def ad(): ArchitectureDescription = Arch.ad\n    override def serializer(): DataContent => String = JSON.from_artDataContent(_, true).value\n    override def deserializer(): String => DataContent = JSON.to_artDataContent(_).left\n  }\n\n  object NoFilter extends Filter {\n    override def filter(in: Flux[Msg]): Publisher[Msg] = in\n  }\n\n  object EvensOnly extends Filter {\n    override def filter(in: Flux[Msg]): Publisher[Msg] = in.filter(_.sequence % 2 == 0)\n  }\n\n  object Require100OrMore extends Rule {\n    override def rule(in: Flux[Msg]): Publisher[_] = in.skip(99).next().single()\n  }\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/test\/util\/bit_codec\/Bit_Codec\/Producer_proc_producer_TestApi.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage bit_codec.Bit_Codec\n\nimport org.sireum._\nimport art.Art\nimport bit_codec._\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n@msig trait Producer_proc_producer_TestApi {\n\n  def BeforeEntrypoint(): Unit = {\n    Art.initTest(Arch.Bit_Codec_Sys_Impl_Instance_proc_producer)\n  }\n\n  def AfterEntrypoint(): Unit = {\n    Art.finalizeTest(Arch.Bit_Codec_Sys_Impl_Instance_proc_producer)\n  }\n\n  def testCompute(): Unit = {\n    Art.manuallyClearOutput()\n    Art.testCompute(Arch.Bit_Codec_Sys_Impl_Instance_proc_producer)\n  }\n\n  def testInitialise(): Unit = {\n    Art.manuallyClearOutput()\n    Art.testInitialise(Arch.Bit_Codec_Sys_Impl_Instance_proc_producer)\n  }\n\n  \/** helper function to check Producer_proc_producer's\n   * output ports.  Use named arguments to check subsets of the output ports.\n   * @param to_filter_u32 method that will be called with the value of the outgoing data\n   *        port 'to_filter_u32'.\n   * @param to_filter_latitude method that will be called with the value of the outgoing data\n   *        port 'to_filter_latitude'.\n   * @param to_filter_longitude method that will be called with the value of the outgoing data\n   *        port 'to_filter_longitude'.\n   * @param to_filter_coordinate method that will be called with the value of the outgoing data\n   *        port 'to_filter_coordinate'.\n   * @param to_filter_mission method that will be called with the payloads to be sent\n   *        on the outgoing event data port 'to_filter_mission'.\n   * @param to_filter_event method that will be called with the number of events to be sent\n   *        on the outgoing event port 'to_filter_event'.\n   *\/\n  def check_concrete_output(to_filter_u32: Base_Types.Bits => B,\n                            to_filter_latitude: Base_Types.Bits => B,\n                            to_filter_longitude: Base_Types.Bits => B,\n                            to_filter_coordinate: Base_Types.Bits => B,\n                            to_filter_mission: ISZ[Base_Types.Bits] => B,\n                            to_filter_event: Z => B): Unit = {\n    var testFailures: ISZ[ST] = ISZ()\n\n    val to_filter_u32Value: Base_Types.Bits = get_to_filter_u32().get\n    if(!to_filter_u32(to_filter_u32Value)) {\n      testFailures = testFailures :+ st\"'to_filter_u32' did not match expected: value of the outgoing data port is ${to_filter_u32Value}\"\n    }\n    val to_filter_latitudeValue: Base_Types.Bits = get_to_filter_latitude().get\n    if(!to_filter_latitude(to_filter_latitudeValue)) {\n      testFailures = testFailures :+ st\"'to_filter_latitude' did not match expected: value of the outgoing data port is ${to_filter_latitudeValue}\"\n    }\n    val to_filter_longitudeValue: Base_Types.Bits = get_to_filter_longitude().get\n    if(!to_filter_longitude(to_filter_longitudeValue)) {\n      testFailures = testFailures :+ st\"'to_filter_longitude' did not match expected: value of the outgoing data port is ${to_filter_longitudeValue}\"\n    }\n    val to_filter_coordinateValue: Base_Types.Bits = get_to_filter_coordinate().get\n    if(!to_filter_coordinate(to_filter_coordinateValue)) {\n      testFailures = testFailures :+ st\"'to_filter_coordinate' did not match expected: value of the outgoing data port is ${to_filter_coordinateValue}\"\n    }\n    var to_filter_missionValue: ISZ[Base_Types.Bits] = ISZ()\n    \/\/ TODO: event data port getter should return all of the events\/payloads\n    \/\/       received on event data ports when queue sizes > 1 support is added\n    \/\/       to ART\n    if(get_to_filter_mission().nonEmpty) { to_filter_missionValue = to_filter_missionValue :+ get_to_filter_mission().get }\n    if(!to_filter_mission(to_filter_missionValue)) {\n      testFailures = testFailures :+ st\"'to_filter_mission' did not match expected: received ${to_filter_missionValue.size} events with the following payloads ${to_filter_missionValue}\"\n    }\n    \/\/ TODO: event port getter should return the number of events in\n    \/\/       the output queue when queue sizes > 1 support is added to ART\n    val to_filter_eventValue: Z = if(get_to_filter_event().nonEmpty) z\"1\" else z\"0\"\n    if(!to_filter_event(to_filter_eventValue)) {\n      testFailures = testFailures :+ st\"'to_filter_event' did not match expected: ${to_filter_eventValue} events were in the outgoing event queue\"\n    }\n\n    assert(testFailures.isEmpty, st\"${(testFailures, \"\\n\")}\".render)\n  }\n\n\n  \/\/ getter for out DataPort\n  def get_to_filter_u32(): Option[Base_Types.Bits] = {\n    val value: Option[Base_Types.Bits] = get_to_filter_u32_payload() match {\n      case Some(Base_Types.Bits_Payload(v)) => Some(v)\n      case Some(v) => halt(s\"Unexpected payload on port to_filter_u32.  Expecting 'Base_Types.Bits_Payload' but received ${v}\")\n      case _ => None[Base_Types.Bits]()\n    }\n    return value\n  }\n\n  \/\/ payload getter for out DataPort\n  def get_to_filter_u32_payload(): Option[Base_Types.Bits_Payload] = {\n    return Art.observeOutInfrastructurePort(Arch.Bit_Codec_Sys_Impl_Instance_proc_producer.initialization_api.to_filter_u32_Id).asInstanceOf[Option[Base_Types.Bits_Payload]]\n  }\n\n  \/\/ getter for out DataPort\n  def get_to_filter_latitude(): Option[Base_Types.Bits] = {\n    val value: Option[Base_Types.Bits] = get_to_filter_latitude_payload() match {\n      case Some(Base_Types.Bits_Payload(v)) => Some(v)\n      case Some(v) => halt(s\"Unexpected payload on port to_filter_latitude.  Expecting 'Base_Types.Bits_Payload' but received ${v}\")\n      case _ => None[Base_Types.Bits]()\n    }\n    return value\n  }\n\n  \/\/ payload getter for out DataPort\n  def get_to_filter_latitude_payload(): Option[Base_Types.Bits_Payload] = {\n    return Art.observeOutInfrastructurePort(Arch.Bit_Codec_Sys_Impl_Instance_proc_producer.initialization_api.to_filter_latitude_Id).asInstanceOf[Option[Base_Types.Bits_Payload]]\n  }\n\n  \/\/ getter for out DataPort\n  def get_to_filter_longitude(): Option[Base_Types.Bits] = {\n    val value: Option[Base_Types.Bits] = get_to_filter_longitude_payload() match {\n      case Some(Base_Types.Bits_Payload(v)) => Some(v)\n      case Some(v) => halt(s\"Unexpected payload on port to_filter_longitude.  Expecting 'Base_Types.Bits_Payload' but received ${v}\")\n      case _ => None[Base_Types.Bits]()\n    }\n    return value\n  }\n\n  \/\/ payload getter for out DataPort\n  def get_to_filter_longitude_payload(): Option[Base_Types.Bits_Payload] = {\n    return Art.observeOutInfrastructurePort(Arch.Bit_Codec_Sys_Impl_Instance_proc_producer.initialization_api.to_filter_longitude_Id).asInstanceOf[Option[Base_Types.Bits_Payload]]\n  }\n\n  \/\/ getter for out DataPort\n  def get_to_filter_coordinate(): Option[Base_Types.Bits] = {\n    val value: Option[Base_Types.Bits] = get_to_filter_coordinate_payload() match {\n      case Some(Base_Types.Bits_Payload(v)) => Some(v)\n      case Some(v) => halt(s\"Unexpected payload on port to_filter_coordinate.  Expecting 'Base_Types.Bits_Payload' but received ${v}\")\n      case _ => None[Base_Types.Bits]()\n    }\n    return value\n  }\n\n  \/\/ payload getter for out DataPort\n  def get_to_filter_coordinate_payload(): Option[Base_Types.Bits_Payload] = {\n    return Art.observeOutInfrastructurePort(Arch.Bit_Codec_Sys_Impl_Instance_proc_producer.initialization_api.to_filter_coordinate_Id).asInstanceOf[Option[Base_Types.Bits_Payload]]\n  }\n\n  \/\/ getter for out EventDataPort\n  def get_to_filter_mission(): Option[Base_Types.Bits] = {\n    val value: Option[Base_Types.Bits] = get_to_filter_mission_payload() match {\n      case Some(Base_Types.Bits_Payload(v)) => Some(v)\n      case Some(v) => halt(s\"Unexpected payload on port to_filter_mission.  Expecting 'Base_Types.Bits_Payload' but received ${v}\")\n      case _ => None[Base_Types.Bits]()\n    }\n    return value\n  }\n\n  \/\/ payload getter for out EventDataPort\n  def get_to_filter_mission_payload(): Option[Base_Types.Bits_Payload] = {\n    return Art.observeOutInfrastructurePort(Arch.Bit_Codec_Sys_Impl_Instance_proc_producer.initialization_api.to_filter_mission_Id).asInstanceOf[Option[Base_Types.Bits_Payload]]\n  }\n\n  \/\/ getter for out EventPort\n  def get_to_filter_event(): Option[art.Empty] = {\n    val value: Option[art.Empty] = get_to_filter_event_payload() match {\n      case Some(art.Empty()) => Some(art.Empty())\n      case Some(v) => halt(s\"Unexpected payload on port to_filter_event.  Expecting 'art.Empty' but received ${v}\")\n      case _ => None[art.Empty]()\n    }\n    return value\n  }\n\n  \/\/ payload getter for out EventPort\n  def get_to_filter_event_payload(): Option[art.Empty] = {\n    return Art.observeOutInfrastructurePort(Arch.Bit_Codec_Sys_Impl_Instance_proc_producer.initialization_api.to_filter_event_Id).asInstanceOf[Option[art.Empty]]\n  }\n\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/test\/util\/bit_codec\/Bit_Codec\/Producer_proc_producer_ScalaTest.scala",
        {
          "type" : "ITestResource",
          "content" : "package bit_codec.Bit_Codec\n\nimport org.scalatest.{BeforeAndAfterEach, OneInstancePerTest}\nimport org.scalatest.funsuite.AnyFunSuite\nimport org.sireum.$internal.MutableMarker\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\nabstract class Producer_proc_producer_ScalaTest extends\n  AnyFunSuite with OneInstancePerTest with BeforeAndAfterEach with\n  Producer_proc_producer_TestApi {\n\n  var clonable: Boolean = true\n  var owned: Boolean = false\n\n  override def string: org.sireum.String = {\n    this.toString()\n  }\n\n  override def $clonable: Boolean = {\n    return clonable\n  }\n\n  override def $clonable_=(b: Boolean): MutableMarker = {\n    clonable = b\n    return this\n  }\n\n  override def $owned: Boolean = {\n    return owned\n  }\n\n  override def $owned_=(b: Boolean): MutableMarker = {\n    owned = b\n    return this\n  }\n\n  override def $clone: MutableMarker = {\n    \/\/ not expecting users to want to clone realizations of this abstract class\n    return this\n  }\n\n  override def beforeEach(): Unit = {\n    BeforeEntrypoint()\n  }\n\n  override def afterEach(): Unit = {\n    AfterEntrypoint()\n  }\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/test\/bridge\/bit_codec\/Bit_Codec\/Producer_proc_producer_Test.scala",
        {
          "type" : "ITestResource",
          "content" : "package bit_codec.Bit_Codec\n\nimport org.sireum._\nimport bit_codec.Bit_Codec._\n\n\/\/ This file will not be overwritten so is safe to edit\nclass Producer_proc_producer_Test extends Producer_proc_producer_ScalaTest {\n\n  test(\"Example Unit Test for Initialise Entry Point\"){\n    \/\/ Initialise Entry Point doesn't read input port values, so just proceed with\n    \/\/ launching the entry point code\n    testInitialise()\n    \/\/ use get_XXX methods and check_concrete_output() from test\/util\/..\/YYY_TestApi\n    \/\/ retrieve values from output ports and check against expected results\n  }\n\n  test(\"Example Unit Test for Compute Entry Point\"){\n    \/\/ use put_XXX methods from test\/util\/..\/YYY_TestApi to seed input ports with values\n    testCompute()\n    \/\/ use get_XXX methods and check_concrete_output() from test\/util\/..\/YYY_TestApi\n    \/\/ retrieve values from output ports and check against expected results\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/bridge\/bit_codec\/Bit_Codec\/Producer_proc_producer_Bridge.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage bit_codec.Bit_Codec\n\nimport org.sireum._\nimport art._\nimport bit_codec._\nimport bit_codec.Bit_Codec.{Producer_proc_producer => component}\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\n@datatype class Producer_proc_producer_Bridge(\n  val id: Art.BridgeId,\n  val name: String,\n  val dispatchProtocol: DispatchPropertyProtocol,\n  val dispatchTriggers: Option[ISZ[Art.PortId]],\n\n  to_filter_u32: Port[Base_Types.Bits],\n  to_filter_latitude: Port[Base_Types.Bits],\n  to_filter_longitude: Port[Base_Types.Bits],\n  to_filter_coordinate: Port[Base_Types.Bits],\n  to_filter_mission: Port[Base_Types.Bits],\n  to_filter_event: Port[art.Empty]\n  ) extends Bridge {\n\n  val ports : Bridge.Ports = Bridge.Ports(\n    dataIns = ISZ[art.UPort](),\n\n    dataOuts = ISZ[art.UPort](to_filter_u32,\n                              to_filter_latitude,\n                              to_filter_longitude,\n                              to_filter_coordinate),\n\n    eventIns = ISZ[art.UPort](),\n\n    eventOuts = ISZ[art.UPort](to_filter_mission,\n                               to_filter_event)\n  )\n\n  val initialization_api : Producer_Initialization_Api = {\n    val api = Producer_Initialization_Api(\n      id,\n      to_filter_u32.id,\n      to_filter_latitude.id,\n      to_filter_longitude.id,\n      to_filter_coordinate.id,\n      to_filter_mission.id,\n      to_filter_event.id\n    )\n    Producer_proc_producer_Bridge.c_initialization_api = Some(api)\n    api\n  }\n\n  val operational_api : Producer_Operational_Api = {\n    val api = Producer_Operational_Api(\n      id,\n      to_filter_u32.id,\n      to_filter_latitude.id,\n      to_filter_longitude.id,\n      to_filter_coordinate.id,\n      to_filter_mission.id,\n      to_filter_event.id\n    )\n    Producer_proc_producer_Bridge.c_operational_api = Some(api)\n    api\n  }\n\n  val entryPoints : Bridge.EntryPoints =\n    Producer_proc_producer_Bridge.EntryPoints(\n      id,\n\n      to_filter_u32.id,\n      to_filter_latitude.id,\n      to_filter_longitude.id,\n      to_filter_coordinate.id,\n      to_filter_mission.id,\n      to_filter_event.id,\n\n      dispatchTriggers,\n\n      initialization_api,\n      operational_api)\n}\n\nobject Producer_proc_producer_Bridge {\n\n  var c_initialization_api: Option[Producer_Initialization_Api] = None()\n  var c_operational_api: Option[Producer_Operational_Api] = None()\n\n  @datatype class EntryPoints(\n    Producer_proc_producer_BridgeId : Art.BridgeId,\n    to_filter_u32_Id : Art.PortId,\n    to_filter_latitude_Id : Art.PortId,\n    to_filter_longitude_Id : Art.PortId,\n    to_filter_coordinate_Id : Art.PortId,\n    to_filter_mission_Id : Art.PortId,\n    to_filter_event_Id : Art.PortId,\n    dispatchTriggers : Option[ISZ[Art.PortId]],\n    initialization_api: Producer_Initialization_Api,\n    operational_api: Producer_Operational_Api) extends Bridge.EntryPoints {\n\n    val dataInPortIds: ISZ[Art.PortId] = IS()\n\n    val eventInPortIds: ISZ[Art.PortId] = IS()\n\n    val dataOutPortIds: ISZ[Art.PortId] = IS(to_filter_u32_Id,\n                                             to_filter_latitude_Id,\n                                             to_filter_longitude_Id,\n                                             to_filter_coordinate_Id)\n\n    val eventOutPortIds: ISZ[Art.PortId] = IS(to_filter_mission_Id,\n                                              to_filter_event_Id)\n\n    def initialise(): Unit = {\n      \/\/ implement the following method in 'component':  def initialise(api: Producer_Initialization_Api): Unit = {}\n      component.initialise(initialization_api)\n      Art.sendOutput(eventOutPortIds, dataOutPortIds)\n    }\n\n    def compute(): Unit = {\n      Art.receiveInput(eventInPortIds, dataInPortIds)\n\n      \/\/ implement the following in 'component':  def timeTriggered(api: Producer_Operational_Api): Unit = {}\n      component.timeTriggered(operational_api)\n\n      Art.sendOutput(eventOutPortIds, dataOutPortIds)\n    }\n\n    def finalise(): Unit = {\n      \/\/ implement the following method in 'component':  def finalise(api: Producer_Operational_Api): Unit = {}\n      component.finalise(operational_api)\n    }\n\n    override\n    def testInitialise(): Unit = {\n      \/\/ implement the following method in 'component':  def initialise(api: Producer_Initialization_Api): Unit = {}\n      component.initialise(initialization_api)\n      Art.releaseOutput(eventOutPortIds, dataOutPortIds)\n    }\n\n    override\n    def testCompute(): Unit = {\n      Art.receiveInput(eventInPortIds, dataInPortIds)\n\n      \/\/ implement the following in 'component':  def timeTriggered(api: Producer_Operational_Api): Unit = {}\n      component.timeTriggered(operational_api)\n\n      Art.releaseOutput(eventOutPortIds, dataOutPortIds)\n    }\n  }\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/bridge\/bit_codec\/Bit_Codec\/Producer_Api.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage bit_codec.Bit_Codec\n\nimport org.sireum._\nimport art._\nimport bit_codec._\n\n@sig trait Producer_Api {\n  def id: Art.BridgeId\n  def to_filter_u32_Id : Art.PortId\n  def to_filter_latitude_Id : Art.PortId\n  def to_filter_longitude_Id : Art.PortId\n  def to_filter_coordinate_Id : Art.PortId\n  def to_filter_mission_Id : Art.PortId\n  def to_filter_event_Id : Art.PortId\n\n  \/\/ Logika spec var representing port state for outgoing data port\n  @spec var to_filter_u32: Base_Types.Bits = $\n\n  def put_to_filter_u32(value : Base_Types.Bits) : Unit = {\n    Contract(\n      Modifies(to_filter_u32),\n      Ensures(\n        to_filter_u32 == value\n      )\n    )\n    Spec {\n      to_filter_u32 = value\n    }\n\n    Art.putValue(to_filter_u32_Id, Base_Types.Bits_Payload(value))\n  }\n\n  \/\/ Logika spec var representing port state for outgoing data port\n  @spec var to_filter_latitude: Base_Types.Bits = $\n\n  def put_to_filter_latitude(value : Base_Types.Bits) : Unit = {\n    Contract(\n      Modifies(to_filter_latitude),\n      Ensures(\n        to_filter_latitude == value\n      )\n    )\n    Spec {\n      to_filter_latitude = value\n    }\n\n    Art.putValue(to_filter_latitude_Id, Base_Types.Bits_Payload(value))\n  }\n\n  \/\/ Logika spec var representing port state for outgoing data port\n  @spec var to_filter_longitude: Base_Types.Bits = $\n\n  def put_to_filter_longitude(value : Base_Types.Bits) : Unit = {\n    Contract(\n      Modifies(to_filter_longitude),\n      Ensures(\n        to_filter_longitude == value\n      )\n    )\n    Spec {\n      to_filter_longitude = value\n    }\n\n    Art.putValue(to_filter_longitude_Id, Base_Types.Bits_Payload(value))\n  }\n\n  \/\/ Logika spec var representing port state for outgoing data port\n  @spec var to_filter_coordinate: Base_Types.Bits = $\n\n  def put_to_filter_coordinate(value : Base_Types.Bits) : Unit = {\n    Contract(\n      Modifies(to_filter_coordinate),\n      Ensures(\n        to_filter_coordinate == value\n      )\n    )\n    Spec {\n      to_filter_coordinate = value\n    }\n\n    Art.putValue(to_filter_coordinate_Id, Base_Types.Bits_Payload(value))\n  }\n\n  \/\/ Logika spec var representing port state for outgoing event data port\n  @spec var to_filter_mission: Option[Base_Types.Bits] = $\n\n  def put_to_filter_mission(value : Base_Types.Bits) : Unit = {\n    Contract(\n      Modifies(to_filter_mission),\n      Ensures(\n        to_filter_mission == Some(value)\n      )\n    )\n    Spec {\n      to_filter_mission = Some(value)\n    }\n\n    Art.putValue(to_filter_mission_Id, Base_Types.Bits_Payload(value))\n  }\n\n  \/\/ Logika spec var representing port state for outgoing event port\n  @spec var to_filter_event: Option[art.Empty] = $\n\n  def put_to_filter_event() : Unit = {\n    Contract(\n      Modifies(to_filter_event),\n      Ensures(\n        to_filter_event == Some(Empty())\n      )\n    )\n    Spec {\n      to_filter_event = Some(Empty())\n    }\n\n    Art.putValue(to_filter_event_Id, art.Empty())\n  }\n\n  def logInfo(msg: String): Unit = {\n    Art.logInfo(id, msg)\n  }\n\n  def logDebug(msg: String): Unit = {\n    Art.logDebug(id, msg)\n  }\n\n  def logError(msg: String): Unit = {\n    Art.logError(id, msg)\n  }\n}\n\n@datatype class Producer_Initialization_Api (\n  val id: Art.BridgeId,\n  val to_filter_u32_Id : Art.PortId,\n  val to_filter_latitude_Id : Art.PortId,\n  val to_filter_longitude_Id : Art.PortId,\n  val to_filter_coordinate_Id : Art.PortId,\n  val to_filter_mission_Id : Art.PortId,\n  val to_filter_event_Id : Art.PortId) extends Producer_Api\n\n@datatype class Producer_Operational_Api (\n  val id: Art.BridgeId,\n  val to_filter_u32_Id : Art.PortId,\n  val to_filter_latitude_Id : Art.PortId,\n  val to_filter_longitude_Id : Art.PortId,\n  val to_filter_coordinate_Id : Art.PortId,\n  val to_filter_mission_Id : Art.PortId,\n  val to_filter_event_Id : Art.PortId) extends Producer_Api {\n\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/component\/bit_codec\/Bit_Codec\/Producer_proc_producer.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage bit_codec.Bit_Codec\n\nimport org.sireum._\nimport bit_codec._\n\n\/\/ This file will not be overwritten so is safe to edit\nobject Producer_proc_producer {\n\n  def initialise(api: Producer_Initialization_Api): Unit = { }\n\n  def timeTriggered(api: Producer_Operational_Api): Unit = { }\n\n  def finalise(api: Producer_Operational_Api): Unit = { }\n}\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/test\/util\/bit_codec\/Bit_Codec\/Filter_proc_filter_TestApi.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage bit_codec.Bit_Codec\n\nimport org.sireum._\nimport art.Art\nimport bit_codec._\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n@msig trait Filter_proc_filter_TestApi {\n\n  def BeforeEntrypoint(): Unit = {\n    Art.initTest(Arch.Bit_Codec_Sys_Impl_Instance_proc_filter)\n  }\n\n  def AfterEntrypoint(): Unit = {\n    Art.finalizeTest(Arch.Bit_Codec_Sys_Impl_Instance_proc_filter)\n  }\n\n  def testCompute(): Unit = {\n    Art.manuallyClearOutput()\n    Art.testCompute(Arch.Bit_Codec_Sys_Impl_Instance_proc_filter)\n  }\n\n  def testInitialise(): Unit = {\n    Art.manuallyClearOutput()\n    Art.testInitialise(Arch.Bit_Codec_Sys_Impl_Instance_proc_filter)\n  }\n\n  \/** helper function to set the values of all input ports.\n   * @param from_producer_u32 payload for data port from_producer_u32\n   * @param from_producer_latitude payload for data port from_producer_latitude\n   * @param from_producer_longitude payload for data port from_producer_longitude\n   * @param from_producer_coordinate payload for data port from_producer_coordinate\n   * @param from_producer_mission payloads for event data port from_producer_mission.\n   *   ART currently supports single element event data queues so\n   *   only the last element of from_producer_mission will be used\n   * @param from_producer_event the number of events to place in the from_producer_event event port queue.\n   *   ART currently supports single element event queues so at most\n   *   one event will be placed in the queue.\n   *\/\n  def put_concrete_inputs(from_producer_u32 : Base_Types.Bits,\n                          from_producer_latitude : Base_Types.Bits,\n                          from_producer_longitude : Base_Types.Bits,\n                          from_producer_coordinate : Base_Types.Bits,\n                          from_producer_mission : ISZ[Base_Types.Bits],\n                          from_producer_event : Z): Unit = {\n    put_from_producer_u32(from_producer_u32)\n    put_from_producer_latitude(from_producer_latitude)\n    put_from_producer_longitude(from_producer_longitude)\n    put_from_producer_coordinate(from_producer_coordinate)\n    for(v <- from_producer_mission){\n      put_from_producer_mission(v)\n    }\n    for(i <- 0 until from_producer_event) {\n      put_from_producer_event()\n    }\n  }\n\n\n  \/** helper function to check Filter_proc_filter's\n   * output ports.  Use named arguments to check subsets of the output ports.\n   * @param to_consumer_u32 method that will be called with the value of the outgoing data\n   *        port 'to_consumer_u32'.\n   * @param to_consumer_latitude method that will be called with the value of the outgoing data\n   *        port 'to_consumer_latitude'.\n   * @param to_consumer_longitude method that will be called with the value of the outgoing data\n   *        port 'to_consumer_longitude'.\n   * @param to_consumer_coordinate method that will be called with the value of the outgoing data\n   *        port 'to_consumer_coordinate'.\n   * @param to_consumer_mission method that will be called with the payloads to be sent\n   *        on the outgoing event data port 'to_consumer_mission'.\n   * @param to_consumer_event method that will be called with the number of events to be sent\n   *        on the outgoing event port 'to_consumer_event'.\n   *\/\n  def check_concrete_output(to_consumer_u32: Base_Types.Bits => B,\n                            to_consumer_latitude: Base_Types.Bits => B,\n                            to_consumer_longitude: Base_Types.Bits => B,\n                            to_consumer_coordinate: Base_Types.Bits => B,\n                            to_consumer_mission: ISZ[Base_Types.Bits] => B,\n                            to_consumer_event: Z => B): Unit = {\n    var testFailures: ISZ[ST] = ISZ()\n\n    val to_consumer_u32Value: Base_Types.Bits = get_to_consumer_u32().get\n    if(!to_consumer_u32(to_consumer_u32Value)) {\n      testFailures = testFailures :+ st\"'to_consumer_u32' did not match expected: value of the outgoing data port is ${to_consumer_u32Value}\"\n    }\n    val to_consumer_latitudeValue: Base_Types.Bits = get_to_consumer_latitude().get\n    if(!to_consumer_latitude(to_consumer_latitudeValue)) {\n      testFailures = testFailures :+ st\"'to_consumer_latitude' did not match expected: value of the outgoing data port is ${to_consumer_latitudeValue}\"\n    }\n    val to_consumer_longitudeValue: Base_Types.Bits = get_to_consumer_longitude().get\n    if(!to_consumer_longitude(to_consumer_longitudeValue)) {\n      testFailures = testFailures :+ st\"'to_consumer_longitude' did not match expected: value of the outgoing data port is ${to_consumer_longitudeValue}\"\n    }\n    val to_consumer_coordinateValue: Base_Types.Bits = get_to_consumer_coordinate().get\n    if(!to_consumer_coordinate(to_consumer_coordinateValue)) {\n      testFailures = testFailures :+ st\"'to_consumer_coordinate' did not match expected: value of the outgoing data port is ${to_consumer_coordinateValue}\"\n    }\n    var to_consumer_missionValue: ISZ[Base_Types.Bits] = ISZ()\n    \/\/ TODO: event data port getter should return all of the events\/payloads\n    \/\/       received on event data ports when queue sizes > 1 support is added\n    \/\/       to ART\n    if(get_to_consumer_mission().nonEmpty) { to_consumer_missionValue = to_consumer_missionValue :+ get_to_consumer_mission().get }\n    if(!to_consumer_mission(to_consumer_missionValue)) {\n      testFailures = testFailures :+ st\"'to_consumer_mission' did not match expected: received ${to_consumer_missionValue.size} events with the following payloads ${to_consumer_missionValue}\"\n    }\n    \/\/ TODO: event port getter should return the number of events in\n    \/\/       the output queue when queue sizes > 1 support is added to ART\n    val to_consumer_eventValue: Z = if(get_to_consumer_event().nonEmpty) z\"1\" else z\"0\"\n    if(!to_consumer_event(to_consumer_eventValue)) {\n      testFailures = testFailures :+ st\"'to_consumer_event' did not match expected: ${to_consumer_eventValue} events were in the outgoing event queue\"\n    }\n\n    assert(testFailures.isEmpty, st\"${(testFailures, \"\\n\")}\".render)\n  }\n\n\n  \/\/ setter for in DataPort\n  def put_from_producer_u32(value : Base_Types.Bits): Unit = {\n    Art.insertInInfrastructurePort(Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.operational_api.from_producer_u32_Id, Base_Types.Bits_Payload(value))\n  }\n\n  \/\/ setter for in DataPort\n  def put_from_producer_latitude(value : Base_Types.Bits): Unit = {\n    Art.insertInInfrastructurePort(Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.operational_api.from_producer_latitude_Id, Base_Types.Bits_Payload(value))\n  }\n\n  \/\/ setter for in DataPort\n  def put_from_producer_longitude(value : Base_Types.Bits): Unit = {\n    Art.insertInInfrastructurePort(Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.operational_api.from_producer_longitude_Id, Base_Types.Bits_Payload(value))\n  }\n\n  \/\/ setter for in DataPort\n  def put_from_producer_coordinate(value : Base_Types.Bits): Unit = {\n    Art.insertInInfrastructurePort(Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.operational_api.from_producer_coordinate_Id, Base_Types.Bits_Payload(value))\n  }\n\n  \/\/ setter for in EventDataPort\n  def put_from_producer_mission(value : Base_Types.Bits): Unit = {\n    Art.insertInInfrastructurePort(Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.operational_api.from_producer_mission_Id, Base_Types.Bits_Payload(value))\n  }\n\n  \/\/ setter for in EventPort\n  def put_from_producer_event(): Unit = {\n    Art.insertInInfrastructurePort(Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.operational_api.from_producer_event_Id, art.Empty())\n  }\n\n  \/\/ getter for out DataPort\n  def get_to_consumer_u32(): Option[Base_Types.Bits] = {\n    val value: Option[Base_Types.Bits] = get_to_consumer_u32_payload() match {\n      case Some(Base_Types.Bits_Payload(v)) => Some(v)\n      case Some(v) => halt(s\"Unexpected payload on port to_consumer_u32.  Expecting 'Base_Types.Bits_Payload' but received ${v}\")\n      case _ => None[Base_Types.Bits]()\n    }\n    return value\n  }\n\n  \/\/ payload getter for out DataPort\n  def get_to_consumer_u32_payload(): Option[Base_Types.Bits_Payload] = {\n    return Art.observeOutInfrastructurePort(Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.initialization_api.to_consumer_u32_Id).asInstanceOf[Option[Base_Types.Bits_Payload]]\n  }\n\n  \/\/ getter for out DataPort\n  def get_to_consumer_latitude(): Option[Base_Types.Bits] = {\n    val value: Option[Base_Types.Bits] = get_to_consumer_latitude_payload() match {\n      case Some(Base_Types.Bits_Payload(v)) => Some(v)\n      case Some(v) => halt(s\"Unexpected payload on port to_consumer_latitude.  Expecting 'Base_Types.Bits_Payload' but received ${v}\")\n      case _ => None[Base_Types.Bits]()\n    }\n    return value\n  }\n\n  \/\/ payload getter for out DataPort\n  def get_to_consumer_latitude_payload(): Option[Base_Types.Bits_Payload] = {\n    return Art.observeOutInfrastructurePort(Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.initialization_api.to_consumer_latitude_Id).asInstanceOf[Option[Base_Types.Bits_Payload]]\n  }\n\n  \/\/ getter for out DataPort\n  def get_to_consumer_longitude(): Option[Base_Types.Bits] = {\n    val value: Option[Base_Types.Bits] = get_to_consumer_longitude_payload() match {\n      case Some(Base_Types.Bits_Payload(v)) => Some(v)\n      case Some(v) => halt(s\"Unexpected payload on port to_consumer_longitude.  Expecting 'Base_Types.Bits_Payload' but received ${v}\")\n      case _ => None[Base_Types.Bits]()\n    }\n    return value\n  }\n\n  \/\/ payload getter for out DataPort\n  def get_to_consumer_longitude_payload(): Option[Base_Types.Bits_Payload] = {\n    return Art.observeOutInfrastructurePort(Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.initialization_api.to_consumer_longitude_Id).asInstanceOf[Option[Base_Types.Bits_Payload]]\n  }\n\n  \/\/ getter for out DataPort\n  def get_to_consumer_coordinate(): Option[Base_Types.Bits] = {\n    val value: Option[Base_Types.Bits] = get_to_consumer_coordinate_payload() match {\n      case Some(Base_Types.Bits_Payload(v)) => Some(v)\n      case Some(v) => halt(s\"Unexpected payload on port to_consumer_coordinate.  Expecting 'Base_Types.Bits_Payload' but received ${v}\")\n      case _ => None[Base_Types.Bits]()\n    }\n    return value\n  }\n\n  \/\/ payload getter for out DataPort\n  def get_to_consumer_coordinate_payload(): Option[Base_Types.Bits_Payload] = {\n    return Art.observeOutInfrastructurePort(Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.initialization_api.to_consumer_coordinate_Id).asInstanceOf[Option[Base_Types.Bits_Payload]]\n  }\n\n  \/\/ getter for out EventDataPort\n  def get_to_consumer_mission(): Option[Base_Types.Bits] = {\n    val value: Option[Base_Types.Bits] = get_to_consumer_mission_payload() match {\n      case Some(Base_Types.Bits_Payload(v)) => Some(v)\n      case Some(v) => halt(s\"Unexpected payload on port to_consumer_mission.  Expecting 'Base_Types.Bits_Payload' but received ${v}\")\n      case _ => None[Base_Types.Bits]()\n    }\n    return value\n  }\n\n  \/\/ payload getter for out EventDataPort\n  def get_to_consumer_mission_payload(): Option[Base_Types.Bits_Payload] = {\n    return Art.observeOutInfrastructurePort(Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.initialization_api.to_consumer_mission_Id).asInstanceOf[Option[Base_Types.Bits_Payload]]\n  }\n\n  \/\/ getter for out EventPort\n  def get_to_consumer_event(): Option[art.Empty] = {\n    val value: Option[art.Empty] = get_to_consumer_event_payload() match {\n      case Some(art.Empty()) => Some(art.Empty())\n      case Some(v) => halt(s\"Unexpected payload on port to_consumer_event.  Expecting 'art.Empty' but received ${v}\")\n      case _ => None[art.Empty]()\n    }\n    return value\n  }\n\n  \/\/ payload getter for out EventPort\n  def get_to_consumer_event_payload(): Option[art.Empty] = {\n    return Art.observeOutInfrastructurePort(Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.initialization_api.to_consumer_event_Id).asInstanceOf[Option[art.Empty]]\n  }\n\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/test\/util\/bit_codec\/Bit_Codec\/Filter_proc_filter_ScalaTest.scala",
        {
          "type" : "ITestResource",
          "content" : "package bit_codec.Bit_Codec\n\nimport org.scalatest.{BeforeAndAfterEach, OneInstancePerTest}\nimport org.scalatest.funsuite.AnyFunSuite\nimport org.sireum.$internal.MutableMarker\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\nabstract class Filter_proc_filter_ScalaTest extends\n  AnyFunSuite with OneInstancePerTest with BeforeAndAfterEach with\n  Filter_proc_filter_TestApi {\n\n  var clonable: Boolean = true\n  var owned: Boolean = false\n\n  override def string: org.sireum.String = {\n    this.toString()\n  }\n\n  override def $clonable: Boolean = {\n    return clonable\n  }\n\n  override def $clonable_=(b: Boolean): MutableMarker = {\n    clonable = b\n    return this\n  }\n\n  override def $owned: Boolean = {\n    return owned\n  }\n\n  override def $owned_=(b: Boolean): MutableMarker = {\n    owned = b\n    return this\n  }\n\n  override def $clone: MutableMarker = {\n    \/\/ not expecting users to want to clone realizations of this abstract class\n    return this\n  }\n\n  override def beforeEach(): Unit = {\n    BeforeEntrypoint()\n  }\n\n  override def afterEach(): Unit = {\n    AfterEntrypoint()\n  }\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/test\/bridge\/bit_codec\/Bit_Codec\/Filter_proc_filter_Test.scala",
        {
          "type" : "ITestResource",
          "content" : "package bit_codec.Bit_Codec\n\nimport org.sireum._\nimport bit_codec.Bit_Codec._\n\n\/\/ This file will not be overwritten so is safe to edit\nclass Filter_proc_filter_Test extends Filter_proc_filter_ScalaTest {\n\n  test(\"Example Unit Test for Initialise Entry Point\"){\n    \/\/ Initialise Entry Point doesn't read input port values, so just proceed with\n    \/\/ launching the entry point code\n    testInitialise()\n    \/\/ use get_XXX methods and check_concrete_output() from test\/util\/..\/YYY_TestApi\n    \/\/ retrieve values from output ports and check against expected results\n  }\n\n  test(\"Example Unit Test for Compute Entry Point\"){\n    \/\/ use put_XXX methods from test\/util\/..\/YYY_TestApi to seed input ports with values\n    testCompute()\n    \/\/ use get_XXX methods and check_concrete_output() from test\/util\/..\/YYY_TestApi\n    \/\/ retrieve values from output ports and check against expected results\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/bridge\/bit_codec\/Bit_Codec\/Filter_proc_filter_Bridge.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage bit_codec.Bit_Codec\n\nimport org.sireum._\nimport art._\nimport bit_codec._\nimport bit_codec.Bit_Codec.{Filter_proc_filter => component}\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\n@datatype class Filter_proc_filter_Bridge(\n  val id: Art.BridgeId,\n  val name: String,\n  val dispatchProtocol: DispatchPropertyProtocol,\n  val dispatchTriggers: Option[ISZ[Art.PortId]],\n\n  from_producer_u32: Port[Base_Types.Bits],\n  from_producer_latitude: Port[Base_Types.Bits],\n  from_producer_longitude: Port[Base_Types.Bits],\n  from_producer_coordinate: Port[Base_Types.Bits],\n  to_consumer_u32: Port[Base_Types.Bits],\n  to_consumer_latitude: Port[Base_Types.Bits],\n  to_consumer_longitude: Port[Base_Types.Bits],\n  to_consumer_coordinate: Port[Base_Types.Bits],\n  from_producer_mission: Port[Base_Types.Bits],\n  to_consumer_mission: Port[Base_Types.Bits],\n  from_producer_event: Port[art.Empty],\n  to_consumer_event: Port[art.Empty]\n  ) extends Bridge {\n\n  val ports : Bridge.Ports = Bridge.Ports(\n    dataIns = ISZ[art.UPort](from_producer_u32,\n                             from_producer_latitude,\n                             from_producer_longitude,\n                             from_producer_coordinate),\n\n    dataOuts = ISZ[art.UPort](to_consumer_u32,\n                              to_consumer_latitude,\n                              to_consumer_longitude,\n                              to_consumer_coordinate),\n\n    eventIns = ISZ[art.UPort](from_producer_mission,\n                              from_producer_event),\n\n    eventOuts = ISZ[art.UPort](to_consumer_mission,\n                               to_consumer_event)\n  )\n\n  val initialization_api : Filter_Initialization_Api = {\n    val api = Filter_Initialization_Api(\n      id,\n      from_producer_u32.id,\n      from_producer_latitude.id,\n      from_producer_longitude.id,\n      from_producer_coordinate.id,\n      to_consumer_u32.id,\n      to_consumer_latitude.id,\n      to_consumer_longitude.id,\n      to_consumer_coordinate.id,\n      from_producer_mission.id,\n      to_consumer_mission.id,\n      from_producer_event.id,\n      to_consumer_event.id\n    )\n    Filter_proc_filter_Bridge.c_initialization_api = Some(api)\n    api\n  }\n\n  val operational_api : Filter_Operational_Api = {\n    val api = Filter_Operational_Api(\n      id,\n      from_producer_u32.id,\n      from_producer_latitude.id,\n      from_producer_longitude.id,\n      from_producer_coordinate.id,\n      to_consumer_u32.id,\n      to_consumer_latitude.id,\n      to_consumer_longitude.id,\n      to_consumer_coordinate.id,\n      from_producer_mission.id,\n      to_consumer_mission.id,\n      from_producer_event.id,\n      to_consumer_event.id\n    )\n    Filter_proc_filter_Bridge.c_operational_api = Some(api)\n    api\n  }\n\n  val entryPoints : Bridge.EntryPoints =\n    Filter_proc_filter_Bridge.EntryPoints(\n      id,\n\n      from_producer_u32.id,\n      from_producer_latitude.id,\n      from_producer_longitude.id,\n      from_producer_coordinate.id,\n      to_consumer_u32.id,\n      to_consumer_latitude.id,\n      to_consumer_longitude.id,\n      to_consumer_coordinate.id,\n      from_producer_mission.id,\n      to_consumer_mission.id,\n      from_producer_event.id,\n      to_consumer_event.id,\n\n      dispatchTriggers,\n\n      initialization_api,\n      operational_api)\n}\n\nobject Filter_proc_filter_Bridge {\n\n  var c_initialization_api: Option[Filter_Initialization_Api] = None()\n  var c_operational_api: Option[Filter_Operational_Api] = None()\n\n  @datatype class EntryPoints(\n    Filter_proc_filter_BridgeId : Art.BridgeId,\n    from_producer_u32_Id : Art.PortId,\n    from_producer_latitude_Id : Art.PortId,\n    from_producer_longitude_Id : Art.PortId,\n    from_producer_coordinate_Id : Art.PortId,\n    to_consumer_u32_Id : Art.PortId,\n    to_consumer_latitude_Id : Art.PortId,\n    to_consumer_longitude_Id : Art.PortId,\n    to_consumer_coordinate_Id : Art.PortId,\n    from_producer_mission_Id : Art.PortId,\n    to_consumer_mission_Id : Art.PortId,\n    from_producer_event_Id : Art.PortId,\n    to_consumer_event_Id : Art.PortId,\n    dispatchTriggers : Option[ISZ[Art.PortId]],\n    initialization_api: Filter_Initialization_Api,\n    operational_api: Filter_Operational_Api) extends Bridge.EntryPoints {\n\n    val dataInPortIds: ISZ[Art.PortId] = IS(from_producer_u32_Id,\n                                            from_producer_latitude_Id,\n                                            from_producer_longitude_Id,\n                                            from_producer_coordinate_Id)\n\n    val eventInPortIds: ISZ[Art.PortId] = IS(from_producer_mission_Id,\n                                             from_producer_event_Id)\n\n    val dataOutPortIds: ISZ[Art.PortId] = IS(to_consumer_u32_Id,\n                                             to_consumer_latitude_Id,\n                                             to_consumer_longitude_Id,\n                                             to_consumer_coordinate_Id)\n\n    val eventOutPortIds: ISZ[Art.PortId] = IS(to_consumer_mission_Id,\n                                              to_consumer_event_Id)\n\n    def initialise(): Unit = {\n      \/\/ implement the following method in 'component':  def initialise(api: Filter_Initialization_Api): Unit = {}\n      component.initialise(initialization_api)\n      Art.sendOutput(eventOutPortIds, dataOutPortIds)\n    }\n\n    def compute(): Unit = {\n      \/\/ transpiler friendly filter\n      def filter(receivedEvents: ISZ[Art.PortId], triggers: ISZ[Art.PortId]): ISZ[Art.PortId] = {\n        var r = ISZ[Art.PortId]()\n        val opsTriggers = ops.ISZOps(triggers)\n        for(e <- receivedEvents) {\n          if(opsTriggers.contains(e)) {\n            r = r :+ e\n          }\n        }\n        return r\n      }\n\n      \/\/ fetch received events ordered by highest urgency then earliest arrival-time\n      val EventTriggered(receivedEvents) = Art.dispatchStatus(Filter_proc_filter_BridgeId)\n\n      \/\/ remove non-dispatching event ports\n      val dispatchableEventPorts: ISZ[Art.PortId] =\n        if(dispatchTriggers.isEmpty) receivedEvents\n        else filter(receivedEvents, dispatchTriggers.get)\n\n      Art.receiveInput(eventInPortIds, dataInPortIds)\n\n      for(portId <- dispatchableEventPorts) {\n        if(portId == from_producer_mission_Id){\n          val Some(Base_Types.Bits_Payload(value)) = Art.getValue(from_producer_mission_Id)\n\n          \/\/ implement the following in 'component':  def handle_from_producer_mission(api: Filter_Operational_Api, value: Base_Types.Bits): Unit = {}\n          component.handle_from_producer_mission(operational_api, value)\n        }\n        else if(portId == from_producer_event_Id) {\n          \/\/ implement the following in 'component':  def handle_from_producer_event(api: Filter_Operational_Api): Unit = {}\n          component.handle_from_producer_event(operational_api)\n        }\n      }\n\n      Art.sendOutput(eventOutPortIds, dataOutPortIds)\n    }\n\n    def finalise(): Unit = {\n      \/\/ implement the following method in 'component':  def finalise(api: Filter_Operational_Api): Unit = {}\n      component.finalise(operational_api)\n    }\n\n    override\n    def testInitialise(): Unit = {\n      \/\/ implement the following method in 'component':  def initialise(api: Filter_Initialization_Api): Unit = {}\n      component.initialise(initialization_api)\n      Art.releaseOutput(eventOutPortIds, dataOutPortIds)\n    }\n\n    override\n    def testCompute(): Unit = {\n      \/\/ transpiler friendly filter\n      def filter(receivedEvents: ISZ[Art.PortId], triggers: ISZ[Art.PortId]): ISZ[Art.PortId] = {\n        var r = ISZ[Art.PortId]()\n        val opsTriggers = ops.ISZOps(triggers)\n        for(e <- receivedEvents) {\n          if(opsTriggers.contains(e)) {\n            r = r :+ e\n          }\n        }\n        return r\n      }\n\n      \/\/ fetch received events ordered by highest urgency then earliest arrival-time\n      val EventTriggered(receivedEvents) = Art.dispatchStatus(Filter_proc_filter_BridgeId)\n\n      \/\/ remove non-dispatching event ports\n      val dispatchableEventPorts: ISZ[Art.PortId] =\n        if(dispatchTriggers.isEmpty) receivedEvents\n        else filter(receivedEvents, dispatchTriggers.get)\n\n      Art.receiveInput(eventInPortIds, dataInPortIds)\n\n      for(portId <- dispatchableEventPorts) {\n        if(portId == from_producer_mission_Id){\n          val Some(Base_Types.Bits_Payload(value)) = Art.getValue(from_producer_mission_Id)\n\n          \/\/ implement the following in 'component':  def handle_from_producer_mission(api: Filter_Operational_Api, value: Base_Types.Bits): Unit = {}\n          component.handle_from_producer_mission(operational_api, value)\n        }\n        else if(portId == from_producer_event_Id) {\n          \/\/ implement the following in 'component':  def handle_from_producer_event(api: Filter_Operational_Api): Unit = {}\n          component.handle_from_producer_event(operational_api)\n        }\n      }\n\n      Art.releaseOutput(eventOutPortIds, dataOutPortIds)\n    }\n  }\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/bridge\/bit_codec\/Bit_Codec\/Filter_Api.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage bit_codec.Bit_Codec\n\nimport org.sireum._\nimport art._\nimport bit_codec._\n\n@sig trait Filter_Api {\n  def id: Art.BridgeId\n  def from_producer_u32_Id : Art.PortId\n  def from_producer_latitude_Id : Art.PortId\n  def from_producer_longitude_Id : Art.PortId\n  def from_producer_coordinate_Id : Art.PortId\n  def to_consumer_u32_Id : Art.PortId\n  def to_consumer_latitude_Id : Art.PortId\n  def to_consumer_longitude_Id : Art.PortId\n  def to_consumer_coordinate_Id : Art.PortId\n  def from_producer_mission_Id : Art.PortId\n  def to_consumer_mission_Id : Art.PortId\n  def from_producer_event_Id : Art.PortId\n  def to_consumer_event_Id : Art.PortId\n\n  \/\/ Logika spec var representing port state for outgoing data port\n  @spec var to_consumer_u32: Base_Types.Bits = $\n\n  def put_to_consumer_u32(value : Base_Types.Bits) : Unit = {\n    Contract(\n      Modifies(to_consumer_u32),\n      Ensures(\n        to_consumer_u32 == value\n      )\n    )\n    Spec {\n      to_consumer_u32 = value\n    }\n\n    Art.putValue(to_consumer_u32_Id, Base_Types.Bits_Payload(value))\n  }\n\n  \/\/ Logika spec var representing port state for outgoing data port\n  @spec var to_consumer_latitude: Base_Types.Bits = $\n\n  def put_to_consumer_latitude(value : Base_Types.Bits) : Unit = {\n    Contract(\n      Modifies(to_consumer_latitude),\n      Ensures(\n        to_consumer_latitude == value\n      )\n    )\n    Spec {\n      to_consumer_latitude = value\n    }\n\n    Art.putValue(to_consumer_latitude_Id, Base_Types.Bits_Payload(value))\n  }\n\n  \/\/ Logika spec var representing port state for outgoing data port\n  @spec var to_consumer_longitude: Base_Types.Bits = $\n\n  def put_to_consumer_longitude(value : Base_Types.Bits) : Unit = {\n    Contract(\n      Modifies(to_consumer_longitude),\n      Ensures(\n        to_consumer_longitude == value\n      )\n    )\n    Spec {\n      to_consumer_longitude = value\n    }\n\n    Art.putValue(to_consumer_longitude_Id, Base_Types.Bits_Payload(value))\n  }\n\n  \/\/ Logika spec var representing port state for outgoing data port\n  @spec var to_consumer_coordinate: Base_Types.Bits = $\n\n  def put_to_consumer_coordinate(value : Base_Types.Bits) : Unit = {\n    Contract(\n      Modifies(to_consumer_coordinate),\n      Ensures(\n        to_consumer_coordinate == value\n      )\n    )\n    Spec {\n      to_consumer_coordinate = value\n    }\n\n    Art.putValue(to_consumer_coordinate_Id, Base_Types.Bits_Payload(value))\n  }\n\n  \/\/ Logika spec var representing port state for outgoing event data port\n  @spec var to_consumer_mission: Option[Base_Types.Bits] = $\n\n  def put_to_consumer_mission(value : Base_Types.Bits) : Unit = {\n    Contract(\n      Modifies(to_consumer_mission),\n      Ensures(\n        to_consumer_mission == Some(value)\n      )\n    )\n    Spec {\n      to_consumer_mission = Some(value)\n    }\n\n    Art.putValue(to_consumer_mission_Id, Base_Types.Bits_Payload(value))\n  }\n\n  \/\/ Logika spec var representing port state for outgoing event port\n  @spec var to_consumer_event: Option[art.Empty] = $\n\n  def put_to_consumer_event() : Unit = {\n    Contract(\n      Modifies(to_consumer_event),\n      Ensures(\n        to_consumer_event == Some(Empty())\n      )\n    )\n    Spec {\n      to_consumer_event = Some(Empty())\n    }\n\n    Art.putValue(to_consumer_event_Id, art.Empty())\n  }\n\n  def logInfo(msg: String): Unit = {\n    Art.logInfo(id, msg)\n  }\n\n  def logDebug(msg: String): Unit = {\n    Art.logDebug(id, msg)\n  }\n\n  def logError(msg: String): Unit = {\n    Art.logError(id, msg)\n  }\n}\n\n@datatype class Filter_Initialization_Api (\n  val id: Art.BridgeId,\n  val from_producer_u32_Id : Art.PortId,\n  val from_producer_latitude_Id : Art.PortId,\n  val from_producer_longitude_Id : Art.PortId,\n  val from_producer_coordinate_Id : Art.PortId,\n  val to_consumer_u32_Id : Art.PortId,\n  val to_consumer_latitude_Id : Art.PortId,\n  val to_consumer_longitude_Id : Art.PortId,\n  val to_consumer_coordinate_Id : Art.PortId,\n  val from_producer_mission_Id : Art.PortId,\n  val to_consumer_mission_Id : Art.PortId,\n  val from_producer_event_Id : Art.PortId,\n  val to_consumer_event_Id : Art.PortId) extends Filter_Api\n\n@datatype class Filter_Operational_Api (\n  val id: Art.BridgeId,\n  val from_producer_u32_Id : Art.PortId,\n  val from_producer_latitude_Id : Art.PortId,\n  val from_producer_longitude_Id : Art.PortId,\n  val from_producer_coordinate_Id : Art.PortId,\n  val to_consumer_u32_Id : Art.PortId,\n  val to_consumer_latitude_Id : Art.PortId,\n  val to_consumer_longitude_Id : Art.PortId,\n  val to_consumer_coordinate_Id : Art.PortId,\n  val from_producer_mission_Id : Art.PortId,\n  val to_consumer_mission_Id : Art.PortId,\n  val from_producer_event_Id : Art.PortId,\n  val to_consumer_event_Id : Art.PortId) extends Filter_Api {\n\n  \/\/ Logika spec var representing port state for incoming data port\n  @spec var from_producer_u32: Base_Types.Bits = $\n\n  def get_from_producer_u32() : Option[Base_Types.Bits] = {\n    Contract(\n      Ensures(\n        Res == Some(from_producer_u32)\n      )\n    )\n    val value : Option[Base_Types.Bits] = Art.getValue(from_producer_u32_Id) match {\n      case Some(Base_Types.Bits_Payload(v)) => Some(v)\n      case Some(v) =>\n        Art.logError(id, s\"Unexpected payload on port from_producer_u32.  Expecting 'Base_Types.Bits_Payload' but received ${v}\")\n        None[Base_Types.Bits]()\n      case _ => None[Base_Types.Bits]()\n    }\n    return value\n  }\n\n  \/\/ Logika spec var representing port state for incoming data port\n  @spec var from_producer_latitude: Base_Types.Bits = $\n\n  def get_from_producer_latitude() : Option[Base_Types.Bits] = {\n    Contract(\n      Ensures(\n        Res == Some(from_producer_latitude)\n      )\n    )\n    val value : Option[Base_Types.Bits] = Art.getValue(from_producer_latitude_Id) match {\n      case Some(Base_Types.Bits_Payload(v)) => Some(v)\n      case Some(v) =>\n        Art.logError(id, s\"Unexpected payload on port from_producer_latitude.  Expecting 'Base_Types.Bits_Payload' but received ${v}\")\n        None[Base_Types.Bits]()\n      case _ => None[Base_Types.Bits]()\n    }\n    return value\n  }\n\n  \/\/ Logika spec var representing port state for incoming data port\n  @spec var from_producer_longitude: Base_Types.Bits = $\n\n  def get_from_producer_longitude() : Option[Base_Types.Bits] = {\n    Contract(\n      Ensures(\n        Res == Some(from_producer_longitude)\n      )\n    )\n    val value : Option[Base_Types.Bits] = Art.getValue(from_producer_longitude_Id) match {\n      case Some(Base_Types.Bits_Payload(v)) => Some(v)\n      case Some(v) =>\n        Art.logError(id, s\"Unexpected payload on port from_producer_longitude.  Expecting 'Base_Types.Bits_Payload' but received ${v}\")\n        None[Base_Types.Bits]()\n      case _ => None[Base_Types.Bits]()\n    }\n    return value\n  }\n\n  \/\/ Logika spec var representing port state for incoming data port\n  @spec var from_producer_coordinate: Base_Types.Bits = $\n\n  def get_from_producer_coordinate() : Option[Base_Types.Bits] = {\n    Contract(\n      Ensures(\n        Res == Some(from_producer_coordinate)\n      )\n    )\n    val value : Option[Base_Types.Bits] = Art.getValue(from_producer_coordinate_Id) match {\n      case Some(Base_Types.Bits_Payload(v)) => Some(v)\n      case Some(v) =>\n        Art.logError(id, s\"Unexpected payload on port from_producer_coordinate.  Expecting 'Base_Types.Bits_Payload' but received ${v}\")\n        None[Base_Types.Bits]()\n      case _ => None[Base_Types.Bits]()\n    }\n    return value\n  }\n\n  \/\/ Logika spec var representing port state for incoming event data port\n  @spec var from_producer_mission: Option[Base_Types.Bits] = $\n\n  def get_from_producer_mission() : Option[Base_Types.Bits] = {\n    Contract(\n      Ensures(\n        Res == from_producer_mission\n      )\n    )\n    val value : Option[Base_Types.Bits] = Art.getValue(from_producer_mission_Id) match {\n      case Some(Base_Types.Bits_Payload(v)) => Some(v)\n      case Some(v) =>\n        Art.logError(id, s\"Unexpected payload on port from_producer_mission.  Expecting 'Base_Types.Bits_Payload' but received ${v}\")\n        None[Base_Types.Bits]()\n      case _ => None[Base_Types.Bits]()\n    }\n    return value\n  }\n\n  \/\/ Logika spec var representing port state for incoming event port\n  @spec var from_producer_event: Option[art.Empty] = $\n\n  def get_from_producer_event() : Option[art.Empty] = {\n    Contract(\n      Ensures(\n        Res == from_producer_event\n      )\n    )\n    val value : Option[art.Empty] = Art.getValue(from_producer_event_Id) match {\n      case Some(Empty()) => Some(Empty())\n      case Some(v) =>\n        Art.logError(id, s\"Unexpected payload on port from_producer_event.  Expecting 'Empty' but received ${v}\")\n        None[art.Empty]()\n      case _ => None[art.Empty]()\n    }\n    return value\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/component\/bit_codec\/Bit_Codec\/Filter_proc_filter.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage bit_codec.Bit_Codec\n\nimport org.sireum._\nimport bit_codec._\n\n\/\/ This file will not be overwritten so is safe to edit\nobject Filter_proc_filter {\n\n  def initialise(api: Filter_Initialization_Api): Unit = { }\n\n  def handle_from_producer_mission(api: Filter_Operational_Api, value: Base_Types.Bits): Unit = { }\n\n  def handle_from_producer_event(api: Filter_Operational_Api): Unit = { }\n\n  def finalise(api: Filter_Operational_Api): Unit = { }\n}\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/test\/util\/bit_codec\/Bit_Codec\/Consumer_proc_consumer_TestApi.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage bit_codec.Bit_Codec\n\nimport org.sireum._\nimport art.Art\nimport bit_codec._\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n@msig trait Consumer_proc_consumer_TestApi {\n\n  def BeforeEntrypoint(): Unit = {\n    Art.initTest(Arch.Bit_Codec_Sys_Impl_Instance_proc_consumer)\n  }\n\n  def AfterEntrypoint(): Unit = {\n    Art.finalizeTest(Arch.Bit_Codec_Sys_Impl_Instance_proc_consumer)\n  }\n\n  def testCompute(): Unit = {\n    Art.manuallyClearOutput()\n    Art.testCompute(Arch.Bit_Codec_Sys_Impl_Instance_proc_consumer)\n  }\n\n  def testInitialise(): Unit = {\n    Art.manuallyClearOutput()\n    Art.testInitialise(Arch.Bit_Codec_Sys_Impl_Instance_proc_consumer)\n  }\n\n  \/** helper function to set the values of all input ports.\n   * @param from_filter_u32 payload for data port from_filter_u32\n   * @param from_filter_latitude payload for data port from_filter_latitude\n   * @param from_filter_longitude payload for data port from_filter_longitude\n   * @param from_filter_coordinate payload for data port from_filter_coordinate\n   * @param from_filter_mission payloads for event data port from_filter_mission.\n   *   ART currently supports single element event data queues so\n   *   only the last element of from_filter_mission will be used\n   * @param from_filter_event the number of events to place in the from_filter_event event port queue.\n   *   ART currently supports single element event queues so at most\n   *   one event will be placed in the queue.\n   *\/\n  def put_concrete_inputs(from_filter_u32 : Base_Types.Bits,\n                          from_filter_latitude : Base_Types.Bits,\n                          from_filter_longitude : Base_Types.Bits,\n                          from_filter_coordinate : Base_Types.Bits,\n                          from_filter_mission : ISZ[Base_Types.Bits],\n                          from_filter_event : Z): Unit = {\n    put_from_filter_u32(from_filter_u32)\n    put_from_filter_latitude(from_filter_latitude)\n    put_from_filter_longitude(from_filter_longitude)\n    put_from_filter_coordinate(from_filter_coordinate)\n    for(v <- from_filter_mission){\n      put_from_filter_mission(v)\n    }\n    for(i <- 0 until from_filter_event) {\n      put_from_filter_event()\n    }\n  }\n\n\n  \/\/ setter for in DataPort\n  def put_from_filter_u32(value : Base_Types.Bits): Unit = {\n    Art.insertInInfrastructurePort(Arch.Bit_Codec_Sys_Impl_Instance_proc_consumer.operational_api.from_filter_u32_Id, Base_Types.Bits_Payload(value))\n  }\n\n  \/\/ setter for in DataPort\n  def put_from_filter_latitude(value : Base_Types.Bits): Unit = {\n    Art.insertInInfrastructurePort(Arch.Bit_Codec_Sys_Impl_Instance_proc_consumer.operational_api.from_filter_latitude_Id, Base_Types.Bits_Payload(value))\n  }\n\n  \/\/ setter for in DataPort\n  def put_from_filter_longitude(value : Base_Types.Bits): Unit = {\n    Art.insertInInfrastructurePort(Arch.Bit_Codec_Sys_Impl_Instance_proc_consumer.operational_api.from_filter_longitude_Id, Base_Types.Bits_Payload(value))\n  }\n\n  \/\/ setter for in DataPort\n  def put_from_filter_coordinate(value : Base_Types.Bits): Unit = {\n    Art.insertInInfrastructurePort(Arch.Bit_Codec_Sys_Impl_Instance_proc_consumer.operational_api.from_filter_coordinate_Id, Base_Types.Bits_Payload(value))\n  }\n\n  \/\/ setter for in EventDataPort\n  def put_from_filter_mission(value : Base_Types.Bits): Unit = {\n    Art.insertInInfrastructurePort(Arch.Bit_Codec_Sys_Impl_Instance_proc_consumer.operational_api.from_filter_mission_Id, Base_Types.Bits_Payload(value))\n  }\n\n  \/\/ setter for in EventPort\n  def put_from_filter_event(): Unit = {\n    Art.insertInInfrastructurePort(Arch.Bit_Codec_Sys_Impl_Instance_proc_consumer.operational_api.from_filter_event_Id, art.Empty())\n  }\n\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/test\/util\/bit_codec\/Bit_Codec\/Consumer_proc_consumer_ScalaTest.scala",
        {
          "type" : "ITestResource",
          "content" : "package bit_codec.Bit_Codec\n\nimport org.scalatest.{BeforeAndAfterEach, OneInstancePerTest}\nimport org.scalatest.funsuite.AnyFunSuite\nimport org.sireum.$internal.MutableMarker\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\nabstract class Consumer_proc_consumer_ScalaTest extends\n  AnyFunSuite with OneInstancePerTest with BeforeAndAfterEach with\n  Consumer_proc_consumer_TestApi {\n\n  var clonable: Boolean = true\n  var owned: Boolean = false\n\n  override def string: org.sireum.String = {\n    this.toString()\n  }\n\n  override def $clonable: Boolean = {\n    return clonable\n  }\n\n  override def $clonable_=(b: Boolean): MutableMarker = {\n    clonable = b\n    return this\n  }\n\n  override def $owned: Boolean = {\n    return owned\n  }\n\n  override def $owned_=(b: Boolean): MutableMarker = {\n    owned = b\n    return this\n  }\n\n  override def $clone: MutableMarker = {\n    \/\/ not expecting users to want to clone realizations of this abstract class\n    return this\n  }\n\n  override def beforeEach(): Unit = {\n    BeforeEntrypoint()\n  }\n\n  override def afterEach(): Unit = {\n    AfterEntrypoint()\n  }\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/test\/bridge\/bit_codec\/Bit_Codec\/Consumer_proc_consumer_Test.scala",
        {
          "type" : "ITestResource",
          "content" : "package bit_codec.Bit_Codec\n\nimport org.sireum._\nimport bit_codec.Bit_Codec._\n\n\/\/ This file will not be overwritten so is safe to edit\nclass Consumer_proc_consumer_Test extends Consumer_proc_consumer_ScalaTest {\n\n  test(\"Example Unit Test for Initialise Entry Point\"){\n    \/\/ Initialise Entry Point doesn't read input port values, so just proceed with\n    \/\/ launching the entry point code\n    testInitialise()\n    \/\/ use get_XXX methods and check_concrete_output() from test\/util\/..\/YYY_TestApi\n    \/\/ retrieve values from output ports and check against expected results\n  }\n\n  test(\"Example Unit Test for Compute Entry Point\"){\n    \/\/ use put_XXX methods from test\/util\/..\/YYY_TestApi to seed input ports with values\n    testCompute()\n    \/\/ use get_XXX methods and check_concrete_output() from test\/util\/..\/YYY_TestApi\n    \/\/ retrieve values from output ports and check against expected results\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/bridge\/bit_codec\/Bit_Codec\/Consumer_proc_consumer_Bridge.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage bit_codec.Bit_Codec\n\nimport org.sireum._\nimport art._\nimport bit_codec._\nimport bit_codec.Bit_Codec.{Consumer_proc_consumer => component}\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\n@datatype class Consumer_proc_consumer_Bridge(\n  val id: Art.BridgeId,\n  val name: String,\n  val dispatchProtocol: DispatchPropertyProtocol,\n  val dispatchTriggers: Option[ISZ[Art.PortId]],\n\n  from_filter_u32: Port[Base_Types.Bits],\n  from_filter_latitude: Port[Base_Types.Bits],\n  from_filter_longitude: Port[Base_Types.Bits],\n  from_filter_coordinate: Port[Base_Types.Bits],\n  from_filter_mission: Port[Base_Types.Bits],\n  from_filter_event: Port[art.Empty]\n  ) extends Bridge {\n\n  val ports : Bridge.Ports = Bridge.Ports(\n    dataIns = ISZ[art.UPort](from_filter_u32,\n                             from_filter_latitude,\n                             from_filter_longitude,\n                             from_filter_coordinate),\n\n    dataOuts = ISZ[art.UPort](),\n\n    eventIns = ISZ[art.UPort](from_filter_mission,\n                              from_filter_event),\n\n    eventOuts = ISZ[art.UPort]()\n  )\n\n  val initialization_api : Consumer_Initialization_Api = {\n    val api = Consumer_Initialization_Api(\n      id,\n      from_filter_u32.id,\n      from_filter_latitude.id,\n      from_filter_longitude.id,\n      from_filter_coordinate.id,\n      from_filter_mission.id,\n      from_filter_event.id\n    )\n    Consumer_proc_consumer_Bridge.c_initialization_api = Some(api)\n    api\n  }\n\n  val operational_api : Consumer_Operational_Api = {\n    val api = Consumer_Operational_Api(\n      id,\n      from_filter_u32.id,\n      from_filter_latitude.id,\n      from_filter_longitude.id,\n      from_filter_coordinate.id,\n      from_filter_mission.id,\n      from_filter_event.id\n    )\n    Consumer_proc_consumer_Bridge.c_operational_api = Some(api)\n    api\n  }\n\n  val entryPoints : Bridge.EntryPoints =\n    Consumer_proc_consumer_Bridge.EntryPoints(\n      id,\n\n      from_filter_u32.id,\n      from_filter_latitude.id,\n      from_filter_longitude.id,\n      from_filter_coordinate.id,\n      from_filter_mission.id,\n      from_filter_event.id,\n\n      dispatchTriggers,\n\n      initialization_api,\n      operational_api)\n}\n\nobject Consumer_proc_consumer_Bridge {\n\n  var c_initialization_api: Option[Consumer_Initialization_Api] = None()\n  var c_operational_api: Option[Consumer_Operational_Api] = None()\n\n  @datatype class EntryPoints(\n    Consumer_proc_consumer_BridgeId : Art.BridgeId,\n    from_filter_u32_Id : Art.PortId,\n    from_filter_latitude_Id : Art.PortId,\n    from_filter_longitude_Id : Art.PortId,\n    from_filter_coordinate_Id : Art.PortId,\n    from_filter_mission_Id : Art.PortId,\n    from_filter_event_Id : Art.PortId,\n    dispatchTriggers : Option[ISZ[Art.PortId]],\n    initialization_api: Consumer_Initialization_Api,\n    operational_api: Consumer_Operational_Api) extends Bridge.EntryPoints {\n\n    val dataInPortIds: ISZ[Art.PortId] = IS(from_filter_u32_Id,\n                                            from_filter_latitude_Id,\n                                            from_filter_longitude_Id,\n                                            from_filter_coordinate_Id)\n\n    val eventInPortIds: ISZ[Art.PortId] = IS(from_filter_mission_Id,\n                                             from_filter_event_Id)\n\n    val dataOutPortIds: ISZ[Art.PortId] = IS()\n\n    val eventOutPortIds: ISZ[Art.PortId] = IS()\n\n    def initialise(): Unit = {\n      \/\/ implement the following method in 'component':  def initialise(api: Consumer_Initialization_Api): Unit = {}\n      component.initialise(initialization_api)\n      Art.sendOutput(eventOutPortIds, dataOutPortIds)\n    }\n\n    def compute(): Unit = {\n      Art.receiveInput(eventInPortIds, dataInPortIds)\n\n      \/\/ implement the following in 'component':  def timeTriggered(api: Consumer_Operational_Api): Unit = {}\n      component.timeTriggered(operational_api)\n\n      Art.sendOutput(eventOutPortIds, dataOutPortIds)\n    }\n\n    def finalise(): Unit = {\n      \/\/ implement the following method in 'component':  def finalise(api: Consumer_Operational_Api): Unit = {}\n      component.finalise(operational_api)\n    }\n\n    override\n    def testInitialise(): Unit = {\n      \/\/ implement the following method in 'component':  def initialise(api: Consumer_Initialization_Api): Unit = {}\n      component.initialise(initialization_api)\n      Art.releaseOutput(eventOutPortIds, dataOutPortIds)\n    }\n\n    override\n    def testCompute(): Unit = {\n      Art.receiveInput(eventInPortIds, dataInPortIds)\n\n      \/\/ implement the following in 'component':  def timeTriggered(api: Consumer_Operational_Api): Unit = {}\n      component.timeTriggered(operational_api)\n\n      Art.releaseOutput(eventOutPortIds, dataOutPortIds)\n    }\n  }\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/bridge\/bit_codec\/Bit_Codec\/Consumer_Api.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage bit_codec.Bit_Codec\n\nimport org.sireum._\nimport art._\nimport bit_codec._\n\n@sig trait Consumer_Api {\n  def id: Art.BridgeId\n  def from_filter_u32_Id : Art.PortId\n  def from_filter_latitude_Id : Art.PortId\n  def from_filter_longitude_Id : Art.PortId\n  def from_filter_coordinate_Id : Art.PortId\n  def from_filter_mission_Id : Art.PortId\n  def from_filter_event_Id : Art.PortId\n\n\n  def logInfo(msg: String): Unit = {\n    Art.logInfo(id, msg)\n  }\n\n  def logDebug(msg: String): Unit = {\n    Art.logDebug(id, msg)\n  }\n\n  def logError(msg: String): Unit = {\n    Art.logError(id, msg)\n  }\n}\n\n@datatype class Consumer_Initialization_Api (\n  val id: Art.BridgeId,\n  val from_filter_u32_Id : Art.PortId,\n  val from_filter_latitude_Id : Art.PortId,\n  val from_filter_longitude_Id : Art.PortId,\n  val from_filter_coordinate_Id : Art.PortId,\n  val from_filter_mission_Id : Art.PortId,\n  val from_filter_event_Id : Art.PortId) extends Consumer_Api\n\n@datatype class Consumer_Operational_Api (\n  val id: Art.BridgeId,\n  val from_filter_u32_Id : Art.PortId,\n  val from_filter_latitude_Id : Art.PortId,\n  val from_filter_longitude_Id : Art.PortId,\n  val from_filter_coordinate_Id : Art.PortId,\n  val from_filter_mission_Id : Art.PortId,\n  val from_filter_event_Id : Art.PortId) extends Consumer_Api {\n\n  \/\/ Logika spec var representing port state for incoming data port\n  @spec var from_filter_u32: Base_Types.Bits = $\n\n  def get_from_filter_u32() : Option[Base_Types.Bits] = {\n    Contract(\n      Ensures(\n        Res == Some(from_filter_u32)\n      )\n    )\n    val value : Option[Base_Types.Bits] = Art.getValue(from_filter_u32_Id) match {\n      case Some(Base_Types.Bits_Payload(v)) => Some(v)\n      case Some(v) =>\n        Art.logError(id, s\"Unexpected payload on port from_filter_u32.  Expecting 'Base_Types.Bits_Payload' but received ${v}\")\n        None[Base_Types.Bits]()\n      case _ => None[Base_Types.Bits]()\n    }\n    return value\n  }\n\n  \/\/ Logika spec var representing port state for incoming data port\n  @spec var from_filter_latitude: Base_Types.Bits = $\n\n  def get_from_filter_latitude() : Option[Base_Types.Bits] = {\n    Contract(\n      Ensures(\n        Res == Some(from_filter_latitude)\n      )\n    )\n    val value : Option[Base_Types.Bits] = Art.getValue(from_filter_latitude_Id) match {\n      case Some(Base_Types.Bits_Payload(v)) => Some(v)\n      case Some(v) =>\n        Art.logError(id, s\"Unexpected payload on port from_filter_latitude.  Expecting 'Base_Types.Bits_Payload' but received ${v}\")\n        None[Base_Types.Bits]()\n      case _ => None[Base_Types.Bits]()\n    }\n    return value\n  }\n\n  \/\/ Logika spec var representing port state for incoming data port\n  @spec var from_filter_longitude: Base_Types.Bits = $\n\n  def get_from_filter_longitude() : Option[Base_Types.Bits] = {\n    Contract(\n      Ensures(\n        Res == Some(from_filter_longitude)\n      )\n    )\n    val value : Option[Base_Types.Bits] = Art.getValue(from_filter_longitude_Id) match {\n      case Some(Base_Types.Bits_Payload(v)) => Some(v)\n      case Some(v) =>\n        Art.logError(id, s\"Unexpected payload on port from_filter_longitude.  Expecting 'Base_Types.Bits_Payload' but received ${v}\")\n        None[Base_Types.Bits]()\n      case _ => None[Base_Types.Bits]()\n    }\n    return value\n  }\n\n  \/\/ Logika spec var representing port state for incoming data port\n  @spec var from_filter_coordinate: Base_Types.Bits = $\n\n  def get_from_filter_coordinate() : Option[Base_Types.Bits] = {\n    Contract(\n      Ensures(\n        Res == Some(from_filter_coordinate)\n      )\n    )\n    val value : Option[Base_Types.Bits] = Art.getValue(from_filter_coordinate_Id) match {\n      case Some(Base_Types.Bits_Payload(v)) => Some(v)\n      case Some(v) =>\n        Art.logError(id, s\"Unexpected payload on port from_filter_coordinate.  Expecting 'Base_Types.Bits_Payload' but received ${v}\")\n        None[Base_Types.Bits]()\n      case _ => None[Base_Types.Bits]()\n    }\n    return value\n  }\n\n  \/\/ Logika spec var representing port state for incoming event data port\n  @spec var from_filter_mission: Option[Base_Types.Bits] = $\n\n  def get_from_filter_mission() : Option[Base_Types.Bits] = {\n    Contract(\n      Ensures(\n        Res == from_filter_mission\n      )\n    )\n    val value : Option[Base_Types.Bits] = Art.getValue(from_filter_mission_Id) match {\n      case Some(Base_Types.Bits_Payload(v)) => Some(v)\n      case Some(v) =>\n        Art.logError(id, s\"Unexpected payload on port from_filter_mission.  Expecting 'Base_Types.Bits_Payload' but received ${v}\")\n        None[Base_Types.Bits]()\n      case _ => None[Base_Types.Bits]()\n    }\n    return value\n  }\n\n  \/\/ Logika spec var representing port state for incoming event port\n  @spec var from_filter_event: Option[art.Empty] = $\n\n  def get_from_filter_event() : Option[art.Empty] = {\n    Contract(\n      Ensures(\n        Res == from_filter_event\n      )\n    )\n    val value : Option[art.Empty] = Art.getValue(from_filter_event_Id) match {\n      case Some(Empty()) => Some(Empty())\n      case Some(v) =>\n        Art.logError(id, s\"Unexpected payload on port from_filter_event.  Expecting 'Empty' but received ${v}\")\n        None[art.Empty]()\n      case _ => None[art.Empty]()\n    }\n    return value\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/component\/bit_codec\/Bit_Codec\/Consumer_proc_consumer.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage bit_codec.Bit_Codec\n\nimport org.sireum._\nimport bit_codec._\n\n\/\/ This file will not be overwritten so is safe to edit\nobject Consumer_proc_consumer {\n\n  def initialise(api: Consumer_Initialization_Api): Unit = { }\n\n  def timeTriggered(api: Consumer_Operational_Api): Unit = { }\n\n  def finalise(api: Consumer_Operational_Api): Unit = { }\n}\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/component\/bit_codec\/TranspilerToucher.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage bit_codec\n\nimport org.sireum._\n\n\/\/ This file will not be overwritten so is safe to edit\n\nobject TranspilerToucher {\n  def touch(): Unit = {\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/nix\/bit_codec\/Producer_proc_producer_App.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage bit_codec\n\nimport org.sireum._\nimport art._\nimport art.Art.PortId._\nimport art.scheduling.nop.NopScheduler\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\nobject Producer_proc_producer_App extends App {\n\n  val entryPoints: Bridge.EntryPoints = Arch.Bit_Codec_Sys_Impl_Instance_proc_producer.entryPoints\n  val appPortId: Art.PortId = IPCPorts.Producer_proc_producer_App\n  val appPortIdOpt: Option[Art.PortId] = Some(appPortId)\n\n  \/\/ incoming ports\n\n  def initialiseArchitecture(seed: Z): Unit = {\n    PlatformComm.initialise(seed, appPortIdOpt)\n\n    Art.run(Arch.ad, NopScheduler())\n  }\n\n  def initialise(): Unit = {\n    entryPoints.initialise()\n  }\n\n  def compute(): Unit = {\n\n    entryPoints.compute()\n    bit_codec.Process.sleep(1000)\n  }\n\n  def finalise(): Unit = {\n    entryPoints.finalise()\n  }\n\n  def main(args: ISZ[String]): Z = {\n\n    val seed: Z = if (args.size == z\"1\") {\n      val n = Z(args(0)).get\n      if (n == z\"0\") 1 else n\n    } else {\n      1\n    }\n\n    initialiseArchitecture(seed)\n\n    PlatformComm.receive(appPortIdOpt, IPCPorts.emptyReceiveOut) \/\/ pause after setting up component\n\n    initialise()\n\n    PlatformComm.receive(appPortIdOpt, IPCPorts.emptyReceiveOut) \/\/ pause after component init\n\n    println(\"Producer_proc_producer_App starting ...\")\n\n    ArtNix.timeDispatch()\n\n    var terminated = F\n    while (!terminated) {\n      val out = IPCPorts.emptyReceiveAsyncOut\n      PlatformComm.receiveAsync(appPortIdOpt, out)\n      if (out.value2.isEmpty) {\n        compute()\n      } else {\n        terminated = T\n      }\n    }\n    exit()\n\n    touch()\n\n    return 0\n  }\n\n  def touch(): Unit = {\n    if(F) {\n      TranspilerToucher.touch()\n\n      \/\/ add types used in Platform.receive and Platform.receiveAsync\n      val mbox2Boolean_Payload: MBox2[Art.PortId, DataContent] = MBox2(portId\"0\", Base_Types.Boolean_Payload(T))\n      val mbox2OptionDataContent: MBox2[Art.PortId, Option[DataContent]] = MBox2(portId\"0\", None())\n\n      \/\/ touch each payload\/type in case some are only used as a field in a record\n      def printDataContent(a: art.DataContent): Unit = { println(s\"${a}\") }\n\n      printDataContent(Base_Types.Bits_Payload(Base_Types.Bits_example()))\n      printDataContent(art.Empty())\n\n      bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_initialization_api.get.logInfo(\"\")\n      bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_initialization_api.get.logDebug(\"\")\n      bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_initialization_api.get.logError(\"\")\n      bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_operational_api.get.logInfo(\"\")\n      bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_operational_api.get.logDebug(\"\")\n      bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_operational_api.get.logError(\"\")\n      bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_initialization_api.get.put_to_filter_u32(Base_Types.Bits_example())\n      bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_operational_api.get.put_to_filter_u32(Base_Types.Bits_example())\n      bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_initialization_api.get.put_to_filter_latitude(Base_Types.Bits_example())\n      bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_operational_api.get.put_to_filter_latitude(Base_Types.Bits_example())\n      bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_initialization_api.get.put_to_filter_longitude(Base_Types.Bits_example())\n      bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_operational_api.get.put_to_filter_longitude(Base_Types.Bits_example())\n      bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_initialization_api.get.put_to_filter_coordinate(Base_Types.Bits_example())\n      bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_operational_api.get.put_to_filter_coordinate(Base_Types.Bits_example())\n      bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_initialization_api.get.put_to_filter_mission(Base_Types.Bits_example())\n      bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_operational_api.get.put_to_filter_mission(Base_Types.Bits_example())\n      bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_initialization_api.get.put_to_filter_event()\n      bit_codec.Bit_Codec.Producer_proc_producer_Bridge.c_operational_api.get.put_to_filter_event()\n    }\n  }\n\n  def exit(): Unit = {\n    finalise()\n    PlatformComm.finalise()\n  }\n\n  override def atExit(): Unit = {\n    exit()\n  }\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "c\/ext-c\/Producer_proc_producer\/Producer_proc_producer.h",
        {
          "type" : "ITestResource",
          "content" : "#ifndef PRODUCER_PROC_PRODUCER_H\n#define PRODUCER_PROC_PRODUCER_H\n\n#include <all.h>\n\nUnit bit_codec_Bit_Codec_Producer_proc_producer_initialise_(STACK_FRAME_ONLY);\n\nUnit bit_codec_Bit_Codec_Producer_proc_producer_finalise_(STACK_FRAME_ONLY);\n\nUnit bit_codec_Bit_Codec_Producer_proc_producer_timeTriggered_(STACK_FRAME_ONLY);\n\n#endif\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "c\/ext-c\/Producer_proc_producer\/Producer_proc_producer.c",
        {
          "type" : "ITestResource",
          "content" : "#include <Producer_proc_producer_api.h>\n#include <Producer_proc_producer.h>\n#include <ext.h>\n\n\/\/ This file will not be overwritten so is safe to edit\n\nstatic char* component_id = \"Bit_Codec_Sys_Impl_Instance_proc_producer\";\n\nUnit bit_codec_Bit_Codec_Producer_proc_producer_initialise_(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer.c\", \"\", \"bit_codec_Bit_Codec_Producer_proc_producer_initialise_\", 0);\n\n  printf(\"%s: bit_codec_Bit_Codec_Producer_proc_producer_initialise_ called\\n\", component_id);\n\n  \/\/ example usage of api setters\n\n  uint8_t t0[numBytes_U32];\n  byte_array_default(SF t0, numBits_U32, numBytes_U32);\n  api_put_to_filter_u32__bit_codec_Bit_Codec_Producer_proc_producer(SF numBits_U32, t0);\n\n  uint8_t t1[numBytes_bit_codec_Bit_Codec_Latitude];\n  byte_array_default(SF t1, numBits_bit_codec_Bit_Codec_Latitude, numBytes_bit_codec_Bit_Codec_Latitude);\n  api_put_to_filter_latitude__bit_codec_Bit_Codec_Producer_proc_producer(SF numBits_bit_codec_Bit_Codec_Latitude, t1);\n\n  uint8_t t2[numBytes_bit_codec_Bit_Codec_Longitude];\n  byte_array_default(SF t2, numBits_bit_codec_Bit_Codec_Longitude, numBytes_bit_codec_Bit_Codec_Longitude);\n  api_put_to_filter_longitude__bit_codec_Bit_Codec_Producer_proc_producer(SF numBits_bit_codec_Bit_Codec_Longitude, t2);\n\n  uint8_t t3[numBytes_bit_codec_Bit_Codec_Coordinate_Impl];\n  byte_array_default(SF t3, numBits_bit_codec_Bit_Codec_Coordinate_Impl, numBytes_bit_codec_Bit_Codec_Coordinate_Impl);\n  api_put_to_filter_coordinate__bit_codec_Bit_Codec_Producer_proc_producer(SF numBits_bit_codec_Bit_Codec_Coordinate_Impl, t3);\n\n  uint8_t t4[numBytes_bit_codec_Bit_Codec_Mission];\n  byte_array_default(SF t4, numBits_bit_codec_Bit_Codec_Mission, numBytes_bit_codec_Bit_Codec_Mission);\n  api_put_to_filter_mission__bit_codec_Bit_Codec_Producer_proc_producer(SF numBits_bit_codec_Bit_Codec_Mission, t4);\n\n  api_put_to_filter_event__bit_codec_Bit_Codec_Producer_proc_producer(SF_LAST);\n\n  \/* example usage of api loggers. Commented out as the constructed String may be too long\n  api_logInfo__bit_codec_Bit_Codec_Producer_proc_producer(SF string(\"Example logInfo\"));\n\n  api_logDebug__bit_codec_Bit_Codec_Producer_proc_producer(SF string(\"Example logDebug\"));\n\n  api_logError__bit_codec_Bit_Codec_Producer_proc_producer(SF string(\"Example logError\"));\n  *\/\n}\n\nUnit bit_codec_Bit_Codec_Producer_proc_producer_finalise_(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer.c\", \"\", \"bit_codec_Bit_Codec_Producer_proc_producer_finalise_\", 0);\n}\n\nUnit bit_codec_Bit_Codec_Producer_proc_producer_timeTriggered_(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer.c\", \"\", \"bit_codec_Bit_Codec_Producer_proc_producer_timeTriggered_\", 0);\n\n}\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "c\/ext-c\/Producer_proc_producer\/Producer_proc_producer_api.h",
        {
          "type" : "ITestResource",
          "content" : "#ifndef PRODUCER_PROC_PRODUCER_API_H\n#define PRODUCER_PROC_PRODUCER_API_H\n\n#include <all.h>\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\nvoid api_put_to_filter_u32__bit_codec_Bit_Codec_Producer_proc_producer(\n  STACK_FRAME\n  size_t numBits,\n  uint8_t *byteArray);\n\nvoid api_put_to_filter_latitude__bit_codec_Bit_Codec_Producer_proc_producer(\n  STACK_FRAME\n  size_t numBits,\n  uint8_t *byteArray);\n\nvoid api_put_to_filter_longitude__bit_codec_Bit_Codec_Producer_proc_producer(\n  STACK_FRAME\n  size_t numBits,\n  uint8_t *byteArray);\n\nvoid api_put_to_filter_coordinate__bit_codec_Bit_Codec_Producer_proc_producer(\n  STACK_FRAME\n  size_t numBits,\n  uint8_t *byteArray);\n\nvoid api_put_to_filter_mission__bit_codec_Bit_Codec_Producer_proc_producer(\n  STACK_FRAME\n  size_t numBits,\n  uint8_t *byteArray);\n\nvoid api_put_to_filter_event__bit_codec_Bit_Codec_Producer_proc_producer(STACK_FRAME_ONLY);\n\nvoid api_logInfo__bit_codec_Bit_Codec_Producer_proc_producer(\n  STACK_FRAME\n  String str);\n\nvoid api_logDebug__bit_codec_Bit_Codec_Producer_proc_producer(\n  STACK_FRAME\n  String str);\n\nvoid api_logError__bit_codec_Bit_Codec_Producer_proc_producer(\n  STACK_FRAME\n  String str);\n\n#endif\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "c\/ext-c\/Producer_proc_producer\/Producer_proc_producer_api.c",
        {
          "type" : "ITestResource",
          "content" : "#include <Producer_proc_producer_api.h>\n#include <Producer_proc_producer.h>\n\nstatic bool apis_initialized = false;\nstatic struct bit_codec_Bit_Codec_Producer_Initialization_Api initialization_api;\nstatic struct bit_codec_Bit_Codec_Producer_Operational_Api operational_api;\n\nstatic void initialize_apis(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer.c\", \"\", \"initialize_apis\", 0);\n\n  \/\/ Option_04250B = Option[bit_codec.Bit_Codec.Producer_Initialization_Api]\n  Option_04250B_get_(SF (bit_codec_Bit_Codec_Producer_Initialization_Api) &initialization_api, bit_codec_Bit_Codec_Producer_proc_producer_Bridge_c_initialization_api(SF_LAST));\n  \/\/ Option_B73B27 = Option[bit_codec.Bit_Codec.Producer_Operational_Api]\n  Option_B73B27_get_(SF (bit_codec_Bit_Codec_Producer_Operational_Api) &operational_api, bit_codec_Bit_Codec_Producer_proc_producer_Bridge_c_operational_api(SF_LAST));\n  apis_initialized = true;\n}\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\nvoid api_put_to_filter_u32__bit_codec_Bit_Codec_Producer_proc_producer(\n  STACK_FRAME\n  size_t numBits,\n  uint8_t *byteArray) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer_api.c\", \"\", \"api_put_to_filter_u32__bit_codec_Bit_Codec_Producer_proc_producer\", 0);\n\n  sfAssert((Z) numBits >= 0, \"numBits must be non-negative for IS[Z, B].\")\n  sfAssert((Z) numBits <= MaxIS_C4F575, \"numBits too large for IS[Z, B].\")\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  DeclNewIS_C4F575(t_0);\n\n  t_0.size = numBits;\n  if(numBits > 0) {\n    size_t numBytes = (numBits - 1) \/ 8 + 1;\n    memcpy(&t_0.value, byteArray, numBytes);\n  }\n\n  bit_codec_Bit_Codec_Producer_Initialization_Api_put_to_filter_u32_(\n    SF\n    &initialization_api,\n    &t_0);\n}\n\nvoid api_put_to_filter_latitude__bit_codec_Bit_Codec_Producer_proc_producer(\n  STACK_FRAME\n  size_t numBits,\n  uint8_t *byteArray) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer_api.c\", \"\", \"api_put_to_filter_latitude__bit_codec_Bit_Codec_Producer_proc_producer\", 0);\n\n  sfAssert((Z) numBits >= 0, \"numBits must be non-negative for IS[Z, B].\")\n  sfAssert((Z) numBits <= MaxIS_C4F575, \"numBits too large for IS[Z, B].\")\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  DeclNewIS_C4F575(t_0);\n\n  t_0.size = numBits;\n  if(numBits > 0) {\n    size_t numBytes = (numBits - 1) \/ 8 + 1;\n    memcpy(&t_0.value, byteArray, numBytes);\n  }\n\n  bit_codec_Bit_Codec_Producer_Initialization_Api_put_to_filter_latitude_(\n    SF\n    &initialization_api,\n    &t_0);\n}\n\nvoid api_put_to_filter_longitude__bit_codec_Bit_Codec_Producer_proc_producer(\n  STACK_FRAME\n  size_t numBits,\n  uint8_t *byteArray) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer_api.c\", \"\", \"api_put_to_filter_longitude__bit_codec_Bit_Codec_Producer_proc_producer\", 0);\n\n  sfAssert((Z) numBits >= 0, \"numBits must be non-negative for IS[Z, B].\")\n  sfAssert((Z) numBits <= MaxIS_C4F575, \"numBits too large for IS[Z, B].\")\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  DeclNewIS_C4F575(t_0);\n\n  t_0.size = numBits;\n  if(numBits > 0) {\n    size_t numBytes = (numBits - 1) \/ 8 + 1;\n    memcpy(&t_0.value, byteArray, numBytes);\n  }\n\n  bit_codec_Bit_Codec_Producer_Initialization_Api_put_to_filter_longitude_(\n    SF\n    &initialization_api,\n    &t_0);\n}\n\nvoid api_put_to_filter_coordinate__bit_codec_Bit_Codec_Producer_proc_producer(\n  STACK_FRAME\n  size_t numBits,\n  uint8_t *byteArray) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer_api.c\", \"\", \"api_put_to_filter_coordinate__bit_codec_Bit_Codec_Producer_proc_producer\", 0);\n\n  sfAssert((Z) numBits >= 0, \"numBits must be non-negative for IS[Z, B].\")\n  sfAssert((Z) numBits <= MaxIS_C4F575, \"numBits too large for IS[Z, B].\")\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  DeclNewIS_C4F575(t_0);\n\n  t_0.size = numBits;\n  if(numBits > 0) {\n    size_t numBytes = (numBits - 1) \/ 8 + 1;\n    memcpy(&t_0.value, byteArray, numBytes);\n  }\n\n  bit_codec_Bit_Codec_Producer_Initialization_Api_put_to_filter_coordinate_(\n    SF\n    &initialization_api,\n    &t_0);\n}\n\nvoid api_put_to_filter_mission__bit_codec_Bit_Codec_Producer_proc_producer(\n  STACK_FRAME\n  size_t numBits,\n  uint8_t *byteArray) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer_api.c\", \"\", \"api_put_to_filter_mission__bit_codec_Bit_Codec_Producer_proc_producer\", 0);\n\n  sfAssert((Z) numBits >= 0, \"numBits must be non-negative for IS[Z, B].\")\n  sfAssert((Z) numBits <= MaxIS_C4F575, \"numBits too large for IS[Z, B].\")\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  DeclNewIS_C4F575(t_0);\n\n  t_0.size = numBits;\n  if(numBits > 0) {\n    size_t numBytes = (numBits - 1) \/ 8 + 1;\n    memcpy(&t_0.value, byteArray, numBytes);\n  }\n\n  bit_codec_Bit_Codec_Producer_Initialization_Api_put_to_filter_mission_(\n    SF\n    &initialization_api,\n    &t_0);\n}\n\nvoid api_put_to_filter_event__bit_codec_Bit_Codec_Producer_proc_producer(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer_api.c\", \"\", \"api_put_to_filter_event__bit_codec_Bit_Codec_Producer_proc_producer\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  bit_codec_Bit_Codec_Producer_Initialization_Api_put_to_filter_event_(\n    SF\n    &initialization_api);\n}\n\nvoid api_logInfo__bit_codec_Bit_Codec_Producer_proc_producer(\n  STACK_FRAME\n  String str) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer_api.c\", \"\", \"api_logInfo__bit_codec_Bit_Codec_Producer_proc_producer\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  bit_codec_Bit_Codec_Producer_Initialization_Api_logInfo_(\n    SF\n    &initialization_api,\n    str);\n}\n\nvoid api_logDebug__bit_codec_Bit_Codec_Producer_proc_producer(\n  STACK_FRAME\n  String str) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer_api.c\", \"\", \"api_logDebug__bit_codec_Bit_Codec_Producer_proc_producer\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  bit_codec_Bit_Codec_Producer_Initialization_Api_logDebug_(\n    SF\n    &initialization_api,\n    str);\n}\n\nvoid api_logError__bit_codec_Bit_Codec_Producer_proc_producer(\n  STACK_FRAME\n  String str) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer_api.c\", \"\", \"api_logError__bit_codec_Bit_Codec_Producer_proc_producer\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  bit_codec_Bit_Codec_Producer_Initialization_Api_logError_(\n    SF\n    &initialization_api,\n    str);\n}\n\nUnit bit_codec_Bit_Codec_Producer_proc_producer_initialise(\n  STACK_FRAME\n  bit_codec_Bit_Codec_Producer_Initialization_Api api) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer_api.c\", \"\", \"bit_codec_Bit_Codec_Producer_proc_producer_initialise\", 0);\n\n  bit_codec_Bit_Codec_Producer_proc_producer_initialise_(SF_LAST);\n}\n\nUnit bit_codec_Bit_Codec_Producer_proc_producer_finalise(\n  STACK_FRAME\n  bit_codec_Bit_Codec_Producer_Operational_Api api) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer_api.c\", \"\", \"bit_codec_Bit_Codec_Producer_proc_producer_finalise\", 0);\n\n  bit_codec_Bit_Codec_Producer_proc_producer_finalise_(SF_LAST);\n}\n\nUnit bit_codec_Bit_Codec_Producer_proc_producer_timeTriggered(\n  STACK_FRAME\n  bit_codec_Bit_Codec_Producer_Operational_Api api) {\n  DeclNewStackFrame(caller, \"Producer_proc_producer_api.c\", \"\", \"bit_codec_Bit_Codec_Producer_proc_producer_timeTriggered\", 0);\n\n  bit_codec_Bit_Codec_Producer_proc_producer_timeTriggered_(SF_LAST);\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/nix\/bit_codec\/Filter_proc_filter_App.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage bit_codec\n\nimport org.sireum._\nimport art._\nimport art.Art.PortId._\nimport art.scheduling.nop.NopScheduler\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\nobject Filter_proc_filter_App extends App {\n\n  val entryPoints: Bridge.EntryPoints = Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.entryPoints\n  val appPortId: Art.PortId = IPCPorts.Filter_proc_filter_App\n  val appPortIdOpt: Option[Art.PortId] = Some(appPortId)\n\n  \/\/ incoming ports\n  val from_producer_u32PortId: Art.PortId = Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.from_producer_u32.id\n  val from_producer_u32PortIdOpt: Option[Art.PortId] = Some(from_producer_u32PortId)\n  val from_producer_latitudePortId: Art.PortId = Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.from_producer_latitude.id\n  val from_producer_latitudePortIdOpt: Option[Art.PortId] = Some(from_producer_latitudePortId)\n  val from_producer_longitudePortId: Art.PortId = Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.from_producer_longitude.id\n  val from_producer_longitudePortIdOpt: Option[Art.PortId] = Some(from_producer_longitudePortId)\n  val from_producer_coordinatePortId: Art.PortId = Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.from_producer_coordinate.id\n  val from_producer_coordinatePortIdOpt: Option[Art.PortId] = Some(from_producer_coordinatePortId)\n  val from_producer_missionPortId: Art.PortId = Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.from_producer_mission.id\n  val from_producer_missionPortIdOpt: Option[Art.PortId] = Some(from_producer_missionPortId)\n  val from_producer_eventPortId: Art.PortId = Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.from_producer_event.id\n  val from_producer_eventPortIdOpt: Option[Art.PortId] = Some(from_producer_eventPortId)\n\n  def initialiseArchitecture(seed: Z): Unit = {\n    PlatformComm.initialise(seed, appPortIdOpt)\n    PlatformComm.initialise(seed, from_producer_u32PortIdOpt)\n    PlatformComm.initialise(seed, from_producer_latitudePortIdOpt)\n    PlatformComm.initialise(seed, from_producer_longitudePortIdOpt)\n    PlatformComm.initialise(seed, from_producer_coordinatePortIdOpt)\n    PlatformComm.initialise(seed, from_producer_missionPortIdOpt)\n    PlatformComm.initialise(seed, from_producer_eventPortIdOpt)\n\n    Art.run(Arch.ad, NopScheduler())\n  }\n\n  def initialise(): Unit = {\n    entryPoints.initialise()\n  }\n\n  def compute(): Unit = {\n    var dispatch = F\n\n    {\n      val out = IPCPorts.emptyReceiveAsyncOut\n      PlatformComm.receiveAsync(from_producer_u32PortIdOpt, out)\n      out.value2 match {\n        case Some(v: Base_Types.Bits_Payload) => ArtNix.updateData(from_producer_u32PortId, v); dispatch = F\n        case Some(v) => halt(s\"Unexpected payload on port from_producer_u32.  Expecting something of type Base_Types.Bits_Payload but received ${v}\")\n        case None() => \/\/ do nothing\n      }\n    }\n    {\n      val out = IPCPorts.emptyReceiveAsyncOut\n      PlatformComm.receiveAsync(from_producer_latitudePortIdOpt, out)\n      out.value2 match {\n        case Some(v: Base_Types.Bits_Payload) => ArtNix.updateData(from_producer_latitudePortId, v); dispatch = F\n        case Some(v) => halt(s\"Unexpected payload on port from_producer_latitude.  Expecting something of type Base_Types.Bits_Payload but received ${v}\")\n        case None() => \/\/ do nothing\n      }\n    }\n    {\n      val out = IPCPorts.emptyReceiveAsyncOut\n      PlatformComm.receiveAsync(from_producer_longitudePortIdOpt, out)\n      out.value2 match {\n        case Some(v: Base_Types.Bits_Payload) => ArtNix.updateData(from_producer_longitudePortId, v); dispatch = F\n        case Some(v) => halt(s\"Unexpected payload on port from_producer_longitude.  Expecting something of type Base_Types.Bits_Payload but received ${v}\")\n        case None() => \/\/ do nothing\n      }\n    }\n    {\n      val out = IPCPorts.emptyReceiveAsyncOut\n      PlatformComm.receiveAsync(from_producer_coordinatePortIdOpt, out)\n      out.value2 match {\n        case Some(v: Base_Types.Bits_Payload) => ArtNix.updateData(from_producer_coordinatePortId, v); dispatch = F\n        case Some(v) => halt(s\"Unexpected payload on port from_producer_coordinate.  Expecting something of type Base_Types.Bits_Payload but received ${v}\")\n        case None() => \/\/ do nothing\n      }\n    }\n    {\n      val out = IPCPorts.emptyReceiveAsyncOut\n      PlatformComm.receiveAsync(from_producer_missionPortIdOpt, out)\n      out.value2 match {\n        case Some(v: Base_Types.Bits_Payload) => ArtNix.updateData(from_producer_missionPortId, v); dispatch = T\n        case Some(v) => halt(s\"Unexpected payload on port from_producer_mission.  Expecting something of type Base_Types.Bits_Payload but received ${v}\")\n        case None() => \/\/ do nothing\n      }\n    }\n    {\n      val out = IPCPorts.emptyReceiveAsyncOut\n      PlatformComm.receiveAsync(from_producer_eventPortIdOpt, out)\n      out.value2 match {\n        case Some(v: art.Empty) => ArtNix.updateData(from_producer_eventPortId, v); dispatch = T\n        case Some(v) => halt(s\"Unexpected payload on port from_producer_event.  Expecting something of type art.Empty but received ${v}\")\n        case None() => \/\/ do nothing\n      }\n    }\n    if (dispatch) {\n      entryPoints.compute()\n      bit_codec.Process.sleep(1000)\n    } else {\n      bit_codec.Process.sleep(10)\n    }\n  }\n\n  def finalise(): Unit = {\n    entryPoints.finalise()\n  }\n\n  def main(args: ISZ[String]): Z = {\n\n    val seed: Z = if (args.size == z\"1\") {\n      val n = Z(args(0)).get\n      if (n == z\"0\") 1 else n\n    } else {\n      1\n    }\n\n    initialiseArchitecture(seed)\n\n    PlatformComm.receive(appPortIdOpt, IPCPorts.emptyReceiveOut) \/\/ pause after setting up component\n\n    initialise()\n\n    PlatformComm.receive(appPortIdOpt, IPCPorts.emptyReceiveOut) \/\/ pause after component init\n\n    println(\"Filter_proc_filter_App starting ...\")\n\n    ArtNix.eventDispatch()\n\n    var terminated = F\n    while (!terminated) {\n      val out = IPCPorts.emptyReceiveAsyncOut\n      PlatformComm.receiveAsync(appPortIdOpt, out)\n      if (out.value2.isEmpty) {\n        compute()\n      } else {\n        terminated = T\n      }\n    }\n    exit()\n\n    touch()\n\n    return 0\n  }\n\n  def touch(): Unit = {\n    if(F) {\n      TranspilerToucher.touch()\n\n      \/\/ add types used in Platform.receive and Platform.receiveAsync\n      val mbox2Boolean_Payload: MBox2[Art.PortId, DataContent] = MBox2(portId\"0\", Base_Types.Boolean_Payload(T))\n      val mbox2OptionDataContent: MBox2[Art.PortId, Option[DataContent]] = MBox2(portId\"0\", None())\n\n      \/\/ touch each payload\/type in case some are only used as a field in a record\n      def printDataContent(a: art.DataContent): Unit = { println(s\"${a}\") }\n\n      printDataContent(Base_Types.Bits_Payload(Base_Types.Bits_example()))\n      printDataContent(art.Empty())\n\n      bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_initialization_api.get.logInfo(\"\")\n      bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_initialization_api.get.logDebug(\"\")\n      bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_initialization_api.get.logError(\"\")\n      bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_operational_api.get.logInfo(\"\")\n      bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_operational_api.get.logDebug(\"\")\n      bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_operational_api.get.logError(\"\")\n      val apiUsage_from_producer_u32: Option[Base_Types.Bits] = bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_operational_api.get.get_from_producer_u32()\n      val apiUsage_from_producer_latitude: Option[Base_Types.Bits] = bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_operational_api.get.get_from_producer_latitude()\n      val apiUsage_from_producer_longitude: Option[Base_Types.Bits] = bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_operational_api.get.get_from_producer_longitude()\n      val apiUsage_from_producer_coordinate: Option[Base_Types.Bits] = bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_operational_api.get.get_from_producer_coordinate()\n      bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_initialization_api.get.put_to_consumer_u32(Base_Types.Bits_example())\n      bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_operational_api.get.put_to_consumer_u32(Base_Types.Bits_example())\n      bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_initialization_api.get.put_to_consumer_latitude(Base_Types.Bits_example())\n      bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_operational_api.get.put_to_consumer_latitude(Base_Types.Bits_example())\n      bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_initialization_api.get.put_to_consumer_longitude(Base_Types.Bits_example())\n      bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_operational_api.get.put_to_consumer_longitude(Base_Types.Bits_example())\n      bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_initialization_api.get.put_to_consumer_coordinate(Base_Types.Bits_example())\n      bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_operational_api.get.put_to_consumer_coordinate(Base_Types.Bits_example())\n      val apiUsage_from_producer_mission: Option[Base_Types.Bits] = bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_operational_api.get.get_from_producer_mission()\n      bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_initialization_api.get.put_to_consumer_mission(Base_Types.Bits_example())\n      bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_operational_api.get.put_to_consumer_mission(Base_Types.Bits_example())\n      val apiUsage_from_producer_event: Option[art.Empty] = bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_operational_api.get.get_from_producer_event()\n      bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_initialization_api.get.put_to_consumer_event()\n      bit_codec.Bit_Codec.Filter_proc_filter_Bridge.c_operational_api.get.put_to_consumer_event()\n    }\n  }\n\n  def exit(): Unit = {\n    finalise()\n    PlatformComm.finalise()\n  }\n\n  override def atExit(): Unit = {\n    exit()\n  }\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "c\/ext-c\/Filter_proc_filter\/Filter_proc_filter.h",
        {
          "type" : "ITestResource",
          "content" : "#ifndef FILTER_PROC_FILTER_H\n#define FILTER_PROC_FILTER_H\n\n#include <all.h>\n\nUnit bit_codec_Bit_Codec_Filter_proc_filter_initialise_(STACK_FRAME_ONLY);\n\nUnit bit_codec_Bit_Codec_Filter_proc_filter_finalise_(STACK_FRAME_ONLY);\n\nUnit bit_codec_Bit_Codec_Filter_proc_filter_handle_from_producer_mission_(\n  STACK_FRAME\n  IS_C4F575 value);\n\nUnit bit_codec_Bit_Codec_Filter_proc_filter_handle_from_producer_event_(STACK_FRAME_ONLY);\n\n#endif\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "c\/ext-c\/Filter_proc_filter\/Filter_proc_filter.c",
        {
          "type" : "ITestResource",
          "content" : "#include <Filter_proc_filter_api.h>\n#include <Filter_proc_filter.h>\n#include <ext.h>\n\n\/\/ This file will not be overwritten so is safe to edit\n\nstatic char* component_id = \"Bit_Codec_Sys_Impl_Instance_proc_filter\";\n\nUnit bit_codec_Bit_Codec_Filter_proc_filter_initialise_(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter.c\", \"\", \"bit_codec_Bit_Codec_Filter_proc_filter_initialise_\", 0);\n\n  printf(\"%s: bit_codec_Bit_Codec_Filter_proc_filter_initialise_ called\\n\", component_id);\n\n  \/\/ example usage of api setters\n\n  uint8_t t0[numBytes_U32];\n  byte_array_default(SF t0, numBits_U32, numBytes_U32);\n  api_put_to_consumer_u32__bit_codec_Bit_Codec_Filter_proc_filter(SF numBits_U32, t0);\n\n  uint8_t t1[numBytes_bit_codec_Bit_Codec_Latitude];\n  byte_array_default(SF t1, numBits_bit_codec_Bit_Codec_Latitude, numBytes_bit_codec_Bit_Codec_Latitude);\n  api_put_to_consumer_latitude__bit_codec_Bit_Codec_Filter_proc_filter(SF numBits_bit_codec_Bit_Codec_Latitude, t1);\n\n  uint8_t t2[numBytes_bit_codec_Bit_Codec_Longitude];\n  byte_array_default(SF t2, numBits_bit_codec_Bit_Codec_Longitude, numBytes_bit_codec_Bit_Codec_Longitude);\n  api_put_to_consumer_longitude__bit_codec_Bit_Codec_Filter_proc_filter(SF numBits_bit_codec_Bit_Codec_Longitude, t2);\n\n  uint8_t t3[numBytes_bit_codec_Bit_Codec_Coordinate_Impl];\n  byte_array_default(SF t3, numBits_bit_codec_Bit_Codec_Coordinate_Impl, numBytes_bit_codec_Bit_Codec_Coordinate_Impl);\n  api_put_to_consumer_coordinate__bit_codec_Bit_Codec_Filter_proc_filter(SF numBits_bit_codec_Bit_Codec_Coordinate_Impl, t3);\n\n  uint8_t t4[numBytes_bit_codec_Bit_Codec_Mission];\n  byte_array_default(SF t4, numBits_bit_codec_Bit_Codec_Mission, numBytes_bit_codec_Bit_Codec_Mission);\n  api_put_to_consumer_mission__bit_codec_Bit_Codec_Filter_proc_filter(SF numBits_bit_codec_Bit_Codec_Mission, t4);\n\n  api_put_to_consumer_event__bit_codec_Bit_Codec_Filter_proc_filter(SF_LAST);\n\n  \/* example usage of api loggers. Commented out as the constructed String may be too long\n  api_logInfo__bit_codec_Bit_Codec_Filter_proc_filter(SF string(\"Example logInfo\"));\n\n  api_logDebug__bit_codec_Bit_Codec_Filter_proc_filter(SF string(\"Example logDebug\"));\n\n  api_logError__bit_codec_Bit_Codec_Filter_proc_filter(SF string(\"Example logError\"));\n  *\/\n}\n\nUnit bit_codec_Bit_Codec_Filter_proc_filter_finalise_(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter.c\", \"\", \"bit_codec_Bit_Codec_Filter_proc_filter_finalise_\", 0);\n}\n\nUnit bit_codec_Bit_Codec_Filter_proc_filter_handle_from_producer_mission_raw(\n  STACK_FRAME\n  size_t numBits,\n  uint8_t *byteArray) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter_api.c\", \"\", \"bit_codec_Bit_Codec_Filter_proc_filter_handle_from_producer_mission_raw\", 0);\n\n  size_t numBytes = numBits == 0 ? 0 : (numBits - 1) \/ 8 + 1;\n\n  printf(\"%s: bit_codec_Bit_Codec_Filter_proc_filter_handle_from_producer_mission_raw called with payload: \\n\", component_id);\n  hex_dump(SF byteArray, numBytes);\n\n  \/* alternative using logInfo.  Commented out as the constructed String may be too large\n  DeclNewString(from_producer_missionString);\n  String__append(SF (String) &from_producer_missionString, string(\"bit_codec_Bit_Codec_Filter_proc_filter_handle_from_producer_mission_raw called with payload: \"));\n  byte_array_string(SF (String) &from_producer_missionString, byteArray, numBytes);\n  api_logInfo__bit_codec_Bit_Codec_Filter_proc_filter (SF (String) &from_producer_missionString);\n  *\/\n}\n\nUnit bit_codec_Bit_Codec_Filter_proc_filter_handle_from_producer_mission_(\n  STACK_FRAME\n  IS_C4F575 value) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter.c\", \"\", \"bit_codec_Bit_Codec_Filter_proc_filter_handle_from_producer_mission_\", 0);\n\n  bit_codec_Bit_Codec_Filter_proc_filter_handle_from_producer_mission_raw(SF value->size, value->value);\n\n  \/\/ examples of api getter usage\n\n  uint8_t t0[numBytes_U32];\n  size_t t0_numBits;\n  if(api_get_from_producer_u32__bit_codec_Bit_Codec_Filter_proc_filter(SF &t0_numBits, t0)) {\n    \/\/ sanity check\n    sfAssert((Z) t0_numBits == numBits_U32, \"numBits received does not match expected\")\n\n    printf(\"%s: Received data on data port from_producer_u32: \\n\", component_id);\n    hex_dump(SF t0, numBytes_U32);\n\n    \/* alternative using logInfo.  Commented out as the constructed String may be too large\n    DeclNewString(from_producer_u32_str);\n    String__append(SF (String) &from_producer_u32_str, string(\"Received data on data port from_producer_u32: \"));\n    byte_array_string(SF (String) &from_producer_u32_str, t0, numBytes_U32);\n    api_logInfo__bit_codec_Bit_Codec_Filter_proc_filter(SF (String) &from_producer_u32_str);\n    *\/\n  }\n\n  uint8_t t1[numBytes_bit_codec_Bit_Codec_Latitude];\n  size_t t1_numBits;\n  if(api_get_from_producer_latitude__bit_codec_Bit_Codec_Filter_proc_filter(SF &t1_numBits, t1)) {\n    \/\/ sanity check\n    sfAssert((Z) t1_numBits == numBits_bit_codec_Bit_Codec_Latitude, \"numBits received does not match expected\")\n\n    printf(\"%s: Received data on data port from_producer_latitude: \\n\", component_id);\n    hex_dump(SF t1, numBytes_bit_codec_Bit_Codec_Latitude);\n\n    \/* alternative using logInfo.  Commented out as the constructed String may be too large\n    DeclNewString(from_producer_latitude_str);\n    String__append(SF (String) &from_producer_latitude_str, string(\"Received data on data port from_producer_latitude: \"));\n    byte_array_string(SF (String) &from_producer_latitude_str, t1, numBytes_bit_codec_Bit_Codec_Latitude);\n    api_logInfo__bit_codec_Bit_Codec_Filter_proc_filter(SF (String) &from_producer_latitude_str);\n    *\/\n  }\n\n  uint8_t t2[numBytes_bit_codec_Bit_Codec_Longitude];\n  size_t t2_numBits;\n  if(api_get_from_producer_longitude__bit_codec_Bit_Codec_Filter_proc_filter(SF &t2_numBits, t2)) {\n    \/\/ sanity check\n    sfAssert((Z) t2_numBits == numBits_bit_codec_Bit_Codec_Longitude, \"numBits received does not match expected\")\n\n    printf(\"%s: Received data on data port from_producer_longitude: \\n\", component_id);\n    hex_dump(SF t2, numBytes_bit_codec_Bit_Codec_Longitude);\n\n    \/* alternative using logInfo.  Commented out as the constructed String may be too large\n    DeclNewString(from_producer_longitude_str);\n    String__append(SF (String) &from_producer_longitude_str, string(\"Received data on data port from_producer_longitude: \"));\n    byte_array_string(SF (String) &from_producer_longitude_str, t2, numBytes_bit_codec_Bit_Codec_Longitude);\n    api_logInfo__bit_codec_Bit_Codec_Filter_proc_filter(SF (String) &from_producer_longitude_str);\n    *\/\n  }\n\n  uint8_t t3[numBytes_bit_codec_Bit_Codec_Coordinate_Impl];\n  size_t t3_numBits;\n  if(api_get_from_producer_coordinate__bit_codec_Bit_Codec_Filter_proc_filter(SF &t3_numBits, t3)) {\n    \/\/ sanity check\n    sfAssert((Z) t3_numBits == numBits_bit_codec_Bit_Codec_Coordinate_Impl, \"numBits received does not match expected\")\n\n    printf(\"%s: Received data on data port from_producer_coordinate: \\n\", component_id);\n    hex_dump(SF t3, numBytes_bit_codec_Bit_Codec_Coordinate_Impl);\n\n    \/* alternative using logInfo.  Commented out as the constructed String may be too large\n    DeclNewString(from_producer_coordinate_str);\n    String__append(SF (String) &from_producer_coordinate_str, string(\"Received data on data port from_producer_coordinate: \"));\n    byte_array_string(SF (String) &from_producer_coordinate_str, t3, numBytes_bit_codec_Bit_Codec_Coordinate_Impl);\n    api_logInfo__bit_codec_Bit_Codec_Filter_proc_filter(SF (String) &from_producer_coordinate_str);\n    *\/\n  }\n\n  uint8_t t4[numBytes_bit_codec_Bit_Codec_Mission];\n  size_t t4_numBits;\n  if(api_get_from_producer_mission__bit_codec_Bit_Codec_Filter_proc_filter(SF &t4_numBits, t4)) {\n    \/\/ sanity check\n    sfAssert((Z) t4_numBits == numBits_bit_codec_Bit_Codec_Mission, \"numBits received does not match expected\")\n\n    printf(\"%s: Received data on event data port from_producer_mission: \\n\", component_id);\n    hex_dump(SF t4, numBytes_bit_codec_Bit_Codec_Mission);\n\n    \/* alternative using logInfo.  Commented out as the constructed String may be too large\n    DeclNewString(from_producer_mission_str);\n    String__append(SF (String) &from_producer_mission_str, string(\"Received data on event data port from_producer_mission: \"));\n    byte_array_string(SF (String) &from_producer_mission_str, t4, numBytes_bit_codec_Bit_Codec_Mission);\n    api_logInfo__bit_codec_Bit_Codec_Filter_proc_filter(SF (String) &from_producer_mission_str);\n    *\/\n  }\n\n  if(api_get_from_producer_event__bit_codec_Bit_Codec_Filter_proc_filter(SF_LAST )){\n    printf(\"%s: Received event on from_producer_event\\n\", component_id);\n\n    \/* alternative using logInfo.  Commented out as the constructed String may be too large\n    String from_producer_event_str = string(\"Received event on event port from_producer_event\");\n    api_logInfo__bit_codec_Bit_Codec_Filter_proc_filter(SF from_producer_event_str);\n    *\/\n  }\n}\n\nUnit bit_codec_Bit_Codec_Filter_proc_filter_handle_from_producer_event_(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter.c\", \"\", \"bit_codec_Bit_Codec_Filter_proc_filter_handle_from_producer_event_\", 0);\n\n  printf(\"%s: bit_codec_Bit_Codec_Filter_proc_filter_handle_from_producer_event called\\n\", component_id);\n\n  \/* alternative using logInfo.  Commented out as the constructed String may be too large\n  DeclNewString(from_producer_eventString);\n  String__append(SF (String) &from_producer_eventString, string(\"bit_codec_Bit_Codec_Filter_proc_filter_handle_from_producer_event called\"));\n  api_logInfo__bit_codec_Bit_Codec_Filter_proc_filter (SF (String) &from_producer_eventString);\n  *\/\n\n  printf(\"%s: Received event on event port from_producer_event: \\n\", component_id);\n\n  \/* alternative using logInfo.  Commented out as the constructed String may be too large\n  String str = string(\"Received event on from_producer_event\");\n  api_logInfo__bit_codec_Bit_Codec_Filter_proc_filter(SF str);\n  *\/\n\n}\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "c\/ext-c\/Filter_proc_filter\/Filter_proc_filter_api.h",
        {
          "type" : "ITestResource",
          "content" : "#ifndef FILTER_PROC_FILTER_API_H\n#define FILTER_PROC_FILTER_API_H\n\n#include <all.h>\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\nbool api_get_from_producer_u32__bit_codec_Bit_Codec_Filter_proc_filter(\n  STACK_FRAME\n  size_t *numBits,\n  uint8_t *byteArray);\n\nbool api_get_from_producer_latitude__bit_codec_Bit_Codec_Filter_proc_filter(\n  STACK_FRAME\n  size_t *numBits,\n  uint8_t *byteArray);\n\nbool api_get_from_producer_longitude__bit_codec_Bit_Codec_Filter_proc_filter(\n  STACK_FRAME\n  size_t *numBits,\n  uint8_t *byteArray);\n\nbool api_get_from_producer_coordinate__bit_codec_Bit_Codec_Filter_proc_filter(\n  STACK_FRAME\n  size_t *numBits,\n  uint8_t *byteArray);\n\nvoid api_put_to_consumer_u32__bit_codec_Bit_Codec_Filter_proc_filter(\n  STACK_FRAME\n  size_t numBits,\n  uint8_t *byteArray);\n\nvoid api_put_to_consumer_latitude__bit_codec_Bit_Codec_Filter_proc_filter(\n  STACK_FRAME\n  size_t numBits,\n  uint8_t *byteArray);\n\nvoid api_put_to_consumer_longitude__bit_codec_Bit_Codec_Filter_proc_filter(\n  STACK_FRAME\n  size_t numBits,\n  uint8_t *byteArray);\n\nvoid api_put_to_consumer_coordinate__bit_codec_Bit_Codec_Filter_proc_filter(\n  STACK_FRAME\n  size_t numBits,\n  uint8_t *byteArray);\n\nbool api_get_from_producer_mission__bit_codec_Bit_Codec_Filter_proc_filter(\n  STACK_FRAME\n  size_t *numBits,\n  uint8_t *byteArray);\n\nvoid api_put_to_consumer_mission__bit_codec_Bit_Codec_Filter_proc_filter(\n  STACK_FRAME\n  size_t numBits,\n  uint8_t *byteArray);\n\nbool api_get_from_producer_event__bit_codec_Bit_Codec_Filter_proc_filter(STACK_FRAME_ONLY);\n\nvoid api_put_to_consumer_event__bit_codec_Bit_Codec_Filter_proc_filter(STACK_FRAME_ONLY);\n\nvoid api_logInfo__bit_codec_Bit_Codec_Filter_proc_filter(\n  STACK_FRAME\n  String str);\n\nvoid api_logDebug__bit_codec_Bit_Codec_Filter_proc_filter(\n  STACK_FRAME\n  String str);\n\nvoid api_logError__bit_codec_Bit_Codec_Filter_proc_filter(\n  STACK_FRAME\n  String str);\n\n#endif\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "c\/ext-c\/Filter_proc_filter\/Filter_proc_filter_api.c",
        {
          "type" : "ITestResource",
          "content" : "#include <Filter_proc_filter_api.h>\n#include <Filter_proc_filter.h>\n\nstatic bool apis_initialized = false;\nstatic struct bit_codec_Bit_Codec_Filter_Initialization_Api initialization_api;\nstatic struct bit_codec_Bit_Codec_Filter_Operational_Api operational_api;\n\nstatic void initialize_apis(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter.c\", \"\", \"initialize_apis\", 0);\n\n  \/\/ Option_21F319 = Option[bit_codec.Bit_Codec.Filter_Initialization_Api]\n  Option_21F319_get_(SF (bit_codec_Bit_Codec_Filter_Initialization_Api) &initialization_api, bit_codec_Bit_Codec_Filter_proc_filter_Bridge_c_initialization_api(SF_LAST));\n  \/\/ Option_2C7884 = Option[bit_codec.Bit_Codec.Filter_Operational_Api]\n  Option_2C7884_get_(SF (bit_codec_Bit_Codec_Filter_Operational_Api) &operational_api, bit_codec_Bit_Codec_Filter_proc_filter_Bridge_c_operational_api(SF_LAST));\n  apis_initialized = true;\n}\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\nbool api_get_from_producer_u32__bit_codec_Bit_Codec_Filter_proc_filter(\n  STACK_FRAME\n  size_t *numBits,\n  uint8_t *byteArray){\n  DeclNewStackFrame(caller, \"Filter_proc_filter_api.c\", \"\", \"api_get_from_producer_u32__bit_codec_Bit_Codec_Filter_proc_filter\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  \/\/ Option_30119F = Option[IS[Z, B]]\n  \/\/ Some_8D03B1 = Some[IS[Z, B]]\n  DeclNewOption_30119F(t_0);\n\n  bit_codec_Bit_Codec_Filter_Operational_Api_get_from_producer_u32_(\n    SF\n    (Option_30119F) &t_0,\n    &operational_api);\n\n  if(t_0.type == TSome_8D03B1){\n    *numBits = t_0.Some_8D03B1.value.size;\n    if(*numBits > 0) {\n      size_t numBytes = (*numBits - 1) \/ 8 + 1;\n      memcpy(byteArray, &t_0.Some_8D03B1.value.value, numBytes);\n    }\n    return true;\n  } else {\n    return false;\n  }\n}\n\nbool api_get_from_producer_latitude__bit_codec_Bit_Codec_Filter_proc_filter(\n  STACK_FRAME\n  size_t *numBits,\n  uint8_t *byteArray){\n  DeclNewStackFrame(caller, \"Filter_proc_filter_api.c\", \"\", \"api_get_from_producer_latitude__bit_codec_Bit_Codec_Filter_proc_filter\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  \/\/ Option_30119F = Option[IS[Z, B]]\n  \/\/ Some_8D03B1 = Some[IS[Z, B]]\n  DeclNewOption_30119F(t_0);\n\n  bit_codec_Bit_Codec_Filter_Operational_Api_get_from_producer_latitude_(\n    SF\n    (Option_30119F) &t_0,\n    &operational_api);\n\n  if(t_0.type == TSome_8D03B1){\n    *numBits = t_0.Some_8D03B1.value.size;\n    if(*numBits > 0) {\n      size_t numBytes = (*numBits - 1) \/ 8 + 1;\n      memcpy(byteArray, &t_0.Some_8D03B1.value.value, numBytes);\n    }\n    return true;\n  } else {\n    return false;\n  }\n}\n\nbool api_get_from_producer_longitude__bit_codec_Bit_Codec_Filter_proc_filter(\n  STACK_FRAME\n  size_t *numBits,\n  uint8_t *byteArray){\n  DeclNewStackFrame(caller, \"Filter_proc_filter_api.c\", \"\", \"api_get_from_producer_longitude__bit_codec_Bit_Codec_Filter_proc_filter\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  \/\/ Option_30119F = Option[IS[Z, B]]\n  \/\/ Some_8D03B1 = Some[IS[Z, B]]\n  DeclNewOption_30119F(t_0);\n\n  bit_codec_Bit_Codec_Filter_Operational_Api_get_from_producer_longitude_(\n    SF\n    (Option_30119F) &t_0,\n    &operational_api);\n\n  if(t_0.type == TSome_8D03B1){\n    *numBits = t_0.Some_8D03B1.value.size;\n    if(*numBits > 0) {\n      size_t numBytes = (*numBits - 1) \/ 8 + 1;\n      memcpy(byteArray, &t_0.Some_8D03B1.value.value, numBytes);\n    }\n    return true;\n  } else {\n    return false;\n  }\n}\n\nbool api_get_from_producer_coordinate__bit_codec_Bit_Codec_Filter_proc_filter(\n  STACK_FRAME\n  size_t *numBits,\n  uint8_t *byteArray){\n  DeclNewStackFrame(caller, \"Filter_proc_filter_api.c\", \"\", \"api_get_from_producer_coordinate__bit_codec_Bit_Codec_Filter_proc_filter\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  \/\/ Option_30119F = Option[IS[Z, B]]\n  \/\/ Some_8D03B1 = Some[IS[Z, B]]\n  DeclNewOption_30119F(t_0);\n\n  bit_codec_Bit_Codec_Filter_Operational_Api_get_from_producer_coordinate_(\n    SF\n    (Option_30119F) &t_0,\n    &operational_api);\n\n  if(t_0.type == TSome_8D03B1){\n    *numBits = t_0.Some_8D03B1.value.size;\n    if(*numBits > 0) {\n      size_t numBytes = (*numBits - 1) \/ 8 + 1;\n      memcpy(byteArray, &t_0.Some_8D03B1.value.value, numBytes);\n    }\n    return true;\n  } else {\n    return false;\n  }\n}\n\nvoid api_put_to_consumer_u32__bit_codec_Bit_Codec_Filter_proc_filter(\n  STACK_FRAME\n  size_t numBits,\n  uint8_t *byteArray) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter_api.c\", \"\", \"api_put_to_consumer_u32__bit_codec_Bit_Codec_Filter_proc_filter\", 0);\n\n  sfAssert((Z) numBits >= 0, \"numBits must be non-negative for IS[Z, B].\")\n  sfAssert((Z) numBits <= MaxIS_C4F575, \"numBits too large for IS[Z, B].\")\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  DeclNewIS_C4F575(t_0);\n\n  t_0.size = numBits;\n  if(numBits > 0) {\n    size_t numBytes = (numBits - 1) \/ 8 + 1;\n    memcpy(&t_0.value, byteArray, numBytes);\n  }\n\n  bit_codec_Bit_Codec_Filter_Initialization_Api_put_to_consumer_u32_(\n    SF\n    &initialization_api,\n    &t_0);\n}\n\nvoid api_put_to_consumer_latitude__bit_codec_Bit_Codec_Filter_proc_filter(\n  STACK_FRAME\n  size_t numBits,\n  uint8_t *byteArray) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter_api.c\", \"\", \"api_put_to_consumer_latitude__bit_codec_Bit_Codec_Filter_proc_filter\", 0);\n\n  sfAssert((Z) numBits >= 0, \"numBits must be non-negative for IS[Z, B].\")\n  sfAssert((Z) numBits <= MaxIS_C4F575, \"numBits too large for IS[Z, B].\")\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  DeclNewIS_C4F575(t_0);\n\n  t_0.size = numBits;\n  if(numBits > 0) {\n    size_t numBytes = (numBits - 1) \/ 8 + 1;\n    memcpy(&t_0.value, byteArray, numBytes);\n  }\n\n  bit_codec_Bit_Codec_Filter_Initialization_Api_put_to_consumer_latitude_(\n    SF\n    &initialization_api,\n    &t_0);\n}\n\nvoid api_put_to_consumer_longitude__bit_codec_Bit_Codec_Filter_proc_filter(\n  STACK_FRAME\n  size_t numBits,\n  uint8_t *byteArray) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter_api.c\", \"\", \"api_put_to_consumer_longitude__bit_codec_Bit_Codec_Filter_proc_filter\", 0);\n\n  sfAssert((Z) numBits >= 0, \"numBits must be non-negative for IS[Z, B].\")\n  sfAssert((Z) numBits <= MaxIS_C4F575, \"numBits too large for IS[Z, B].\")\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  DeclNewIS_C4F575(t_0);\n\n  t_0.size = numBits;\n  if(numBits > 0) {\n    size_t numBytes = (numBits - 1) \/ 8 + 1;\n    memcpy(&t_0.value, byteArray, numBytes);\n  }\n\n  bit_codec_Bit_Codec_Filter_Initialization_Api_put_to_consumer_longitude_(\n    SF\n    &initialization_api,\n    &t_0);\n}\n\nvoid api_put_to_consumer_coordinate__bit_codec_Bit_Codec_Filter_proc_filter(\n  STACK_FRAME\n  size_t numBits,\n  uint8_t *byteArray) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter_api.c\", \"\", \"api_put_to_consumer_coordinate__bit_codec_Bit_Codec_Filter_proc_filter\", 0);\n\n  sfAssert((Z) numBits >= 0, \"numBits must be non-negative for IS[Z, B].\")\n  sfAssert((Z) numBits <= MaxIS_C4F575, \"numBits too large for IS[Z, B].\")\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  DeclNewIS_C4F575(t_0);\n\n  t_0.size = numBits;\n  if(numBits > 0) {\n    size_t numBytes = (numBits - 1) \/ 8 + 1;\n    memcpy(&t_0.value, byteArray, numBytes);\n  }\n\n  bit_codec_Bit_Codec_Filter_Initialization_Api_put_to_consumer_coordinate_(\n    SF\n    &initialization_api,\n    &t_0);\n}\n\nbool api_get_from_producer_mission__bit_codec_Bit_Codec_Filter_proc_filter(\n  STACK_FRAME\n  size_t *numBits,\n  uint8_t *byteArray){\n  DeclNewStackFrame(caller, \"Filter_proc_filter_api.c\", \"\", \"api_get_from_producer_mission__bit_codec_Bit_Codec_Filter_proc_filter\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  \/\/ Option_30119F = Option[IS[Z, B]]\n  \/\/ Some_8D03B1 = Some[IS[Z, B]]\n  DeclNewOption_30119F(t_0);\n\n  bit_codec_Bit_Codec_Filter_Operational_Api_get_from_producer_mission_(\n    SF\n    (Option_30119F) &t_0,\n    &operational_api);\n\n  if(t_0.type == TSome_8D03B1){\n    *numBits = t_0.Some_8D03B1.value.size;\n    if(*numBits > 0) {\n      size_t numBytes = (*numBits - 1) \/ 8 + 1;\n      memcpy(byteArray, &t_0.Some_8D03B1.value.value, numBytes);\n    }\n    return true;\n  } else {\n    return false;\n  }\n}\n\nvoid api_put_to_consumer_mission__bit_codec_Bit_Codec_Filter_proc_filter(\n  STACK_FRAME\n  size_t numBits,\n  uint8_t *byteArray) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter_api.c\", \"\", \"api_put_to_consumer_mission__bit_codec_Bit_Codec_Filter_proc_filter\", 0);\n\n  sfAssert((Z) numBits >= 0, \"numBits must be non-negative for IS[Z, B].\")\n  sfAssert((Z) numBits <= MaxIS_C4F575, \"numBits too large for IS[Z, B].\")\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  DeclNewIS_C4F575(t_0);\n\n  t_0.size = numBits;\n  if(numBits > 0) {\n    size_t numBytes = (numBits - 1) \/ 8 + 1;\n    memcpy(&t_0.value, byteArray, numBytes);\n  }\n\n  bit_codec_Bit_Codec_Filter_Initialization_Api_put_to_consumer_mission_(\n    SF\n    &initialization_api,\n    &t_0);\n}\n\nbool api_get_from_producer_event__bit_codec_Bit_Codec_Filter_proc_filter(STACK_FRAME_ONLY){\n  DeclNewStackFrame(caller, \"Filter_proc_filter_api.c\", \"\", \"api_get_from_producer_event__bit_codec_Bit_Codec_Filter_proc_filter\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  \/\/ Option_C622DB = Option[art.Empty]\n  \/\/ Some_4782C6 = Some[art.Empty]\n  DeclNewOption_C622DB(t_0);\n  bit_codec_Bit_Codec_Filter_Operational_Api_get_from_producer_event_(\n    SF\n    (Option_C622DB) &t_0,\n    &operational_api);\n\n  if(t_0.type == TSome_4782C6){\n    return true;\n  } else {\n    return false;\n  }\n}\n\nvoid api_put_to_consumer_event__bit_codec_Bit_Codec_Filter_proc_filter(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter_api.c\", \"\", \"api_put_to_consumer_event__bit_codec_Bit_Codec_Filter_proc_filter\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  bit_codec_Bit_Codec_Filter_Initialization_Api_put_to_consumer_event_(\n    SF\n    &initialization_api);\n}\n\nvoid api_logInfo__bit_codec_Bit_Codec_Filter_proc_filter(\n  STACK_FRAME\n  String str) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter_api.c\", \"\", \"api_logInfo__bit_codec_Bit_Codec_Filter_proc_filter\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  bit_codec_Bit_Codec_Filter_Initialization_Api_logInfo_(\n    SF\n    &initialization_api,\n    str);\n}\n\nvoid api_logDebug__bit_codec_Bit_Codec_Filter_proc_filter(\n  STACK_FRAME\n  String str) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter_api.c\", \"\", \"api_logDebug__bit_codec_Bit_Codec_Filter_proc_filter\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  bit_codec_Bit_Codec_Filter_Initialization_Api_logDebug_(\n    SF\n    &initialization_api,\n    str);\n}\n\nvoid api_logError__bit_codec_Bit_Codec_Filter_proc_filter(\n  STACK_FRAME\n  String str) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter_api.c\", \"\", \"api_logError__bit_codec_Bit_Codec_Filter_proc_filter\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  bit_codec_Bit_Codec_Filter_Initialization_Api_logError_(\n    SF\n    &initialization_api,\n    str);\n}\n\nUnit bit_codec_Bit_Codec_Filter_proc_filter_initialise(\n  STACK_FRAME\n  bit_codec_Bit_Codec_Filter_Initialization_Api api) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter_api.c\", \"\", \"bit_codec_Bit_Codec_Filter_proc_filter_initialise\", 0);\n\n  bit_codec_Bit_Codec_Filter_proc_filter_initialise_(SF_LAST);\n}\n\nUnit bit_codec_Bit_Codec_Filter_proc_filter_finalise(\n  STACK_FRAME\n  bit_codec_Bit_Codec_Filter_Operational_Api api) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter_api.c\", \"\", \"bit_codec_Bit_Codec_Filter_proc_filter_finalise\", 0);\n\n  bit_codec_Bit_Codec_Filter_proc_filter_finalise_(SF_LAST);\n}\n\nUnit bit_codec_Bit_Codec_Filter_proc_filter_handle_from_producer_mission(\n  STACK_FRAME\n  bit_codec_Bit_Codec_Filter_Operational_Api api,\n  IS_C4F575 value) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter_api.c\", \"\", \"bit_codec_Bit_Codec_Filter_proc_filter_handle_from_producer_mission\", 0);\n\n  bit_codec_Bit_Codec_Filter_proc_filter_handle_from_producer_mission_(SF value);\n}\n\nUnit bit_codec_Bit_Codec_Filter_proc_filter_handle_from_producer_event(\n  STACK_FRAME\n  bit_codec_Bit_Codec_Filter_Operational_Api api) {\n  DeclNewStackFrame(caller, \"Filter_proc_filter_api.c\", \"\", \"bit_codec_Bit_Codec_Filter_proc_filter_handle_from_producer_event\", 0);\n\n  bit_codec_Bit_Codec_Filter_proc_filter_handle_from_producer_event_(SF_LAST);\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/nix\/bit_codec\/Consumer_proc_consumer_App.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage bit_codec\n\nimport org.sireum._\nimport art._\nimport art.Art.PortId._\nimport art.scheduling.nop.NopScheduler\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\nobject Consumer_proc_consumer_App extends App {\n\n  val entryPoints: Bridge.EntryPoints = Arch.Bit_Codec_Sys_Impl_Instance_proc_consumer.entryPoints\n  val appPortId: Art.PortId = IPCPorts.Consumer_proc_consumer_App\n  val appPortIdOpt: Option[Art.PortId] = Some(appPortId)\n\n  \/\/ incoming ports\n  val from_filter_u32PortId: Art.PortId = Arch.Bit_Codec_Sys_Impl_Instance_proc_consumer.from_filter_u32.id\n  val from_filter_u32PortIdOpt: Option[Art.PortId] = Some(from_filter_u32PortId)\n  val from_filter_latitudePortId: Art.PortId = Arch.Bit_Codec_Sys_Impl_Instance_proc_consumer.from_filter_latitude.id\n  val from_filter_latitudePortIdOpt: Option[Art.PortId] = Some(from_filter_latitudePortId)\n  val from_filter_longitudePortId: Art.PortId = Arch.Bit_Codec_Sys_Impl_Instance_proc_consumer.from_filter_longitude.id\n  val from_filter_longitudePortIdOpt: Option[Art.PortId] = Some(from_filter_longitudePortId)\n  val from_filter_coordinatePortId: Art.PortId = Arch.Bit_Codec_Sys_Impl_Instance_proc_consumer.from_filter_coordinate.id\n  val from_filter_coordinatePortIdOpt: Option[Art.PortId] = Some(from_filter_coordinatePortId)\n  val from_filter_missionPortId: Art.PortId = Arch.Bit_Codec_Sys_Impl_Instance_proc_consumer.from_filter_mission.id\n  val from_filter_missionPortIdOpt: Option[Art.PortId] = Some(from_filter_missionPortId)\n  val from_filter_eventPortId: Art.PortId = Arch.Bit_Codec_Sys_Impl_Instance_proc_consumer.from_filter_event.id\n  val from_filter_eventPortIdOpt: Option[Art.PortId] = Some(from_filter_eventPortId)\n\n  def initialiseArchitecture(seed: Z): Unit = {\n    PlatformComm.initialise(seed, appPortIdOpt)\n    PlatformComm.initialise(seed, from_filter_u32PortIdOpt)\n    PlatformComm.initialise(seed, from_filter_latitudePortIdOpt)\n    PlatformComm.initialise(seed, from_filter_longitudePortIdOpt)\n    PlatformComm.initialise(seed, from_filter_coordinatePortIdOpt)\n    PlatformComm.initialise(seed, from_filter_missionPortIdOpt)\n    PlatformComm.initialise(seed, from_filter_eventPortIdOpt)\n\n    Art.run(Arch.ad, NopScheduler())\n  }\n\n  def initialise(): Unit = {\n    entryPoints.initialise()\n  }\n\n  def compute(): Unit = {\n\n    {\n      val out = IPCPorts.emptyReceiveAsyncOut\n      PlatformComm.receiveAsync(from_filter_u32PortIdOpt, out)\n      out.value2 match {\n        case Some(v: Base_Types.Bits_Payload) => ArtNix.updateData(from_filter_u32PortId, v)\n        case Some(v) => halt(s\"Unexpected payload on port from_filter_u32.  Expecting something of type Base_Types.Bits_Payload but received ${v}\")\n        case None() => \/\/ do nothing\n      }\n    }\n    {\n      val out = IPCPorts.emptyReceiveAsyncOut\n      PlatformComm.receiveAsync(from_filter_latitudePortIdOpt, out)\n      out.value2 match {\n        case Some(v: Base_Types.Bits_Payload) => ArtNix.updateData(from_filter_latitudePortId, v)\n        case Some(v) => halt(s\"Unexpected payload on port from_filter_latitude.  Expecting something of type Base_Types.Bits_Payload but received ${v}\")\n        case None() => \/\/ do nothing\n      }\n    }\n    {\n      val out = IPCPorts.emptyReceiveAsyncOut\n      PlatformComm.receiveAsync(from_filter_longitudePortIdOpt, out)\n      out.value2 match {\n        case Some(v: Base_Types.Bits_Payload) => ArtNix.updateData(from_filter_longitudePortId, v)\n        case Some(v) => halt(s\"Unexpected payload on port from_filter_longitude.  Expecting something of type Base_Types.Bits_Payload but received ${v}\")\n        case None() => \/\/ do nothing\n      }\n    }\n    {\n      val out = IPCPorts.emptyReceiveAsyncOut\n      PlatformComm.receiveAsync(from_filter_coordinatePortIdOpt, out)\n      out.value2 match {\n        case Some(v: Base_Types.Bits_Payload) => ArtNix.updateData(from_filter_coordinatePortId, v)\n        case Some(v) => halt(s\"Unexpected payload on port from_filter_coordinate.  Expecting something of type Base_Types.Bits_Payload but received ${v}\")\n        case None() => \/\/ do nothing\n      }\n    }\n    {\n      val out = IPCPorts.emptyReceiveAsyncOut\n      PlatformComm.receiveAsync(from_filter_missionPortIdOpt, out)\n      out.value2 match {\n        case Some(v: Base_Types.Bits_Payload) => ArtNix.updateData(from_filter_missionPortId, v)\n        case Some(v) => halt(s\"Unexpected payload on port from_filter_mission.  Expecting something of type Base_Types.Bits_Payload but received ${v}\")\n        case None() => \/\/ do nothing\n      }\n    }\n    {\n      val out = IPCPorts.emptyReceiveAsyncOut\n      PlatformComm.receiveAsync(from_filter_eventPortIdOpt, out)\n      out.value2 match {\n        case Some(v: art.Empty) => ArtNix.updateData(from_filter_eventPortId, v)\n        case Some(v) => halt(s\"Unexpected payload on port from_filter_event.  Expecting something of type art.Empty but received ${v}\")\n        case None() => \/\/ do nothing\n      }\n    }\n    entryPoints.compute()\n    bit_codec.Process.sleep(1000)\n  }\n\n  def finalise(): Unit = {\n    entryPoints.finalise()\n  }\n\n  def main(args: ISZ[String]): Z = {\n\n    val seed: Z = if (args.size == z\"1\") {\n      val n = Z(args(0)).get\n      if (n == z\"0\") 1 else n\n    } else {\n      1\n    }\n\n    initialiseArchitecture(seed)\n\n    PlatformComm.receive(appPortIdOpt, IPCPorts.emptyReceiveOut) \/\/ pause after setting up component\n\n    initialise()\n\n    PlatformComm.receive(appPortIdOpt, IPCPorts.emptyReceiveOut) \/\/ pause after component init\n\n    println(\"Consumer_proc_consumer_App starting ...\")\n\n    ArtNix.timeDispatch()\n\n    var terminated = F\n    while (!terminated) {\n      val out = IPCPorts.emptyReceiveAsyncOut\n      PlatformComm.receiveAsync(appPortIdOpt, out)\n      if (out.value2.isEmpty) {\n        compute()\n      } else {\n        terminated = T\n      }\n    }\n    exit()\n\n    touch()\n\n    return 0\n  }\n\n  def touch(): Unit = {\n    if(F) {\n      TranspilerToucher.touch()\n\n      \/\/ add types used in Platform.receive and Platform.receiveAsync\n      val mbox2Boolean_Payload: MBox2[Art.PortId, DataContent] = MBox2(portId\"0\", Base_Types.Boolean_Payload(T))\n      val mbox2OptionDataContent: MBox2[Art.PortId, Option[DataContent]] = MBox2(portId\"0\", None())\n\n      \/\/ touch each payload\/type in case some are only used as a field in a record\n      def printDataContent(a: art.DataContent): Unit = { println(s\"${a}\") }\n\n      printDataContent(Base_Types.Bits_Payload(Base_Types.Bits_example()))\n      printDataContent(art.Empty())\n\n      bit_codec.Bit_Codec.Consumer_proc_consumer_Bridge.c_initialization_api.get.logInfo(\"\")\n      bit_codec.Bit_Codec.Consumer_proc_consumer_Bridge.c_initialization_api.get.logDebug(\"\")\n      bit_codec.Bit_Codec.Consumer_proc_consumer_Bridge.c_initialization_api.get.logError(\"\")\n      bit_codec.Bit_Codec.Consumer_proc_consumer_Bridge.c_operational_api.get.logInfo(\"\")\n      bit_codec.Bit_Codec.Consumer_proc_consumer_Bridge.c_operational_api.get.logDebug(\"\")\n      bit_codec.Bit_Codec.Consumer_proc_consumer_Bridge.c_operational_api.get.logError(\"\")\n      val apiUsage_from_filter_u32: Option[Base_Types.Bits] = bit_codec.Bit_Codec.Consumer_proc_consumer_Bridge.c_operational_api.get.get_from_filter_u32()\n      val apiUsage_from_filter_latitude: Option[Base_Types.Bits] = bit_codec.Bit_Codec.Consumer_proc_consumer_Bridge.c_operational_api.get.get_from_filter_latitude()\n      val apiUsage_from_filter_longitude: Option[Base_Types.Bits] = bit_codec.Bit_Codec.Consumer_proc_consumer_Bridge.c_operational_api.get.get_from_filter_longitude()\n      val apiUsage_from_filter_coordinate: Option[Base_Types.Bits] = bit_codec.Bit_Codec.Consumer_proc_consumer_Bridge.c_operational_api.get.get_from_filter_coordinate()\n      val apiUsage_from_filter_mission: Option[Base_Types.Bits] = bit_codec.Bit_Codec.Consumer_proc_consumer_Bridge.c_operational_api.get.get_from_filter_mission()\n      val apiUsage_from_filter_event: Option[art.Empty] = bit_codec.Bit_Codec.Consumer_proc_consumer_Bridge.c_operational_api.get.get_from_filter_event()\n    }\n  }\n\n  def exit(): Unit = {\n    finalise()\n    PlatformComm.finalise()\n  }\n\n  override def atExit(): Unit = {\n    exit()\n  }\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "c\/ext-c\/Consumer_proc_consumer\/Consumer_proc_consumer.h",
        {
          "type" : "ITestResource",
          "content" : "#ifndef CONSUMER_PROC_CONSUMER_H\n#define CONSUMER_PROC_CONSUMER_H\n\n#include <all.h>\n\nUnit bit_codec_Bit_Codec_Consumer_proc_consumer_initialise_(STACK_FRAME_ONLY);\n\nUnit bit_codec_Bit_Codec_Consumer_proc_consumer_finalise_(STACK_FRAME_ONLY);\n\nUnit bit_codec_Bit_Codec_Consumer_proc_consumer_timeTriggered_(STACK_FRAME_ONLY);\n\n#endif\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "c\/ext-c\/Consumer_proc_consumer\/Consumer_proc_consumer.c",
        {
          "type" : "ITestResource",
          "content" : "#include <Consumer_proc_consumer_api.h>\n#include <Consumer_proc_consumer.h>\n#include <ext.h>\n\n\/\/ This file will not be overwritten so is safe to edit\n\nstatic char* component_id = \"Bit_Codec_Sys_Impl_Instance_proc_consumer\";\n\nUnit bit_codec_Bit_Codec_Consumer_proc_consumer_initialise_(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer.c\", \"\", \"bit_codec_Bit_Codec_Consumer_proc_consumer_initialise_\", 0);\n\n  printf(\"%s: bit_codec_Bit_Codec_Consumer_proc_consumer_initialise_ called\\n\", component_id);\n\n  \/\/ example usage of api setters\n\n\n  \/* example usage of api loggers. Commented out as the constructed String may be too long\n  api_logInfo__bit_codec_Bit_Codec_Consumer_proc_consumer(SF string(\"Example logInfo\"));\n\n  api_logDebug__bit_codec_Bit_Codec_Consumer_proc_consumer(SF string(\"Example logDebug\"));\n\n  api_logError__bit_codec_Bit_Codec_Consumer_proc_consumer(SF string(\"Example logError\"));\n  *\/\n}\n\nUnit bit_codec_Bit_Codec_Consumer_proc_consumer_finalise_(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer.c\", \"\", \"bit_codec_Bit_Codec_Consumer_proc_consumer_finalise_\", 0);\n}\n\nUnit bit_codec_Bit_Codec_Consumer_proc_consumer_timeTriggered_(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer.c\", \"\", \"bit_codec_Bit_Codec_Consumer_proc_consumer_timeTriggered_\", 0);\n\n  \/\/ examples of api getter usage\n\n  uint8_t t0[numBytes_U32];\n  size_t t0_numBits;\n  if(api_get_from_filter_u32__bit_codec_Bit_Codec_Consumer_proc_consumer(SF &t0_numBits, t0)) {\n    \/\/ sanity check\n    sfAssert((Z) t0_numBits == numBits_U32, \"numBits received does not match expected\")\n\n    printf(\"%s: Received data on data port from_filter_u32: \\n\", component_id);\n    hex_dump(SF t0, numBytes_U32);\n\n    \/* alternative using logInfo.  Commented out as the constructed String may be too large\n    DeclNewString(from_filter_u32_str);\n    String__append(SF (String) &from_filter_u32_str, string(\"Received data on data port from_filter_u32: \"));\n    byte_array_string(SF (String) &from_filter_u32_str, t0, numBytes_U32);\n    api_logInfo__bit_codec_Bit_Codec_Consumer_proc_consumer(SF (String) &from_filter_u32_str);\n    *\/\n  }\n\n  uint8_t t1[numBytes_bit_codec_Bit_Codec_Latitude];\n  size_t t1_numBits;\n  if(api_get_from_filter_latitude__bit_codec_Bit_Codec_Consumer_proc_consumer(SF &t1_numBits, t1)) {\n    \/\/ sanity check\n    sfAssert((Z) t1_numBits == numBits_bit_codec_Bit_Codec_Latitude, \"numBits received does not match expected\")\n\n    printf(\"%s: Received data on data port from_filter_latitude: \\n\", component_id);\n    hex_dump(SF t1, numBytes_bit_codec_Bit_Codec_Latitude);\n\n    \/* alternative using logInfo.  Commented out as the constructed String may be too large\n    DeclNewString(from_filter_latitude_str);\n    String__append(SF (String) &from_filter_latitude_str, string(\"Received data on data port from_filter_latitude: \"));\n    byte_array_string(SF (String) &from_filter_latitude_str, t1, numBytes_bit_codec_Bit_Codec_Latitude);\n    api_logInfo__bit_codec_Bit_Codec_Consumer_proc_consumer(SF (String) &from_filter_latitude_str);\n    *\/\n  }\n\n  uint8_t t2[numBytes_bit_codec_Bit_Codec_Longitude];\n  size_t t2_numBits;\n  if(api_get_from_filter_longitude__bit_codec_Bit_Codec_Consumer_proc_consumer(SF &t2_numBits, t2)) {\n    \/\/ sanity check\n    sfAssert((Z) t2_numBits == numBits_bit_codec_Bit_Codec_Longitude, \"numBits received does not match expected\")\n\n    printf(\"%s: Received data on data port from_filter_longitude: \\n\", component_id);\n    hex_dump(SF t2, numBytes_bit_codec_Bit_Codec_Longitude);\n\n    \/* alternative using logInfo.  Commented out as the constructed String may be too large\n    DeclNewString(from_filter_longitude_str);\n    String__append(SF (String) &from_filter_longitude_str, string(\"Received data on data port from_filter_longitude: \"));\n    byte_array_string(SF (String) &from_filter_longitude_str, t2, numBytes_bit_codec_Bit_Codec_Longitude);\n    api_logInfo__bit_codec_Bit_Codec_Consumer_proc_consumer(SF (String) &from_filter_longitude_str);\n    *\/\n  }\n\n  uint8_t t3[numBytes_bit_codec_Bit_Codec_Coordinate_Impl];\n  size_t t3_numBits;\n  if(api_get_from_filter_coordinate__bit_codec_Bit_Codec_Consumer_proc_consumer(SF &t3_numBits, t3)) {\n    \/\/ sanity check\n    sfAssert((Z) t3_numBits == numBits_bit_codec_Bit_Codec_Coordinate_Impl, \"numBits received does not match expected\")\n\n    printf(\"%s: Received data on data port from_filter_coordinate: \\n\", component_id);\n    hex_dump(SF t3, numBytes_bit_codec_Bit_Codec_Coordinate_Impl);\n\n    \/* alternative using logInfo.  Commented out as the constructed String may be too large\n    DeclNewString(from_filter_coordinate_str);\n    String__append(SF (String) &from_filter_coordinate_str, string(\"Received data on data port from_filter_coordinate: \"));\n    byte_array_string(SF (String) &from_filter_coordinate_str, t3, numBytes_bit_codec_Bit_Codec_Coordinate_Impl);\n    api_logInfo__bit_codec_Bit_Codec_Consumer_proc_consumer(SF (String) &from_filter_coordinate_str);\n    *\/\n  }\n\n  uint8_t t4[numBytes_bit_codec_Bit_Codec_Mission];\n  size_t t4_numBits;\n  if(api_get_from_filter_mission__bit_codec_Bit_Codec_Consumer_proc_consumer(SF &t4_numBits, t4)) {\n    \/\/ sanity check\n    sfAssert((Z) t4_numBits == numBits_bit_codec_Bit_Codec_Mission, \"numBits received does not match expected\")\n\n    printf(\"%s: Received data on event data port from_filter_mission: \\n\", component_id);\n    hex_dump(SF t4, numBytes_bit_codec_Bit_Codec_Mission);\n\n    \/* alternative using logInfo.  Commented out as the constructed String may be too large\n    DeclNewString(from_filter_mission_str);\n    String__append(SF (String) &from_filter_mission_str, string(\"Received data on event data port from_filter_mission: \"));\n    byte_array_string(SF (String) &from_filter_mission_str, t4, numBytes_bit_codec_Bit_Codec_Mission);\n    api_logInfo__bit_codec_Bit_Codec_Consumer_proc_consumer(SF (String) &from_filter_mission_str);\n    *\/\n  }\n\n  if(api_get_from_filter_event__bit_codec_Bit_Codec_Consumer_proc_consumer(SF_LAST )){\n    printf(\"%s: Received event on from_filter_event\\n\", component_id);\n\n    \/* alternative using logInfo.  Commented out as the constructed String may be too large\n    String from_filter_event_str = string(\"Received event on event port from_filter_event\");\n    api_logInfo__bit_codec_Bit_Codec_Consumer_proc_consumer(SF from_filter_event_str);\n    *\/\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "c\/ext-c\/Consumer_proc_consumer\/Consumer_proc_consumer_api.h",
        {
          "type" : "ITestResource",
          "content" : "#ifndef CONSUMER_PROC_CONSUMER_API_H\n#define CONSUMER_PROC_CONSUMER_API_H\n\n#include <all.h>\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\nbool api_get_from_filter_u32__bit_codec_Bit_Codec_Consumer_proc_consumer(\n  STACK_FRAME\n  size_t *numBits,\n  uint8_t *byteArray);\n\nbool api_get_from_filter_latitude__bit_codec_Bit_Codec_Consumer_proc_consumer(\n  STACK_FRAME\n  size_t *numBits,\n  uint8_t *byteArray);\n\nbool api_get_from_filter_longitude__bit_codec_Bit_Codec_Consumer_proc_consumer(\n  STACK_FRAME\n  size_t *numBits,\n  uint8_t *byteArray);\n\nbool api_get_from_filter_coordinate__bit_codec_Bit_Codec_Consumer_proc_consumer(\n  STACK_FRAME\n  size_t *numBits,\n  uint8_t *byteArray);\n\nbool api_get_from_filter_mission__bit_codec_Bit_Codec_Consumer_proc_consumer(\n  STACK_FRAME\n  size_t *numBits,\n  uint8_t *byteArray);\n\nbool api_get_from_filter_event__bit_codec_Bit_Codec_Consumer_proc_consumer(STACK_FRAME_ONLY);\n\nvoid api_logInfo__bit_codec_Bit_Codec_Consumer_proc_consumer(\n  STACK_FRAME\n  String str);\n\nvoid api_logDebug__bit_codec_Bit_Codec_Consumer_proc_consumer(\n  STACK_FRAME\n  String str);\n\nvoid api_logError__bit_codec_Bit_Codec_Consumer_proc_consumer(\n  STACK_FRAME\n  String str);\n\n#endif\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "c\/ext-c\/Consumer_proc_consumer\/Consumer_proc_consumer_api.c",
        {
          "type" : "ITestResource",
          "content" : "#include <Consumer_proc_consumer_api.h>\n#include <Consumer_proc_consumer.h>\n\nstatic bool apis_initialized = false;\nstatic struct bit_codec_Bit_Codec_Consumer_Initialization_Api initialization_api;\nstatic struct bit_codec_Bit_Codec_Consumer_Operational_Api operational_api;\n\nstatic void initialize_apis(STACK_FRAME_ONLY) {\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer.c\", \"\", \"initialize_apis\", 0);\n\n  \/\/ Option_D48929 = Option[bit_codec.Bit_Codec.Consumer_Initialization_Api]\n  Option_D48929_get_(SF (bit_codec_Bit_Codec_Consumer_Initialization_Api) &initialization_api, bit_codec_Bit_Codec_Consumer_proc_consumer_Bridge_c_initialization_api(SF_LAST));\n  \/\/ Option_3F2E13 = Option[bit_codec.Bit_Codec.Consumer_Operational_Api]\n  Option_3F2E13_get_(SF (bit_codec_Bit_Codec_Consumer_Operational_Api) &operational_api, bit_codec_Bit_Codec_Consumer_proc_consumer_Bridge_c_operational_api(SF_LAST));\n  apis_initialized = true;\n}\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\nbool api_get_from_filter_u32__bit_codec_Bit_Codec_Consumer_proc_consumer(\n  STACK_FRAME\n  size_t *numBits,\n  uint8_t *byteArray){\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer_api.c\", \"\", \"api_get_from_filter_u32__bit_codec_Bit_Codec_Consumer_proc_consumer\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  \/\/ Option_30119F = Option[IS[Z, B]]\n  \/\/ Some_8D03B1 = Some[IS[Z, B]]\n  DeclNewOption_30119F(t_0);\n\n  bit_codec_Bit_Codec_Consumer_Operational_Api_get_from_filter_u32_(\n    SF\n    (Option_30119F) &t_0,\n    &operational_api);\n\n  if(t_0.type == TSome_8D03B1){\n    *numBits = t_0.Some_8D03B1.value.size;\n    if(*numBits > 0) {\n      size_t numBytes = (*numBits - 1) \/ 8 + 1;\n      memcpy(byteArray, &t_0.Some_8D03B1.value.value, numBytes);\n    }\n    return true;\n  } else {\n    return false;\n  }\n}\n\nbool api_get_from_filter_latitude__bit_codec_Bit_Codec_Consumer_proc_consumer(\n  STACK_FRAME\n  size_t *numBits,\n  uint8_t *byteArray){\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer_api.c\", \"\", \"api_get_from_filter_latitude__bit_codec_Bit_Codec_Consumer_proc_consumer\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  \/\/ Option_30119F = Option[IS[Z, B]]\n  \/\/ Some_8D03B1 = Some[IS[Z, B]]\n  DeclNewOption_30119F(t_0);\n\n  bit_codec_Bit_Codec_Consumer_Operational_Api_get_from_filter_latitude_(\n    SF\n    (Option_30119F) &t_0,\n    &operational_api);\n\n  if(t_0.type == TSome_8D03B1){\n    *numBits = t_0.Some_8D03B1.value.size;\n    if(*numBits > 0) {\n      size_t numBytes = (*numBits - 1) \/ 8 + 1;\n      memcpy(byteArray, &t_0.Some_8D03B1.value.value, numBytes);\n    }\n    return true;\n  } else {\n    return false;\n  }\n}\n\nbool api_get_from_filter_longitude__bit_codec_Bit_Codec_Consumer_proc_consumer(\n  STACK_FRAME\n  size_t *numBits,\n  uint8_t *byteArray){\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer_api.c\", \"\", \"api_get_from_filter_longitude__bit_codec_Bit_Codec_Consumer_proc_consumer\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  \/\/ Option_30119F = Option[IS[Z, B]]\n  \/\/ Some_8D03B1 = Some[IS[Z, B]]\n  DeclNewOption_30119F(t_0);\n\n  bit_codec_Bit_Codec_Consumer_Operational_Api_get_from_filter_longitude_(\n    SF\n    (Option_30119F) &t_0,\n    &operational_api);\n\n  if(t_0.type == TSome_8D03B1){\n    *numBits = t_0.Some_8D03B1.value.size;\n    if(*numBits > 0) {\n      size_t numBytes = (*numBits - 1) \/ 8 + 1;\n      memcpy(byteArray, &t_0.Some_8D03B1.value.value, numBytes);\n    }\n    return true;\n  } else {\n    return false;\n  }\n}\n\nbool api_get_from_filter_coordinate__bit_codec_Bit_Codec_Consumer_proc_consumer(\n  STACK_FRAME\n  size_t *numBits,\n  uint8_t *byteArray){\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer_api.c\", \"\", \"api_get_from_filter_coordinate__bit_codec_Bit_Codec_Consumer_proc_consumer\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  \/\/ Option_30119F = Option[IS[Z, B]]\n  \/\/ Some_8D03B1 = Some[IS[Z, B]]\n  DeclNewOption_30119F(t_0);\n\n  bit_codec_Bit_Codec_Consumer_Operational_Api_get_from_filter_coordinate_(\n    SF\n    (Option_30119F) &t_0,\n    &operational_api);\n\n  if(t_0.type == TSome_8D03B1){\n    *numBits = t_0.Some_8D03B1.value.size;\n    if(*numBits > 0) {\n      size_t numBytes = (*numBits - 1) \/ 8 + 1;\n      memcpy(byteArray, &t_0.Some_8D03B1.value.value, numBytes);\n    }\n    return true;\n  } else {\n    return false;\n  }\n}\n\nbool api_get_from_filter_mission__bit_codec_Bit_Codec_Consumer_proc_consumer(\n  STACK_FRAME\n  size_t *numBits,\n  uint8_t *byteArray){\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer_api.c\", \"\", \"api_get_from_filter_mission__bit_codec_Bit_Codec_Consumer_proc_consumer\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  \/\/ Option_30119F = Option[IS[Z, B]]\n  \/\/ Some_8D03B1 = Some[IS[Z, B]]\n  DeclNewOption_30119F(t_0);\n\n  bit_codec_Bit_Codec_Consumer_Operational_Api_get_from_filter_mission_(\n    SF\n    (Option_30119F) &t_0,\n    &operational_api);\n\n  if(t_0.type == TSome_8D03B1){\n    *numBits = t_0.Some_8D03B1.value.size;\n    if(*numBits > 0) {\n      size_t numBytes = (*numBits - 1) \/ 8 + 1;\n      memcpy(byteArray, &t_0.Some_8D03B1.value.value, numBytes);\n    }\n    return true;\n  } else {\n    return false;\n  }\n}\n\nbool api_get_from_filter_event__bit_codec_Bit_Codec_Consumer_proc_consumer(STACK_FRAME_ONLY){\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer_api.c\", \"\", \"api_get_from_filter_event__bit_codec_Bit_Codec_Consumer_proc_consumer\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  \/\/ Option_C622DB = Option[art.Empty]\n  \/\/ Some_4782C6 = Some[art.Empty]\n  DeclNewOption_C622DB(t_0);\n  bit_codec_Bit_Codec_Consumer_Operational_Api_get_from_filter_event_(\n    SF\n    (Option_C622DB) &t_0,\n    &operational_api);\n\n  if(t_0.type == TSome_4782C6){\n    return true;\n  } else {\n    return false;\n  }\n}\n\nvoid api_logInfo__bit_codec_Bit_Codec_Consumer_proc_consumer(\n  STACK_FRAME\n  String str) {\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer_api.c\", \"\", \"api_logInfo__bit_codec_Bit_Codec_Consumer_proc_consumer\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  bit_codec_Bit_Codec_Consumer_Initialization_Api_logInfo_(\n    SF\n    &initialization_api,\n    str);\n}\n\nvoid api_logDebug__bit_codec_Bit_Codec_Consumer_proc_consumer(\n  STACK_FRAME\n  String str) {\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer_api.c\", \"\", \"api_logDebug__bit_codec_Bit_Codec_Consumer_proc_consumer\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  bit_codec_Bit_Codec_Consumer_Initialization_Api_logDebug_(\n    SF\n    &initialization_api,\n    str);\n}\n\nvoid api_logError__bit_codec_Bit_Codec_Consumer_proc_consumer(\n  STACK_FRAME\n  String str) {\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer_api.c\", \"\", \"api_logError__bit_codec_Bit_Codec_Consumer_proc_consumer\", 0);\n\n  if(!apis_initialized) { initialize_apis(SF_LAST); }\n\n  bit_codec_Bit_Codec_Consumer_Initialization_Api_logError_(\n    SF\n    &initialization_api,\n    str);\n}\n\nUnit bit_codec_Bit_Codec_Consumer_proc_consumer_initialise(\n  STACK_FRAME\n  bit_codec_Bit_Codec_Consumer_Initialization_Api api) {\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer_api.c\", \"\", \"bit_codec_Bit_Codec_Consumer_proc_consumer_initialise\", 0);\n\n  bit_codec_Bit_Codec_Consumer_proc_consumer_initialise_(SF_LAST);\n}\n\nUnit bit_codec_Bit_Codec_Consumer_proc_consumer_finalise(\n  STACK_FRAME\n  bit_codec_Bit_Codec_Consumer_Operational_Api api) {\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer_api.c\", \"\", \"bit_codec_Bit_Codec_Consumer_proc_consumer_finalise\", 0);\n\n  bit_codec_Bit_Codec_Consumer_proc_consumer_finalise_(SF_LAST);\n}\n\nUnit bit_codec_Bit_Codec_Consumer_proc_consumer_timeTriggered(\n  STACK_FRAME\n  bit_codec_Bit_Codec_Consumer_Operational_Api api) {\n  DeclNewStackFrame(caller, \"Consumer_proc_consumer_api.c\", \"\", \"bit_codec_Bit_Codec_Consumer_proc_consumer_timeTriggered\", 0);\n\n  bit_codec_Bit_Codec_Consumer_proc_consumer_timeTriggered_(SF_LAST);\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "c\/ext-schedule\/legacy.c",
        {
          "type" : "ITestResource",
          "content" : "#include <all.h>\n\n\/\/ This file will not be overwritten so is safe to edit\n\nUnit art_scheduling_legacy_LegacyInterface_computePhase(STACK_FRAME IS_058E6F bridges) {\n  printf(\"Infeasible.  You should not get here in C\");\n  exit(1);\n}",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "c\/ext-schedule\/round_robin.c",
        {
          "type" : "ITestResource",
          "content" : "#include <all.h>\n#include <signal.h>\n\n\/\/ This file will not be overwritten so is safe to edit\n\n\/\/ Transpiled signature of the Slang variable bit_codec.Schedulers.roundRobinSchedule\n\/\/ in architecture\/bit_codec\/Schedulers.scala.  This weak function declaration allows\n\/\/ bit_codec_ScheduleProviderI_getRoundRobinOrder to detect whether the Slang variable was deleted\n__attribute__((weak)) IS_FDDCB6 bit_codec_Schedulers_roundRobinSchedule(STACK_FRAME_ONLY);\n\nvolatile sig_atomic_t shouldStop = 0;\n\n\/*!\n * Example C implementation of the Slang extension method bit_codec.ScheduleProviderI.getRoundRobinOrder()\n * defined in architecture\/bit_codec\/Schedulers.scala\n *\n * @param result an empty schedule.  Add components in the order you want them to be dispatched.\n *               IS_FDDCB6=ISZ[art.Art.BridgeId], i.e. an immutable sequence of art.Bridge\n *\/\nvoid bit_codec_ScheduleProviderI_getRoundRobinOrder(STACK_FRAME IS_FDDCB6 result) {\n  DeclNewStackFrame(caller, \"round_robin.c\", \"\", \"bit_codec_ScheduleProviderI_getRoundRobinOrder\", 0);\n\n  if(bit_codec_Schedulers_roundRobinSchedule) {\n    printf(\"Using the round robin order provided in architecture\/bit_codec\/Schedulers.scala. Edit method \\n\");\n    printf(\"  bit_codec_ScheduleProviderI_getRoundRobinOrder located in round_robin.c\\n\");\n    printf(\"to supply your own\\n\");\n\n    IS_FDDCB6 order = bit_codec_Schedulers_roundRobinSchedule(SF_LAST);\n    memcpy(result->value, order->value, sizeof(art_Art_BridgeId) * order->size);\n    result->size = order->size;\n\n  } else {\n    printf(\"Transpiled Slang variable bit_codec.Schedulers.roundRobinSchedule not found.  Using an example schedule from method\");\n    printf(\"  bit_codec_ScheduleProviderI_getRoundRobinOrder located in round_robin.c\\n\");\n\n    \/\/ example schedule\n    int i = 0;\n    IS_FDDCB6_up(result, i++, (art_Art_BridgeId) bit_codec_Arch_Bit_Codec_Sys_Impl_Instance_proc_producer(SF_LAST)->id);\n    IS_FDDCB6_up(result, i++, (art_Art_BridgeId) bit_codec_Arch_Bit_Codec_Sys_Impl_Instance_proc_filter(SF_LAST)->id);\n    IS_FDDCB6_up(result, i++, (art_Art_BridgeId) bit_codec_Arch_Bit_Codec_Sys_Impl_Instance_proc_consumer(SF_LAST)->id);\n\n    result->size = i;\n  }\n}\n\n\/*!\n * signal handler that sets shouldStop to true when invoked\n *\/\nvoid sigHandler(int signo) {\n  shouldStop = 1;\n}\n\n\/*!\n * Example C implementation of Slang extension method art.scheduling.roundrobin.RoundRobinExtensions.init()\n * defined in art\/scheduling\/roundrobin\/RoundRobin.scala.  The scheduler calls this\n * during the initialization phase\n *\n * It registers a signal handler that is used to shut down the demo when it receives\n * SIGINT (CTRL+C), SIGTERM\n *\/\nUnit art_scheduling_roundrobin_RoundRobinExtensions_init(STACK_FRAME_ONLY){\n  int sigs[] = {SIGINT, SIGTERM};\n  for(int i = 0; i < sizeof(sigs) \/ sizeof(int); i++){\n    if(signal(sigs[i], sigHandler) == SIG_ERR) {\n      printf(\"Error occurred while setting signal handler for %i\\n\", sigs[i]);\n      exit(-1);\n    }\n  }\n}\n\n\/*!\n * Example C implementation of Slang extension method art.scheduling.roundrobin.RoundRobinExtensions.shouldStop()\n * defined in art\/scheduling\/roundrobin\/RoundRobin.scala.  The scheduler calls this\n * during the compute phase to determine when it should transition to the finalize phase\n *\/\nB art_scheduling_roundrobin_RoundRobinExtensions_shouldStop(STACK_FRAME_ONLY){\n    return shouldStop == 1;\n}\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "c\/ext-schedule\/static_scheduler.c",
        {
          "type" : "ITestResource",
          "content" : "#include <all.h>\n\n\/\/ This file will not be overwritten so is safe to edit\n\n\/\/ Transpiled signature of the Slang variable bit_codec.Schedulers.staticSchedule\n\/\/ in architecture\/bit_codec\/Schedulers.scala.  This weak function declaration allows\n\/\/ bit_codec_ScheduleProviderI_getStaticSchedule to detect whether the Slang variable was deleted\n__attribute__((weak)) art_scheduling_static_Schedule_DScheduleSpec bit_codec_Schedulers_defaultStaticSchedule(STACK_FRAME_ONLY);\n\n\/\/ helper method\nvoid fillInSlot(IS_5AA467 slotSequence, int index, Z bridgeId, int length);\n\n\/*!\n * Example C implementation of the Slang extension method bit_codec.ScheduleProviderI.getStaticSchedule()\n * defined in architecture\/bit_codec\/Schedulers.scala\n *\n * @param result an empty schedule. Add slots in the order you want components to be dispatched.\n *\/\nvoid bit_codec_ScheduleProviderI_getStaticSchedule(STACK_FRAME art_scheduling_static_Schedule_DScheduleSpec result){\n  DeclNewStackFrame(caller, \"static_scheduler.c\", \"\", \"bit_codec_ScheduleProviderI_getStaticSchedule\", 0);\n\n  if(bit_codec_Schedulers_defaultStaticSchedule) {\n    printf(\"Using the static schedule provided in architecture\/bit_codec\/Schedulers.scala. Edit method \\n\");\n    printf(\"  bit_codec_ScheduleProviderI_getStaticSchedule located in static_scheduler.c\\n\");\n    printf(\"to supply your own\\n\");\n\n    art_scheduling_static_Schedule_DScheduleSpec schedule = bit_codec_Schedulers_defaultStaticSchedule(SF_LAST);\n    result->hyperPeriod = schedule->hyperPeriod;\n    result->maxDomain = schedule->maxDomain;\n    memcpy(&result->schedule, &schedule->schedule, sizeof(struct art_scheduling_static_Schedule_DSchedule));\n\n  } else {\n    printf(\"Transpiled Slang variable bit_codec.Schedulers.staticSchedule not found.  Using an example schedule from method\");\n    printf(\"  bit_codec_ScheduleProviderI_getStaticSchedule located in static_scheduler.c\\n\");\n\n    \/\/ IS_5AA467=IS[Z, art.scheduling.static.Schedule.Slot], i.e. an immutable sequence of art.scheduling.static.Schedule.Slot\n    DeclNewIS_5AA467(slotSequence);\n\n    Z length = 1000 \/ 3;\n\n    int i = 0;\n    fillInSlot(&slotSequence, i++, bit_codec_Arch_Bit_Codec_Sys_Impl_Instance_proc_producer(SF_LAST)->id, length);\n    fillInSlot(&slotSequence, i++, bit_codec_Arch_Bit_Codec_Sys_Impl_Instance_proc_filter(SF_LAST)->id, length);\n    fillInSlot(&slotSequence, i++, bit_codec_Arch_Bit_Codec_Sys_Impl_Instance_proc_consumer(SF_LAST)->id, length);\n    slotSequence.size = i;\n\n    DeclNewart_scheduling_static_Schedule_DSchedule(dschedule);\n    art_scheduling_static_Schedule_DSchedule_apply(SF &dschedule, &slotSequence);\n\n    Z maxDomain = 100;\n    Z hyperPeriod = 1000;\n\n    art_scheduling_static_Schedule_DScheduleSpec_apply(SF result, maxDomain, hyperPeriod, &dschedule);\n  }\n}\n\nvoid fillInSlot(IS_5AA467 slotSequence, int index, Z bridgeId, int length) {\n  \/\/ TODO: need to refactor to adjust to 2023.10 Slang changes\n  exit(1);\n  \/\/slotSequence->value[index].bridgeId = bridgeId;\n  \/\/slotSequence->value[index].length = length;\n}\n\nUnit art_scheduling_static_StaticSchedulerIO_message(STACK_FRAME String m) {\n  printf(\"%s\\n\", m->value);\n}\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "c\/ext-schedule\/process.c",
        {
          "type" : "ITestResource",
          "content" : "#include <all.h>\n\n#include <sys\/time.h>\n#include <time.h>\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\n\/** Returns current system time in milliseconds\n  * NOTE: this requires returning 64bit ints\n  *\/\nS64 art_Process_time(STACK_FRAME_ONLY) {\n  struct timeval tv; \/\/Get a time structure\n  gettimeofday(&tv, NULL); \/\/Get the current time\n  int64_t t = tv.tv_sec;\n  t *= 1000;\n  t += tv.tv_usec\/1000;\n  return  t;\n}\n\nUnit Os_Ext_exit(STACK_FRAME Z code) {\n  exit(code);\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "c\/ext-c\/ext.c",
        {
          "type" : "ITestResource",
          "content" : "#include <ext.h>\n\n\/\/ This file will not be overwritten so is safe to edit\n\n\/\/ add c extension code here\n\n\/\/ example method that sets the first numBits bits of byteArray to 1\nvoid byte_array_default(STACK_FRAME uint8_t* byteArray, size_t numBits, size_t numBytes) {\n  DeclNewStackFrame(caller, \"ext.c\", \"\", \"byte_array_default\", 0);\n\n  sfAssert((numBits - 1) \/ 8  + 1 <= numBytes, \"byte_array_default: numBytes * 8 must be at least numBits\")\n\n  for(size_t byte = 0; byte < numBytes; byte++) {\n    uint8_t v = 0;\n    for(uint8_t bit = 0; bit < 8; bit++) {\n      if(byte * 8 + bit < numBits) {\n        v |= 1UL << bit;\n      }\n    }\n    byteArray[byte] = v;\n  }\n}\n\n\/\/ example method that places the hex value of the bytes in byteArray into str\nvoid byte_array_string(STACK_FRAME String str, uint8_t* byteArray, size_t numBytes) {\n  DeclNewStackFrame(caller, \"ext.c\", \"\", \"byte_array_string\", 0);\n\n  sfAssert((str->size + numBytes) <= MaxString, \"byte_array_string: Insufficient maximum for String characters, consider increasing the --max-string-size option\")\n\n  for(size_t byte = 0; byte < numBytes; byte++) {\n    U8_string_(SF str, byteArray[byte]);\n    String__append(SF str, string(\" \"));\n  }\n}\n\n\/\/ example method that directly prints the hex values of the bytes in byte_array\nvoid hex_dump(STACK_FRAME uint8_t* byte_array, size_t numBytes) {\n  DeclNewStackFrame(caller, \"ext.c\", \"\", \"hex_dump\", 0);\n\n  printf(\"[ \");\n  for(size_t byte = 0; byte < numBytes; byte++) {\n    if(byte != 0 && byte % 16 == 0) { printf(\"\\n  \"); }\n    printf(\"%02X \", byte_array[byte]);\n  }\n  printf(\"]\\n\");\n}",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "c\/ext-c\/ext.h",
        {
          "type" : "ITestResource",
          "content" : "#ifndef EXT_H\n#define EXT_H\n\n\/\/ This file will not be overwritten so is safe to edit\n\n#include <all.h>\n\n\/\/ bit-codec size for U32\n#define numBits_U32 32\n#define numBytes_U32 ((numBits_U32 - 1) \/ 8 + 1)\n\n\/\/ bit-codec size for bit_codec_Bit_Codec_Latitude\n#define numBits_bit_codec_Bit_Codec_Latitude 32\n#define numBytes_bit_codec_Bit_Codec_Latitude ((numBits_bit_codec_Bit_Codec_Latitude - 1) \/ 8 + 1)\n\n\/\/ bit-codec size for bit_codec_Bit_Codec_Longitude\n#define numBits_bit_codec_Bit_Codec_Longitude 30\n#define numBytes_bit_codec_Bit_Codec_Longitude ((numBits_bit_codec_Bit_Codec_Longitude - 1) \/ 8 + 1)\n\n\/\/ bit-codec size for bit_codec_Bit_Codec_Coordinate_Impl\n#define numBits_bit_codec_Bit_Codec_Coordinate_Impl 60\n#define numBytes_bit_codec_Bit_Codec_Coordinate_Impl ((numBits_bit_codec_Bit_Codec_Coordinate_Impl - 1) \/ 8 + 1)\n\n\/\/ bit-codec size for bit_codec_Bit_Codec_Mission\n#define numBits_bit_codec_Bit_Codec_Mission 288\n#define numBytes_bit_codec_Bit_Codec_Mission ((numBits_bit_codec_Bit_Codec_Mission - 1) \/ 8 + 1)\n\nvoid byte_array_default(STACK_FRAME uint8_t* byteArray, size_t numBits, size_t numBytes);\n\nvoid byte_array_string(STACK_FRAME String str, uint8_t* byteArray, size_t numBytes);\n\nvoid hex_dump(STACK_FRAME uint8_t* byte_array, size_t numBytes);\n#endif",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/nix\/bit_codec\/SharedMemory.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage bit_codec\n\nimport org.sireum._\nimport art._\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\n@ext object SharedMemory {\n  def create(id: Z): Z = $\n  def get(id: Z): Z = $\n  def send(appId: Z, portId: Z, d: DataContent): Unit = $\n  def sendAsync(appId: Z, portId: Z, d: DataContent): B = $\n  def receive(portId: Z, out: MBox2[Art.PortId, DataContent]): Unit = $\n  def receiveAsync(portId: Z, out: MBox2[Art.PortId, Option[DataContent]]): Unit = $\n  def remove(id: Z): Unit = $\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/nix\/bit_codec\/SharedMemory_Ext.scala",
        {
          "type" : "ITestResource",
          "content" : "package bit_codec\n\nimport org.sireum._\nimport art._\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\nobject SharedMemory_Ext {\n  def create(id: Z): Z = halt(\"stub\")\n  def get(id: Z): Z = halt(\"stub\")\n  def send(appId: Z, portId: Z, d: DataContent): Unit = halt(\"stub\")\n  def sendAsync(appId: Z, portId: Z, d: DataContent): B = halt(\"stub\")\n  def receive(portId: Z, out: MBox2[Art.PortId, DataContent]): Unit = halt(\"stub\")\n  def receiveAsync(portId: Z, out: MBox2[Art.PortId, Option[DataContent]]): Unit = halt(\"stub\")\n  def remove(id: Z): Unit = halt(\"stub\")\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/nix\/bit_codec\/IPC.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage bit_codec\n\nimport org.sireum._\nimport art._\nimport art.Art.PortId._\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\nobject IPCPorts {\n  val Producer_proc_producer_App: Art.PortId = Art.PortId.fromZ(24)\n  val Filter_proc_filter_App: Art.PortId = Art.PortId.fromZ(25)\n  val Consumer_proc_consumer_App: Art.PortId = Art.PortId.fromZ(26)\n  val Main: Art.PortId = Art.PortId.fromZ(27)\n\n  def emptyReceiveOut: MBox2[Art.PortId, DataContent] = {\n    return MBox2(portId\"0\", art.Empty())\n  }\n\n  def emptyReceiveAsyncOut: MBox2[Art.PortId, Option[DataContent]] = {\n    return MBox2(portId\"0\", None())\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/nix\/bit_codec\/ArtNix.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage bit_codec\n\nimport org.sireum._\nimport art._\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\nobject ArtNix {\n\n  val maxPortIds: Z = IPCPorts.Main.toZ + 1\n  val timeTriggered: TimeTriggered = TimeTriggered()\n  val noData: Option[DataContent] = None()\n  val data: MS[Art.PortId, Option[DataContent]] = MS.create(maxPortIds, noData)\n  val connection: MS[Art.PortId, IS[Art.ConnectionId, (Art.PortId, Art.PortId)]] = {\n    \/\/ mapping from src ports to pairs holding the destination app port ids and component port ids\n    val r = MS.create[Art.PortId, IS[Art.ConnectionId, (Art.PortId, Art.PortId)]](maxPortIds, IS())\n\n    r(Arch.Bit_Codec_Sys_Impl_Instance_proc_producer.to_filter_u32.id) = IS(\n      (IPCPorts.Filter_proc_filter_App, Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.from_producer_u32.id)\n    )\n    r(Arch.Bit_Codec_Sys_Impl_Instance_proc_producer.to_filter_latitude.id) = IS(\n      (IPCPorts.Filter_proc_filter_App, Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.from_producer_latitude.id)\n    )\n    r(Arch.Bit_Codec_Sys_Impl_Instance_proc_producer.to_filter_longitude.id) = IS(\n      (IPCPorts.Filter_proc_filter_App, Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.from_producer_longitude.id)\n    )\n    r(Arch.Bit_Codec_Sys_Impl_Instance_proc_producer.to_filter_coordinate.id) = IS(\n      (IPCPorts.Filter_proc_filter_App, Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.from_producer_coordinate.id)\n    )\n    r(Arch.Bit_Codec_Sys_Impl_Instance_proc_producer.to_filter_mission.id) = IS(\n      (IPCPorts.Filter_proc_filter_App, Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.from_producer_mission.id)\n    )\n    r(Arch.Bit_Codec_Sys_Impl_Instance_proc_producer.to_filter_event.id) = IS(\n      (IPCPorts.Filter_proc_filter_App, Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.from_producer_event.id)\n    )\n    r(Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.to_consumer_u32.id) = IS(\n      (IPCPorts.Consumer_proc_consumer_App, Arch.Bit_Codec_Sys_Impl_Instance_proc_consumer.from_filter_u32.id)\n    )\n    r(Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.to_consumer_latitude.id) = IS(\n      (IPCPorts.Consumer_proc_consumer_App, Arch.Bit_Codec_Sys_Impl_Instance_proc_consumer.from_filter_latitude.id)\n    )\n    r(Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.to_consumer_longitude.id) = IS(\n      (IPCPorts.Consumer_proc_consumer_App, Arch.Bit_Codec_Sys_Impl_Instance_proc_consumer.from_filter_longitude.id)\n    )\n    r(Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.to_consumer_coordinate.id) = IS(\n      (IPCPorts.Consumer_proc_consumer_App, Arch.Bit_Codec_Sys_Impl_Instance_proc_consumer.from_filter_coordinate.id)\n    )\n    r(Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.to_consumer_mission.id) = IS(\n      (IPCPorts.Consumer_proc_consumer_App, Arch.Bit_Codec_Sys_Impl_Instance_proc_consumer.from_filter_mission.id)\n    )\n    r(Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.to_consumer_event.id) = IS(\n      (IPCPorts.Consumer_proc_consumer_App, Arch.Bit_Codec_Sys_Impl_Instance_proc_consumer.from_filter_event.id)\n    )\n\n    r\n  }\n  val eventInPorts: MS[Art.PortId, Art.PortId] = MS[Art.PortId, Art.PortId] (\n    Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.from_producer_mission.id,\n    Arch.Bit_Codec_Sys_Impl_Instance_proc_filter.from_producer_event.id,\n    Arch.Bit_Codec_Sys_Impl_Instance_proc_consumer.from_filter_mission.id,\n    Arch.Bit_Codec_Sys_Impl_Instance_proc_consumer.from_filter_event.id\n  )\n  var frozen: MS[Art.PortId, Option[DataContent]] = MS.create(maxPortIds, noData)\n  var outgoing: MS[Art.PortId, Option[DataContent]] = MS.create(maxPortIds, noData)\n  var isTimeDispatch: B = F\n\n  def updateData(port: Art.PortId, d: DataContent): Unit = {\n    data(port) = Some(d)\n  }\n\n  def timeDispatch(): Unit = {\n    isTimeDispatch = T\n  }\n\n  def eventDispatch(): Unit = {\n    isTimeDispatch = F\n  }\n\n  def dispatchStatus(bridgeId: Art.BridgeId): DispatchStatus = {\n    if (isTimeDispatch) {\n      return timeTriggered\n    } else {\n      var r = ISZ[Art.PortId]()\n      for (i <- eventInPorts if data(i).nonEmpty) {\n        r = r :+ i\n      }\n      return EventTriggered(r)\n    }\n  }\n\n  def receiveInput(eventPortIds: ISZ[Art.PortId], dataPortIds: ISZ[Art.PortId]): Unit = {\n    frozen = data\n    for (i <- eventPortIds) {\n      data(i) = noData\n    }\n  }\n\n  def putValue(portId: Art.PortId, data: DataContent): Unit = {\n    outgoing(portId) = Some(data)\n  }\n\n  def getValue(portId: Art.PortId): Option[DataContent] = {\n    return frozen(portId)\n  }\n\n  def sendOutput(eventPortIds: ISZ[Art.PortId], dataPortIds: ISZ[Art.PortId]): Unit = {\n    for (p <- dataPortIds) {\n      outgoing(p) match {\n        case Some(d) =>\n          outgoing(p) = noData\n          for(e <- connection(p)){\n            PlatformComm.sendAsync(e._1, e._2, d)\n          }\n        case _ =>\n      }\n    }\n\n    for (p <- eventPortIds) {\n      outgoing(p) match {\n        case Some(d) =>\n          outgoing(p) = noData\n          for(e <- connection(p)){\n            PlatformComm.sendAsync(e._1, e._2, d)\n          }\n        case _ =>\n      }\n    }\n  }\n\n  def logInfo(title: String, msg: String): Unit = {\n    print(title)\n    print(\": \")\n    println(msg)\n  }\n\n  def logError(title: String, msg: String): Unit = {\n    eprint(title)\n    eprint(\": \")\n    eprintln(msg)\n  }\n\n  def logDebug(title: String, msg: String): Unit = {\n    print(title)\n    print(\": \")\n    println(msg)\n  }\n\n  def time(): Art.Time = {\n    return Process.time()\n  }\n\n  def run(): Unit = {}\n\n  def tearDownSystemState(): Unit = {}\n\n  def setUpSystemState(): Unit = {}\n\n  def initializePhase(): Unit = {}\n\n  def computePhase(): Unit = {}\n\n  def finalizePhase(): Unit = {}\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/nix\/bit_codec\/LegacyDemo.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage bit_codec\n\nimport org.sireum._\nimport art._\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\nobject LegacyDemo extends App {\n  def main(args: ISZ[String]): Z = {\n\n    val seed: Z = if (args.size == z\"1\") {\n      val n = Z(args(0)).get\n      if (n <= z\"0\") 1 else n\n    } else {\n      1\n    }\n\n    PlatformComm.initialise(seed, None())\n\n    val empty = art.Empty()\n\n    PlatformComm.sendAsync(IPCPorts.Producer_proc_producer_App, IPCPorts.Producer_proc_producer_App, empty)\n    PlatformComm.sendAsync(IPCPorts.Filter_proc_filter_App, IPCPorts.Filter_proc_filter_App, empty)\n    PlatformComm.sendAsync(IPCPorts.Consumer_proc_consumer_App, IPCPorts.Consumer_proc_consumer_App, empty)\n\n    PlatformComm.finalise()\n    return 0\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/nix\/bit_codec\/PlatformComm.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage bit_codec\n\nimport org.sireum._\nimport art._\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\n@ext object PlatformComm {\n  def initialise(seed: Z, portOpt: Option[Art.PortId]): Unit = $\n  def receive(portOpt: Option[Art.PortId],  out: MBox2[Art.PortId, DataContent]): Unit = $\n  def send(app: Art.PortId, port: Art.PortId, data: DataContent): Unit = $\n  def sendAsync(app: Art.PortId, port: Art.PortId, data: DataContent): B = $\n  def receiveAsync(portOpt: Option[Art.PortId], out: MBox2[Art.PortId, Option[DataContent]]): Unit = $\n  def finalise(): Unit = $\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/nix\/bit_codec\/PlatformComm_Ext.scala",
        {
          "type" : "ITestResource",
          "content" : "package bit_codec\n\nimport org.sireum._\nimport art._\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\nobject PlatformComm_Ext {\n  def initialise(seed: Z, portOpt: Option[Art.PortId]): Unit = halt(\"stub\")\n  def receive(portOpt: Option[Art.PortId], out: MBox2[Art.PortId, DataContent]) = halt(\"stub\")\n  def send(app: Art.PortId, port: Art.PortId, data: DataContent): Unit = halt(\"stub\")\n  def sendAsync(app: Art.PortId, port: Art.PortId, data: DataContent): B = halt(\"stub\")\n  def receiveAsync(portOpt: Option[Art.PortId], out: MBox2[Art.PortId, Option[DataContent]]): Unit = halt(\"stub\")\n  def finalise(): Unit = halt(\"stub\")\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/nix\/bit_codec\/PlatformCommNix.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\npackage bit_codec\n\nimport org.sireum._\nimport art._\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\nobject PlatformCommNix {\n\n  var seed: Z = 0\n  var ids: IS[Art.PortId, Z] = IS()\n\n  def initialise(seed: Z, portOpt: Option[Art.PortId]): Unit = {\n    PlatformCommNix.seed = seed\n    portOpt match {\n      case Some(port) =>\n        val id = seed + port.toZ\n        SharedMemory.create(id)\n        ids = ids :+ id\n      case _ =>\n    }\n  }\n\n  def receive(portOpt: Option[Art.PortId], out: MBox2[Art.PortId, DataContent]): Unit = {\n    portOpt match {\n      case Some(port) =>\n        out.value1 = port\n        SharedMemory.receive(seed + port.toZ, out)\n      case _ => halt(\"Unsupported receive operation without port.\")\n    }\n  }\n\n  def send(app: Art.PortId, port: Art.PortId, data: DataContent): Unit = {\n    SharedMemory.send(app.toZ, seed + port.toZ, data)\n  }\n\n  def sendAsync(app: Art.PortId, port: Art.PortId, data: DataContent): B = {\n    val r = SharedMemory.sendAsync(app.toZ, seed + port.toZ, data)\n    return r\n  }\n\n  def receiveAsync(portOpt: Option[Art.PortId], out: MBox2[Art.PortId, Option[DataContent]]): Unit = {\n    portOpt match {\n      case Some(port) => SharedMemory.receiveAsync(seed + port.toZ, out)\n      case _ => halt(\"Unsupported receive operation without port.\")\n    }\n  }\n\n  def finalise(): Unit = {\n    for (id <- ids) {\n      SharedMemory.remove(id)\n    }\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/nix\/bit_codec\/Process.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\npackage bit_codec\n\nimport org.sireum._\nimport art.Art\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\n@ext object Process {\n  def sleep(n: Z): Unit = $\n\n  def time(): Art.Time = $\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/nix\/bit_codec\/Process_Ext.scala",
        {
          "type" : "ITestResource",
          "content" : "package bit_codec\n\nimport org.sireum._\nimport art.Art\n\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\n\nobject Process_Ext {\n  def sleep(millis: Z): Unit = halt(\"stub\")\n\n  def time(): Art.Time = halt(\"stub\")\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "c\/bin\/compile.cmd",
        {
          "type" : "ITestResource",
          "content" : "::\/*#! 2> \/dev\/null                                   #\r\n@ 2>\/dev\/null # 2>nul & echo off & goto BOF           #\r\nif [ -z ${SIREUM_HOME} ]; then                       #\r\n  echo \"Please set SIREUM_HOME env var\"               #\r\n  exit -1                                             #\r\nfi                                                    #\r\nexec ${SIREUM_HOME}\/bin\/sireum slang run \"$0\" \"$@\" #\r\n:BOF\r\nsetlocal\r\nif not defined SIREUM_HOME (\r\n  echo Please set SIREUM_HOME env var\r\n  exit \/B -1\r\n)\r\n%SIREUM_HOME%\\\\bin\\\\sireum.bat slang run \"%0\" %*\r\nexit \/B %errorlevel%\r\n::!#*\/\r\n\/\/ #Sireum\r\n\r\nimport org.sireum._\r\n\r\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\r\n\r\nval home = Os.slashDir\r\n\r\nCli(Os.pathSepChar).parseCompile(Os.cliArgs, 0) match {\r\n  case Some(o: Cli.CompileOption) if o.args.size == 0 =>\r\n    val nixDir = home \/ \"\/..\/nix\" \/ \"slang-build\"\r\n    if(!nixDir.up.exists){\r\n      eprintln(s\"Directory does not exist, have your run the transpiler? ${nixDir.up}\")\r\n      Os.exit(-1)\r\n    }\r\n    nixDir.mkdir()\r\n\r\n    if((nixDir \/ \"CMakeCache.txt\").exists) {\r\n      \/\/ remove cached transpiler variables\r\n      proc\"cmake -U BOUND_CHECK -U NO_PRINT -U RANGE_CHECK -U WITH_LOC ..\".at(nixDir).console.runCheck()\r\n    }\r\n\r\n    var cmake: ISZ[String] = ISZ(\"cmake\")\r\n    if(o.boundCheck) { cmake = cmake :+ \"-D\" :+ \"BOUND_CHECK=ON\" }\r\n    if(o.noPrint) { cmake = cmake :+ \"-D\" :+ \"NO_PRINT=ON\" }\r\n    if(o.rangeCheck) { cmake = cmake :+ \"-D\" :+ \"RANGE_CHECK=ON\" }\r\n    if(o.withLoc) { cmake = cmake :+ \"-D\" :+ \"WITH_LOC=ON\" }\r\n    cmake = (cmake :+ \"-D\" :+ s\"CMAKE_BUILD_TYPE=${o.build}\") :+ \"..\"\r\n\r\n    if(o.verbose) { println(st\"${(cmake, \" \")}\".render) }\r\n\r\n    Os.proc(cmake).at(nixDir).console.runCheck()\r\n\r\n    val MAKE_ARGS: String = Os.env(\"MAKE_ARGS\") match {\r\n      case Some(o) => o\r\n      case _ => \"\"\r\n    }\r\n\r\n    proc\"make --jobs ${o.jobs} ${MAKE_ARGS}\".at(nixDir).console.runCheck()\r\n\r\n    val binDir = home \/ \"slang-build\"\r\n    binDir.removeAll()\r\n    binDir.mkdir()\r\n\r\n    if(Os.isWin) {\r\n      nixDir.list.filter(p => p.ext == \"exe\").foreach((f: Os.Path) => f.moveTo(binDir \/ f.name))\r\n    } else {\r\n      nixDir.list.filter(p => ops.StringOps(p.name).endsWith(\"_App\")).foreach((f: Os.Path) => f.moveTo(binDir \/ f.name))\r\n      val candidates: ISZ[Os.Path] = ISZ[String](\"Demo\", \"LegacyDemo\").map((m: String) => nixDir \/ m)\r\n      val main: ISZ[Os.Path] = candidates.filter((p: Os.Path) => p.exists)\r\n      if(main.isEmpty || main.size > 1) {\r\n        eprintln(s\"Found ${main.size} possible main programs.  There should be only one of the following: ${candidates}\")\r\n        Os.exit(1)\r\n      }\r\n      main(0).moveTo(binDir \/ main(0).name)\r\n    }\r\n\r\n    Os.exit(0)\r\n\r\n  case Some(o: Cli.CompileOption) =>\r\n    println(o.help)\r\n    Os.exit(0)\r\n  case Some(o: Cli.HelpOption) => Os.exit(0)\r\n  case _ =>\r\n    eprintln(\"Could not recognize arguments\")\r\n}\r\n\r\nOs.exit(-1)\r\n\r\nimport org.sireum._\r\n\r\nobject Cli {\r\n\r\n  @datatype trait CompileTopOption\r\n\r\n  @datatype class HelpOption extends CompileTopOption\r\n\r\n  @enum object CompileChoice {\r\n    'Release\r\n    'Debug\r\n  }\r\n\r\n  @datatype class CompileOption(\r\n    val help: String,\r\n    val args: ISZ[String],\r\n    val boundCheck: B,\r\n    val noPrint: B,\r\n    val rangeCheck: B,\r\n    val withLoc: B,\r\n    val jobs: Z,\r\n    val build: CompileChoice.Type,\r\n    val verbose: B\r\n  ) extends CompileTopOption\r\n}\r\n\r\nimport Cli._\r\n\r\n@record class Cli(val pathSep: C) {\r\n\r\n  def parseCompileChoiceH(arg: String): Option[CompileChoice.Type] = {\r\n    arg.native match {\r\n      case \"release\" => return Some(CompileChoice.Release)\r\n      case \"debug\" => return Some(CompileChoice.Debug)\r\n      case s =>\r\n        eprintln(s\"Expecting one of the following: { release, debug }, but found '$s'.\")\r\n        return None()\r\n    }\r\n  }\r\n\r\n  def parseCompileChoice(args: ISZ[String], i: Z): Option[CompileChoice.Type] = {\r\n    if (i >= args.size) {\r\n      eprintln(\"Expecting one of the following: { release, debug }, but none found.\")\r\n      return None()\r\n    }\r\n    val r = parseCompileChoiceH(args(i))\r\n    return r\r\n  }\r\n\r\n  def parseCompile(args: ISZ[String], i: Z): Option[CompileTopOption] = {\r\n    val help =\r\n      st\"\"\"Compile Slang Embedded Programs\r\n          |\r\n          |Usage: <option>*\r\n          |\r\n          |Available Options:\r\n          |-b, --bound-check        Build the program with sequence bound checking\r\n          |-p, --no-print           Build the program without console output\r\n          |-r, --range-check        Build the program with range checking\r\n          |-l, --with-loc           Build the program with Slang location info\r\n          |-j, --jobs               Number of make jobs to run in parallel (expects an\r\n          |                           integer; min is 1; default is 4)\r\n          |-t, --build-type         Build type (expects one of { release, debug };\r\n          |                           default: release)\r\n          |-v, --verbose            Echo cmake command\r\n          |-h, --help               Display this information\"\"\".render\r\n\r\n    var boundCheck: B = false\r\n    var noPrint: B = false\r\n    var rangeCheck: B = false\r\n    var withLoc: B = false\r\n    var jobs: Z = 4\r\n    var build: CompileChoice.Type = CompileChoice.Release\r\n    var verbose: B = false\r\n    var j = i\r\n    var isOption = T\r\n    while (j < args.size && isOption) {\r\n      val arg = args(j)\r\n      if (ops.StringOps(arg).first == '-') {\r\n        if (args(j) == \"-h\" || args(j) == \"--help\") {\r\n          println(help)\r\n          return Some(HelpOption())\r\n        } else if (arg == \"-b\" || arg == \"--bound-check\") {\r\n           val o: Option[B] = { j = j - 1; Some(!boundCheck) }\r\n           o match {\r\n             case Some(v) => boundCheck = v\r\n             case _ => return None()\r\n           }\r\n         } else if (arg == \"-p\" || arg == \"--no-print\") {\r\n           val o: Option[B] = { j = j - 1; Some(!noPrint) }\r\n           o match {\r\n             case Some(v) => noPrint = v\r\n             case _ => return None()\r\n           }\r\n         } else if (arg == \"-r\" || arg == \"--range-check\") {\r\n           val o: Option[B] = { j = j - 1; Some(!rangeCheck) }\r\n           o match {\r\n             case Some(v) => rangeCheck = v\r\n             case _ => return None()\r\n           }\r\n         } else if (arg == \"-l\" || arg == \"--with-loc\") {\r\n           val o: Option[B] = { j = j - 1; Some(!withLoc) }\r\n           o match {\r\n             case Some(v) => withLoc = v\r\n             case _ => return None()\r\n           }\r\n         } else if (arg == \"-j\" || arg == \"--jobs\") {\r\n           val o: Option[Z] = parseNum(args, j + 1, Some(1), None())\r\n           o match {\r\n             case Some(v) => jobs = v\r\n             case _ => return None()\r\n           }\r\n         } else if (arg == \"-t\" || arg == \"--build-type\") {\r\n           val o: Option[CompileChoice.Type] = parseCompileChoice(args, j + 1)\r\n           o match {\r\n             case Some(v) => build = v\r\n             case _ => return None()\r\n           }\r\n         } else if (arg == \"-v\" || arg == \"--verbose\") {\r\n           val o: Option[B] = { j = j - 1; Some(!verbose) }\r\n           o match {\r\n             case Some(v) => verbose = v\r\n             case _ => return None()\r\n           }\r\n         } else {\r\n          eprintln(s\"Unrecognized option '$arg'.\")\r\n          return None()\r\n        }\r\n        j = j + 2\r\n      } else {\r\n        isOption = F\r\n      }\r\n    }\r\n    return Some(CompileOption(help, parseArguments(args, j), boundCheck, noPrint, rangeCheck, withLoc, jobs, build, verbose))\r\n  }\r\n\r\n  def parseArguments(args: ISZ[String], i: Z): ISZ[String] = {\r\n    var r = ISZ[String]()\r\n    var j = i\r\n    while (j < args.size) {\r\n      r = r :+ args(j)\r\n      j = j + 1\r\n    }\r\n    return r\r\n  }\r\n\r\n  def parsePaths(args: ISZ[String], i: Z): Option[ISZ[String]] = {\r\n    return tokenize(args, i, \"path\", pathSep, F)\r\n  }\r\n\r\n  def parsePath(args: ISZ[String], i: Z): Option[Option[String]] = {\r\n    if (i >= args.size) {\r\n      eprintln(\"Expecting a path, but none found.\")\r\n    }\r\n    return Some(Some(args(i)))\r\n  }\r\n\r\n  def parseStrings(args: ISZ[String], i: Z, sep: C): Option[ISZ[String]] = {\r\n    tokenize(args, i, \"string\", sep, F) match {\r\n      case r@Some(_) => return r\r\n      case _ => return None()\r\n    }\r\n  }\r\n\r\n  def parseString(args: ISZ[String], i: Z): Option[Option[String]] = {\r\n    if (i >= args.size) {\r\n      eprintln(\"Expecting a string, but none found.\")\r\n      return None()\r\n    }\r\n    return Some(Some(args(i)))\r\n  }\r\n\r\n  def parseNums(args: ISZ[String], i: Z, sep: C, minOpt: Option[Z], maxOpt: Option[Z]): Option[ISZ[Z]] = {\r\n    tokenize(args, i, \"integer\", sep, T) match {\r\n      case Some(sargs) =>\r\n        var r = ISZ[Z]()\r\n        for (arg <- sargs) {\r\n          parseNumH(F, arg, minOpt, maxOpt)._2 match {\r\n            case Some(n) => r = r :+ n\r\n            case _ => return None()\r\n          }\r\n        }\r\n        return Some(r)\r\n      case _ => return None()\r\n    }\r\n  }\r\n\r\n  def tokenize(args: ISZ[String], i: Z, tpe: String, sep: C, removeWhitespace: B): Option[ISZ[String]] = {\r\n    if (i >= args.size) {\r\n      eprintln(s\"Expecting a sequence of $tpe separated by '$sep', but none found.\")\r\n      return None()\r\n    }\r\n    val arg = args(i)\r\n    return Some(tokenizeH(arg, sep, removeWhitespace))\r\n  }\r\n\r\n  def tokenizeH(arg: String, sep: C, removeWhitespace: B): ISZ[String] = {\r\n    val argCis = conversions.String.toCis(arg)\r\n    var r = ISZ[String]()\r\n    var cis = ISZ[C]()\r\n    var j = 0\r\n    while (j < argCis.size) {\r\n      val c = argCis(j)\r\n      if (c == sep) {\r\n        r = r :+ conversions.String.fromCis(cis)\r\n        cis = ISZ[C]()\r\n      } else {\r\n        val allowed: B = c match {\r\n          case c\"\\n\" => !removeWhitespace\r\n          case c\" \" => !removeWhitespace\r\n          case c\"\\r\" => !removeWhitespace\r\n          case c\"\\t\" => !removeWhitespace\r\n          case _ => T\r\n        }\r\n        if (allowed) {\r\n          cis = cis :+ c\r\n        }\r\n      }\r\n      j = j + 1\r\n    }\r\n    if (cis.size > 0) {\r\n      r = r :+ conversions.String.fromCis(cis)\r\n    }\r\n    return r\r\n  }\r\n\r\n  def parseNumChoice(args: ISZ[String], i: Z, choices: ISZ[Z]): Option[Z] = {\r\n    val set = HashSet.empty[Z] ++ choices\r\n    parseNum(args, i, None(), None()) match {\r\n      case r@Some(n) =>\r\n        if (set.contains(n)) {\r\n          return r\r\n        } else {\r\n          eprintln(s\"Expecting one of the following: $set, but found $n.\")\r\n          return None()\r\n        }\r\n      case r => return r\r\n    }\r\n  }\r\n\r\n  def parseNum(args: ISZ[String], i: Z, minOpt: Option[Z], maxOpt: Option[Z]): Option[Z] = {\r\n    if (i >= args.size) {\r\n      eprintln(s\"Expecting an integer, but none found.\")\r\n      return None()\r\n    }\r\n    return parseNumH(F, args(i), minOpt, maxOpt)._2\r\n  }\r\n\r\n  def parseNumFlag(args: ISZ[String], i: Z, minOpt: Option[Z], maxOpt: Option[Z]): Option[Option[Z]] = {\r\n    if (i >= args.size) {\r\n      return Some(None())\r\n    }\r\n    parseNumH(T, args(i), minOpt, maxOpt) match {\r\n      case (T, vOpt) => return Some(vOpt)\r\n      case _ => return None()\r\n    }\r\n  }\r\n\r\n  def parseNumH(optArg: B, arg: String, minOpt: Option[Z], maxOpt: Option[Z]): (B, Option[Z]) = {\r\n    Z(arg) match {\r\n      case Some(n) =>\r\n        minOpt match {\r\n          case Some(min) =>\r\n            if (n < min) {\r\n              eprintln(s\"Expecting an integer at least $min, but found $n.\")\r\n              return (F, None())\r\n            }\r\n          case _ =>\r\n        }\r\n        maxOpt match {\r\n          case Some(max) =>\r\n            if (n > max) {\r\n              eprintln(s\"Expecting an integer at most $max, but found $n.\")\r\n              return (F, None())\r\n            }\r\n          case _ =>\r\n        }\r\n        return (T, Some(n))\r\n      case _ =>\r\n        if (!optArg) {\r\n          eprintln(s\"Expecting an integer, but found '$arg'.\")\r\n          return (F, None())\r\n        } else {\r\n          return (T, None())\r\n       }\r\n    }\r\n  }\r\n\r\n  def select(mode: String, args: ISZ[String], i: Z, choices: ISZ[String]): Option[String] = {\r\n    val arg = args(i)\r\n    var cs = ISZ[String]()\r\n    for (c <- choices) {\r\n      if (ops.StringOps(c).startsWith(arg)) {\r\n        cs = cs :+ c\r\n      }\r\n    }\r\n    cs.size match {\r\n      case z\"0\" =>\r\n        eprintln(s\"$arg is not a mode of $mode.\")\r\n        return None()\r\n      case z\"1\" => return Some(cs(0))\r\n      case _ =>\r\n        eprintln(\r\n          st\"\"\"Which one of the following modes did you mean by '$arg'?\r\n              |${(cs, \"\\n\")}\"\"\".render)\r\n        return None()\r\n    }\r\n  }\r\n}\r\n\/\/ @formatter:on\r\n\r\n\/\/ BEGIN USER CODE\r\n\r\n\/\/ END USER CODE\r\n\r\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : true,
          "makeCRLF" : true,
          "isDatatype" : false
        }
      ],
      [
        "c\/bin\/run.sh",
        {
          "type" : "ITestResource",
          "content" : "#!\/usr\/bin\/env bash\n#\n# Do not edit this file as it will be overwritten if HAMR codegen is rerun\n#\nset -e\nexport SCRIPT_HOME=$( cd \"$( dirname \"$0\" )\" &> \/dev\/null && pwd )\ncd $SCRIPT_HOME\n\n# Uncomment the following to prevent terminal from closing when the app shuts down or crashes\n#PREVENT_CLOSE=\"; bash -i\"\n\n# check if getopt supports long options\ngetopt -T > \/dev\/null || ret=$?\n[[ $ret -eq 4 ]] && GNU_GETOPT=0 || GNU_GETOPT=1\n\nOPTIONS=s:h\nLONGOPTS=scheduler:,help\n\nfunction usage {\n  echo \"\"\n  echo \"Usage: <option>*\"\n  echo \"\"\n  echo \"Available Options:\"\n  if [[ $GNU_GETOPT -eq 0 ]]; then\n    echo \"-s, --scheduler        The scheduler to use (expects one of\"\n    echo \"                         { default, roundRobin, static, legacy};\"\n    echo \"                         default: default)\"\n    echo \"-h, --help             Display this information\"\n  else\n    echo \"-s                     The scheduler to use (expects one of\"\n    echo \"                         { default, roundRobin, static, legacy};\"\n    echo \"                         default: default)\"\n    echo \"-h                     Display this information\"\n  fi\n}\n\nif [[ $GNU_GETOPT -eq 0 ]]; then\n  ! PARSED=$(getopt --options=$OPTIONS --longoptions=$LONGOPTS --name \"$0\" -- \"$@\")\nelse\n  ! PARSED=$(getopt $OPTIONS \"$@\")\nfi\n\nif [[ ${PIPESTATUS[0]} -ne 0 ]]; then\n  usage\n  exit 1\nfi\n\neval set -- \"$PARSED\"\n\nSCHEDULER=\"default\"\nwhile true; do\n  case \"$1\" in\n    -h|--help) usage; exit 0 ;;\n    -s|--scheduler)\n      case \"$2\" in\n        default|roundRobin|static|legacy)\n          SCHEDULER=\"$2\" ;;\n        *)\n          echo \"Invalid scheduler: ${2}\"\n          exit 2 ;;\n      esac\n      shift 2 ;;\n    --) shift; break ;;\n  esac\ndone\n\n# handle non-option arguments\nif [[ $# -ne 0 ]]; then\n  echo \"$0: Unexpected non-option arguments\"\n  usage\n  exit 3\nfi\n\nfunction launch() {\n  if [ \"$2\" ]; then SCHEDULER_ARG=\" -s ${2}\"; fi\n  if [ -n \"$COMSPEC\" -a -x \"$COMSPEC\" ]; then\n    for APP in $1; do\n      cygstart mintty \/bin\/bash -c \"slang-build\/${APP}${SCHEDULER_ARG}${PREVENT_CLOSE}\" &\n    done\n  elif [[ \"$(uname)\" == \"Darwin\" ]]; then\n    for APP in $1; do\n      # workaround to launch the applications via separate Terminals. Create a shell script in the\n      # \/tmp directory that launches the application. Then delete the shell script when the\n      # application exits\n      echo \"${SCRIPT_HOME}\/slang-build\/${APP}${SCHEDULER_ARG}${PREVENT_CLOSE} ; rm \/tmp\/${APP}.sh\" > \/tmp\/${APP}.sh ; chmod +x \/tmp\/${APP}.sh ; open -a Terminal \/tmp\/${APP}.sh &\n    done\n  elif [[ \"$(expr substr $(uname -s) 1 5)\" == \"Linux\" ]]; then\n    for APP in $1; do\n      x-terminal-emulator -T ${APP} -e sh -i -c \"slang-build\/${APP}${SCHEDULER_ARG}${PREVENT_CLOSE}\" &\n    done\n  else\n    >&2 echo \"Platform not supported: $(uname).\"\n    exit 1\n  fi\n}\n\nEXT=\"\"\nif [ -n \"$COMSPEC\" -a -x \"$COMSPEC\" ]; then EXT=\".exe\"; fi\n\ncase \"${SCHEDULER}\" in\n  legacy)\n    if [ ! -f .\/slang-build\/LegacyDemo${EXT} ]; then\n      if [ -f .\/slang-build\/Demo${EXT} ]; then\n        echo \"Error: Found program for Slang based schedulers.  Pass '--legacy' to the\"\n        echo \"transpiler script in order to use the legacy scheduler\"\n      else\n        echo \"Expected program not found, have you compiled? ${SCRIPT_HOME}\/slang-build\/LegacyDemo${EXT}\"\n      fi\n      exit 1\n    fi\n\n    launch \"Producer_proc_producer_App${EXT} Filter_proc_filter_App${EXT} Consumer_proc_consumer_App${EXT}\";\n\n    read -p \"Press enter to initialise components ...\"\n    slang-build\/LegacyDemo${EXT}\n    read -p \"Press enter again to start ...\"\n    slang-build\/LegacyDemo${EXT}\n    ;;\n  *)\n    if [ ! -f .\/slang-build\/Demo${EXT} ]; then\n      if [ -f .\/slang-build\/LegacyDemo${EXT} ]; then\n        echo \"Error: Found program for the legacy scheduler. Either pass '-s legacy' to the\"\n        echo \"run script if you want to use the legacy scheduler, or, do not pass\"\n        echo \"'--legacy' to the transpiler script if you want to use a Slang based scheduler\"\n      else\n        echo \"Expected program not found, have you compiled? ${SCRIPT_HOME}\/slang-build\/Demo${EXT}\"\n      fi\n      exit 1\n    fi\n\n    launch \"Demo\" ${SCHEDULER};\n    ;;\nesac\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : true,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "c\/bin\/stop.sh",
        {
          "type" : "ITestResource",
          "content" : "#!\/usr\/bin\/env bash\n#\n# Do not edit this file as it will be overwritten if HAMR codegen is rerun\n#\nAPPS=\"Demo Producer_proc_producer_App Filter_proc_filter_App Consumer_proc_consumer_App\"\nfor APP in ${APPS}; do\n  pkill -SIGTERM -f $APP\ndone\nME=`whoami`\n\n# message queue\nIPCS_Q=`ipcs -q | egrep \"[0-9a-f]+[0-9]+\" | grep $ME | awk '{print $2}'`\nfor id in $IPCS_Q; do\n  ipcrm -q $id;\ndone\n\n# shared memory\nIPCS_Q=`ipcs -m | egrep \"[0-9a-f]+[0-9]+\" | grep $ME | awk '{print $2}'`\nfor id in $IPCS_Q; do\n  ipcrm -m $id;\ndone\n\n# semaphores\nIPCS_Q=`ipcs -s | egrep \"[0-9a-f]+[0-9]+\" | grep $ME | awk '{print $2}'`\nfor id in $IPCS_Q; do\n  ipcrm -s $id;\ndone\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : true,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "c\/etc\/ipc.c",
        {
          "type" : "ITestResource",
          "content" : "#include <all.h>\n#include <sys\/types.h>\n#include <sys\/shm.h>\n#include <sys\/sem.h>\n#include <unistd.h>\n\n\/\/ This file is auto-generated.  Do not edit\n\ninline void sem_op(int sid, short val) {\n    struct sembuf sem_op;\n    sem_op.sem_num = 0;\n    sem_op.sem_op = val;\n    sem_op.sem_flg = 0;\n    semop(sid, &sem_op, 1);\n}\n\ninline void lock(int sid) {\n    sem_op(sid, -1);\n}\n\ninline void unlock(int sid) {\n    sem_op(sid, 1);\n}\n\ninline int create_sem(Z msgid) {\n    unsigned int permission = 0666;\n    unsigned int mask = IPC_CREAT;\n    int sem_set_id = semget((key_t) msgid, 1, mask | permission);\n\n    if (sem_set_id >= 0) {\n        union semun {\n            int val;\n            struct semid_ds *buf;\n            ushort *array;\n        } sem_val;\n        sem_val.val = 1;\n        semctl(sem_set_id, 0, SETVAL, sem_val);\n    }\n    return sem_set_id;\n}\n\nZ bit_codec_SharedMemory_create(STACK_FRAME Z id) {\n    unsigned int permission = 0666;\n    unsigned int mask = IPC_CREAT;\n\n    create_sem(id);\n\n    int shmid = shmget((key_t) id, sizeof(union Option_8E9F45), (int) (permission | mask));\n    void *p = shmat(shmid, (void *) 0, 0);\n    memset(p, 0, sizeof(union Option_8E9F45));\n    shmdt(p);\n\n    return (Z) shmid;\n}\n\n\/\/ MBox2_43CC67=MBox2[art.Art.PortId, art.DataContent]\nUnit bit_codec_SharedMemory_receive(STACK_FRAME Z port, MBox2_43CC67 out) {\n    int sid = semget((key_t) port, 1, 0666);\n\n    lock(sid);\n\n    int shmid = shmget((key_t) port, sizeof(union Option_8E9F45), 0666);\n\n    Option_8E9F45 p = (Option_8E9F45) shmat(shmid, (void *) 0, 0);\n\n    while (p->type != TSome_D29615) { \/\/ wait until there is data\n        unlock(sid);\n        usleep((useconds_t) 10 * 1000);\n        lock(sid);\n    }\n\n    art_DataContent d = &p->Some_D29615.value;\n    Type_assign(&(out->value2), d, sizeOf((Type) d));\n    memset(p, 0, sizeof(union Option_8E9F45));\n    shmdt(p);\n\n    unlock(sid);\n}\n\n\/\/ MBox2_37E193=MBox2[art.Art.PortId, Option[art.DataContent]]\nUnit bit_codec_SharedMemory_receiveAsync(STACK_FRAME Z port, MBox2_37E193 out) {\n    int sid = semget((key_t) port, 1, 0666);\n\n    lock(sid);\n\n    int shmid = shmget((key_t) port, sizeof(union Option_8E9F45), 0666);\n\n    Option_8E9F45 p = (Option_8E9F45) shmat(shmid, (void *) 0, 0);\n\n    if (p->type == TSome_D29615) {\n        Type_assign(&(out->value2), p, sizeOf((Type) p));\n        memset(p, 0, sizeof(union Option_8E9F45));\n    } else {\n        out->value2.type = TNone_964667;\n    }\n\n    shmdt(p);\n\n    unlock(sid);\n}\n\nUnit bit_codec_SharedMemory_send(STACK_FRAME Z appPortId, Z componentPortId, art_DataContent d) {\n    int sid = semget((key_t) componentPortId, 1, 0666);\n\n    lock(sid);\n\n    int shmid = shmget((key_t) componentPortId, sizeof(union Option_8E9F45), 0666);\n\n    Option_8E9F45 p = (Option_8E9F45) shmat(shmid, (void *) 0, 0);\n\n    while (p->type == TSome_D29615) {\n        unlock(sid);\n        usleep((useconds_t) 10 * 1000);\n        lock(sid);\n    }\n\n    p->type = TSome_D29615;\n    Type_assign(&(p->Some_D29615.value), d, sizeOf((Type) d));\n\n    shmdt(p);\n\n    unlock(sid);\n}\n\nB bit_codec_SharedMemory_sendAsync(STACK_FRAME Z appPortId, Z componentPortId, art_DataContent d) {\n    int sid = semget((key_t) componentPortId, 1, 0666);\n\n    lock(sid);\n\n    int shmid = shmget((key_t) componentPortId, sizeof(union Option_8E9F45), 0666);\n\n    Option_8E9F45 p = (Option_8E9F45) shmat(shmid, (void *) 0, 0);\n    p->type = TSome_D29615;\n    Type_assign(&(p->Some_D29615.value), d, sizeOf((Type) d));\n\n    shmdt(p);\n\n    unlock(sid);\n    return T;\n}\n\nUnit bit_codec_SharedMemory_remove(STACK_FRAME Z id) {\n    semctl(semget((key_t) id, 1, 0666), 0, IPC_RMID);\n    shmctl(shmget((key_t) id, sizeof(union Option_8E9F45), 0666), IPC_RMID, NULL);\n}\n\nUnit bit_codec_Process_sleep(STACK_FRAME Z n) {\n    usleep((useconds_t) n * 1000);\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/bin\/transpile.cmd",
        {
          "type" : "ITestResource",
          "content" : "::\/*#! 2> \/dev\/null                                   #\r\n@ 2>\/dev\/null # 2>nul & echo off & goto BOF           #\r\nif [ -z ${SIREUM_HOME} ]; then                        #\r\n  echo \"Please set SIREUM_HOME env var\"               #\r\n  exit -1                                             #\r\nfi                                                    #\r\nexec ${SIREUM_HOME}\/bin\/sireum slang run \"$0\" \"$@\"    #\r\n:BOF\r\nsetlocal\r\nif not defined SIREUM_HOME (\r\n  echo Please set SIREUM_HOME env var\r\n  exit \/B -1\r\n)\r\n%SIREUM_HOME%\\\\bin\\\\sireum.bat slang run \"%0\" %*\r\nexit \/B %errorlevel%\r\n::!#*\/\r\n\/\/ #Sireum\r\n\r\nimport org.sireum._\r\n\r\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\r\n\r\n\/\/ If you want to make changes to this script, make a copy of it and edit that version\r\n\r\n\/\/ Origin of custom sequence sizes\r\n\/\/   MS[Z,Option[art.Bridge]]=3 - Needed for Art.bridges\r\n\/\/   IS[Z,String]=3 - Needed for the CLI arguments to the Demo Slang app\r\n\/\/   IS[Z,art.Art.PortId]=5 - Needed for the sending and receiving of messages in ART and the bridges\r\n\/\/   IS[Z,art.UPort]=5 - Needed for producer's dataOuts ports\r\n\/\/   IS[Z,B]=288 - Needed for the max bit size specified in the model -- see Bit_Codec::Mission\r\n\/\/   MS[Z,art.UPort]=5 - Needed for the ops.ISZOps(sorted).tail call used by ArtNativeSlang\r\n\/\/   IS[Z,(Z,art.ArtSlangMessage)]=28 - Needed for the backing store of Map[Z, ArgSlangMessage] in ArtNativeSlang\r\n\/\/   IS[Z,art.Art.BridgeId]=3 - Needed for Schedulers.roundRobinSchedule\r\n\/\/   IS[Z,art.scheduling.static.Schedule.Slot]=3 - Needed for Schedulers.staticSchedule\r\n\/\/   IS[Z,(String,art.Art.BridgeId)]=3 - Needed for the backing store of Scheduler.threadNickNames\r\n\r\nval SCRIPT_HOME: Os.Path = Os.slashDir\r\nval PATH_SEP: String = Os.pathSep\r\n\r\nvar project: ISZ[String] = Cli(Os.pathSepChar).parseTranspile(Os.cliArgs, 0) match {\r\n  case Some(o: Cli.TranspileOption) =>\r\n    if(o.legacy) {\r\n      println(\"Using Legacy Scheduler\")\r\n\r\n      val main: ISZ[String] = ISZ(\r\n        \"--sourcepath\", s\"${SCRIPT_HOME}\/..\/src\/main\",\r\n        \"--output-dir\", s\"${SCRIPT_HOME}\/..\/..\/c\/nix\",\r\n        \"--name\", \"main\",\r\n        \"--apps\", \"bit_codec.Producer_proc_producer_App,bit_codec.Filter_proc_filter_App,bit_codec.Consumer_proc_consumer_App,bit_codec.LegacyDemo\",\r\n        \"--fingerprint\", \"3\",\r\n        \"--bits\", \"64\",\r\n        \"--string-size\", \"300\",\r\n        \"--sequence-size\", \"1\",\r\n        \"--sequence\", s\"MS[Z,Option[art.Bridge]]=3;IS[Z,String]=3;IS[Z,art.Art.PortId]=5;IS[Z,art.UPort]=5;IS[Z,B]=288\",\r\n        \"--constants\", s\"art.Art.numComponents=3;art.Art.numPorts=28;art.Art.numConnections=12\",\r\n        \"--forward\", \"art.ArtNative=bit_codec.ArtNix,bit_codec.PlatformComm=bit_codec.PlatformCommNix\",\r\n        \"--stack-size\", \"131072\",\r\n        \"--stable-type-id\",\r\n        \"--exts\", s\"${SCRIPT_HOME}\/..\/..\/c\/ext-c${PATH_SEP}${SCRIPT_HOME}\/..\/..\/c\/etc\",\r\n        \"--exclude-build\", \"bit_codec.Bit_Codec.Producer_proc_producer,bit_codec.Bit_Codec.Filter_proc_filter,bit_codec.Bit_Codec.Consumer_proc_consumer\")\r\n      main\r\n    } else {\r\n      val main: ISZ[String] = ISZ(\r\n        \"--sourcepath\", s\"${SCRIPT_HOME}\/..\/src\/main\",\r\n        \"--output-dir\", s\"${SCRIPT_HOME}\/..\/..\/c\/nix\",\r\n        \"--name\", \"main\",\r\n        \"--apps\", \"bit_codec.Demo\",\r\n        \"--fingerprint\", \"3\",\r\n        \"--bits\", \"64\",\r\n        \"--string-size\", \"300\",\r\n        \"--sequence-size\", \"1\",\r\n        \"--sequence\", s\"MS[Z,Option[art.Bridge]]=3;IS[Z,String]=3;IS[Z,art.Art.PortId]=5;IS[Z,art.UPort]=5;IS[Z,B]=288;MS[Z,art.UPort]=5;IS[Z,(Z,art.ArtSlangMessage)]=28;IS[Z,art.Art.BridgeId]=3;IS[Z,art.scheduling.static.Schedule.Slot]=3;IS[Z,(String,art.Art.BridgeId)]=3\",\r\n        \"--constants\", s\"art.Art.numComponents=3;art.Art.numPorts=28;art.Art.numConnections=12\",\r\n        \"--forward\", \"art.ArtNative=art.ArtNativeSlang\",\r\n        \"--stack-size\", \"131072\",\r\n        \"--stable-type-id\",\r\n        \"--exts\", s\"${SCRIPT_HOME}\/..\/..\/c\/ext-schedule${PATH_SEP}${SCRIPT_HOME}\/..\/..\/c\/ext-c${PATH_SEP}${SCRIPT_HOME}\/..\/..\/c\/etc\",\r\n        \"--exclude-build\", \"bit_codec.Bit_Codec.Producer_proc_producer,bit_codec.Bit_Codec.Filter_proc_filter,bit_codec.Bit_Codec.Consumer_proc_consumer\")\r\n      main\r\n    }\r\n  case Some(o: Cli.HelpOption) =>\r\n    Os.exit(0);\r\n    halt(\"\")\r\n  case _ =>\r\n    eprintln(\"Could not recognize arguments\")\r\n    Os.exit(-1)\r\n    halt(\"\")\r\n}\r\n\r\nprintln(\"Initializing runtime library ...\")\r\nSireum.initRuntimeLibrary()\r\n\r\nval result = Sireum.run(ISZ[String](\"slang\", \"transpilers\", \"c\") ++ project)\r\n\r\nOs.exit(result)\r\n\r\nimport org.sireum._\r\n\r\nobject Cli {\r\n\r\n  @datatype trait TranspileTopOption\r\n\r\n  @datatype class HelpOption extends TranspileTopOption\r\n\r\n  @datatype class TranspileOption(\r\n    val help: String,\r\n    val args: ISZ[String],\r\n    val legacy: B\r\n  ) extends TranspileTopOption\r\n}\r\n\r\nimport Cli._\r\n\r\n@record class Cli(val pathSep: C) {\r\n\r\n  def parseTranspile(args: ISZ[String], i: Z): Option[TranspileTopOption] = {\r\n    val help =\r\n      st\"\"\"Transpile Slang Embedded Program\r\n          |\r\n          |Usage: <option>*\r\n          |\r\n          |Available Options:\r\n          |-l, --legacy             Use legacy scheduler\r\n          |-h, --help               Display this information\"\"\".render\r\n\r\n    var legacy: B = false\r\n    var j = i\r\n    var isOption = T\r\n    while (j < args.size && isOption) {\r\n      val arg = args(j)\r\n      if (ops.StringOps(arg).first == '-') {\r\n        if (args(j) == \"-h\" || args(j) == \"--help\") {\r\n          println(help)\r\n          return Some(HelpOption())\r\n        } else if (arg == \"-l\" || arg == \"--legacy\") {\r\n           val o: Option[B] = { j = j - 1; Some(!legacy) }\r\n           o match {\r\n             case Some(v) => legacy = v\r\n             case _ => return None()\r\n           }\r\n         } else {\r\n          eprintln(s\"Unrecognized option '$arg'.\")\r\n          return None()\r\n        }\r\n        j = j + 2\r\n      } else {\r\n        isOption = F\r\n      }\r\n    }\r\n    return Some(TranspileOption(help, parseArguments(args, j), legacy))\r\n  }\r\n\r\n  def parseArguments(args: ISZ[String], i: Z): ISZ[String] = {\r\n    var r = ISZ[String]()\r\n    var j = i\r\n    while (j < args.size) {\r\n      r = r :+ args(j)\r\n      j = j + 1\r\n    }\r\n    return r\r\n  }\r\n\r\n  def parsePaths(args: ISZ[String], i: Z): Option[ISZ[String]] = {\r\n    return tokenize(args, i, \"path\", pathSep, F)\r\n  }\r\n\r\n  def parsePath(args: ISZ[String], i: Z): Option[Option[String]] = {\r\n    if (i >= args.size) {\r\n      eprintln(\"Expecting a path, but none found.\")\r\n    }\r\n    return Some(Some(args(i)))\r\n  }\r\n\r\n  def parseStrings(args: ISZ[String], i: Z, sep: C): Option[ISZ[String]] = {\r\n    tokenize(args, i, \"string\", sep, F) match {\r\n      case r@Some(_) => return r\r\n      case _ => return None()\r\n    }\r\n  }\r\n\r\n  def parseString(args: ISZ[String], i: Z): Option[Option[String]] = {\r\n    if (i >= args.size) {\r\n      eprintln(\"Expecting a string, but none found.\")\r\n      return None()\r\n    }\r\n    return Some(Some(args(i)))\r\n  }\r\n\r\n  def parseNums(args: ISZ[String], i: Z, sep: C, minOpt: Option[Z], maxOpt: Option[Z]): Option[ISZ[Z]] = {\r\n    tokenize(args, i, \"integer\", sep, T) match {\r\n      case Some(sargs) =>\r\n        var r = ISZ[Z]()\r\n        for (arg <- sargs) {\r\n          parseNumH(F, arg, minOpt, maxOpt)._2 match {\r\n            case Some(n) => r = r :+ n\r\n            case _ => return None()\r\n          }\r\n        }\r\n        return Some(r)\r\n      case _ => return None()\r\n    }\r\n  }\r\n\r\n  def tokenize(args: ISZ[String], i: Z, tpe: String, sep: C, removeWhitespace: B): Option[ISZ[String]] = {\r\n    if (i >= args.size) {\r\n      eprintln(s\"Expecting a sequence of $tpe separated by '$sep', but none found.\")\r\n      return None()\r\n    }\r\n    val arg = args(i)\r\n    return Some(tokenizeH(arg, sep, removeWhitespace))\r\n  }\r\n\r\n  def tokenizeH(arg: String, sep: C, removeWhitespace: B): ISZ[String] = {\r\n    val argCis = conversions.String.toCis(arg)\r\n    var r = ISZ[String]()\r\n    var cis = ISZ[C]()\r\n    var j = 0\r\n    while (j < argCis.size) {\r\n      val c = argCis(j)\r\n      if (c == sep) {\r\n        r = r :+ conversions.String.fromCis(cis)\r\n        cis = ISZ[C]()\r\n      } else {\r\n        val allowed: B = c match {\r\n          case c\"\\n\" => !removeWhitespace\r\n          case c\" \" => !removeWhitespace\r\n          case c\"\\r\" => !removeWhitespace\r\n          case c\"\\t\" => !removeWhitespace\r\n          case _ => T\r\n        }\r\n        if (allowed) {\r\n          cis = cis :+ c\r\n        }\r\n      }\r\n      j = j + 1\r\n    }\r\n    if (cis.size > 0) {\r\n      r = r :+ conversions.String.fromCis(cis)\r\n    }\r\n    return r\r\n  }\r\n\r\n  def parseNumChoice(args: ISZ[String], i: Z, choices: ISZ[Z]): Option[Z] = {\r\n    val set = HashSet.empty[Z] ++ choices\r\n    parseNum(args, i, None(), None()) match {\r\n      case r@Some(n) =>\r\n        if (set.contains(n)) {\r\n          return r\r\n        } else {\r\n          eprintln(s\"Expecting one of the following: $set, but found $n.\")\r\n          return None()\r\n        }\r\n      case r => return r\r\n    }\r\n  }\r\n\r\n  def parseNum(args: ISZ[String], i: Z, minOpt: Option[Z], maxOpt: Option[Z]): Option[Z] = {\r\n    if (i >= args.size) {\r\n      eprintln(s\"Expecting an integer, but none found.\")\r\n      return None()\r\n    }\r\n    return parseNumH(F, args(i), minOpt, maxOpt)._2\r\n  }\r\n\r\n  def parseNumFlag(args: ISZ[String], i: Z, minOpt: Option[Z], maxOpt: Option[Z]): Option[Option[Z]] = {\r\n    if (i >= args.size) {\r\n      return Some(None())\r\n    }\r\n    parseNumH(T, args(i), minOpt, maxOpt) match {\r\n      case (T, vOpt) => return Some(vOpt)\r\n      case _ => return None()\r\n    }\r\n  }\r\n\r\n  def parseNumH(optArg: B, arg: String, minOpt: Option[Z], maxOpt: Option[Z]): (B, Option[Z]) = {\r\n    Z(arg) match {\r\n      case Some(n) =>\r\n        minOpt match {\r\n          case Some(min) =>\r\n            if (n < min) {\r\n              eprintln(s\"Expecting an integer at least $min, but found $n.\")\r\n              return (F, None())\r\n            }\r\n          case _ =>\r\n        }\r\n        maxOpt match {\r\n          case Some(max) =>\r\n            if (n > max) {\r\n              eprintln(s\"Expecting an integer at most $max, but found $n.\")\r\n              return (F, None())\r\n            }\r\n          case _ =>\r\n        }\r\n        return (T, Some(n))\r\n      case _ =>\r\n        if (!optArg) {\r\n          eprintln(s\"Expecting an integer, but found '$arg'.\")\r\n          return (F, None())\r\n        } else {\r\n          return (T, None())\r\n       }\r\n    }\r\n  }\r\n\r\n  def select(mode: String, args: ISZ[String], i: Z, choices: ISZ[String]): Option[String] = {\r\n    val arg = args(i)\r\n    var cs = ISZ[String]()\r\n    for (c <- choices) {\r\n      if (ops.StringOps(c).startsWith(arg)) {\r\n        cs = cs :+ c\r\n      }\r\n    }\r\n    cs.size match {\r\n      case z\"0\" =>\r\n        eprintln(s\"$arg is not a mode of $mode.\")\r\n        return None()\r\n      case z\"1\" => return Some(cs(0))\r\n      case _ =>\r\n        eprintln(\r\n          st\"\"\"Which one of the following modes did you mean by '$arg'?\r\n              |${(cs, \"\\n\")}\"\"\".render)\r\n        return None()\r\n    }\r\n  }\r\n}\r\n\/\/ @formatter:on\r\n\r\n\/\/ BEGIN USER CODE\r\n\r\n\/\/ END USER CODE\r\n\r\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : true,
          "makeCRLF" : true,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/architecture\/bit_codec\/Platform.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage bit_codec\n\nimport org.sireum._\n\n\/\/ This file will not be overwritten so is safe to edit\n\nobject Platform {\n\n  def setup(): Unit = {\n    \/\/ BEGIN MARKER PLATFORM SETUP\n    \/\/ END MARKER PLATFORM SETUP\n  }\n\n  def tearDown(): Unit = {\n    \/\/ BEGIN MARKER PLATFORM TEARDOWN\n    \/\/ END MARKER PLATFORM TEARDOWN\n  }\n}",
          "markers" : [
            {
              "type" : "TestMarker",
              "beginMarker" : "\/\/ BEGIN MARKER PLATFORM SETUP",
              "endMarker" : "\/\/ END MARKER PLATFORM SETUP"
            },
            {
              "type" : "TestMarker",
              "beginMarker" : "\/\/ BEGIN MARKER PLATFORM TEARDOWN",
              "endMarker" : "\/\/ END MARKER PLATFORM TEARDOWN"
            }
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/bin\/project.cmd",
        {
          "type" : "ITestResource",
          "content" : "::\/*#! 2> \/dev\/null                                   #\r\n@ 2>\/dev\/null # 2>nul & echo off & goto BOF           #\r\nif [ -z ${SIREUM_HOME} ]; then                        #\r\n  echo \"Please set SIREUM_HOME env var\"               #\r\n  exit -1                                             #\r\nfi                                                    #\r\nexec ${SIREUM_HOME}\/bin\/sireum slang run \"$0\" \"$@\"    #\r\n:BOF\r\nsetlocal\r\nif not defined SIREUM_HOME (\r\n  echo Please set SIREUM_HOME env var\r\n  exit \/B -1\r\n)\r\n%SIREUM_HOME%\\\\bin\\\\sireum.bat slang run \"%0\" %*\r\nexit \/B %errorlevel%\r\n::!#*\/\r\n\/\/ #Sireum\r\n\r\n\/\/ Example Sireum Proyek build definitions -- the contents of this file will not be overwritten\r\n\/\/\r\n\/\/ To install Sireum (Proyek and IVE) see https:\/\/sireum.org\/getting-started\/\r\n\/\/\r\n\/\/ The following commands should be executed in the parent of the 'bin' directory.\r\n\/\/\r\n\/\/ Command Line:\r\n\/\/   To run the demo from the command line using the default scheduler:\r\n\/\/     sireum proyek run . bit_codec.Demo\r\n\/\/\r\n\/\/   To see the available CLI options:\r\n\/\/     sireum proyek run . bit_codec.Demo -h\r\n\/\/\r\n\/\/   To run the example unit tests from the command line:\r\n\/\/     sireum proyek test .\r\n\/\/\r\n\/\/   To build an executable jar:\r\n\/\/     sireum proyek assemble --uber --main bit_codec.Demo .\r\n\/\/\r\n\/\/ Sireum IVE:\r\n\/\/\r\n\/\/   Create the IVE project if Codegen was not run locally or if its no-proyek-ive\r\n\/\/   option was used:\r\n\/\/     sireum proyek ive .\r\n\/\/\r\n\/\/   Then in IVE select 'File > Open ...' and navigate to the parent of the\r\n\/\/   'bin' directory and click 'OK'.\r\n\/\/\r\n\/\/   To run the demo from within Sireum IVE:\r\n\/\/     Right click src\/main\/architecture\/bit_codec\/Demo.scala and choose \"Run 'Demo'\"\r\n\/\/\r\n\/\/   To run the unit test cases from within Sireum IVE:\r\n\/\/     Right click the src\/test\/bridge and choose \"Run ScalaTests in bridge\"\r\n\r\nimport org.sireum._\r\nimport org.sireum.project.{Module, Project, Target}\r\n\r\nval home: Os.Path = Os.slashDir.up.canon\r\n\r\nval slangModule: Module = Module(\r\n  id = \"Bit_Codec_Sys_Impl_Instance\",\r\n  basePath = (home \/ \"src\").string,\r\n  subPathOpt = None(),\r\n  deps = ISZ(),\r\n  targets = ISZ(Target.Jvm),\r\n  ivyDeps = ISZ(\"org.sireum.kekinian::library:\",\r\n                \"org.sireum.kekinian::hamr-vision:\"),\r\n  sources = for(m <- ISZ(\"art\", \"architecture\", \"bridge\", \"component\", \"data\", \"nix\", \"seL4Nix\", \"util\")) yield (Os.path(\"main\") \/ m).string,\r\n  resources = ISZ(),\r\n  testSources = for (m <- ISZ(\"bridge\", \"system\", \"util\")) yield (Os.path(\"test\") \/ m).string,\r\n  testResources = ISZ(),\r\n  publishInfoOpt = None()\r\n)\r\n\r\nval inspectorModule: Module = slangModule(\r\n  sources = slangModule.sources :+ (Os.path(\"main\") \/ \"inspector\").string,\r\n  ivyDeps = slangModule.ivyDeps ++ ISZ(\"org.sireum:inspector-capabilities:\", \"org.sireum:inspector-gui:\", \"org.sireum:inspector-services-jvm:\")\r\n)\r\n\r\nval slangProject: Project = Project.empty + slangModule\r\nval inspectorProject: Project = Project.empty + inspectorModule\r\n\r\nval prj: Project = slangProject\r\n\/\/val prj: Project = inspectorProject()\r\n\r\nprintln(project.JSON.fromProject(prj, T))\r\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : true,
          "makeCRLF" : true,
          "isDatatype" : false
        }
      ],
      [
        "slang\/versions.properties",
        {
          "type" : "ITestResource",
          "content" : "org.sireum.slang-embedded-art%%slang-embedded-art%=94cf914\n\norg.sireum%inspector-capabilities%=0.6-SNAPSHOT\norg.sireum%inspector-gui%=0.6-SNAPSHOT\norg.sireum%inspector-services-jvm%=0.6-SNAPSHOT\n\norg.sireum.kekinian%%hamr-vision%=e0a27067d4\n\n# remove the following entries if you want to use the versions\n# that ship with sireum (i.e. $SIREUM_HOME\/bin\/sireum --version)\n\n# Scala compiler plugin for Slang\norg.sireum%%scalac-plugin%=4.20240725.7f9e248\n\norg.sireum.kekinian%%library%=e0a27067d4\n\norg.scala-lang%scala-library%=2.13.14\norg.scalatest%%scalatest%%=3.2.19\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/build.sc",
        {
          "type" : "ITestResource",
          "content" : "import mill._\nimport scalalib._\n\n\/\/ Example mill build -- the contents of this file will not be overwritten.\n\/\/\n\/\/ A custom mill build for Sireum can be obtained from https:\/\/github.com\/sireum\/rolling\/releases\/tag\/mill\n\/\/ On Windows, rename 'mill' to 'mill.bat'\n\/\/\n\/\/ To run the demo from the command line:\n\/\/   mill bit_codec.run\n\/\/\n\/\/ To run the example unit tests:\n\/\/   mill bit_codec.tests\n\/\/\n\/\/ Sireum IVE: Installation instructions available at https:\/\/sireum.org\/getting-started\/\n\/\/\n\/\/   First cd to the directory containing this file and execute the following:\n\/\/\n\/\/     $SIREUM_HOME\/bin\/sireum tools ivegen -f -m mill -n slang ..\/\n\/\/\n\/\/   Then in IVE select 'File > Open ...' and navigate to the directory\n\/\/   containing this file then click 'OK'.  To have the codebase and its\n\/\/   test suites recompiled upon changes, run:\n\/\/\n\/\/     $SIREUM_HOME\/bin\/mill -w bit_codec.tests.compile\n\/\/\n\/\/ Visual Studio Code:\n\/\/   Follow Sireum Kekinian's instructions for setting up a development\n\/\/   environment using Scala Metals: https:\/\/github.com\/sireum\/kekinian#scala-metals\n\/\/   Then open the folder containing this file in VS Code and import the\n\/\/   mill build when asked.\n\n\nobject `bit_codec` extends slangEmbeddedProject\n\ntrait SlangEmbeddedModule extends ScalaModule {\n\n  \/\/ refer to https:\/\/github.com\/sireum\/kekinian\/blob\/master\/versions.properties\n  \/\/ to get the most recent versions of the following dependencies\n\n  \/\/ versions.properties key: org.scala-lang%scala-library%\n  val scalaVer = \"2.13.14\"\n\n  \/\/ versions.properties key: org.scalatest%%scalatest%%\n  val scalaTestVersion = \"3.2.19\"\n\n  \/\/ versions.properties key: org.sireum%%scalac-plugin%\n  \/\/ https:\/\/github.com\/sireum\/scalac-plugin\/tree\/4.20240725.7f9e248\n  val sireumScalacVersion = \"4.20240725.7f9e248\"\n\n\n  \/\/ refer to https:\/\/github.com\/sireum\/kekinian\/releases to get the latest\n  \/\/ Sireum Kekinian release: https:\/\/github.com\/sireum\/kekinian\/tree\/e0a27067d4\n  val kekinianVersion = \"e0a27067d4\"\n\n\n  val inspectorVersion = \"0.6-SNAPSHOT\"\n\n  val formsRtVersion = \"7.0.3\"\n\n\n  def scalaVersion = scalaVer\n\n  override def javacOptions = T { Seq(\"-source\", \"1.8\", \"-target\", \"1.8\", \"-encoding\", \"utf8\") }\n\n  override def scalacOptions = T { Seq(\n    \"-release:8\",\n    \"-deprecation\",\n    \"-Yrangepos\",\n    \"-Ydelambdafy:method\",\n    \"-feature\",\n    \"-unchecked\",\n    \"-Xfatal-warnings\",\n    \"-language:postfixOps\"\n  ) }\n\n  override def ivyDeps = Agg(\n    ivy\"org.sireum.kekinian::library::${kekinianVersion}\",\n    ivy\"org.sireum.kekinian::hamr-vision::${kekinianVersion}\",\n\n    \/\/ Jetbrains UI Designer\n    ivy\"com.intellij:forms_rt:${formsRtVersion}\"\n  )\n\n  override def scalacPluginIvyDeps = Agg(ivy\"org.sireum::scalac-plugin::${sireumScalacVersion}\")\n\n  override def repositories = super.repositories :+ coursier.Repositories.jitpack\n\n  override def mainClass = T { Some(\"bit_codec.Demo\") }\n\n  implicit def osPath2PathRef(p: os.Path): PathRef = PathRef(p)\n}\n\ntrait slangEmbeddedProject extends SlangEmbeddedModule {\n\n  def contributedSources: Seq[PathRef] = Seq(\n    millSourcePath \/ os.up \/ \"src\" \/ \"main\" \/ \"architecture\",\n    millSourcePath \/ os.up \/ \"src\" \/ \"main\" \/ \"art\",\n    millSourcePath \/ os.up \/ \"src\" \/ \"main\" \/ \"bridge\",\n    millSourcePath \/ os.up \/ \"src\" \/ \"main\" \/ \"component\",\n    millSourcePath \/ os.up \/ \"src\" \/ \"main\" \/ \"data\",\n    millSourcePath \/ os.up \/ \"src\" \/ \"main\" \/ \"nix\",\n    millSourcePath \/ os.up \/ \"src\" \/ \"main\" \/ \"seL4Nix\",\n    millSourcePath \/ os.up \/ \"src\" \/ \"main\" \/ \"util\"\n  )\n\n  override def sources = T.sources(contributedSources)\n\n  object tests extends Tests {\n\n    final override def millSourcePath = super.millSourcePath \/ os.up \/ os.up \/ \"src\" \/ \"test\"\n\n    override def sources = T.sources( millSourcePath \/ \"bridge\",\n                                      millSourcePath \/ \"system\",\n                                      millSourcePath \/ \"util\" )\n\n    override def ivyDeps = Agg(ivy\"org.scalatest::scalatest::${scalaTestVersion}\")\n\n    override def testFrameworks = T { Seq(\"org.scalatest.tools.Framework\") }\n  }\n}\n\ntrait slangEmbeddedInspectorProject extends slangEmbeddedProject {\n\n  override def mainClass = T { Some(\"bit_codec.InspectorDemo\") }\n\n  override def contributedSources =\n    super.contributedSources :+ millSourcePath \/ os.up \/ \"src\" \/ \"main\" \/ \"inspector\"\n\n  \/\/ FIXME: 2021.01.04 - the following doesn't work due to javafx\/mill resolution issue\n  \/\/        -- refer to https:\/\/github.com\/lihaoyi\/mill\/issues\/767\n  \/\/ override def ivyDeps = Agg(\n  \/\/   ivy\"org.sireum::inspector-capabilities::${inspectorVersion}\",\n  \/\/   ivy\"org.sireum::inspector-gui::${inspectorVersion}\",\n  \/\/   ivy\"org.sireum::inspector-services-jvm::${inspectorVersion}\"\n\n  \/\/ workaround to #767 -- refer to https:\/\/github.com\/lihaoyi\/mill\/issues\/767#issuecomment-652799588\n  override def unmanagedClasspath = T {\n    import coursier._\n\n    val files = Fetch().addDependencies(\n      dep\"org.sireum:inspector-capabilities:0.6-SNAPSHOT\",\n      dep\"org.sireum:inspector-gui:0.6-SNAPSHOT\",\n      dep\"org.sireum:inspector-services-jvm:0.6-SNAPSHOT\"\n    ).addRepositories(\n      Repositories.sonatype(\"releases\"),\n      Repositories.jitpack\n    ).run()\n    val pathRefs = files.map(f => PathRef(os.Path(f)))\n    Agg(pathRefs : _*)\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/build.sbt",
        {
          "type" : "ITestResource",
          "content" : "\/\/ Example sbt build definitions -- the contents of this file will not be overwritten\n\/\/\n\/\/ sbt can be obtained from https:\/\/www.scala-sbt.org\/download.html\n\/\/\n\/\/ To run the demo from the command line using the default scheduler:\n\/\/   sbt run\n\/\/\n\/\/ To see the available CLI options:\n\/\/   sbt \"run -h\"\n\/\/\n\/\/ To run the example unit tests from the command line:\n\/\/   sbt test\n\/\/\n\/\/ To build a runnable\/executable jar:\n\/\/   sbt assembly\n\/\/\n\/\/ To skip running the unit tests while building the executable jar:\n\/\/   sbt 'set test in assembly := {}' assembly\n\/\/ on Linux\/Mac, or\n\/\/   sbt \"set test in assembly := {}\" assembly\n\/\/ on Windows\n\/\/\n\/\/ Sireum IVE: Installation instructions available at https:\/\/sireum.org\/getting-started\/\n\/\/\n\/\/   In IVE select 'File > Open ...' and navigate to the directory containing\n\/\/   this file then click 'OK'.\n\/\/\n\/\/   To run the demo from within Sireum IVE:\n\/\/     Right click src\/main\/architecture\/bit_codec\/Demo.scala and choose \"Run 'Demo'\"\n\/\/\n\/\/   To run the unit test cases from within Sireum IVE:\n\/\/     Right click the src\/test\/bridge directory and choose \"Run ScalaTests in bridge\"\n\/\/\n\/\/   NOTE: A ClassNotFoundException may be raised the first time you try to\n\/\/         run the demo or unit tests.  If this occurs simply delete the directory\n\/\/         named 'target' and retry\n\n\nlazy val Bit_Codec_Sys_Impl_Instance = slangEmbeddedProject(\"Bit_Codec_Sys_Impl_Instance\", \".\")\n\n\/\/ refer to https:\/\/github.com\/sireum\/kekinian\/blob\/master\/versions.properties\n\/\/ to get the most recent versions of the following dependencies\n\n\/\/ versions.properties key: org.scala-lang%scala-library%\nval scalaVer = \"2.13.14\"\n\n\/\/ versions.properties key: org.scalatest%%scalatest%%\nval scalaTestVersion = \"3.2.19\"\n\n\/\/ versions.properties key: org.sireum%%scalac-plugin%\n\/\/ https:\/\/github.com\/sireum\/scalac-plugin\/tree\/4.20240725.7f9e248\nval sireumScalacVersion = \"4.20240725.7f9e248\"\n\n\n\/\/ refer to https:\/\/github.com\/sireum\/kekinian\/releases to get the latest\n\/\/ Sireum Kekinian release: https:\/\/github.com\/sireum\/kekinian\/tree\/e0a27067d4\nval kekinianVersion = \"e0a27067d4\"\n\n\nval inspectorVersion = \"0.6-SNAPSHOT\"\n\nval formsRtVersion = \"7.0.3\"\n\n\n\nval commonSettings = Seq(\n  organization := \"org.sireum\",\n  incOptions := incOptions.value.withLogRecompileOnMacro(false),\n  scalaVersion := scalaVer,\n  scalacOptions := Seq(\"-release:8\", \"-deprecation\",\n    \"-Ydelambdafy:method\", \"-feature\", \"-unchecked\", \"-Xfatal-warnings\"),\n  Test \/ parallelExecution := true,\n  resolvers ++= Resolver.sonatypeOssRepos(\"public\") ++ Seq(\"jitpack\" at \"https:\/\/jitpack.io\"),\n  addCompilerPlugin(\"org.sireum\" %% \"scalac-plugin\" % sireumScalacVersion),\n  ThisBuild \/ evictionErrorLevel := Level.Warn,\n  libraryDependencies ++= Seq(\n    \"org.sireum.kekinian\" %% \"library\" % kekinianVersion withSources(),\n    \"org.sireum.kekinian\" %% \"hamr-vision\" % kekinianVersion withSources()\n  )\n)\n\nimport sbtassembly.AssemblyPlugin.defaultUniversalScript\nval slangEmbeddedSettings = Seq(\n  Compile \/ unmanagedSourceDirectories += baseDirectory.value \/ \"src\/main\/art\",\n  Compile \/ unmanagedSourceDirectories += baseDirectory.value \/ \"src\/main\/architecture\",\n  Compile \/ unmanagedSourceDirectories += baseDirectory.value \/ \"src\/main\/bridge\",\n  Compile \/ unmanagedSourceDirectories += baseDirectory.value \/ \"src\/main\/component\",\n  Compile \/ unmanagedSourceDirectories += baseDirectory.value \/ \"src\/main\/data\",\n  Compile \/ unmanagedSourceDirectories += baseDirectory.value \/ \"src\/main\/nix\",\n  Compile \/ unmanagedSourceDirectories += baseDirectory.value \/ \"src\/main\/seL4Nix\",\n  Compile \/ unmanagedSourceDirectories += baseDirectory.value \/ \"src\/main\/util\",\n\n  Compile \/ unmanagedSourceDirectories in Test += baseDirectory.value \/ \"src\/test\/bridge\",\n  Compile \/ unmanagedSourceDirectories in Test += baseDirectory.value \/ \"src\/test\/system\",\n  Compile \/ unmanagedSourceDirectories in Test += baseDirectory.value \/ \"src\/test\/util\",\n\n  libraryDependencies += \"org.scalatest\" %% \"scalatest\" % scalaTestVersion % \"test\",\n\n  \/\/ Jetbrains UI Designer\n  libraryDependencies += \"com.intellij\" % \"forms_rt\" % formsRtVersion,\n\n  mainClass in (Compile, run) := Some(\"bit_codec.Demo\"),\n\n  mainClass in assembly := Some(\"bit_codec.Demo\"),\n  assemblyJarName in assembly := \"Bit_Codec_Sys_Impl_Instance.jar\",\n  assemblyOption in assembly := (assemblyOption in assembly).value.copy(prependShellScript = Some(defaultUniversalScript(shebang = false))),\n\n  assemblyMergeStrategy in assembly := {\n    case PathList(\"META-INF\", xs @ _*) => MergeStrategy.discard\n    case x => MergeStrategy.first\n  }\n)\n\nval slangEmbeddedInspectorSettings = Seq(\n  Compile \/ unmanagedSourceDirectories += baseDirectory.value \/ \"src\/main\/inspector\",\n\n  libraryDependencies += \"org.sireum\" % \"inspector-capabilities\" % inspectorVersion withSources(),\n  libraryDependencies += \"org.sireum\" % \"inspector-gui\" % inspectorVersion withSources(),\n  libraryDependencies += \"org.sireum\" % \"inspector-services-jvm\" % inspectorVersion withSources(),\n\n  mainClass in (Compile, run) := Some(\"bit_codec.InspectorDemo\"),\n)\n\ndef slangEmbeddedProject(projId: String, projectDirectory: String) =\n  Project(id = projId, base = file(projectDirectory)).\n    settings(commonSettings ++ slangEmbeddedSettings)\n\ndef slangEmbeddedInspectorProject(projId: String, projectDirectory: String) = {\n  Project(id = projId, base = file(projectDirectory)).\n    settings(commonSettings ++ slangEmbeddedSettings ++ slangEmbeddedInspectorSettings)\n}\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/project\/build.properties",
        {
          "type" : "ITestResource",
          "content" : "sbt.version=1.9.0\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/project\/plugins.sbt",
        {
          "type" : "ITestResource",
          "content" : "addSbtPlugin(\"com.eed3si9n\" % \"sbt-assembly\" % \"0.15.0\")\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/ArchitectureDescription.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art\n\nimport org.sireum._\n\n\n@datatype class ArchitectureDescription(components: IS[Art.BridgeId, Bridge],\n                                        connections: IS[Art.ConnectionId, UConnection]) {\n  @spec val allPorts: ISZ[UPort] = $\n\n  @spec def allPortsSpec(i: Z): ISZ[UPort] = $\n  \/*\n    l\"\"\"\n    = base:  ISZ[UPort](), if i == 0\n    = rec:   components(i).ports.all ++ allPorts(i - 1), if 0 < i \u2227 i < components.size\n  \"\"\"\n\n  l\"\"\" invariant\n\n         AllPorts:\n           allPorts \u2261 allPortsSpec(components.size - 1)\n\n         ComponentIdUnique:\n           \u2200i: [0, components.size)\n             \u2200j: [0, components.size)\n               i \u2260 j \u2192 components(i).id \u2260 components(j).id\n\n         PortIdUnique:\n           \u2200i: [0, allPorts.size)\n             \u2200j: [0, allPorts.size)\n               i \u2260 j \u2192 allPorts(i).id \u2260 allPorts(j).id\n   \"\"\"\n  *\/\n}\n\n@datatype trait UConnection {\n  \/*\n  l\"\"\" invariant\n         FromPortOut:   from.mode \u2261 PortMode.DataOut \u2228 from.mode \u2261 PortMode.EventOut\n         DataPort:    (from.mode \u2261 PortMode.DataOut) \u2261 (to.mode \u2261 PortMode.DataIn)\n         EventPort:  (from.mode \u2261 PortMode.EventOut) \u2261 (to.mode \u2261 PortMode.EventIn)  \"\"\"\n  *\/\n\n  def from: UPort\n\n  def to: UPort\n}\n\n@datatype class Connection(val from: UPort, val to: UPort)\n  extends UConnection\n\n\n@enum object PortMode {\n  'DataIn\n  'DataOut\n  'EventIn\n  'EventOut\n}\n\n@datatype trait UPort {\n  def id: Art.PortId\n\n  def name: String\n\n  def mode: PortMode.Type\n}\n\n@datatype trait PortProto extends UPort\n\n@datatype class Port[T](val id: Art.PortId,\n                        val name: String,\n                        val mode: PortMode.Type)\n  extends PortProto\n\n@datatype trait UrgentPortProto extends UPort {\n  def urgency: Z\n}\n\n@datatype class UrgentPort[T](val id: Art.PortId,\n                              val name: String,\n                              val mode: PortMode.Type,\n                              val urgency: Z)\n  extends UrgentPortProto\n\n@sig trait Bridge {\n  def id: Art.BridgeId\n\n  def name: String\n\n  def ports: Bridge.Ports\n\n  def entryPoints: Bridge.EntryPoints\n\n  def dispatchProtocol: DispatchPropertyProtocol\n}\n\n\nobject Bridge {\n\n  \/\/ initialise()  ( compute() )* finalise()\n  @sig trait EntryPoints {\n\n    def initialise(): Unit\n\n    def compute(): Unit\n\n    def finalise(): Unit\n\n    def testCompute(): Unit = {\n      println(\"Default testCompute\")\n    }\n\n    def testInitialise(): Unit = {\n      println(\"Default testInitialise\")\n    }\n  }\n\n  @datatype class Ports(dataIns: ISZ[UPort],\n                        dataOuts: ISZ[UPort],\n                        eventIns: ISZ[UPort],\n                        eventOuts: ISZ[UPort])\n\n}\n\n\n@datatype trait DispatchPropertyProtocol\n\nobject DispatchPropertyProtocol {\n\n  @datatype class Periodic(period: Z) extends DispatchPropertyProtocol\n\n  \/\/ @datatype class Aperiodic() extends DispatchPropertyProtocol\n\n  @datatype class Sporadic(min: Z) extends DispatchPropertyProtocol\n\n  \/\/ @datatype class Timed() extends DispatchPropertyProtocol\n\n  \/\/ @datatype class Hybrid() extends DispatchPropertyProtocol\n}\n\n@datatype trait DispatchStatus\n\n@datatype class TimeTriggered() extends DispatchStatus\n\n@datatype class EventTriggered(portIds: ISZ[Art.PortId]) extends DispatchStatus",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/Art.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art\n\nimport org.sireum._\nimport art.scheduling.Scheduler\n\nobject Art {\n\n  @range(min = 0, max = 2, index = T) class BridgeId\n\n  @range(min = 0, max = 27, index = T) class PortId\n\n  @range(min = 0, max = 11, index = T) class ConnectionId\n\n  type Time = S64 \/\/ Z might be too small after transpiling\n\n  val numComponents: Z = 3\n  val numPorts: Z = 28\n  val numConnections: Z = 12\n\n  val logTitle: String = \"Art\"\n\n  val bridges: MSZ[Option[Bridge]] = MS.create(numComponents, None[Bridge]())\n  val ports: MS[Art.PortId, Option[UPort]] = MS.create[Art.PortId, Option[UPort]](numPorts, None[UPort]())\n  val connections: MS[Art.PortId, IS[Art.ConnectionId, Art.PortId]] = MS.create[Art.PortId, IS[Art.ConnectionId, Art.PortId]](numPorts, IS())\n\n  \/\/ Note on transpiling:\n  \/\/ ports and connections are not touched\/transpiled when targeting seL4. Bridges\n  \/\/ are isolated when transpiling so BridgeId.Max could be 0, but changing Min\/Max is\n  \/\/ not currently supported by the transpiler so instead bridges is defined as an MSZ\n  \/\/ so that that its size can be set to 1 and thus reduce stack space requirements\n\n\n  @pure def bridge(bridgeId: Art.BridgeId): Bridge = {\n    return bridges(bridgeId.toZ).get\n  }\n\n  @pure def port(p: Art.PortId): UPort = {\n    return ports(p).get\n  }\n\n  def register(bridge: Bridge): Unit = {\n    bridges(bridge.id.toZ) = Some(bridge)\n    bridge.dispatchProtocol match {\n      case DispatchPropertyProtocol.Periodic(period) =>\n        ArtNative.logInfo(logTitle, s\"Registered component: ${bridge.name} (periodic: $period)\")\n      case DispatchPropertyProtocol.Sporadic(min) =>\n        ArtNative.logInfo(logTitle, s\"Registered component: ${bridge.name} (sporadic: $min)\")\n    }\n\n    def r(uports: ISZ[UPort]): Unit = {\n      for (port <- uports) {\n        ports(port.id) = Some(port)\n        \/* transpiler does not emit an extractor for matches in nested functions\n        port.mode match {\n          case PortMode.DataIn => ArtNative.logInfo(logTitle, s\"- Registered port: ${port.name} (data in)\")\n          case PortMode.DataOut => ArtNative.logInfo(logTitle, s\"- Registered port: ${port.name} (data out)\")\n          case PortMode.EventIn => ArtNative.logInfo(logTitle, s\"- Registered port: ${port.name} (event in)\")\n          case PortMode.EventOut => ArtNative.logInfo(logTitle, s\"- Registered port: ${port.name} (event out)\")\n        }\n        *\/\n        val typ: String = if (port.mode == PortMode.DataIn) \"(data in)\" else if (port.mode == PortMode.DataOut) \"(data out)\" else if (port.mode == PortMode.EventOut) \"(event out)\" else if (port.mode == PortMode.EventIn) \"(event in)\" else \"(infeasible)\"\n        ArtNative.logInfo(logTitle, s\"- Registered port: ${port.name} $typ\")\n      }\n    }\n\n    r(bridge.ports.dataIns)\n    r(bridge.ports.dataOuts)\n    r(bridge.ports.eventIns)\n    r(bridge.ports.eventOuts)\n  }\n\n  \/\/ can't find definition in the standard ??\n  def dispatchStatus(bridgeId: Art.BridgeId): DispatchStatus = { \/\/ DISPATCH_STATUS\n    return ArtNative.dispatchStatus(bridgeId)\n  }\n\n  def receiveInput(eventPortIds: ISZ[Art.PortId], dataPortIds: ISZ[Art.PortId]): Unit = { \/\/ RECEIVE_INPUT\n    ArtNative.receiveInput(eventPortIds, dataPortIds)\n  }\n\n  def putValue(portId: PortId, data: DataContent): Unit = { \/\/ PUT_VALUE\n    ArtNative.putValue(portId, data)\n  }\n\n  def getValue(portId: PortId): Option[DataContent] = { \/\/ GET_VALUE\n    return ArtNative.getValue(portId)\n  }\n\n  def sendOutput(eventPortIds: ISZ[Art.PortId], dataPortIds: ISZ[Art.PortId]): Unit = { \/\/ SEND_OUTPUT\n    ArtNative.sendOutput(eventPortIds, dataPortIds)\n  }\n\n  \/** The seL4 platform doesn't use the bridges data structure and its\n    * version of the loggers ignore the 'title' parameter. Not pattern matching\n    * here as that adds an Option to the stack which increases the stack size.\n    *\/\n  def logInfo(bridgeId: Art.BridgeId, msg: String): Unit = {\n    if (bridges(bridgeId.toZ).nonEmpty) {\n      ArtNative.logInfo(bridges(bridgeId.toZ).get.name, msg)\n    } else {\n      ArtNative.logInfo(\"\", msg)\n    }\n  }\n\n  def logError(bridgeId: Art.BridgeId, msg: String): Unit = {\n    if (bridges(bridgeId.toZ).nonEmpty) {\n      ArtNative.logError(bridges(bridgeId.toZ).get.name, msg)\n    } else {\n      ArtNative.logError(\"\", msg)\n    }\n  }\n\n  def logDebug(bridgeId: Art.BridgeId, msg: String): Unit = {\n    if (bridges(bridgeId.toZ).nonEmpty) {\n      ArtNative.logDebug(bridges(bridgeId.toZ).get.name, msg)\n    } else {\n      ArtNative.logDebug(\"\", msg)\n    }\n  }\n\n  def connect(from: UPort, to: UPort): Unit = {\n    connections(from.id) = connections(from.id) :+ to.id\n    ArtNative.logInfo(logTitle, s\"Connected ports: ${from.name} -> ${to.name}\")\n  }\n\n  \/\/ JH: Refactor\n  \/\/ Define explicit assemble phase (to support both test and execution modes)\n  def assemble(system: ArchitectureDescription): Unit = {\n    for (component <- system.components) {\n      register(component)\n    }\n\n    for (connection <- system.connections) {\n      connect(connection.from, connection.to)\n    }\n  }\n\n  def run(system: ArchitectureDescription,\n          scheduler: Scheduler): Unit = {\n\n    assemble(system)\n\n    setUpArchitecture()\n    setUpPlatform()\n    setUpSystemState(scheduler)\n\n    initializePhase(scheduler)\n    computePhase(scheduler)\n    finalizePhase(scheduler)\n\n    tearDownSystemState()\n    tearDownPlatform()\n    tearDownArchitecture()\n  }\n\n  def initializePhase(scheduler: Scheduler): Unit = {\n    ArtNative.initializePhase()\n    scheduler.initializationPhase()\n  }\n\n  def computePhase(scheduler: Scheduler): Unit = {\n    ArtNative.computePhase()\n    scheduler.computePhase()\n  }\n\n  def finalizePhase(scheduler: Scheduler): Unit = {\n    ArtNative.finalizePhase()\n    scheduler.finalizePhase()\n  }\n\n  def setUpArchitecture(): Unit = {}\n\n  def tearDownArchitecture(): Unit = {}\n\n  def setUpPlatform(): Unit = {}\n\n  def tearDownPlatform(): Unit = {}\n\n  def setUpSystemState(scheduler: Scheduler): Unit = {\n    ArtNative.setUpSystemState()\n    scheduler.initialize()\n  }\n\n  def tearDownSystemState(): Unit = {\n    ArtNative.tearDownSystemState()\n  }\n\n  def time(): Time = {\n    return ArtNative.time()\n  }\n\n  \/\/\/\/\/\/\/\/\/\/\/\/\/\n  \/\/ TESTING \/\/\n  \/\/\/\/\/\/\/\/\/\/\/\/\/\n\n  \/**\n   * Clears any existing ports and bridges, then sets up ports\/bridges for the next test.\n   *\n   * Automatically called by BridgeTestSuite before each test.\n   *\/\n  def initTest(bridge: Bridge): Unit = {\n    \/\/ remove all bridges\n    for (i <- bridges.indices) {\n      bridges(i) = None()\n    }\n\n    \/\/ remove all connections\n    for (i <- connections.indices) {\n      connections(i) = IS()\n    }\n\n    \/\/ remove all ports\n    for (i <- ports.indices) {\n      ports(i) = None()\n    }\n\n    \/\/ register bridge passed to this method\n    register(bridge)\n\n    \/\/ call ArtNative to reset the state of the specific thread component\n    ArtNative.initTest(bridge)\n  }\n\n  \/**\n  * Executes a component (identified by bridge) Initialize Entry Point (application code)\n  * for the purposes of unit testing.\n  *\n  * This infrastructure method is called with automatically generated unit testing support code.\n  * The developer-facing version of this method (called by a developer unit test)\n  * provided by the unit testing support code hides the bridge argument.  The bridge\n  * value is retrieved from the testing infrastructure code before passing the call\n  * through to this method.\n  *\/\n  def testInitialise(bridge: Bridge): Unit = {\n    ArtNative.testInitialise(bridge)\n  }\n\n  \/**\n   * Executes a component (identified by bridge) Compute Entry Point (application code)\n   * for the purposes of unit testing.\n   *\n   * This infrastructure method is called with automatically generated unit testing support code.\n   * The developer-facing version of this method (called by a developer unit test)\n   * provided by the unit testing support code hides the bridge argument.  The bridge\n   * value is retrieved from the testing infrastructure code before passing the call\n   * through to this method.\n   *\/\n  def testCompute(bridge: Bridge): Unit = {\n    ArtNative.testCompute(bridge)\n  }\n\n\n  def finalizeTest(bridge: Bridge): Unit = {\n    ArtNative.finalizeTest(bridge)\n  }\n\n  \/\/ JH: Refactored\n  \/\/   add system test capability\n  def initSystemTest(system: ArchitectureDescription,\n                     scheduler: Scheduler): Unit = {\n    \/\/ remove all bridges\n    for (i <- bridges.indices) {\n      bridges(i) = None()\n    }\n\n    \/\/ remove all connections\n    for (i <- connections.indices) {\n      connections(i) = IS()\n    }\n\n    \/\/ remove all ports\n    for (i <- ports.indices) {\n      ports(i) = None()\n    }\n    \/\/ It seems to me that it might be best to do this once and for all (not for every test) as it is really\n    \/\/ a static description of the model that will not be changing.\n    assemble(system)\n\n    \/\/ let ArtNative reset itself as well\n    ArtNative.initSystemTest(scheduler)\n  }\n\n  \/\/  def executeSystemTest(): Unit = {\n  \/\/    ArtNative.executeTest()\n  \/\/  }\n\n  \/\/ JH: Refactored\n  \/\/   add system test capability\n  def finalizeSystemTest(): Unit = {\n    ArtNative.finalizeSystemTest()\n  }\n\n  def releaseOutput(eventPortIds: ISZ[Art.PortId], dataPortIds: ISZ[Art.PortId]): Unit = {\n    ArtNative.releaseOutput(eventPortIds, dataPortIds)\n  }\n\n  def manuallyClearOutput(): Unit = {\n    ArtNative.manuallyClearOutput()\n  }\n\n  def insertInInfrastructurePort(dstPortId: Art.PortId, data: DataContent): Unit = {\n    ArtNative.insertInInfrastructurePort(dstPortId, data)\n  }\n\n  def observeInInfrastructurePort(portId: Art.PortId): Option[DataContent] = {\n    return ArtNative.observeInInfrastructurePort(portId)\n  }\n\n  def observeOutInfrastructurePort(portId: Art.PortId): Option[DataContent] = {\n    return ArtNative.observeOutInfrastructurePort(portId)\n  }\n\n  def observeInPortVariable(portId: Art.PortId): Option[DataContent] = {\n    return ArtNative.observeInPortVariable(portId)\n  }\n\n  def observeOutPortVariable(portId: Art.PortId): Option[DataContent] = {\n    return ArtNative.observeOutPortVariable(portId)\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/ArtDebug.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art\n\nimport org.sireum._\n\n@ext object ArtDebug {\n\n  def injectPort(bridgeId: Art.BridgeId, port: Art.PortId, data: DataContent): Unit = $\n\n  def registerListener(listener: ArtListener): Unit = $\n\n  def setDebugObject[T](key: String, o: T): Unit = $\n\n  def getDebugObject[T](key: String): Option[T] = $\n}\n\n@msig trait ArtListener {\n\n  \/\/ lifecycle information\n  def start(time: Art.Time): Unit\n\n  def stop(time: Art.Time): Unit\n\n  \/\/ communication information\n  def output(src: Art.PortId, dst: Art.PortId, data: DataContent, time: Art.Time): Unit\n\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/ArtDebug_Ext.scala",
        {
          "type" : "ITestResource",
          "content" : "package art\n\nimport org.sireum._\nimport art.Art.Time\nimport scala.collection.mutable.{Map => MMap, Set => MSet}\n\nobject ArtDebug_Ext {\n  private val debugObjects: MMap[String, Any] = ArtNative_Ext.concMap()\n  private val listeners: MSet[ArtListener] = concSet()\n\n  protected[art] def start(): Unit = {\n    val time = Art.time()\n    listeners.foreach((listener: ArtListener) => listener.start(time))\n  }\n\n  protected[art] def stop(): Unit = {\n    val time = Art.time()\n    listeners.foreach((listener: ArtListener) => listener.stop(time))\n  }\n\n  protected[art] def outputCallback(src: Art.PortId, dst: Art.PortId, data: DataContent, time: Time): Unit = {\n    listeners.foreach((listener: ArtListener) => listener.output(src, dst, data, time))\n  }\n\n  def setDebugObject[T](key: String, o: T): Unit = {\n    ArtNative.logDebug(Art.logTitle, s\"Set debug object for $key\")\n    debugObjects(key) = o\n  }\n\n  def getDebugObject[T](key: String): Option[T] = {\n    debugObjects.get(key) match {\n      case scala.Some(o) => Some(o.asInstanceOf[T])\n      case _ => None[T]()\n    }\n  }\n\n  def injectPort(bridgeId: Art.BridgeId, port: Art.PortId, data: DataContent): Unit = {\n\n    val bridge = Art.bridges(bridgeId.toZ).get\n\n    if (bridge.ports.dataOuts.elements.map(_.id).contains(port) ||\n      bridge.ports.eventOuts.elements.map(_.id).contains(port)) {\n\n      ArtNative.logDebug(Art.logTitle, s\"Injecting from port ${Art.ports(port).get.name}\")\n\n      ArtNative.putValue(port, data)\n\n      ArtNative.sendOutput(bridge.ports.eventOuts.map(_.id), bridge.ports.dataOuts.map(_.id))\n    } else {\n      ArtNative.logDebug(Art.logTitle, s\"Injecting to port ${Art.ports(port).get.name}\")\n\n      \/\/ right now, there is no difference between treatment of data and event ports, but keep the logic\n      \/\/ separate for further refactoring\n      if (bridge.ports.dataIns.elements.map(_.id).contains(port)) {\n        ArtNative_Ext.inInfrastructurePorts(port.toZ) = ArtMessage(data)\n      } else {\n        ArtNative_Ext.inInfrastructurePorts(port.toZ) = ArtMessage(data)\n      }\n    }\n  }\n\n  def registerListener(listener: ArtListener): Unit = {\n    listeners.add(listener)\n  }\n\n  def concSet[K](): MSet[K] = {\n    import org.sireum.$internal.CollectionCompat.Converters._\n    val m: java.util.Set[K] = java.util.concurrent.ConcurrentHashMap.newKeySet()\n    m.asScala\n  }\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/ArtNative.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art\n\nimport org.sireum._\nimport art.scheduling.Scheduler\n\n@ext object ArtNative {\n\n  def shouldDispatch(bridgeId: Art.BridgeId): B = $\n\n  def dispatchStatus(bridgeId: Art.BridgeId): DispatchStatus = $\n\n\n  def receiveInput(eventPortIds: ISZ[Art.PortId], dataPortIds: ISZ[Art.PortId]): Unit = $\n\n  def putValue(portId: Art.PortId, data: DataContent): Unit = $\n\n  def getValue(portId: Art.PortId): Option[DataContent] = $\n\n  def sendOutput(eventPortIds: ISZ[Art.PortId], dataPortIds: ISZ[Art.PortId]): Unit = $\n\n\n  def logInfo(title: String, msg: String): Unit = $\n\n  def logError(title: String, msg: String): Unit = $\n\n  def logDebug(title: String, msg: String): Unit = $\n\n\n  def tearDownSystemState(): Unit = $\n\n  def setUpSystemState(): Unit = $\n\n  \/\/ JH: Refactor\n  def initializePhase(): Unit = $\n\n  \/\/ JH: Refactor\n  def computePhase(): Unit = $\n\n  \/\/ JH: Refactor\n  def finalizePhase(): Unit = $\n\n  def time(): Art.Time = $\n\n  \/\/\/\/\/\/\/\/\/\/\/\/\/\n  \/\/ TESTING \/\/\n  \/\/\/\/\/\/\/\/\/\/\/\/\/\n\n  \/**\n   * Calls the initialize entry points on all registered bridges.\n   *\n   * An analogue to this method does not show up in developer-written unit tests because\n   * the it's invoked behind the scenes by the automatically generated unit test infrastructure\n   * as a prelude to each test.\n   *\n   *\/\n  def initTest(bridge: Bridge): Unit = $\n\n  \/**\n   * Executes the application code in the Initialize Entry Point for the component (identified\n   * by given bridge) for the purposes of testing.\n   *\n   * Precondition: testInit() has been called prior.\n   *\n   * Unlike [[Art.run()]], this method does NOT wrap compute calls in a try-catch block.\n   * This is to ensure no exceptions are overlooked during testing.\n  *\/\n  def testInitialise(bridge: Bridge): Unit = $\n\n  \/**\n   * Executes the application code in the Compute Entry Point for the component (identified\n   * by given bridge) for the purposes of testing.\n   *\n   * Precondition: initTest() has been called prior.\n   *\n   * Unlike [[Art.run()]], this method does NOT wrap compute calls in a try-catch block.\n   * This is to ensure no exceptions are overlooked during testing.\n   *\/\n  def testCompute(bridge: Bridge): Unit = $\n\n  \/**\n   * Calls the finalize entry points on all registered bridges.\n   *\n   * An analogue to this method does not show up in developer-written unit tests because\n   * the it's invoked behind the scenes by the automatically generated unit test infrastructure\n   * as a postlude to each test.\n   *\/\n  def finalizeTest(bridge: Bridge): Unit = $\n\n  \/\/ JH: Refactored\n  \/\/   add system test capability\n  def initSystemTest(scheduler: Scheduler): Unit = $\n\n  \/\/  def executeSystemTest(): Unit = $\n\n  \/\/ JH: Refactored\n  \/\/   add system test capability\n  def finalizeSystemTest(): Unit = $\n\n  \/**\n   * A method that replaces bridge.compute()'s calls to [[Art.sendOutput()]] in its equivalent testCompute() method.\n   *\n   * This method is currently a NO-OP, but may gain functionality later.\n   *\n   * @param eventPortIds the event ports to be \"copied and cleared\" (but currently nothing happens)\n   * @param dataPortIds the data ports to be \"copied and cleared\" (but currently nothing happens)\n   *\/\n  def releaseOutput(eventPortIds: ISZ[Art.PortId], dataPortIds: ISZ[Art.PortId]): Unit = $\n\n  \/**\n   * Because a bridge's testCompute() doesn't clear outputs, this method can be used by users to manually\n   * clear the output if desired. This is useful for tests involving multiple dispatches.\n   *\/\n  def manuallyClearOutput(): Unit = $\n\n  \/**\n   * Inserts a value into an \"infrastructure in\" port. For testing only, normally this is handled by Art.\n   *\n   * @param dstPortId the portId to place the passed [[DataContent]] into\n   * @param data the [[DataContent]] which will be placed in the dstPort\n   *\/\n  def insertInInfrastructurePort(dstPortId: Art.PortId, data: DataContent): Unit = $\n\n  \/**\n   * Returns the value of an infrastructure in port.\n   *\n   * @param portId the id of the INPUT infrastructure port to return a value from\n   * @return If the port is non-empty, a [[Some]] of [[DataContent]]. Otherwise [[None]].\n   *\/\n  def observeInInfrastructurePort(portId: Art.PortId): Option[DataContent] = $\n\n  \/**\n   * Returns the value of an infrastructure out port.\n   *\n   * @param portId the id of the OUTPUT port to return a value from\n   * @return If the port is non-empty, a [[Some]] of [[DataContent]]. Otherwise [[None]].\n   *\/\n  def observeOutInfrastructurePort(portId: Art.PortId): Option[DataContent] = $\n\n  \/**\n     * Returns the value of an application in port.\n     *\n     * @param portId the id of the INPUT port to return a value from\n     * @return If the port is non-empty, a [[Some]] of [[DataContent]]. Otherwise [[None]].\n     *\/\n  def observeInPortVariable(portId: Art.PortId): Option[DataContent] = $\n\n  \/**\n     * Returns the value of an application out port.\n     *\n     * @param portId the id of the OUTPUT port to return a value from\n     * @return If the port is non-empty, a [[Some]] of [[DataContent]]. Otherwise [[None]].\n     *\/\n  def observeOutPortVariable(portId: Art.PortId): Option[DataContent] = $\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/ArtNativeSlang.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art\n\nimport org.sireum._\nimport art.DispatchPropertyProtocol.{Periodic, Sporadic}\nimport org.sireum.S64._\n\nobject ArtSlangMessage {\n  val UNSET_TIME: Art.Time = s64\"-1\"\n}\n\n@datatype class ArtSlangMessage(data: DataContent,\n\n                                srcPortId: Art.PortId,\n                                dstPortId: Option[Art.PortId],\n\n                                \/\/ when putValue was called by producer\n                                putValueTimestamp: Art.Time,\n\n                                \/\/ when sendOutput transferred message from out port var of producer\n                                sendOutputTimestamp: Art.Time,\n\n                                \/\/ when message arrived via transport layer\n                                dstArrivalTimestamp: Art.Time,\n\n                                \/\/ when receiveInput transferred message to in port vars of consumer\n                                receiveInputTimestamp: Art.Time\n                               )\n\nobject ArtNativeSlang {\n\n  var inInfrastructurePorts: Map[Z, ArtSlangMessage] = Map.empty\n  var outInfrastructurePorts: Map[Z, ArtSlangMessage] = Map.empty\n  var inPortVariables: Map[Z, ArtSlangMessage] = Map.empty\n  var outPortVariables: Map[Z, ArtSlangMessage] = Map.empty\n\n  def shouldDispatch(bridgeId: Art.BridgeId): B = {\n    assert(Art.bridges(bridgeId.toZ).nonEmpty, s\"Bridge ${bridgeId} does not exist\")\n\n    Art.bridges(bridgeId.toZ).get.dispatchProtocol match {\n      case DispatchPropertyProtocol.Periodic(_) => return T\n      case DispatchPropertyProtocol.Sporadic(minRate) =>\n\n        val eventIns = Art.bridges(bridgeId.toZ).get.ports.eventIns\n\n        var hasEvents = F\n        \/\/ transpiler workaround -- doesn't support .exists\n        for (e <- eventIns) {\n          if (inInfrastructurePorts.contains(e.id.toZ)) {\n            hasEvents = T\n          }\n        }\n        return hasEvents\n    }\n  }\n\n  \/\/ transpiler friendly comparator\n  def lt(a: art.UPort, b: art.UPort): B = { \/\/ reverse sort\n    val r: B = (a, b) match {\n      \/\/ sorting function to make prioritized sequence of event port ids\n      \/\/   compare p1 to p2  (p1 represents the port to process earlier, i.e., should have priority)\n      case (p1: UrgentPortProto, p2: UrgentPortProto) =>\n        \/\/ if p1 has a strictly less urgency it comes after p2\n        if (p1.urgency < p2.urgency) F\n        \/\/ if p1 has a strictly greater urgency, it comes before p2\n        else if (p1.urgency > p2.urgency) T\n        \/\/ if p1 and p2 have the same urgency, the ordering is determined by arrival timestamps\n        else inInfrastructurePorts.get(p1.id.toZ).get.dstArrivalTimestamp < inInfrastructurePorts.get(p2.id.toZ).get.dstArrivalTimestamp\n      case (_: UrgentPortProto, _: PortProto) => T \/\/ urgent ports take precedence\n      case (_: PortProto, _: UrgentPortProto) => F \/\/ urgent ports take precedence\n      case (p1: PortProto, p2: PortProto) =>\n        inInfrastructurePorts.get(p1.id.toZ).get.dstArrivalTimestamp < inInfrastructurePorts.get(p2.id.toZ).get.dstArrivalTimestamp\n    }\n    return r\n  }\n\n  \/\/ transpiler friendly sort\n  def sort(ports: ISZ[UPort]): ISZ[UPort] = {\n    def insert(p: UPort, sorted: ISZ[UPort]): ISZ[UPort] = {\n      if (sorted.isEmpty) {\n        return ISZ[UPort](p)\n      }\n      else {\n        if (lt(sorted(0), p)) {\n          return sorted(0) +: insert(p, ops.ISZOps(sorted).tail)\n        }\n        else {\n          return p +: sorted\n        }\n      }\n    }\n\n    if (ports.isEmpty) {\n      return ports\n    }\n    else {\n      val sorted = sort(ops.ISZOps(ports).tail)\n      return insert(ports(0), sorted)\n    }\n  }\n\n  def dispatchStatus(bridgeId: Art.BridgeId): DispatchStatus = {\n    val ret: DispatchStatus = Art.bridges(bridgeId.toZ).get.dispatchProtocol match {\n      case Periodic(_) => TimeTriggered()\n      case Sporadic(_) =>\n        \/\/ get ids for non-empty input event ports\n        val uports: ISZ[UPort] =\n          for (p <- Art.bridges(bridgeId.toZ).get.ports.eventIns if inInfrastructurePorts.get(p.id.toZ).nonEmpty) yield p\n\n        if (uports.isEmpty) {\n          halt(s\"Unexpected: shouldDispatch() should have returned true in order to get here, however the incoming event ports are empty for bridge id ${bridgeId}\")\n        }\n\n        val urgentFifo = sort(uports)\n        EventTriggered(for (p <- urgentFifo) yield p.id)\n    }\n    return ret\n  }\n\n  def receiveInput(eventPortIds: ISZ[Art.PortId], dataPortIds: ISZ[Art.PortId]): Unit = {\n    \/\/ remove any old events from previous dispatch\n    for (portId <- eventPortIds if inPortVariables.contains(portId.toZ)) {\n      inPortVariables = inPortVariables - ((portId.toZ, inPortVariables.get(portId.toZ).get))\n    }\n\n    \/\/ transfer received data\/events from the infrastructure ports to the port variables\n    for (portId <- eventPortIds) {\n      inInfrastructurePorts.get(portId.toZ) match {\n        case Some(data) =>\n          inInfrastructurePorts = inInfrastructurePorts - ((portId.toZ, data))\n          inPortVariables = inPortVariables + (portId.toZ ~> data(receiveInputTimestamp = Art.time()))\n        case _ =>\n      }\n    }\n    for (portId <- dataPortIds) {\n      inInfrastructurePorts.get(portId.toZ) match {\n        case Some(data) =>\n          inPortVariables = inPortVariables + (portId.toZ ~> data)\n        case _ =>\n      }\n    }\n  }\n\n  def putValue(portId: Art.PortId, data: DataContent): Unit = {\n    \/\/ wrap the Art.DataContent value into an ArtMessage with time stamps\n    outPortVariables = outPortVariables + (portId.toZ ~>\n      ArtSlangMessage(data = data, srcPortId = portId, putValueTimestamp = Art.time(),\n        dstPortId = None(), sendOutputTimestamp = ArtSlangMessage.UNSET_TIME, dstArrivalTimestamp = ArtSlangMessage.UNSET_TIME, receiveInputTimestamp = ArtSlangMessage.UNSET_TIME))\n  }\n\n  def getValue(portId: Art.PortId): Option[DataContent] = {\n    \/\/ To return the value of the port to the application code, project\n    \/\/ out the actual payload value (v.data) from ArtMessage (which includes timestamps, etc.)\n    \/\/ to Art.DataContent (the \"top\"\/union data type supported by Art.\n    \/\/ The projecting preserves the option of structure of ArtMessage value.\n    if (inPortVariables.contains(portId.toZ)) {\n      return Some(inPortVariables.get(portId.toZ).get.data)\n    } else {\n      return None()\n    }\n  }\n\n  def sendOutput(eventPortIds: ISZ[Art.PortId], dataPortIds: ISZ[Art.PortId]): Unit = {\n    for (srcPortId <- eventPortIds ++ dataPortIds) {\n      outPortVariables.get(srcPortId.toZ) match {\n        case Some(msg) => {\n\n          \/\/ move payload from out port port variables to the out infrastructure ports\n          outInfrastructurePorts = outInfrastructurePorts + (srcPortId.toZ ~> msg)\n          outPortVariables = outPortVariables - ((srcPortId.toZ, msg))\n\n          \/\/ simulate sending msg via transport middleware\n          for (dstPortId <- Art.connections(srcPortId)) {\n            val _msg = msg(dstPortId = Some(dstPortId), sendOutputTimestamp = Art.time())\n\n            \/\/ send via middleware\n\n            inInfrastructurePorts = inInfrastructurePorts + (dstPortId.toZ ~>\n              _msg(dstArrivalTimestamp = Art.time()))\n          }\n\n          \/\/ payload delivered so remove it from out infrastructure port\n          outInfrastructurePorts = outInfrastructurePorts - ((srcPortId.toZ, msg))\n        }\n        case _ =>\n      }\n    }\n    \/\/ could clear outPortVariables for passed in portids but not strictly necessary\n  }\n\n  \/**\n   * Returns the value of an in infrastructure port.\n   *\n   * @param portId the id of the INPUT port to return a value from\n   * @return If the port is non-empty, a [[Some]] of [[DataContent]]. Otherwise [[None]].\n   *\/\n  def observeInInfrastructurePort(portId: Art.PortId): Option[DataContent] = {\n    \/\/ right now, with event data port queues limited to size one, there is no difference in the logic\n    \/\/ between how data ports are treated, and how event\/event data ports are treated.\n    Art.port(portId).mode match {\n      case PortMode.DataIn =>\n        inInfrastructurePorts.get(portId.toZ) match {\n          case Some(value) => return Some(value.data)\n          case _ => return None()\n        }\n      case PortMode.EventIn =>\n        inInfrastructurePorts.get(portId.toZ) match {\n          case Some(value) => return Some(value.data)\n          case _ => return None()\n        }\n      case _ => {\n        assert(false, \"expecting in port\")\n        return None()\n      }\n    }\n  }\n\n  \/**\n   * Returns the value of an infrastructure out port.\n   *\n   * @param portId the id of the OUTPUT port to return a value from\n   * @return If the port is non-empty, a [[Some]] of [[DataContent]]. Otherwise [[None]].\n   *\/\n  def observeOutInfrastructurePort(portId: Art.PortId): Option[DataContent] = {\n    \/\/ note: would be changed when we refactor to support event queues of size > 1\n    outInfrastructurePorts.get(portId.toZ) match {\n      case Some(value) => return Some(value.data)\n      case _ => return None()\n    }\n  }\n\n  \/**\n   * Returns the value of an application in port.\n   *\n   * @param portId the id of the INPUT port to return a value from\n   * @return If the port is non-empty, a [[Some]] of [[DataContent]]. Otherwise [[None]].\n   *\/\n  def observeInPortVariable(portId: Art.PortId): Option[DataContent] = {\n    \/\/ right now, with event data port queues limited to size one, there is no difference in the logic\n    \/\/ between how data ports are treated, and how event\/event data ports are treated.\n    Art.port(portId).mode match {\n      case PortMode.DataIn =>\n        inPortVariables.get(portId.toZ) match {\n          case Some(value) => return Some(value.data)\n          case _ => return None()\n        }\n      case PortMode.EventIn =>\n        inPortVariables.get(portId.toZ) match {\n          case Some(value) => return Some(value.data)\n          case _ => return None()\n        }\n      case _ => {\n        assert(false, \"expecting in port\")\n        return None()\n      }\n    }\n  }\n\n  \/**\n     * Returns the value of an application out port.\n     *\n     * @param portId the id of the OUTPUT port to return a value from\n     * @return If the port is non-empty, a [[Some]] of [[DataContent]]. Otherwise [[None]].\n     *\/\n  def observeOutPortVariable(portId: Art.PortId): Option[DataContent] = {\n    \/\/ note: would be changed when we refactor to support event queues of size > 1\n    outPortVariables.get(portId.toZ) match {\n      case Some(value) => return Some(value.data)\n      case _ => return None()\n    }\n  }\n\n  def logInfo(title: String, msg: String): Unit = {\n    print(title)\n    print(\": \")\n    println(msg)\n  }\n\n  def logDebug(title: String, msg: String): Unit = {\n    eprint(title)\n    eprint(\": \")\n    eprintln(msg)\n  }\n\n  def logError(title: String, msg: String): Unit = {\n    print(title)\n    print(\": \")\n    println(msg)\n  }\n\n\n  def setUpSystemState(): Unit = {\n    \/\/ probably nothing to do here\n  }\n\n  def tearDownSystemState(): Unit = {\n    \/\/ probably nothing to do here\n  }\n\n\n  def initializePhase(): Unit = {\n    \/\/ probably nothing to do here\n  }\n\n  def computePhase(): Unit = {\n    \/\/ probably nothing to do here\n  }\n\n  def finalizePhase(): Unit = {\n    \/\/ probably nothing to do here\n  }\n\n\n  def time(): Art.Time = {\n    return Process.time()\n  }\n}\n\n@ext(name = \"art.ArtNative_Ext\") object Process {\n  def time(): Art.Time = $\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/ArtNative_Ext.scala",
        {
          "type" : "ITestResource",
          "content" : "package art\n\nimport org.sireum._\nimport art.DispatchPropertyProtocol.{Periodic, Sporadic}\nimport art.scheduling.Scheduler\nimport org.sireum.S64._\nimport scala.collection.mutable.{Map => MMap}\n\nobject ArtMessage {\n  val UNSET_TIME: Art.Time = s64\"-1\"\n}\n\ncase class ArtMessage(data: DataContent,\n\n                      var srcPortId: Option[Art.PortId] = None(),\n                      var dstPortId: Option[Art.PortId] = None(),\n\n                      \/\/ when putValue was called by producer\n                      var putValueTimestamp: Art.Time = ArtMessage.UNSET_TIME,\n\n                      \/\/ when sendOutput transferred message from out port var of producer\n                      var sendOutputTimestamp: Art.Time = ArtMessage.UNSET_TIME,\n\n                      \/\/ when message arrived via transport layer\n                      var dstArrivalTimestamp: Art.Time = ArtMessage.UNSET_TIME,\n\n                      \/\/ when receiveInput transferred message to in port vars of consumer\n                      var receiveInputTimestamp: Art.Time = ArtMessage.UNSET_TIME\n                     )\n\nobject ArtNative_Ext {\n  val noTime: Art.Time = s64\"0\"\n\n  val slowdown: Z = 1\n\n  \/\/================================================================\n  \/\/   A r c h i t e c t u r e     D e s c r i p t i o n\n  \/\/================================================================\n\n  \/\/ Architecture description includes any data structures built from Arch information\n  \/\/ to support system execution (i.e., by making certain types of lookup of Arch\n  \/\/ information easier).   This information persists across runs, i.e., it doesn't\n  \/\/ need to be changed between different runs of the system as long as the architecture\n  \/\/ has not changed.\n\n  \/\/ JH: Refactored - moved out of legacy run method to enable separate\n  \/\/ init\/compute\/finalize phase methods.\n  \/\/    This structure is essentially a helper for accessing the Arch description.\n  \/\/    We should study the Arch description to assess (more systematically)\n  \/\/    what types of helpers are needed and where they would go.\n  \/*\n  var activeBridges: IS[Art.BridgeId, Art.BridgeId] = ISZ()\n  def setUpArchitecture() : Unit = {\n    for(e <- Art.bridges.elements if(e.nonEmpty)) {\n      activeBridges = activeBridges :+ e.get.id\n    }\n  }\n  def tearDownArchitecture() : Unit = {\n    activeBridges = IS[Art.BridgeId, Art.BridgeId]()\n  }\n  *\/\n\n  \/\/================================================================\n  \/\/   P l a t f o r m     S t a t e\n  \/\/================================================================\n\n  \/\/ Architecture description includes any infrastructure necessary to\n  \/\/ support the platform including communication instrastructure and\n  \/\/ other resources that may exist across multiple executions\n\n  \/*\n  def setUpPlatform() : Unit = {\n  }\n  def tearDownPlatform() : Unit = {\n  }\n  *\/\n\n  \/\/================================================================\n  \/\/   S y s t e m     S t a t e\n  \/\/================================================================\n\n  val inInfrastructurePorts: MMap[Z, ArtMessage] = concMap()\n  val outInfrastructurePorts: MMap[Z, ArtMessage] = concMap()\n  val inPortVariables: MMap[Z, ArtMessage] = concMap()\n  val outPortVariables: MMap[Z, ArtMessage] = concMap()\n\n\n  \/\/ Initializes system state in preparation for execution of initialize, compute, and finalize phases\n  \/\/ System state includes any state associated with system execution, e.g., things that would need to be\n  \/\/ set up and cleared between runs, but does not include things related to system architecture or platform\n  \/\/ infrastructure that could persist between runs.\n\n  def setUpSystemState(): Unit = {\n    inInfrastructurePorts.clear()\n    inPortVariables.clear()\n    outPortVariables.clear()\n    outInfrastructurePorts.clear()\n\n    \/\/ cancel pending ArtTimer callbacks (also done after a test completes)\n    ArtTimer_Ext.scheduledCallbacks.keys.foreach(ArtTimer_Ext.cancel)\n\n    \/\/scheduler.initialize()\n  }\n\n  def tearDownSystemState(): Unit = {\n    inInfrastructurePorts.clear()\n    inPortVariables.clear()\n    outPortVariables.clear()\n    outInfrastructurePorts.clear()\n\n    \/\/ cancel pending ArtTimer callbacks (also done after a test completes)\n    ArtTimer_Ext.scheduledCallbacks.keys.foreach(ArtTimer_Ext.cancel)\n  }\n\n\n  \/\/===============================================================================\n  \/\/  Port-related AADL run-time services\n  \/\/===============================================================================\n\n  \/\/ JH: Refactored -- renamed port data structures\n  \/\/ TODO -- Consider whether changing the value from ArtMessage to Art.DataContent should happen here (instead of in getValue)\n  def receiveInput(eventPortIds: ISZ[Art.PortId], dataPortIds: ISZ[Art.PortId]): Unit = {\n    \/\/ remove any old events from previous dispatch\n    for (portId <- eventPortIds if inPortVariables.contains(portId.toZ)) {\n      inPortVariables -= portId.toZ\n    }\n\n    \/\/ transfer received data\/events from the infrastructure ports to the port variables\n    for (portId <- eventPortIds) {\n      inInfrastructurePorts.get(portId.toZ) match {\n        case scala.Some(data) =>\n          inInfrastructurePorts -= portId.toZ \/\/ dequeue from infrastructure port\n          inPortVariables(portId.toZ) = data \/\/ when we shift to queue size greater than 1, we would enqueue here\n        case _ =>\n      }\n    }\n    for (portId <- dataPortIds) {\n      inInfrastructurePorts.get(portId.toZ) match {\n        case scala.Some(data) =>\n          \/\/ for data ports, we don't dequeue from infrastastructure ports\n          inPortVariables(portId.toZ) = data\n        case _ =>\n      }\n    }\n  }\n\n  def putValue(portId: Art.PortId, data: DataContent): Unit = {\n    \/\/ wrap the Art.DataContent value into an ArtMessage with time stamps\n    outPortVariables(portId.toZ) = ArtMessage(data = data, srcPortId = Some(portId), putValueTimestamp = Art.time())\n  }\n\n  def getValue(portId: Art.PortId): Option[DataContent] = {\n    \/\/ To return the value of the port to the application code, project\n    \/\/ out the actual payload value (v.data) from ArtMessage (which includes timestamps, etc.)\n    \/\/ to Art.DataContent (the \"top\"\/union data type supported by Art.\n    \/\/ The projecting preserves the option of structure of ArtMessage value.\n    val data = inPortVariables.get(portId.toZ) match {\n      case scala.Some(v) => org.sireum.Some(v.data)\n      case _ => org.sireum.None[DataContent]()\n    }\n    return data\n  }\n\n  \/\/ JH: Refactored\n  \/\/      - change names of port data structures\n  \/\/      - introduce a distinction between output port variables and output infrastructure ports\n  \/\/ ToDo: Introduce the concept of a distinct transfer method.\n  \/\/  The way that implementation treats outPortVariables and outInfrastructurePorts is almost nonsensical\n  \/\/  until that refactoring is made.\n  def sendOutput(eventPortIds: ISZ[Art.PortId], dataPortIds: ISZ[Art.PortId]): Unit = { \/\/ SEND_OUTPUT\n    for (srcPortId <- eventPortIds ++ dataPortIds) {\n      outPortVariables.get(srcPortId.toZ) match {\n        case scala.Some(msg) =>\n          \/\/ move payload from out port port variables to the out infrastructure ports\n          outInfrastructurePorts(srcPortId.toZ) = outPortVariables(srcPortId.toZ)\n          outPortVariables -= srcPortId.toZ\n\n          \/\/ simulate sending msg via transport middleware\n          for (dstPortId <- Art.connections(srcPortId).elements) {\n\n            val _msg = msg.copy(dstPortId = Some(dstPortId), sendOutputTimestamp = Art.time())\n\n            Art.port(dstPortId).mode match {\n              \/\/ right now, there is no difference in the logic between data and event ports,\n              \/\/ but keep the code separate for future refactorings\n              case PortMode.DataIn | PortMode.DataOut =>\n                inInfrastructurePorts(dstPortId.toZ) = _msg\n              case PortMode.EventIn | PortMode.EventOut =>\n                inInfrastructurePorts(dstPortId.toZ) = _msg\n            }\n\n            _msg.dstArrivalTimestamp = Art.time()\n\n            ArtDebug_Ext.outputCallback(srcPortId, dstPortId, _msg.data, _msg.dstArrivalTimestamp)\n          }\n\n          \/\/ payload delivered so remove it from out infrastructure port\n          outInfrastructurePorts -= srcPortId.toZ\n        case _ =>\n      }\n    }\n  }\n\n  \/\/ JH: Refactor\n  \/\/ Manually added by JH to support debugging framework\n  \/\/  -- to support being able to see inputs and outputs of a a thread (before\/after compute),\n  \/\/     clearing of output ports is removed from send_output.\n  \/\/  This function is called by scheduler, before calling compute to initialize the\n  \/\/  component port state\n  def clearPortVariables(bridgeId: Art.BridgeId): Unit = {\n    \/\/ val b = Art.bridge(bridgeId) -- refactor\n    \/\/ ToDo: the computation of input\/output port ids should be helper functions in Bridge\n    \/\/ compute inPortIds\n    val inPortIds = Art.bridges(bridgeId.toZ).get.ports.eventIns.elements.map(_.id) ++ Art.bridges(bridgeId.toZ).get.ports.dataIns.elements.map(_.id)\n    \/\/ iterate through inPortIds and clear the value of each corresponding port variable\n    for (portId <- inPortIds) {\n      inPortVariables -= portId.toZ;\n    }\n    \/\/ compute outPortIds\n    val outPortIds = Art.bridges(bridgeId.toZ).get.ports.eventOuts.elements.map(_.id) ++ Art.bridges(bridgeId.toZ).get.ports.dataOuts.elements.map(_.id)\n    \/\/ iterate through outPortIds and clear the value of each corresponding port variable\n    for (portId <- outPortIds) {\n      outPortVariables -= portId.toZ\n    }\n  }\n\n  \/\/===============================================================================\n  \/\/  HAMR Library Services\n  \/\/===============================================================================\n\n  def logInfo(title: String, msg: String): Unit = log(\"info\", title, msg)\n\n  def logError(title: String, msg: String): Unit = log(\"error\", title, msg)\n\n  def logDebug(title: String, msg: String): Unit = log(\"debug\", title, msg)\n\n  def time(): Art.Time = toS64(System.currentTimeMillis())\n\n  \/\/===============================================================================\n  \/\/  AADL Thread\/Scheduling services\n  \/\/===============================================================================\n\n  \/\/ JH: Refactor to match logic in semantics, group with dispatch status\n  def shouldDispatch(bridgeId: Art.BridgeId): B = {\n    assert(Art.bridges(bridgeId.toZ).nonEmpty, s\"Bridge ${bridgeId} does not exist\")\n\n    Art.bridges(bridgeId.toZ).get.dispatchProtocol match {\n      case DispatchPropertyProtocol.Periodic(_) => return T\n      case DispatchPropertyProtocol.Sporadic(minRate) =>\n        return Art.bridges(bridgeId.toZ).get.ports.eventIns.elements.exists(\n          port => inInfrastructurePorts.contains(port.id.toZ))\n    }\n  }\n\n  \/\/ JH: Refactored -- renamed port data structures\n  \/\/     ToDo: add comments justifying various sections of the logic by reference to standard clauses\n  def dispatchStatus(bridgeId: Art.BridgeId): DispatchStatus = {\n    val ret: DispatchStatus = Art.bridges(bridgeId.toZ).get.dispatchProtocol match {\n      case Periodic(_) => TimeTriggered()\n      case Sporadic(_) =>\n        \/\/ get ids for non-empty input event ports\n        val portIds = ISZ[Art.PortId](Art.bridges(bridgeId.toZ).get.ports.eventIns.map((u: UPort) => u.id).elements.filter((i: Art.PortId) => inInfrastructurePorts.get(i.toZ).nonEmpty): _*)\n        val urgentFifo: Seq[Art.PortId] = portIds.map((pid: Art.PortId) => Art.port(pid)).elements.sortWith { \/\/ reverse sort\n          \/\/ sorting function to make prioritized sequence of event port ids\n          \/\/   compare p1 to p2  (p1 represents the port to process earlier, i.e., should have priority)\n          case (p1: UrgentPort[_], p2: UrgentPort[_]) => Z\n            \/\/ if p1 has a strictly less urgency it comes after p2\n            if (p1.urgency < p2.urgency) F\n            \/\/ if p1 has a strictly greater urgency, it comes before p2\n            else if (p1.urgency > p2.urgency) T\n            \/\/ if p1 and p2 have the same urgency, the ordering is determined by arrival timestamps\n            else inInfrastructurePorts(p1.id.toZ).dstArrivalTimestamp < inInfrastructurePorts(p2.id.toZ).dstArrivalTimestamp\n          case (_: UrgentPort[_], _: Port[_]) => T \/\/ urgent ports take precedence\n          case (_: Port[_], _: UrgentPort[_]) => F \/\/ urgent ports take precedence\n          case (p1: Port[_], p2: Port[_]) =>\n            inInfrastructurePorts(p1.id.toZ).dstArrivalTimestamp < inInfrastructurePorts(p2.id.toZ).dstArrivalTimestamp\n        }.map(_.id)\n        EventTriggered(ISZ[Art.PortId](urgentFifo: _*))\n    }\n    return ret\n  }\n\n  \/\/===============================================================================\n  \/\/  AADL Execution Phases\n  \/\/\n  \/\/   Note: this could be synchronized a bit more with thread states \/ hybrid automata\n  \/\/   in AADL standard\n  \/\/===============================================================================\n\n  def initializePhase(): Unit = {\n    logInfo(Art.logTitle, s\"Initializing component...\")\n  }\n\n  def computePhase(): Unit = {\n    logInfo(Art.logTitle, s\"Begin execution...\")\n  }\n\n  def finalizePhase(): Unit = {\n    logInfo(Art.logTitle, s\"End execution...\")\n\n    ArtTimer_Ext.finalise()\n  }\n\n  var logStream: java.io.PrintStream = System.out\n\n  def log(kind: String, title: String, msg: String): Unit = {\n    logStream.println(st\"\"\"{ \"log\" : \"$kind\", \"title\" : ${Json.Printer.printString(title)}, \"msg\" : ${Json.Printer.printString(msg)}, \"time\" : \"${time()}\" }\"\"\".render)\n    logStream.flush()\n  }\n\n  def toS64(value: Long): S64 = S64(value)\n\n  def concMap[K, V](): MMap[K, V] = {\n    import org.sireum.$internal.CollectionCompat.Converters._\n    new java.util.concurrent.ConcurrentHashMap[K, V].asInstanceOf[java.util.Map[K, V]].asScala\n  }\n\n\n\n\n  \/\/\/\/\/\/\/\/\/\/\/\/\/\n  \/\/ TESTING \/\/\n  \/\/\/\/\/\/\/\/\/\/\/\/\/\n\n  \/**\n   * Sets up the state of a thread component (identified by bridge) for the purpose of\n   * testing.\n   *\n   * An analogue to this method does not show up in developer-written unit tests because\n   * it's invoked behind the scenes by the automatically generated unit test infrastructure\n   * as a prelude to each test.\n   *\/\n  def initTest(bridge: Bridge): Unit = {\n    \/\/ delete ALL port values\n    inInfrastructurePorts.clear()\n    inPortVariables.clear()\n    outPortVariables.clear()\n    outInfrastructurePorts.clear()\n\n    \/\/ cancel pending ArtTimer callbacks (also done after a test completes)\n    ArtTimer_Ext.scheduledCallbacks.keys.foreach(ArtTimer_Ext.cancel)\n\n    bridge.entryPoints.testInitialise()\n    logInfo(Art.logTitle, s\"Initialized bridge: ${bridge.name}\")\n  }\n\n  \/**\n   * Executes the application code in the Initialize Entry Point for the component (identified\n   * by given bridge) for the purposes of testing.  This is achieved by\n   * calling the testInitialise() method on given bridge.\n   *\n   * Precondition: initTest() has been called prior.\n   *\n   * Unlike [[Art.run()]], this method does NOT wrap compute calls in a try-catch block.\n   * This is to ensure no exceptions are overlooked during testing.\n   *\/\n  def testInitialise(bridge: Bridge): Unit = {\n    bridge.entryPoints.testInitialise()\n  }\n\n  \/**\n   * Executes the application code in the Compute Entry Point for the component (identified\n   * by given bridge) for the purposes of testing.  This is achieved by\n   * calling the testCompute() method on given bridge.\n   *\n   * Precondition: initTest() has been called prior.\n   *\n   * Unlike [[Art.run()]], this method does NOT wrap compute calls in a try-catch block.\n   * This is to ensure no exceptions are overlooked during testing.\n   *\/\n  def testCompute(bridge: Bridge): Unit = {\n    bridge.entryPoints.testCompute()\n  }\n\n  \/**\n   * Calls the finalize entry points on all registered bridges.\n   * Testers should NOT call this method because BridgeTestSuite will automatically call this method after each test.\n   *\n   *\/\n  def finalizeTest(bridge: Bridge): Unit = {\n    bridge.entryPoints.finalise()\n    logInfo(Art.logTitle, s\"Finalized bridge: ${bridge.name}\")\n\n    \/\/ cancel pending ArtTimer callbacks (also done before a test begins)\n    ArtTimer_Ext.scheduledCallbacks.keys.foreach(ArtTimer_Ext.cancel)\n  }\n\n  \/\/ JH: Refactored\n  \/\/   add system test capability\n  def initSystemTest(scheduler: Scheduler): Unit = {\n    Art.setUpArchitecture()\n    Art.setUpPlatform()\n    Art.setUpSystemState(scheduler)\n    logInfo(Art.logTitle, s\"Initialized system for system test\")\n  }\n\n  \/\/  def executeSystemTest(): Unit = $\n\n  \/\/ JH: Refactored\n  \/\/   add system test capability\n  def finalizeSystemTest(): Unit = {\n    Art.tearDownSystemState()\n    Art.tearDownPlatform()\n    Art.tearDownArchitecture()\n  }\n\n  \/\/ JH: Refactor\n  \/\/  Add code to address the fact that out port variables are now distinct from\n  \/\/  out infrastructure ports,  i.e., we must copy from out port variables to\n  \/\/  out infrastructure ports\n  \/**\n   * A method that replaces bridge.compute()'s calls to [[Art.sendOutput()]] in\n   * its equivalent testCompute() method.\n   *\n   * This method is currently a NO-OP, but may gain functionality later.\n   *\n   * @param eventPortIds the event ports to be \"copied and cleared\" (but currently nothing happens)\n   * @param dataPortIds the data ports to be \"copied and cleared\" (but currently nothing happens)\n   *\/\n  def releaseOutput(eventPortIds: ISZ[Art.PortId], dataPortIds: ISZ[Art.PortId]): Unit = { \/\/ testing SEND_OUTPUT\n    \/\/ note: sendOutput is usually accessed via:\n    \/\/   Art.sendOutput -> ArtNative.sendOutput -> ArtNative_Ext.sendOutput\n    \/\/JH added:\n    for (srcPortId <- eventPortIds ++ dataPortIds) {\n      outPortVariables.get(srcPortId.toZ) match {\n        case scala.Some(msg) =>\n          outInfrastructurePorts(srcPortId.toZ) = outPortVariables(srcPortId.toZ)\n        case _ =>\n      }\n    }\n  }\n\n  \/**\n   * Because a bridge's testCompute() doesn't clear outputs, this method can be\n   * used by users to manually clear the output if desired. This is useful for\n   * tests involving multiple dispatches.\n   *\/\n  def manuallyClearOutput(): Unit = {\n    outPortVariables.clear()\n  }\n\n  \/\/ JH: Refactor\n  \/\/ ToDo: Rename the functions below to align with the variable names inInfrastructurePort, etc.\n  \/**\n   * Inserts a value into an \"infrastructure in\" port. For testing only, normally\n   * this is handled by Art.\n   *\n   * @param dstPortId the portId to place the passed [[DataContent]] into\n   * @param data the [[DataContent]] which will be placed in the dstPort\n   *\/\n  def insertInInfrastructurePort(dstPortId: Art.PortId, data: DataContent): Unit = {\n    \/\/ note: that could would be changed when we refactor to support event queues of size > 1\n    val artMessage = ArtMessage(data = data, dstPortId = Some(dstPortId), dstArrivalTimestamp = Art.time())\n    \/\/ note: right now, there is no difference in the logic between data and event ports, but keep the\n    \/\/ logic separate for future refactoring\n    Art.port(dstPortId).mode match {\n      case PortMode.DataIn | PortMode.DataOut =>\n        inInfrastructurePorts(dstPortId.toZ) = artMessage\n      case PortMode.EventIn | PortMode.EventOut =>\n        inInfrastructurePorts(dstPortId.toZ) = artMessage\n    }\n  }\n\n\n  \/**\n   * Returns the value of an in infrastructure port.\n   *\n   * @param portId the id of the INPUT port to return a value from\n   * @return If the port is non-empty, a [[Some]] of [[DataContent]]. Otherwise [[None]].\n   *\/\n  def observeInInfrastructurePort(portId: Art.PortId): Option[DataContent] = {\n    \/\/ right now, with event data port queues limited to size one, there is no difference in the logic\n    \/\/ between how data ports are treated, and how event\/event data ports are treated.\n    Art.port(portId).mode match {\n      case PortMode.DataIn =>\n        inInfrastructurePorts.get(portId.toZ) match {\n          case scala.Some(value: ArtMessage) => org.sireum.Some[DataContent](value.data)\n          case scala.None => org.sireum.None[DataContent]()\n        }\n      case PortMode.EventIn =>\n        inInfrastructurePorts.get(portId.toZ) match {\n          case scala.Some(value: ArtMessage) => org.sireum.Some[DataContent](value.data)\n          case scala.None => org.sireum.None[DataContent]()\n        }\n      case _ => {\n        assert(false, \"expecting in port\")\n        org.sireum.None[DataContent]()\n      }\n    }\n  }\n\n  \/**\n   * Returns the value of an infrastructure out port.\n   *\n   * @param portId the id of the OUTPUT port to return a value from\n   * @return If the port is non-empty, a [[Some]] of [[DataContent]]. Otherwise [[None]].\n   *\/\n  def observeOutInfrastructurePort(portId: Art.PortId): Option[DataContent] = {\n    \/\/ note: would be changed when we refactor to support event queues of size > 1\n    outInfrastructurePorts.get(portId.toZ) match {\n      case scala.Some(value: ArtMessage) => org.sireum.Some[DataContent](value.data)\n      case scala.None => org.sireum.None[DataContent]()\n    }\n  }\n\n  \/**\n   * Returns the value of an application in port.\n   *\n   * @param portId the id of the INPUT port to return a value from\n   * @return If the port is non-empty, a [[Some]] of [[DataContent]]. Otherwise [[None]].\n   *\/\n  def observeInPortVariable(portId: Art.PortId): Option[DataContent] = {\n    \/\/ right now, with event data port queues limited to size one, there is no difference in the logic\n    \/\/ between how data ports are treated, and how event\/event data ports are treated.\n    Art.port(portId).mode match {\n      case PortMode.DataIn =>\n        inPortVariables.get(portId.toZ) match {\n          case scala.Some(value: ArtMessage) => org.sireum.Some[DataContent](value.data)\n          case scala.None => org.sireum.None[DataContent]()\n        }\n      case PortMode.EventIn =>\n        inPortVariables.get(portId.toZ) match {\n          case scala.Some(value: ArtMessage) => org.sireum.Some[DataContent](value.data)\n          case scala.None => org.sireum.None[DataContent]()\n        }\n      case _ => {\n        assert(false, \"expecting in port\")\n        org.sireum.None[DataContent]()\n      }\n    }\n  }\n\n  \/**\n     * Returns the value of an application out port.\n     *\n     * @param portId the id of the OUTPUT port to return a value from\n     * @return If the port is non-empty, a [[Some]] of [[DataContent]]. Otherwise [[None]].\n     *\/\n  def observeOutPortVariable(portId: Art.PortId): Option[DataContent] = {\n    \/\/ note: that could would be changed when we refactor to support event queues of size > 1\n    outPortVariables.get(portId.toZ) match {\n      case scala.Some(value: ArtMessage) => org.sireum.Some[DataContent](value.data)\n      case scala.None => org.sireum.None[DataContent]()\n    }\n  }\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/ArtTimer.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art\n\nimport org.sireum._\n\n@sig trait TimerCallback {\n  def callback(): Unit\n}\n\n@ext object ArtTimer {\n\n  def schedule(id: String, replaceExisting: B, delay: Art.Time, callback: () => Unit): Unit = $\n\n  \/\/ if transpiling then use this version as transpiler does not support function passing\n  def scheduleTrait(id: String, replaceExisting: B, delay: Art.Time, callback: TimerCallback): Unit = $\n\n  def cancel(id: String): Unit = $\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/ArtTimer_Ext.scala",
        {
          "type" : "ITestResource",
          "content" : "package art\n\nimport org.sireum.S64._\nimport org.sireum.{B, F, String, T}\n\nimport java.util.concurrent.atomic.AtomicBoolean\nimport java.util.concurrent.{Executors, TimeUnit}\nimport scala.collection.mutable.{Map => MMap}\n\nobject ArtTimer_Ext {\n\n  protected[art] val scheduledCallbacks: MMap[String, AtomicBoolean] = ArtNative_Ext.concMap()\n  private val executor = Executors.newSingleThreadScheduledExecutor()\n\n  def finalise(): Unit = {\n    executor.shutdownNow()\n    ArtNative.logInfo(Art.logTitle, \"Finalized ArtTimer\")\n  }\n\n  def cancel(id: String): Unit = {\n    scheduledCallbacks.get(id) match {\n      case Some(b) =>\n        val userRequested = b.get()\n        b.set(F)\n        scheduledCallbacks.remove(id)\n        if (userRequested) {\n          ArtNative.logInfo(Art.logTitle, s\"Callback cleared for $id\")\n        }\n      case _ =>\n    }\n  }\n\n  def scheduleTrait(id: String, replaceExisting: B, delay: Art.Time, callback: TimerCallback): Unit = {\n    schedule(id, replaceExisting, delay, callback.callback _)\n  }\n\n  def schedule(id: String, replaceExisting: B, delay: Art.Time, callback: () => Unit): Unit = {\n    if (scheduledCallbacks.get(id).nonEmpty) {\n      if (!replaceExisting) {\n        ArtNative.logInfo(Art.logTitle, s\"Callback already scheduled for $id\")\n        return\n      } else {\n        cancel(id)\n      }\n    }\n\n    if (delay < s64\"0\") {\n      ArtNative.logInfo(Art.logTitle, s\"Invalid delay time: ${delay}.  Value must be non-negative.\")\n      return\n    }\n\n    \/\/ the below runnable will be run in a separate thread when it's\n    \/\/ dispatched by the executor. If the user requests to cancel the\n    \/\/ timeout before that then shouldInvokeCallback will be set to\n    \/\/ false and therefore the callback will not be invoked\n    val shouldInvokeCallback = new AtomicBoolean(T)\n\n    val task = new Runnable {\n      override def run(): Unit = {\n        if (shouldInvokeCallback.get()) {\n          shouldInvokeCallback.set(F)\n          cancel(id)\n\n          callback()\n        }\n      }\n    }\n\n    scheduledCallbacks.put(id, shouldInvokeCallback)\n\n    val adjusted = delay.toMP.toLong * ArtNative_Ext.slowdown.toMP.toLong\n    executor.schedule(task, adjusted, TimeUnit.MILLISECONDS)\n\n    ArtNative.logInfo(Art.logTitle, s\"Callback scheduled for $id: $delay ms\")\n  }\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/DataContent.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art\n\nimport org.sireum._\n\n@sig trait DataContent\n\n@datatype class Empty extends art.DataContent",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : true
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/Scheduler.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art.scheduling\n\nimport org.sireum._\n\n\/\/ msig to allow schedulers to have mutable state\n@msig trait Scheduler {\n\n  def initialize(): Unit\n\n  def initializationPhase(): Unit\n\n  def computePhase(): Unit\n\n  def finalizePhase(): Unit\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/legacy\/Legacy.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art.scheduling.legacy\n\nimport org.sireum._\nimport art.Art\nimport art.scheduling.Scheduler\n\n@record class Legacy(bridges: IS[Art.BridgeId, art.Bridge]) extends Scheduler {\n\n  override def initialize(): Unit = {}\n\n  override def initializationPhase(): Unit = {\n    for (bridge <- bridges) {\n      bridge.entryPoints.initialise()\n      Art.logInfo(bridge.id, s\"Initialized bridge: ${bridge.name}\")\n    }\n  }\n\n  override def computePhase(): Unit = {\n    LegacyInterface.computePhase(bridges)\n  }\n\n  override def finalizePhase(): Unit = {\n    for (bridge <- bridges) {\n      bridge.entryPoints.finalise()\n      Art.logInfo(bridge.id, s\"Finalized bridge: ${bridge.name}\")\n    }\n  }\n}\n\n@ext object LegacyInterface {\n  def computePhase(bridges: IS[Art.BridgeId, art.Bridge]): Unit = $\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/legacy\/LegacyInterface_Ext.scala",
        {
          "type" : "ITestResource",
          "content" : "package art.scheduling.legacy\n\nimport art.{Art, ArtNative, ArtNative_Ext, DispatchPropertyProtocol}\nimport scala.collection.mutable.{Map => MMap}\nimport org.sireum._\n\nobject LegacyInterface_Ext {\n  val slowdown: Z = 1\n\n  def computePhase(bridges: IS[Art.BridgeId, art.Bridge]): Unit = {\n    var terminated = false\n    var numTerminated: Z = 0\n\n    for (bridge <- bridges) {\n\n      val (rate, isSporadic) = bridge.dispatchProtocol match {\n        case DispatchPropertyProtocol.Periodic(period) => (period, F)\n        case DispatchPropertyProtocol.Sporadic(min) => (min, T)\n      }\n\n      new Thread(() => {\n        ArtNative.logInfo(Art.logTitle, s\"Thread for ${bridge.name} instantiated.\")\n        ArtNative_Ext.synchronized {\n          ArtNative_Ext.wait()\n        }\n        while (!terminated) {\n          Thread.sleep((rate * slowdown).toMP.toLong)\n          if (ArtNative.shouldDispatch(bridge.id)) {\n            try {\n              bridge.synchronized {\n                bridge.entryPoints.compute()\n              }\n            }\n            catch {\n              case x: Throwable =>\n                x.printStackTrace()\n                terminated = true\n            }\n          }\n        }\n        ArtNative_Ext.synchronized {\n          numTerminated += 1\n        }\n      }).start()\n    }\n\n    Thread.sleep(1000)\n\n    ArtNative.logInfo(Art.logTitle, s\"Start execution (press Enter twice to terminate) ...\")\n\n    ArtNative_Ext.synchronized {\n      ArtNative_Ext.notifyAll()\n    }\n\n    Console.in.readLine()\n    terminated = true\n\n    while (numTerminated != bridges.size) {\n      Thread.sleep(1000)\n    }\n  }\n\n  def concMap[K, V](): MMap[K, V] = {\n    import org.sireum.$internal.CollectionCompat.Converters._\n    new java.util.concurrent.ConcurrentHashMap[K, V].asInstanceOf[java.util.Map[K, V]].asScala\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/nop\/NopScheduler.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art.scheduling.nop\n\nimport org.sireum._\nimport art.scheduling.Scheduler\n\n@record class NopScheduler extends Scheduler {\n\n  override def initialize(): Unit = {}\n\n  override def initializationPhase(): Unit = {}\n\n  override def computePhase(): Unit = {}\n\n  override def finalizePhase(): Unit = {}\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/roundrobin\/RoundRobin.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\npackage art.scheduling.roundrobin\n\nimport org.sireum._\nimport art.scheduling.Scheduler\nimport art.{Art, ArtNative, DispatchPropertyProtocol}\nimport org.sireum.S64._\n\n@record class RoundRobin(schedule: ISZ[Art.BridgeId]) extends Scheduler {\n\n  var lastDispatch: MS[Art.BridgeId, Art.Time] = MS.create[Art.BridgeId, Art.Time](schedule.size, s64\"0\")\n  var lastSporadic: MS[Art.BridgeId, Art.Time] = MS.create[Art.BridgeId, Art.Time](schedule.size, s64\"0\")\n\n  override def initialize(): Unit = {\n    RoundRobinExtensions.init()\n  }\n\n  override def initializationPhase(): Unit = {\n    for (bridgeId <- schedule) {\n      Art.bridges(bridgeId.toZ).get.entryPoints.initialise()\n      Art.logInfo(bridgeId, s\"Initialized bridge: ${Art.bridges(bridgeId.toZ).get.name}\")\n    }\n  }\n\n  def shouldDispatch(bridgeId: Art.BridgeId): B = {\n    Art.bridges(bridgeId.toZ).get.dispatchProtocol match {\n      case DispatchPropertyProtocol.Periodic(period) =>\n        if (Art.time() - lastDispatch(bridgeId) > conversions.Z.toS64(period)) {\n          return ArtNative.shouldDispatch(bridgeId) \/\/ will always return true\n        } else {\n          return F\n        }\n      case DispatchPropertyProtocol.Sporadic(minRate) =>\n        if (Art.time() - lastSporadic(bridgeId) < conversions.Z.toS64(minRate)) {\n          return F\n        } else {\n          \/\/ check if there are events waiting in incoming infrastructure port\n          return ArtNative.shouldDispatch(bridgeId)\n        }\n    }\n  }\n\n  override def computePhase(): Unit = {\n    while (!RoundRobinExtensions.shouldStop()) {\n      for (bridgeId <- schedule) {\n        if (shouldDispatch(bridgeId)) {\n          lastDispatch(bridgeId) = Art.time()\n          Art.bridges(bridgeId.toZ).get.entryPoints.compute()\n\n          if (Art.bridges(bridgeId.toZ).get.dispatchProtocol.isInstanceOf[DispatchPropertyProtocol.Sporadic]) {\n            lastSporadic(bridgeId) = Art.time()\n          }\n        }\n      }\n    }\n  }\n\n  override def finalizePhase(): Unit = {\n    for (bridgeId <- schedule) {\n      Art.bridges(bridgeId.toZ).get.entryPoints.finalise()\n      Art.logInfo(bridgeId, s\"Finalized bridge: ${Art.bridges(bridgeId.toZ).get.name}\")\n    }\n  }\n}\n\n@ext object RoundRobinExtensions {\n  def init(): Unit = $\n\n  def shouldStop(): B = $\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/roundrobin\/RoundRobinExtensions_Ext.scala",
        {
          "type" : "ITestResource",
          "content" : "package art.scheduling.roundrobin\n\nimport art.{Art, ArtNative}\nimport org.sireum.B\nimport java.util.concurrent.atomic.AtomicBoolean\n\nobject RoundRobinExtensions_Ext {\n  var terminated = new AtomicBoolean(false)\n\n  def init(): Unit = {\n    ArtNative.logInfo(Art.logTitle, s\"Start execution (press Enter twice to terminate) ...\")\n\n    new Thread(() => {\n      Console.in.readLine()\n      terminated.set(true)\n    }).start()\n  }\n\n  def shouldStop(): B = {\n    return terminated.get()\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/static\/CliCommandProvider.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art.scheduling.static\n\nimport org.sireum._\n\n@record class CliCommandProvider extends CommandProvider {\n  override def nextCommand(): Command = {\n    return getCommand()\n  }\n\n  def getCommand(): Command = {\n    val cmdString: String = StaticSchedulerIO.getCommand(\"HAMR> \")\n    val args: ISZ[String] = ops.StringOps(cmdString).split(c => c == ' ')\n    val arg0: String = args(0)\n    if (arg0 == \"x\") {\n      return Stop()\n    } else if (arg0 == \"s\") {\n      var numSteps: Z = 1\n      if (args.size > 1) {\n        Z(args(1)) match {\n          case Some(numStepsCli) => numSteps = numStepsCli\n          case None() => return Unsupported()\n        }\n      }\n      return Sstep(numSteps)\n    } else if (arg0 == \"help\") {\n      return Help()\n    } else if (arg0 == \"h\") {\n      var numSteps: Z = 1\n      if (args.size > 1) {\n        Z(args(1)) match {\n          case Some(numStepsCli) => numSteps = numStepsCli\n          case None() => return Unsupported()\n        }\n      }\n      return Hstep(numSteps)\n    } else if (arg0 == \"i\") {\n      if (args.size < 2) {\n        println(\"i requires a second option\")\n        return Help()\n      }\n      \/\/ need to insert a check for size greater than 1\n      if (args(1) == \"st\") {\n        return Infostate()\n      } else if (args(1) == \"sc\") {\n        return Infoschedule()\n      } else if (args(1) == \"out\") {\n        return InfoOutputs()\n      } else if (args(1) == \"in\") {\n        return InfoInputs()\n      } else if (args(1) == \"cpn\") {\n        if (args.size > 2) {\n          Z(args(2)) match {\n            case Some(bridgeId) => return InfoComponentStateId(bridgeId)\n            case None() => return Unsupported() \/\/ expected bridgeId arg is not an integer\n          }\n        }\n        return Unsupported() \/\/ incorrect number of arguments for \"i cp\" (missing bridge id arg)\n      } else if (args(1) == \"cp\") {\n        if (args.size > 2) {\n          return InfoComponentState(args(2))\n        }\n        return Unsupported() \/\/ incorrect number of arguments for \"i cp\" (missing bridge id arg)\n      } else if (args(1) == \"nn\") {\n        return InfoThreadNickNames()\n      } \/\/ incorrect number of arguments for \"i cp\" (missing bridge id arg)\n      else { \/\/ ... no other info commands supported\n        return Unsupported()\n      }\n    } else if (arg0 == \"rh\") {\n      Z(args(1)) match {\n        case Some(hpTarget) => return RunToHP(hpTarget)\n        case None() => return Unsupported()\n      }\n    } else if (arg0 == \"rd\") {\n      Z(args(1)) match {\n        case Some(domainIdTarget) => return RunToDomain(domainIdTarget)\n        case None() => return Unsupported()\n      }\n    } else if (arg0 == \"rt\") {\n      val threadNickName = args(1)\n      return RunToThread(threadNickName)\n    } else if (arg0 == \"rs\") {\n      if (args.size == 2) { \/\/ run to slot\n        Z(args(1)) match {\n          case Some(slotNumTarget) => return RunToSlot(slotNumTarget)\n          case None() => return Unsupported()\n        }\n      } else if (args.size == 3) { \/\/ run to state\n        (Z(args(1)), Z(args(2))) match {\n          case (Some(hpNum), Some(slotNum)) => return RunToState(hpNum, slotNum)\n          case _ => return Unsupported()\n        }\n      } else {\n        return Unsupported()\n      }\n    } else {\n      return Unsupported()\n    }\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/static\/CliInfoProvider.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\npackage art.scheduling.static\n\nimport org.sireum._\nimport art.Art.BridgeId\nimport art.scheduling.static.Schedule.DScheduleSpec\n\nobject CliInfoProvider {\n\n  \/\/ prototyping APIs that any HAMR debugging interface should support\n  def message(m: String): Unit = {\n    StaticSchedulerIO.message(m)\n  }\n\n  def printHelpMessage(): Unit = {\n    println(\"s <n?>     - step n slots (default 0)\")\n    println(\"h <n?>     - step n hyper-periods (default 0)\")\n    println(\"rs <n>     - run to slot n (wrap to next hyper-period if needed)\")\n    println(\"rs <h> <n> - run to state hyperperiod h and slot n (do nothing if past this state)\")\n    println(\"rh <n>     - run to hyper-period n (do nothing if already past the beginning of hyper-period n)\")\n    println(\"rt <name>  - run to slot containing thread with nickname <name>\")\n    println(\"i st       - show current state\")\n    println(\"i sc       - show schedule and current position\")\n    println(\"i out      - show output port values of most recently run thread\")\n    println(\"i in       - show input  port values of next thread to run\")\n    println(\"i cp <nickname> - show port values of component with given nickname\")\n    println(\"i nn       - show thread nicknames\")\n    println(\"x          - exit\")\n    println()\n  }\n\n  def formatState(scheduleState: Explorer.ScheduleState, domain: Z, bridgeId: BridgeId, threadNickName: String): String = {\n    \/\/ val outString = \"STATE: slot#: \" + scheduleState.slotNum.toString + \" ; HP#: \" + scheduleState.hyperperiodNum.toString\n    return s\"STATE: HP#: ${scheduleState.hyperperiodNum} slot#: ${scheduleState.slotNum} domain: $domain  thread: $threadNickName ($bridgeId)\"\n  }\n\n  def formatStateH(scheduleState: Explorer.ScheduleState): String = {\n    val domain = Schedule.getDomainFromScheduleState(scheduleState)\n    val bridgeId = Schedule.getBridgeIdFromScheduleState(scheduleState)\n    val threadNickName = Schedule.getThreadNickNameFromScheduleState(scheduleState)\n    return formatState(scheduleState, domain, bridgeId, threadNickName)\n  }\n\n  \/\/ The \"show\" methods below need to be refactored to better support MVC\n\n  def showNickNames(): Unit = {\n    message(\" Thread Nicknames\")\n    message(\"-------------------\")\n    for (e <- StaticScheduler.threadNickNames.keys) {\n      message(e)\n    }\n  }\n\n  def showState(scheduleState: Explorer.ScheduleState, domain: Z, bridgeId: BridgeId, threadNickName: String): Unit = {\n    message(formatState(scheduleState, domain, bridgeId, threadNickName))\n  }\n\n  def showStateH(scheduleState: Explorer.ScheduleState): Unit = {\n    message(formatStateH(scheduleState))\n  }\n\n  def showSchedule(scheduleState: Explorer.ScheduleState, dScheduleSpec: Schedule.DScheduleSpec): Unit = {\n    val slots = dScheduleSpec.schedule.slots\n    val hyperPeriodLength = dScheduleSpec.hyperPeriod\n    val hyperPeriodNum = scheduleState.hyperperiodNum\n    val stateSlotNum = scheduleState.slotNum\n    message(s\" Schedule ($hyperPeriodLength tot ticks) HP#: $hyperPeriodNum\")\n    message(\"-------------------------------------------------\")\n    var slotNum: Z = 0\n    for (s <- slots) {\n      var prefix: String = \"  \"\n      var suffix: String = \"\"\n      if (slotNum == stateSlotNum) {\n        val (elaspedHPTicks, remainingHPTicks) = Schedule.computeElaspedRemainingHPTicks(slotNum, dScheduleSpec)\n        prefix = \" *\"\n        suffix = s\"(elapsed= $elaspedHPTicks, remaining=$remainingHPTicks)\"\n      }\n      message(s\"${prefix}$slotNum [domain=${s.domain},length=${s.length}] $suffix\")\n      slotNum = slotNum + 1\n    }\n    message(\"-------------------------------------------------\")\n  }\n\n  def showStep(preScheduleState: Explorer.ScheduleState,\n               postScheduleState: Explorer.ScheduleState,\n               dScheduleSpec: DScheduleSpec): Unit = {\n    val slotNum = preScheduleState.slotNum\n    val slot = dScheduleSpec.schedule.slots(slotNum)\n    val domain = slot.domain\n    val bridgeId = Schedule.getBridgeIdFromSlotNumber(slotNum)\n    val length = slot.length\n    message(\"============= S t e p =============\")\n    message(s\"PRE-${formatState(preScheduleState, Schedule.getDomainFromScheduleState(preScheduleState), Schedule.getBridgeIdFromScheduleState(preScheduleState), Schedule.getThreadNickNameFromScheduleState(preScheduleState))}\")\n    message(s\"   Executing:  Domain#: $domain   Max Duration: $length\")\n    message(s\"POST-${formatState(postScheduleState, Schedule.getDomainFromScheduleState(postScheduleState), Schedule.getBridgeIdFromScheduleState(postScheduleState), Schedule.getThreadNickNameFromScheduleState(postScheduleState))}\")\n  }\n\n  def showHyperPeriodBoundary(scheduleState: Explorer.ScheduleState): Unit = {\n    message(s\"********* Hyper-Period ${scheduleState.hyperperiodNum} (beginning) **********\")\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/static\/Command.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art.scheduling.static\n\nimport org.sireum._\n\n@msig trait CommandProvider {\n  def nextCommand(): Command\n}\n\n@msig trait InfoCommandProvider extends CommandProvider {\n  def threadNickNames: Map[String, art.Art.BridgeId]\n  def numSlots: Z\n  def displayOrder: ISZ[art.Art.BridgeId]\n\n  def init(threadNickNames: Map[String, art.Art.BridgeId], numSlots: Z, displayOrder: ISZ[art.Art.BridgeId]): CommandProvider\n}\n\n@datatype trait Command\n\n@datatype class Unrecognized extends Command\n\n@datatype class Unsupported extends Command\n\n\/\/ end debugging session\n@datatype class Stop extends Command\n\n\/\/ display support commands\n@datatype class Help extends Command\n\n\/\/ step numSteps of slots\n@datatype class Sstep(numSteps: Z) extends Command\n\n\/\/ step numSteps of hyper-periods\n@datatype class Hstep(numSteps: Z) extends Command\n\n\/\/ run to hp#\n@datatype class RunToHP(hpNum: Z) extends Command\n\n\/\/ run to scheduler state (hp#,slot#)\n@datatype class RunToState(hpNum: Z, slotNum: Z) extends Command\n\n\/\/ run to domain\n@datatype class RunToDomain(domainId: Z) extends Command\n\n\/\/ run to thread\n@datatype class RunToSlot(slotNum: Z) extends Command\n\n\/\/ run to thread\n@datatype class RunToThread(ThreadId: String) extends Command\n\n\/\/ get info current state (hyper-period number, slot number)\n@datatype class Infostate extends Command\n\n\/\/ get info of domain schedule with next slot to be executed marked\n@datatype class Infoschedule extends Command\n\n\/\/ get values of input ports of component to be executed in the next slot\n@datatype class InfoInputs extends Command\n\n\/\/ get values of output ports of component that was executed in the previous slot\n@datatype class InfoOutputs extends Command\n\n\/\/ get values of input and outputs ports for the given component the last time that it was executed\n@datatype class InfoComponentStateId(bridgeId: Z) extends Command\n\n@datatype class InfoComponentState(threadNickName: String) extends Command\n\n\/\/ show thread nicknames\n@datatype class InfoThreadNickNames extends Command\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/static\/CommandInterpreter.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\npackage art.scheduling.static\n\nimport org.sireum._\nimport art.Art.BridgeId\n\nobject CommandInterpreter {\n\n  def message(str: String): Unit = {\n    CliInfoProvider.message(str)\n  }\n\n  def interpretCmd(cmd: Command): B = {\n    var done: B = false\n    cmd match {\n      case _: Help =>\n        CliInfoProvider.printHelpMessage()\n\n      case Sstep(n) =>\n        assert(n >= 1)\n        message(s\"...Stepping $n slot(s)\")\n        Explorer.stepSystemNSlotsIMP(n)\n\n      case Hstep(n) =>\n        assert(n >= 1)\n        message(s\"...Stepping $n hyper-period(s)\")\n        if (n == 1) {\n          Explorer.stepSystemOneHPIMP()\n        } else if (Explorer.isHyperPeriodBoundaryH()) {\n          Explorer.stepSystemNHPIMP(n)\n        } else {\n          message(\"Command not applicable: not on hyper-period boundary\")\n        }\n\n      case RunToHP(hpNum) =>\n        assert(hpNum >= 0 & hpNum <= 1000)\n        Explorer.runToHP(hpNum)\n\n      case RunToSlot(slotNum) =>\n        assert(slotNum >= 0 & slotNum < Schedule.dScheduleSpec.schedule.slots.size)\n        message(s\"...Running to slot# $slotNum\")\n        Explorer.runToSlot(slotNum)\n\n      case RunToThread(threadNickName) =>\n        Explorer.runToThread(threadNickName)\n\n      case RunToState(hpNum, slotNum) =>\n        assert(hpNum >= 0 & hpNum <= 1000)\n        assert(slotNum >= 0 & slotNum < Schedule.dScheduleSpec.schedule.slots.size)\n        Explorer.runToState(hpNum, slotNum)\n\n      case RunToDomain(domainId) =>\n        assert(0 <= domainId & domainId <= Schedule.dScheduleSpec.maxDomain)\n        Explorer.runToDomain(domainId)\n\n      case _: Stop => done = T\n\n      case _: Infostate =>\n        val s = Explorer.scheduleState\n        CliInfoProvider.showState(s, Schedule.getDomainFromScheduleState(s), Schedule.getBridgeIdFromScheduleState(s), Schedule.threadNickName(Schedule.getBridgeIdFromScheduleState(s)))\n\n      case _: Infoschedule =>\n        CliInfoProvider.showSchedule(Explorer.scheduleState, Schedule.dScheduleSpec)\n\n      case _: InfoInputs =>\n        StateObserver.printPortContentsInputsCurrent()\n\n      case _: InfoOutputs =>\n        StateObserver.printPortContentsOutputsCurrent()\n\n      case InfoComponentStateId(bridgId) =>\n        StateObserver.printPortContents(BridgeId.fromZ(bridgId))\n\n      case InfoComponentState(threadNickName) =>\n        StateObserver.printPortContentsByNickName(threadNickName)\n\n      case _: InfoThreadNickNames =>\n        CliInfoProvider.showNickNames()\n\n      case _: Unrecognized => message(\"Unrecognized command\")\n\n      case _: Unsupported => message(\"Unsupported command\")\n\n      case _ =>\n    }\n    return done\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/static\/DefaultCommandProvider.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\npackage art.scheduling.static\n\nimport org.sireum._\n\n@record class DefaultCommandProvider extends CommandProvider {\n  override def nextCommand(): Command = {\n    return Hstep(1)\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/static\/Explorer.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art.scheduling.static\n\nimport org.sireum._\nimport art.{Art, ArtNative}\nimport art.scheduling.static.Schedule._\n\n\/\/ Possible commands\/concepts\n\/\/\n\/\/ init system\n\/\/ s n - step n slots; n >= 1, if n >= remaining slots in hyper-period, then run to end of hyper-period\n\/\/ h n - step n hyper-periods; n >= 1\n\/\/ executing info display mode\n\/\/  show domain \/ bridge\n\/\/  show infrastructure input \/ output ports\n\/\/  show in\/out ports for selected components\n\/\/  inject certain values on input ports (random, specific, random with constraints, generator, seeded from test vector)\n\/\/ run until various conditions\n\/\/ check contract \/ constraint (component-wise or global)\n\/\/ checkpoint state, rollback to checkpointed state\n\/\/ save step as unit tests\n\/\/ calculate dependences during execution\n\n\n\/\/ stepDSchedule(2,dScheduleSpec1)\n\n\/\/ var inpt: Z = 0\n\/\/ inpt = readInt()\n\nobject Explorer {\n\n  \/\/================ schedule state ====================\n\n  \/\/ data structure for schedule state\n  \/\/   - zero-based indexing into the time-line of the scheduler\n  @datatype class ScheduleState(slotNum: Z, hyperperiodNum: Z)\n\n  \/\/ \"invariant\" for schedule state\n  def validState(state: ScheduleState, dScheduleSpec: DScheduleSpec): B = {\n    val slotNum = state.slotNum\n    \/\/ TODO: also check valid scheduleSpec??\n    val slotInRange: B = slotNum >= 0 & slotNum < dScheduleSpec.schedule.slots.size\n    val hyperperiodInRange: B = state.hyperperiodNum >= 0\n    return slotInRange & hyperperiodInRange\n  }\n\n  def isHyperPeriodBoundary(state: ScheduleState): B = {\n    return state.slotNum == 0\n  }\n\n  def isHyperPeriodBoundaryH(): B = {\n    return isHyperPeriodBoundary(scheduleState)\n  }\n\n  \/\/ schedule state \"global\" variable\n  var scheduleState: ScheduleState = initialScheduleState()\n\n  \/\/ helper method to define initial state value\n  def initialScheduleState(): ScheduleState = {\n    return ScheduleState(0, 0)\n  }\n\n  \/\/ method to initialize schedule state\n  def initializeScheduleStateIMP(): Unit = {\n    scheduleState = initialScheduleState()\n  }\n\n  def isInitial(scheduleState: ScheduleState): B = {\n    return scheduleState == initialScheduleState()\n  }\n\n  def isInitialIMP(): B = {\n    return isInitial(scheduleState)\n  }\n\n  \/\/=============== stepping functions ===================\n\n  \/\/ -- methods for executing thread in a particular slot in the schedule.\n  \/\/    A thread can be referenced by slot data structure or by slot number (two different methods)\n\n  \/\/ execute thread by slot data structure\n  def executeSlotIMP(slot: Slot): Unit = {\n    val domainId: Z = slot.domain\n    val bridgeId: Art.BridgeId = Schedule.domainToBridgeIdMap(domainId)\n    \/\/ val bridge: Bridge = Art.bridges(bridgeId).get  -- debug with Robby\n    \/\/ This is cause an Invalid 'None' operation 'get' exception\n    \/\/ Art.clearPortVariables(bridgeId)\n    \/\/ bridge.entryPoints.compute()  -- debug with Robby\n    \/\/ Art.bridges(bridgeId).asInstanceOf[MSome[Bridge]].value.entryPoints.compute()\n    if (ArtNative.shouldDispatch(bridgeId)) {\n      Art.bridges(bridgeId.toZ).get.entryPoints.compute()\n    }\n  }\n\n  \/\/ execute thread by slot number\n  def executeSlotNumIMP(slotNum: Z): Unit = {\n    \/\/ pre-condition\n    assert(slotNum >= 0 & slotNum < dScheduleSpec.schedule.slots.size, s\"slotNum: ${slotNum}, Slot Size: ${dScheduleSpec.schedule.slots.size}\")\n    \/\/ body\n    val slots = dScheduleSpec.schedule.slots\n    executeSlotIMP(slots(slotNum))\n  }\n\n  \/\/ -- methods for updating schedule state (these do not actually execute the thread)\n\n  \/\/ purely functional method to compute the next schedule state\n  def nextState(state: ScheduleState, dScheduleSpec: DScheduleSpec): ScheduleState = {\n    \/\/ pre-condition\n    assert(validState(state, dScheduleSpec))\n    \/\/ body\n    val slots = dScheduleSpec.schedule.slots\n    var nextSlotNum = state.slotNum + 1\n    var nextHyperPeriodNum = state.hyperperiodNum\n    \/\/ handle wrap around\n    if (nextSlotNum == slots.size) {\n      nextSlotNum = 0\n      nextHyperPeriodNum = nextHyperPeriodNum + 1\n    }\n    return ScheduleState(nextSlotNum, nextHyperPeriodNum)\n  }\n\n  \/\/ purely functional method to compute the next schedule state\n  def previousState(state: ScheduleState, dScheduleSpec: DScheduleSpec): Option[ScheduleState] = {\n    \/\/ pre-condition\n    assert(validState(state, dScheduleSpec))\n    \/\/ body\n    if (isInitial(state)) {\n      return None()\n    }\n\n    val slots = dScheduleSpec.schedule.slots\n\n    var nextSlotNum = state.slotNum - 1 \/\/ assume for now we don't wrap around\n    var nextHyperPeriodNum = state.hyperperiodNum \/\/ assume for now we stay at same hyper-period\n\n    \/\/ handle wrap around\n    if (state.slotNum == 0) { \/\/ if current state has initial slot number, then wrap to end\n      nextSlotNum = slots.size - 1 \/\/ set nextSlotNum to last slot number\n      nextHyperPeriodNum = nextHyperPeriodNum - 1 \/\/ this is sound since we already checked that current state is not initial\n    }\n    return Some(ScheduleState(nextSlotNum, nextHyperPeriodNum))\n  }\n\n  \/\/ advance the state to the next schedule slot (side-effecting schedule state)\n  def advanceStateIMP(): Unit = {\n    scheduleState = nextState(scheduleState, dScheduleSpec)\n  }\n\n  def stepSystemOneSlotIMP(info: B): Unit = {\n    \/\/ pre-condition (invariants on scheduleState and dScheduleSpec)\n    \/\/ assert(validDScheduleSpec(dScheduleSpec))\n    assert(validState(scheduleState, dScheduleSpec))\n    \/\/ body\n    \/\/   execute thread in current slot\n    val preScheduleState = scheduleState\n    executeSlotNumIMP(scheduleState.slotNum)\n    \/\/   advance the schedule state\n    advanceStateIMP()\n    val postScheduleState = scheduleState\n    if (info) {\n      CliInfoProvider.showStep(preScheduleState, postScheduleState, dScheduleSpec)\n    }\n  }\n\n  def stepSystemNSlotsIMP(numSlots: Z): Unit = {\n    \/\/ pre-condition\n    assert(numSlots > 0)\n    \/\/ pre-condition (invariants on scheduleState and dScheduleSpec)\n    assert(validState(scheduleState, dScheduleSpec))\n    \/\/ body\n    for (i <- 1 to numSlots) {\n      stepSystemOneSlotIMP(T)\n    }\n  }\n\n  \/\/ Steps the system one hyper-period.\n  \/\/ Does not require the system to be on a hyper-period boundary.\n  \/\/ If state indicates that hyper-period is already in progress, the method will run to the start of the next hyper-period.\n  def stepSystemOneHPIMP(): Unit = {\n    \/\/ pre-condition (invariants on scheduleState and dScheduleSpec)\n    assert(validState(scheduleState, dScheduleSpec))\n    \/\/ var currentSlotNum: Z = scheduleState.slotNum\n    val numStepsToStartOfHP: Z = dScheduleSpec.schedule.slots.size - scheduleState.slotNum\n    stepSystemNSlotsIMP(numStepsToStartOfHP)\n    \/\/ assert that current state is at the beginning of a HP\n    assert(isHyperPeriodBoundary(scheduleState))\n\n    CliInfoProvider.showHyperPeriodBoundary(scheduleState)\n  }\n\n  \/\/ Steps the system N hyper-periods.\n  \/\/ Make an somewhat arbitrary but rational decision that this method should not be\n  \/\/ called when the system is not on a hyper-period boundary (start of hyper-period)\n  def stepSystemNHPIMP(numHyperPeriods: Z): Unit = {\n    for (hpcount <- 1 to numHyperPeriods) {\n      stepSystemOneHPIMP()\n    }\n  }\n\n  \/\/ Runs the system to the start of the given hyper-period number\n  def runToHP(hpNum: Z): Unit = {\n    \/\/ pre-condition (invariants on scheduleState and dScheduleSpec)\n    assert(validState(scheduleState, dScheduleSpec))\n    assert(hpNum >= 0)\n    \/\/ body\n\n    CliInfoProvider.message(s\"...Running to beginning of hyper-period# $hpNum\")\n\n    while (scheduleState.hyperperiodNum < hpNum) {\n      stepSystemOneSlotIMP(F)\n    }\n\n    CliInfoProvider.message(\"*********** Run to ... Completed *************\")\n\n    CliInfoProvider.showStateH(scheduleState)\n  }\n\n  \/\/ Runs the system to the start of the given state (hp# and slot#)\n  def runToState(hpNum: Z, slotNum: Z): Unit = {\n    \/\/ pre-condition (invariants on scheduleState and dScheduleSpec)\n    assert(validState(scheduleState, dScheduleSpec))\n    assert(hpNum >= 0)\n    assert(slotNum >= 0 & slotNum < Schedule.dScheduleSpec.schedule.slots.size)\n    \/\/ body\n\n    CliInfoProvider.message(s\"...Running to state [hp = $hpNum, slot = $slotNum]\")\n\n    while (scheduleState.hyperperiodNum < hpNum) {\n      stepSystemOneSlotIMP(F)\n    }\n    while (scheduleState.slotNum < slotNum) {\n      stepSystemOneSlotIMP(F)\n    }\n\n    CliInfoProvider.message(\"*********** Run to ... Completed *************\")\n\n    CliInfoProvider.showStateH(scheduleState)\n  }\n\n  \/\/ Runs the system to the start of the given slot#\n  def runToSlot(slotNum: Z): Unit = {\n    \/\/ pre-condition (invariants on scheduleState and dScheduleSpec)\n    assert(validState(scheduleState, dScheduleSpec))\n    assert(slotNum >= 0 & slotNum < Schedule.dScheduleSpec.schedule.slots.size)\n    \/\/ body\n    while (scheduleState.slotNum != slotNum) {\n      stepSystemOneSlotIMP(F)\n    }\n\n    CliInfoProvider.message(\"*********** Run to ... Completed *************\")\n\n    CliInfoProvider.showStateH(scheduleState)\n  }\n\n  \/\/ Runs the system to the start of the given domain\n  def runToDomain(domainId: Z): Unit = {\n    \/\/ pre-condition (invariants on scheduleState and dScheduleSpec)\n    assert(validState(scheduleState, dScheduleSpec))\n    assert(domainId >= 0 & domainId <= Schedule.dScheduleSpec.maxDomain)\n    \/\/ body\n    CliInfoProvider.message(s\"...Running to domain $domainId\")\n\n    while (Schedule.dScheduleSpec.schedule.slots(scheduleState.slotNum).domain != domainId) {\n      stepSystemOneSlotIMP(F)\n    }\n\n    CliInfoProvider.message(\"*********** Run to ... Completed *************\")\n\n    CliInfoProvider.showStateH(scheduleState)\n  }\n\n\n  \/\/ Runs the system to the start of the given domain\n  def runToThread(threadNickName: String): Unit = {\n    \/\/ pre-condition (invariants on scheduleState and dScheduleSpec)\n    assert(validState(scheduleState, dScheduleSpec))\n    val bridgeId = StaticScheduler.threadNickNames.get(threadNickName).get \/\/ ToDo: fix error handling\n    val domainId = StaticScheduler.bridgeIdToDomainMap(bridgeId)\n\n    CliInfoProvider.message(s\"...Running to thread $threadNickName (domain $domainId)\")\n    while (Schedule.dScheduleSpec.schedule.slots(scheduleState.slotNum).domain != domainId) {\n      stepSystemOneSlotIMP(F)\n    }\n    CliInfoProvider.message(\"*********** Run to ... Completed *************\")\n\n    CliInfoProvider.showStateH(scheduleState)\n  }\n\n\n  \/\/ Runs the system according to the static schedule without debugging, but still uses the debugging scheduling state\n  def runSystem(): Unit = {\n    \/\/ pre-condition (invariants on scheduleState and dScheduleSpec)\n    \/\/ assert valid schedule\n    \/\/ body\n    CliInfoProvider.message (s\"...Running system according to static schedule\")\n\n    Explorer.initializeScheduleStateIMP()\n    var systemStopCondition: B = false \/\/ right now we don't have a system stop condition\n    while (!systemStopCondition) {\n      executeSlotNumIMP(scheduleState.slotNum)\n      advanceStateIMP()\n      for (i <- 1 to 100000) {\n        None[String]()\n      }\n    }\n  }\n}\n\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/static\/ISZCommandProvider.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\npackage art.scheduling.static\n\nimport org.sireum._\n\n@record class ISZCommandProvider(commands: ISZ[Command]) extends CommandProvider {\n\n  var index: Z = 0\n\n  override def nextCommand(): Command = {\n    assert(commands.nonEmpty, \"commands must be non-empty\")\n    assert(index >= 0 && index < commands.size, s\"index must be >= 0 and < ${commands.size}\")\n\n    if (index == commands.size - 1 && !commands(index).isInstanceOf[Stop]) {\n      assert(F, \"Last command must be Stop\")\n      halt(\"Last command must be Stop\")\n    }\n    index = index + 1\n    return commands(index - 1)\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/static\/Schedule.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art.scheduling.static\n\nimport org.sireum._\nimport art.Art\nimport art.scheduling.static.Explorer.ScheduleState\n\nobject Schedule {\n\n  \/\/ const dschedule_t ksDomSchedule[] = { \/\/ (1 tick == 2ms)\n  \/\/  { .domain = 0, .length = 100 }, \/\/ all other seL4 threads, init, 200ms\n  \/\/  { .domain = 1, .length =   5 }, \/\/ pacer        10ms\n  \/\/  { .domain = 0, .length =  95 }, \/\/ domain0     190ms\n  \/\/  { .domain = 2, .length =   5 }, \/\/ source       10ms\n  \/\/  { .domain = 0, .length =  95 }, \/\/ domain0     190ms\n  \/\/  { .domain = 3, .length =   5 }, \/\/ destination  10ms\n  \/\/  { .domain = 0, .length = 195 }, \/\/ domain0     390ms\n  \/\/ };\n\n  \/\/ const word_t ksDomScheduleLength = sizeof(ksDomSchedule) \/ sizeof(dschedule_t);\n\n  @datatype class DScheduleSpec(maxDomain: Z, \/\/ the highest domain # used\n                                hyperPeriod: Z, \/\/ the hyper period in ticks\n                                schedule: DSchedule)\n\n  \/\/ contract invariants on schedule\n\n  @datatype class DSchedule(slots: ISZ[Slot])\n\n  \/\/ contract invariants on schedule\n\n  @datatype class Slot(domain: Z, length: Z)\n\n  val emptyDScheduleSpec: DScheduleSpec = DScheduleSpec(0, 0, DSchedule(ISZ()))\n\n  \/\/ ---------- schedule structure\n\n  var dScheduleSpec: DScheduleSpec = emptyDScheduleSpec\n  var domainToBridgeIdMap: ISZ[Art.BridgeId] = ISZ()\n\n  def setSchedule(spec: DScheduleSpec,\n                  domainsToBridgeMap: ISZ[Art.BridgeId]): Unit = {\n    \/\/ pre-condition -- all structural invariants for the domain schedule hold\n    validDScheduleSpec(spec)\n    \/\/ checking period for each thread requires alignment with model -- cannot check that here -- client should guarantee\n    \/\/ body\n    dScheduleSpec = spec\n    domainToBridgeIdMap = domainsToBridgeMap\n    \/\/\n    \/\/ Technically, after this point, the schedule is \"frozen\" and we should have to check the invariant properties on the\n    \/\/ schedule again.\n  }\n\n  \/\/ --------- helper method for accessing schedule info\n\n  def getBridgeIdFromSlot(slot: Slot): Art.BridgeId = {\n    return domainToBridgeIdMap(slot.domain)\n  }\n\n  def getBridgeIdFromSlotNumber(slotNum: Z): Art.BridgeId = {\n    return getBridgeIdFromSlot(dScheduleSpec.schedule.slots(slotNum))\n  }\n\n  def getBridgeIdFromScheduleState(scheduleState: ScheduleState): Art.BridgeId = {\n    return getBridgeIdFromSlotNumber(scheduleState.slotNum)\n  }\n\n  def getDomainFromSlotNum(slotNum: Z): Z = {\n    return dScheduleSpec.schedule.slots(slotNum).domain\n  }\n\n  def getDomainFromScheduleState(scheduleState: Explorer.ScheduleState): Z = {\n    return getDomainFromSlotNum(scheduleState.slotNum)\n  }\n\n  def threadNickName(bridgeId: Art.BridgeId): String = {\n    for (e <- StaticScheduler.threadNickNames.entries) {\n      if (e._2 == bridgeId) {\n        return e._1\n      }\n    }\n    return \"<not found>\"\n  }\n\n  def getThreadNickNameFromScheduleState(scheduleState: Explorer.ScheduleState): String = {\n    val bridgeId = Schedule.getBridgeIdFromSlotNumber(scheduleState.slotNum)\n    return threadNickName(bridgeId)\n  }\n\n  \/\/ ------------- contract invariants on schedule -------------\n\n  \/\/ aggregate invariant on static schedule\n  def validDScheduleSpec(dScheduleSpec: DScheduleSpec): B = {\n    return checkMaxDomain(dScheduleSpec) &&\n      checkNoMissingDomain(dScheduleSpec) &&\n      checkHyperPeriodTicks(dScheduleSpec)\n  }\n\n  \/\/ Invariant: no domain id referenced in a slot exceeds the specified max domain\n  def checkMaxDomain(dScheduleSpec: DScheduleSpec): B = {\n    \/\/ Note: transpiler doesn't current support function passing\n    \/\/return All(dScheduleSpec.schedule.slots)(s => s.domain <= dScheduleSpec.maxDomain)\n    for (s <- dScheduleSpec.schedule.slots if s.domain > dScheduleSpec.maxDomain) {\n      return F\n    }\n    return T\n  }\n\n  \/\/ Invariant: every domain 0 .. maxDomain is referenced by at least one slot\n  def checkNoMissingDomain(dScheduleSpec: DScheduleSpec): B = {\n    \/\/ NOTE: transpiler doesn't currently support function passing\n    \/\/return All(0 until dScheduleSpec.maxDomain)(d =>\n    \/\/  Exists(dScheduleSpec.schedule.slots)(s => s.domain == d)\n    \/\/)\n    for (d <- 0 until dScheduleSpec.maxDomain) {\n      var exists: B = F\n      for (s <- dScheduleSpec.schedule.slots if !exists) {\n        exists = exists || s.domain == d\n      }\n      if (!exists) {\n        return F\n      }\n    }\n    return T\n  }\n\n  \/\/ Invariant: the total time (in ticks) across all slots matches the specified hyper-period\n  def checkHyperPeriodTicks(dScheduleSpec: DScheduleSpec): B = {\n    var computedHyperPeriod: Z = 0\n    for (s <- dScheduleSpec.schedule.slots) {\n      computedHyperPeriod = computedHyperPeriod + s.length\n    }\n    return (computedHyperPeriod == dScheduleSpec.hyperPeriod)\n  }\n\n\n  \/\/ add Clock period\n\n  \/\/ This property is not an invariant per se, but rather a consistency property between the model-specified\n  \/\/ thread periods and the implied periods in the static schedule.  Thus, this property is omitted from the\n  \/\/ structural invariant on the static schedule.\n  \/\/\n  \/\/ Model-consistency: for a given domain, the period implied by the schedule (calculated period) matches\n  \/\/ the period (parameter) specified in the model\n  \/*\n   * @param domain identifier of domain to be checked\n   * @param period specified period of domain in ticks\n   * @param dScheduleSpec static schedule\n   *\/\n  def checkPeriodTicks(domain: Z, period: Z, dScheduleSpec: DScheduleSpec): B = {\n    var computedPeriod: Z = 0 \/\/ computed period in ticks\n    var computedTicksBeforeOccurrence: Z = 0\n    \/\/ number of ticks before first occurrence\n    \/\/ used to determine period, when periods \"wraps around\" the schedule\n    var occurrence: Z = 0 \/\/ how many times has domain occurred so far in schedule\n\n    for (s <- dScheduleSpec.schedule.slots) {\n      \/\/ println(occurrence, \", \", computedTicksBeforeOccurrence, \", \", computedPeriod)\n      if (s.domain == domain) { \/\/ if we are at a slot for the domain in the schedule\n        \/\/ if this is not the first occurrence, then we have computed the time (in ticks)\n        \/\/ since the last occurrence, so compare computed period to specified period\n        if (occurrence > 0) {\n          if (computedPeriod != period) {\n            return false\n          }\n        }\n        \/\/ at all occurrences (first or otherwise), increment the occurrence counter\n        occurrence = occurrence + 1\n        \/\/ re-start the accumulation of time leading to period\n        computedPeriod = s.length \/\/ \"initialize\" the computed period with length of domain's time slot\n      } else {\n        \/\/\n        if (occurrence > 0) { \/\/ if we have previously encountered the domain in the schedule\n          computedPeriod = computedPeriod + s.length \/\/ add current time slice\n        } else {\n          \/\/ if we haven't see the domain yet, add the time to the \"before occurrence\" accumulator\n          computedTicksBeforeOccurrence = computedTicksBeforeOccurrence + s.length\n        }\n      }\n    }\n    \/\/ println(occurrence, \", \", computedTicksBeforeOccurrence, \", \", computedPeriod)\n    \/\/ at this point, we have reached the end of the schedule.  We need to check for the domain\n    \/\/ as it wraps around.  Given our other invariants, we know that the domain occurs at least\n    \/\/ once.  So computedPeriod should hold the time since it was seen, whereas\n    \/\/ computedTicksBeforeOccurrence should hold the time before it was seen.\n    \/\/ The sum of these values should equal the period.\n    return (computedPeriod + computedTicksBeforeOccurrence == period)\n  }\n\n  def computeElaspedRemainingHPTicks(slotNum: Z, dScheduleSpec: DScheduleSpec): (Z, Z) = {\n    \/\/ pre-condition\n    \/\/  TODO: well-formed dScheduleSpec\n    \/\/  TODO: valid slotNum (define function for below)\n    assert(0 <= slotNum & slotNum < dScheduleSpec.schedule.slots.size)\n    \/\/ body\n    var elaspedHPTicks: Z = 0\n    for (s <- 0 until slotNum) {\n      elaspedHPTicks = elaspedHPTicks + dScheduleSpec.schedule.slots(0).length\n    }\n    val remainingHPTicks: Z = dScheduleSpec.hyperPeriod - elaspedHPTicks\n    return (elaspedHPTicks, remainingHPTicks)\n  }\n}\n\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/static\/StateObserver.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art.scheduling.static\n\nimport org.sireum._\nimport art.{Art, DataContent}\n\nobject StateObserver {\n\n  def observeInPortValue(bridgeId: Art.BridgeId, portId: Art.PortId): Option[DataContent] = {\n    return Art.observeInInfrastructurePort(portId)\n  }\n\n  def observeOutPortValue(bridgeId: Art.BridgeId, portId: Art.PortId): Option[DataContent] = {\n    return Art.observeOutPortVariable(portId)\n  }\n\n  def observeInPortValues(bridgeId: Art.BridgeId): ISZ[(String, Option[DataContent])] = {\n    val bridge = Art.bridges(bridgeId.toZ).get\n    var portValues: ISZ[(String, Option[DataContent])] = ISZ()\n\n    for (port <- bridge.ports.dataIns) {\n      portValues = portValues :+ ((port.name, Art.observeInInfrastructurePort(port.id)))\n    }\n\n    for (port <- bridge.ports.eventIns) {\n      portValues = portValues :+ ((port.name, Art.observeInInfrastructurePort(port.id)))\n    }\n    return portValues\n  }\n\n  def observeOutPortValues(bridgeId: Art.BridgeId): ISZ[(String, Option[DataContent])] = {\n    val bridge = Art.bridges(bridgeId.toZ).get\n    var portValues: ISZ[(String, Option[DataContent])] = ISZ()\n\n    for (port <- bridge.ports.dataOuts) {\n      portValues = portValues :+ ((port.name, Art.observeOutPortVariable(port.id)))\n    }\n\n    for (port <- bridge.ports.eventOuts) {\n      portValues = portValues :+ ((port.name, Art.observeOutPortVariable(port.id)))\n    }\n    return portValues\n  }\n\n  def observeInPortValuesByNickName(threadNickName: String): ISZ[(String, Option[DataContent])] = {\n    halt(\"TODO\")\n    \/\/val bridgeId = art.StaticScheduling.threadNickNames.get(threadNickName).get \/\/ ToDo: fix error handling\n    \/\/return observeInPortValues(bridgeId)\n  }\n\n  def observeOutPortValuesByNickName(threadNickName: String): ISZ[(String, Option[DataContent])] = {\n    halt(\"TODO\")\n    \/\/val bridgeId = art.StaticScheduling.threadNickNames.get(threadNickName).get \/\/ ToDo: fix error handling\n    \/\/return observeOutPortValues(bridgeId)\n  }\n\n  \/\/=======================================================================\n  \/\/ State Observations (primary methods for interpreting debug commands)\n  \/\/=======================================================================\n\n  def printPortContentsInputsCurrent(): Unit = {\n    val bridgeId = Schedule.getBridgeIdFromSlotNumber(Explorer.scheduleState.slotNum)\n    val inPortInfo = observeInPortValues(bridgeId)\n\n    println(\"****************************\")\n    println(s\"   Next Component: ${Schedule.threadNickName(bridgeId)} (id = $bridgeId)\")\n    println(\"****************************\")\n    println(\" Input Ports\")\n    println(\" ===============\")\n    printPortInfo(inPortInfo)\n  }\n\n  def printPortContentsOutputsCurrent(): Unit = {\n    val previousStateOpt: Option[Explorer.ScheduleState] =\n      Explorer.previousState(Explorer.scheduleState, Schedule.dScheduleSpec)\n\n    previousStateOpt match {\n      case Some(previousState) => {\n        val bridgeId = Schedule.getBridgeIdFromSlotNumber(previousState.slotNum)\n        val outPortInfo = observeOutPortValues(bridgeId)\n        println(\"****************************\")\n        println(s\"   Previous Component: ${Schedule.threadNickName(bridgeId)} (id = $bridgeId)\")\n        println(\"****************************\")\n        println(\" Output Ports\")\n        println(\" ===============\")\n        printPortInfo(outPortInfo)\n      }\n      case None() => {\n        println(\"(initial state - no previous state to show)\")\n      }\n    }\n  }\n\n  def printPortInfo(portVals: ISZ[(String, Option[DataContent])]): Unit = {\n    for (e <- portVals) {\n      println(s\"${e._1} = ${e._2}\")\n    }\n  }\n\n  def printPortContents(bridgeId: Art.BridgeId): Unit = {\n    val inPortInfo = observeInPortValues(bridgeId)\n    val outPortInfo = observeOutPortValues(bridgeId)\n    println(\"****************************\")\n    println(s\"   Component: ${Schedule.threadNickName(bridgeId)} (id = $bridgeId)\")\n    println(\"****************************\")\n    println(\" Input Ports\")\n    println(\" ===============\")\n    printPortInfo(inPortInfo)\n    println()\n    println(\" Output Ports\")\n    println(\" ================\")\n    printPortInfo(outPortInfo)\n  }\n\n  def printPortContentsByNickName(threadNickName: String): Unit = {\n    val bridgeId = StaticScheduler.threadNickNames.get(threadNickName).get \/\/ ToDo: fix error handling\n    printPortContents(bridgeId)\n  }\n}",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/static\/StaticScheduler.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\npackage art.scheduling.static\n\nimport org.sireum._\nimport art.Art\nimport art.scheduling.Scheduler\nimport art.scheduling.static.Schedule.DScheduleSpec\n\nobject StaticScheduler {\n  var threadNickNames: Map[String, Art.BridgeId] = Map.empty\n  var domainToBridgeIdMap: ISZ[Art.BridgeId] = ISZ()\n\n  def bridgeIdToDomainMap(bridgeId: Art.BridgeId): Z = {\n    for (i <- 0 until domainToBridgeIdMap.size if bridgeId == domainToBridgeIdMap(i)) {\n      return i\n    }\n    assert(F, s\"domain for $bridgeId not found\")\n    halt(s\"domain for $bridgeId not found\")\n  }\n}\n\n@record class StaticScheduler(staticSchedule: DScheduleSpec,\n                              bridges: IS[Art.BridgeId, art.Bridge],\n                              domainToBridgeIdMap: ISZ[Art.BridgeId],\n                              threadNickNames: Map[String, Art.BridgeId],\n                              commandProvider: CommandProvider) extends Scheduler {\n\n  override def initialize(): Unit = {\n    StaticScheduler.threadNickNames = threadNickNames\n    StaticScheduler.domainToBridgeIdMap = domainToBridgeIdMap\n\n    Schedule.setSchedule(staticSchedule, domainToBridgeIdMap)\n\n    Explorer.initializeScheduleStateIMP()\n  }\n\n  override def initializationPhase(): Unit = {\n    for (bridgeId <- domainToBridgeIdMap) {\n      bridges(bridgeId).entryPoints.initialise()\n      art.Art.logInfo(bridgeId, s\"Initialized bridge: ${bridges(bridgeId).name}\")\n    }\n  }\n\n  override def computePhase(): Unit = {\n    var done: B = F\n    while (!done) {\n      done = CommandInterpreter.interpretCmd(commandProvider.nextCommand())\n    }\n  }\n\n  override def finalizePhase(): Unit = {\n    for (bridgeId <- domainToBridgeIdMap) {\n      bridges(bridgeId).entryPoints.finalise()\n      art.Art.logInfo(bridgeId, s\"Finalized bridge: ${bridges(bridgeId).name}\")\n    }\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/static\/StaticSchedulerIO.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage art.scheduling.static\n\nimport org.sireum._\n\n@ext object StaticSchedulerIO {\n  def getCommand(prompt: String): String = $\n\n  def message(m: String): Unit = $\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/art\/art\/scheduling\/static\/StaticSchedulerIO_Ext.scala",
        {
          "type" : "ITestResource",
          "content" : "package art.scheduling.static\n\nimport org.sireum._\n\nimport scala.io.StdIn.readLine\n\nobject StaticSchedulerIO_Ext {\n  var logStream: java.io.PrintStream = System.out\n\n  def getCommand(prompt: String): String = {\n    print(prompt)\n    val command = readLine()\n    return command\n  }\n\n  def message(m: String): Unit = {\n    logStream.println(m)\n    logStream.flush()\n  }\n}\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : false
        }
      ],
      [
        "slang\/src\/main\/data\/bit_codec\/Aux_Types.scala",
        {
          "type" : "ITestResource",
          "content" : "\/\/ #Sireum\n\npackage bit_codec\n\nimport org.sireum._\n\n\/\/ This file will not be overwritten so is safe to edit\n\n\/\/ Any datatype definitions placed in this file will be processed by sergen and SlangCheck\n",
          "markers" : [
          ],
          "overwrite" : false,
          "makeExecutable" : false,
          "makeCRLF" : false,
          "isDatatype" : true
        }
      ],
      [
        "slang\/bin\/sergen.cmd",
        {
          "type" : "ITestResource",
          "content" : "::\/*#! 2> \/dev\/null                                   #\r\n@ 2>\/dev\/null # 2>nul & echo off & goto BOF           #\r\nif [ -z ${SIREUM_HOME} ]; then                        #\r\n  echo \"Please set SIREUM_HOME env var\"               #\r\n  exit -1                                             #\r\nfi                                                    #\r\nexec ${SIREUM_HOME}\/bin\/sireum slang run \"$0\" \"$@\"    #\r\n:BOF\r\nsetlocal\r\nif not defined SIREUM_HOME (\r\n  echo Please set SIREUM_HOME env var\r\n  exit \/B -1\r\n)\r\n%SIREUM_HOME%\\\\bin\\\\sireum.bat slang run \"%0\" %*\r\nexit \/B %errorlevel%\r\n::!#*\/\r\n\/\/ #Sireum\r\n\r\nimport org.sireum._\r\n\r\nval sireum = Os.path(Os.env(\"SIREUM_HOME\").get) \/ \"bin\" \/ (if (Os.isWin) \"sireum.bat\" else \"sireum\")\r\n\r\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\r\n\r\n\/\/ create serializers\/deserializers for the Slang types used in the project\r\n\r\nval files: ISZ[String] = ISZ(\"..\/src\/main\/data\/bit_codec\/Base_Types.scala\",\r\n                             \"..\/src\/main\/art\/art\/DataContent.scala\",\r\n                             \"..\/src\/main\/data\/bit_codec\/Aux_Types.scala\")\r\n\r\nval toolargs: String = st\"${(files, \" \")}\".render\r\n\r\n(Os.slashDir.up \/ \"src\" \/ \"main\" \/ \"util\" \/ \"bit_codec\").mkdirAll()\r\n\r\nproc\"$sireum tools sergen -p bit_codec -m json,msgpack -o ${Os.slashDir.up}\/src\/main\/util\/bit_codec $toolargs\".at(Os.slashDir).console.runCheck()\r\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : true,
          "makeCRLF" : true,
          "isDatatype" : false
        }
      ],
      [
        "slang\/bin\/slangcheck.cmd",
        {
          "type" : "ITestResource",
          "content" : "::\/*#! 2> \/dev\/null                                   #\r\n@ 2>\/dev\/null # 2>nul & echo off & goto BOF           #\r\nif [ -z ${SIREUM_HOME} ]; then                        #\r\n  echo \"Please set SIREUM_HOME env var\"               #\r\n  exit -1                                             #\r\nfi                                                    #\r\nexec ${SIREUM_HOME}\/bin\/sireum slang run \"$0\" \"$@\"    #\r\n:BOF\r\nsetlocal\r\nif not defined SIREUM_HOME (\r\n  echo Please set SIREUM_HOME env var\r\n  exit \/B -1\r\n)\r\n%SIREUM_HOME%\\\\bin\\\\sireum.bat slang run \"%0\" %*\r\nexit \/B %errorlevel%\r\n::!#*\/\r\n\/\/ #Sireum\r\n\r\nimport org.sireum._\r\n\r\nval sireum = Os.path(Os.env(\"SIREUM_HOME\").get) \/ \"bin\" \/ (if (Os.isWin) \"sireum.bat\" else \"sireum\")\r\n\r\n\/\/ Do not edit this file as it will be overwritten if HAMR codegen is rerun\r\n\r\n\/\/ create SlangCheck artifacts for the Slang types used in the project\r\n\r\nval files: ISZ[String] = ISZ(\"..\/src\/main\/data\/bit_codec\/Base_Types.scala\",\r\n                             \"..\/src\/main\/art\/art\/DataContent.scala\",\r\n                             \"..\/src\/main\/data\/bit_codec\/Aux_Types.scala\")\r\n\r\nval toolargs: String = st\"${(files, \" \")}\".render\r\n\r\n(Os.slashDir.up \/ \"src\" \/ \"main\" \/ \"util\" \/ \"bit_codec\").mkdirAll()\r\n\r\nproc\"$sireum proyek slangcheck -p bit_codec -o ${Os.slashDir.up}\/src\/main\/util\/bit_codec ${Os.slashDir.up} $toolargs\".at(Os.slashDir).console.runCheck()\r\n\r\n\/\/ call to the tools version of SlangCheck which does not invoke Tipe\r\n\/\/proc\"$sireum tools slangcheck generator -p bit_codec -o ${Os.slashDir.up}\/src\/main\/util\/bit_codec $toolargs\".at(Os.slashDir).console.runCheck()\r\n",
          "markers" : [
          ],
          "overwrite" : true,
          "makeExecutable" : true,
          "makeCRLF" : true,
          "isDatatype" : false
        }
      ]
    ]
  }
}